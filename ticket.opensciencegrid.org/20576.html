<!DOCTYPE html>
<html lang="en">
  <head>
  <base href="">
    <title>[20576] Gluex jobs failing to complete at rcac.purdue</title>    <meta charset="utf-8" />
    <meta name="verify-v1" content="na5IcAJsZVOfEkboRxuIiZ1zpZgnZiWra+nKcS7nA/o=" />
    <meta name="google-site-verification" content="DLrk3ft4s8b-S2TloLCL2LD_t6wcTjgSluf5pmiu2kA" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="" />
    <link href="https://ticket.opensciencegrid.org/rss" rel="alternate" type="application/rss+xml" title="GOC Ticket Update feed" />

    <style type="text/css">
      body {
        padding-top: 50px;
        padding-bottom: 40px;
      }
      .sidebar-nav {
        padding: 9px 0;
      }
     #search {
            width: 300px;
     }

    </style>

<script src="https://code.jquery.com/jquery-3.0.0.js"></script>
<script src="https://code.jquery.com/jquery-migrate-3.0.1.js"></script>

   <link href="https://netdna.bootstrapcdn.com/bootstrap/2.3.2/css/bootstrap.min.css" rel="stylesheet"/>
    <script src="https://netdna.bootstrapcdn.com/bootstrap/2.3.2/js/bootstrap.min.js"></script>

    <link href="https://netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet"/>
    <link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/themes/smoothness/jquery-ui.min.css" rel="stylesheet"/>
 <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>


    <link href="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.0-rc.2/css/select2.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.0-rc.2/js/select2.min.js"></script>

    <link href="css/ticket.css" rel="stylesheet" />
    <script src="lib/jquery.cookie.js"></script>

    <link href="images/tag_orange.png" rel="icon" type="image/png"/>
  </head>

  <body>
    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container-fluid">
            <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </a>

            <a class="brand" style="padding: 6px 0px 0px 6px;" href="http://opensciencegrid.org"><img src="images/osglogo.40x30.png"/></a>
            <ul class="nav">
                <li class="dropdown"><a href="https://ticket.opensciencegrid.org/#" class="dropdown-toggle" data-toggle="dropdown">GOC Ticket <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    <li><a href="https://my.opensciencegrid.org">MyOSG</a></li>
                    <li><a href="https://oim.opensciencegrid.org">OIM</a></li>
                    <li class="active"><a href="https://ticket.opensciencegrid.org/index">Ticket</a></li>
	<li class="divider"></li>
	<li><a href="http://repo.grid.iu.edu">Repo</a></li>
	<li class="divider"></li>
	<li><a href="http://blogs.grid.iu.edu">Blog</a></li>
                    <li><a href="http://display.grid.iu.edu">Display</a></li>
                    <li><a href="http://osggoc.blogspot.com/">News</a></li>
                    </ul>
                </li>
            </ul>
            <ul class="nav pull-right">
                <li><a href="https://ticket.opensciencegrid.org/sso/">Login</a></li>            </ul>

            <div class="nav-collapse">
                <ul class="nav">
			 <li id="menu_submit"><a href="https://ticket.opensciencegrid.org/submit">Submit</a></li><li id="menu_view" class="dropdown"><a href="https://ticket.opensciencegrid.org/\#" class="dropdown-toggle" data-toggle="dropdown">View <b class="caret"></b></a><ul class="dropdown-menu"><li id="submenu_listopen"><a href="https://ticket.opensciencegrid.org/list/open">Open Tickets</a></li><li id="submenu_listrecentclose"><a href="https://ticket.opensciencegrid.org/list/recentclose">Recently Closed Tickets</a></li><li class="divider"></li><li id="submenu_alltickets"><a href="https://ticket.opensciencegrid.org/search?q=&amp;sort=id">All Tickets</a></li></ul></li>                </ul>

                <form class="navbar-search pull-right" action="https://ticket.opensciencegrid.org/viewer">
                    <input id="search" type="text" name="id" class="search-query span2" placeholder="Search Ticket" value=""/>
                </form>
            </div>
        </div>
      </div>
    </div>

<script type='text/javascript' src='lib/jquery.timeago.js'></script>
<script type='text/javascript' src='lib/byte2size.js'></script>
<style>
#updates .toolbar {
position: relative;
margin-top: 0px;
top: -10px;
font-weight: normal;
}
#updates a.anchor {
position: relative;
top: -50px;
}
#updates .selected pre {
animation:selected 2s;
animation-iteration-count: 2;
animation-direction: alternate;
-webkit-animation:selected 2s; 
-webkit-animation-iteration-count: 2;
-webkit-animation-direction: alternate;
box-shadow: inset 1px 1px 20px #9ad;
border: 1px solid #9ab;
margin: 5px 0px;
padding-left: 10px;
}
@keyframes selected {
    from  {
        box-shadow: inset 1px 1px 20px #9ad;
        border: 1px solid #9ab;
    }
    to {
        box-shadow: inset 1px 1px 20px #05c;
        border: 1px solid #05c;
    }
}
@-webkit-keyframes selected {
    from  {
        box-shadow: inset 1px 1px 20px #9ad;
        border: 1px solid #9ad;
    }
    to {
        box-shadow: inset 1px 1px 20px #05c;
        border: 1px solid #05c;
    }
}
#updates pre {
background-color: inherit;
line-height: 15px;
padding: 5px;
}
#updates .header {
color: #999;
}
#updates .update_history pre {
background-color: #eee;
color: #666;
font-size: 85%;
}
#updates .clickable {
cursor: pointer;
}
#updates .clickable:hover {
color: #D98719;
}
#updates .meta_information pre {
background-color: #fed;
}
#similar_tickets {
max-height: 300px;
overflow-y: auto;
pointer-events: none;
padding: 5px;
background-color: #f4f4f4;
}
.btn-toolbar {
margin-bottom: 0;
height: 30px;
}
#peers {
position: fixed;
bottom: 0px;
right: 0px;
z-index: 100;
list-style: none;
padding: 5px 0px 0px 5px;
margin: 0px;
background-color: white;
box-shadow: 0px 0px 10px white;
}
#peers li {
background-color: #ccc;
color: #000;
display: inline-block;
padding: 5px 10px;
margin-right: 5px;
position: relative;
}
/*
#peers li:hover {
background-color: #999;
cursor: pointer;
}
*/
#peers span.ip {
padding-left: 5px;
color: #666;
}
#peers .new {
bottom: -30px;
}
/*
#peers .me {
background-color: red;
}
*/
</style>

<div class="container-fluid">
<ul id="peers"></ul>
<div class="alert alert-danger"><a class="close" href="https://ticket.opensciencegrid.org/#" data-dismiss="alert">&times;</a>By the end of May 2018, the ticketing system at https://ticket.opensciencegrid.org will be retired and support will be provided at https://support.opensciencegrid.org. Throughout this transition the support email (help@opensciencegrid.org) will be available as a point of contact.<br><br>                                                   
                                                                                                                                                                                   
Please see the service migration page for details: https://opensciencegrid.github.io/technology/policy/service-migrations-spring-2018/#ticket</div><div id="presence" class="pull-right"></div><div class="ticketgui"><script type="text/javascript" src="lib/checktab.js"></script>

<script>
var expanded = false;
function expand_description() {
    var desc = $(".description");
    if(!expanded) {
        expanded = true;
        //expand to minheight
        var min = 250;
        if(desc.height() < min) {
            desc.animate({height: min}, 200);
        }
    }
}

$(document).ready(function() {
    $("input[name='nad']").datepicker({
        dateFormat: 'yy-mm-dd'
    });
});

</script>



<style>
.form-horizontal .control-label {
padding-top: inherit;
font-size:90%;
color:#666;
}
label {
margin-bottom: 0px;
}
.controls {
line-height: 18px;
}
</style>
<form class="form-horizontal" action="https://ticket.opensciencegrid.org/viewer/updatebasic?id=20576" method="post">
<div class="page-header">
    <h3><span class="muted">20576</span> / Gluex jobs failing to complete at rcac.purdue</h3>
</div>

<div class="row-fluid">
<div class="span5">
    <legend>Contact</legend>
    <div class="control-group">
        <label class="control-label">Full Name</label>
        <div class="controls">Richard T. Jones</div>
    </div>
    <div class="control-group">
        <label class="control-label">Email</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>
    <div class="control-group">
        <label class="control-label">Phone</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>
    <div class="control-group">
        <label class="control-label">CC</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>

    <legend>Details</legend>
    <div class="control-group"><label class="control-label">Resource Name</label><div class="controls">Purdue-Hansen</div></div><div class="control-group"><label class="control-label">Associated VO</label><div class="controls">CMS</div></div><div class="control-group"><label class="control-label">Submitted Via</label><div class="controls">GOC Ticket/submit</div></div><div class="control-group"><label class="control-label">Submitter</label><div class="controls">Richard T. Jones</div></div><div class="control-group"><label class="control-label">Support Center</label><div class="controls">USCMS_Tier2</div></div>
    <div class="control-group">
        <label class="control-label">Ticket Type</label>
        <div class="controls">Problem/Request</div>
    </div>
    <div class="control-group">
        <label class="control-label">Priority</label>
        <div class="controls">Normal</div>
    </div>
    <div class="control-group">
        <label class="control-label">Status</label>
        <div class="controls">
Closed</div>
    </div>
    <div class="control-group">
        <label class="control-label">Next Action</label>
        <div class="controls">Ping Richard</div>
    </div>
    <div class="control-group">
        <label class="control-label">Next Action Deadline</label>
        <div class="controls flag_red">2014-06-25</div>
    </div>

</div><!--span-->
<div class="span7">
    <legend>Assignees</legend>
    <div class="assignee" style="width: 60%">USCMS Tier 2 <span class="muted"> / OSG Support Centers</span></div>    <br>

    <legend>Assignees</legend>
    TODO
    <br>

    <style>
legend.noborder {
border-bottom: none;
}
</style>

<div id="attachment-list"/>
<script>
$(function () {
    var first = true;
    $.getJSON("attachment/list/20576", function (files) {
        //console.dir(files);
        var html = "<table class=\"table table-condensed\">";
        $(files).each(function() {
            if(first) {
                first = false;
                html += "<legend class=\"noborder\">Attachmenets</legend>";
            }
            html += "<tr class=\"attachment\">";
            html += "<td><img src=\""+this.thumbnail_url+"\"/></td>";
            html += "<td><a href=\""+this.url+"\" target=\"_blank\">"+this.name+"</a></td>";
            html += "<td>"+bytesToSize(this.size, 1)+"</td>";
            html += "</tr>";
        });
        html += "</table>";
        $("#attachment-list").html(html);
    });
});

function download(url) {
    window.open(url, "_blank");
}
</script>


</div><!--span-->
</div><!--row-fluid-->


</form>

</div>
<div id="updates" style="clear: both;">
    <legend>Past Updates
    <div class="btn-toolbar pull-right toolbar">
        <div class="btn-group">
                <a class="btn btn-small" href="https://ticket.opensciencegrid.org/20576?sort=up&amp;"><i class="icon-arrow-up"></i> Sort</a>

        
        <a class="btn btn-small" href="https://ticket.opensciencegrid.org/20576?expandall=true&amp;">Expand Descriptions</a>        <a class="btn btn-small" target="_blank" href="mailto:osg@tick.globalnoc.iu.edu?subject=Open%20Science%20Grid%3A%20Gluex%20jobs%20failing%20to%20complete%20at%20rcac.purdue%20ISSUE%3D20576%20PROJ%3D71"><i class="icon-envelope"></i> Update w/Email</a>
        </div>
    </div><!--btn-toolbar-->
    </legend>

    <div class='update_description'><i onclick="document.location='20576#1403716654'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-25T17:17:34+00:00">Jun 25, 2014 05:17 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1403716654">&nbsp;</a></div><pre>Closing this ticket as requested.

~Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1403545883'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-23T17:51:23+00:00">Jun 23, 2014 05:51 PM UTC</time> by <b>boj@....</b><a class="anchor" name="1403545883">&nbsp;</a></div><pre>I am away from the lab and will have limited email access until June 28, 2014.</pre></div><div class='update_description'><i onclick="document.location='20576#1403545731'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-23T17:48:51+00:00">Jun 23, 2014 05:48 PM UTC</time><a class="anchor" name="1403545731">&nbsp;</a></div><pre>Let us close this ticket.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1403123547'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-18T20:32:27+00:00">Jun 18, 2014 08:32 PM UTC</time> by <b>Vince Neal</b><a class="anchor" name="1403123547">&nbsp;</a></div><pre>Richard,

Have you had an opportunity to review the information that Majid provided?
If I can assist please let me know.

Thank you,
Vince</pre></div><div class='update_description'><i onclick="document.location='20576#1402690260'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-13T20:11:00+00:00">Jun 13, 2014 08:11 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1402690260">&nbsp;</a></div><pre>Hello Richard,

Did the information that Majid supplied answer your question or are you still in need of investigation?

Thanks,
Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1401990660'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-05T17:51:00+00:00">Jun 5, 2014 05:51 PM UTC</time><a class="anchor" name="1401990660">&nbsp;</a></div><pre>Hi Richard,

Despite network dispute, I should  mention that (  as you have already mentioned and   are suspicious that your jobs get killed or preempted by another application or another user)
I talked to people who designed condor opportunistic policy here at Purdue since 2006 and here is the policy&#58;
the worker nodes on hansen, coates and rossmann clusters are worker nodes for two scheduler&#58; PBS and Condor
the PBS has the highest priority and condor is lowest priority ( pure opportunistic Policy ) such that if the node receives a pbs job it preempts and vacates condor job (in your case the condor job  would be killed).
I also was told  that the optimized wall time would be around 45 minutes for condor jobs, Therefore  if your jobs take more than 45 mins have the highest probability to be killed.
If this situation does not explain yet your case then we need to dig more.

Regards,
-Majid

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=marabgol/CN=653155/CN=Majid Arabgol</pre></div><div class='update_description'><i onclick="document.location='20576#1401883268'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-04T12:01:08+00:00">Jun 4, 2014 12:01 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401883268">&nbsp;</a></div><pre>Manoj,

Can you explain what jumbo UDP packets have to do with our jobs running on
your site?  There are no errors related to UDP connectivity, and no
reliance on UDP by any of our workflow, as far as I know.

-Richard J.

On Tue, Jun 3, 2014 at 6&#58;22 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401834159'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T22:22:39+00:00">Jun 3, 2014 10:22 PM UTC</time><a class="anchor" name="1401834159">&nbsp;</a></div><pre>Our site people  have opinion that router at UConn end may have configuration problem.  If there is other problem, then let us know.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1401833529'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T22:12:09+00:00">Jun 3, 2014 10:12 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401833529">&nbsp;</a></div><pre>Hello Manoj,

I do not understand the relevance of exchanging jumbo udp packets between
UConn and Purdue to this ticket.  My hope with this ticket was to
understand and resolve the issues that are preventing our jobs from running
efficiently at Purdue.  Can we focus the discussion on that?  I have
provided a substantial amount of detailed information related to this
matter in previous messages, and can provide more if requested.

-Richard Jones

On Tue, Jun 3, 2014 at 4&#58;54 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401828885'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T20:54:45+00:00">Jun 3, 2014 08:54 PM UTC</time><a class="anchor" name="1401828885">&nbsp;</a></div><pre>Hi Richard,
Jobs from CMS contact factory at &#34;submit-3.t2.ucsd.edu&#34;.    The command &#34;traceroute&#34;  works in this case for packet size greater than 1500 bytes.

&#34;&#34;&#34;
[jha2@hansen-a045 ~]$ traceroute submit-3.t2.ucsd.edu 1501
traceroute to submit-3.t2.ucsd.edu (169.228.130.27), 30 hops max, 1501 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.338 ms  1.496 ms  2.733 ms
2  math-g190-c6509e-02-t3-4.tcom.purdue.edu (172.17.0.73)  0.662 ms math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.416 ms math-g190-c6509e-02-t4-4.tcom.purdue.edu (172.17.0.81)  0.751 ms
3  math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  0.721 ms  0.743 ms math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  0.798 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.792 ms  0.842 ms  0.891 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.199 ms * *
6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.809 ms  1.956 ms  1.796 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  10.380 ms  10.363 ms  10.615 ms
8  et-10-0-0.106.rtr.kans.net.internet2.edu (198.71.45.15)  17.568 ms  17.549 ms  17.906 ms
9  et-1-0-0.109.rtr.hous.net.internet2.edu (198.71.45.16)  32.548 ms  32.344 ms  32.514 ms
10  hpr-lax-hpr2--i2-houston.cenic.net (137.164.26.204)  68.208 ms  67.956 ms  67.928 ms
11  hpr-ucsd-10ge-2--lax-hpr.cenic.net (137.164.26.30)  67.754 ms  66.987 ms  67.593 ms
12  nodem-core--mx0-30ge.ucsd.edu (132.239.254.163)  67.678 ms  67.530 ms  66.986 ms
13  hep720--node-m720-p2p.ucsd.edu (137.110.255.209)  67.096 ms  67.102 ms  67.260 ms
14  submit-3.t2.ucsd.edu (169.228.130.27)  67.256 ms !X  67.274 ms !X  67.048 ms !X
[jha2@hansen-a045 ~]$

&#34;&#34;&#34;
Worker nodes configuration are optimized according to CMS use case.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1401827950'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T20:39:10+00:00">Jun 3, 2014 08:39 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401827950">&nbsp;</a></div><pre>Hello,

Can you explain, why are you testing UDP connectivity?  Don&#39;t you want to
test tcp connectivity?  Please use the option -T, and chose an active port,
eg. adding option &#34;-p 22&#34; to your traceroute command.

-Richard Jones

On Tue, Jun 3, 2014 at 9&#58;37 AM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401802649'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T13:37:29+00:00">Jun 3, 2014 01:37 PM UTC</time><a class="anchor" name="1401802649">&nbsp;</a></div><pre>The command &#39;traceroute&#39;    to  &#39;gremlin.phys.uconn.edu &#39;  with packet size greater than 1500 bytes are still failing from one of the worker nodes  of our clusters.

&#34;&#34;&#34;
[jha2@hansen-a045 ~]$  traceroute  gremlin.phys.uconn.edu 1501
traceroute to gremlin.phys.uconn.edu (137.99.19.34), 30 hops max, 1501 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.270 ms  1.463 ms  2.702 ms
2  math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.641 ms math-g190-c6509e-03-t3-4.tcom.purdue.edu (172.17.0.77)  0.730 ms math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.797 ms
3  math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  1.178 ms math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  1.213 ms math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  1.226 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.775 ms  0.828 ms  0.871 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.197 ms * *
6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.817 ms  1.813 ms  1.921 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  6.913 ms  6.500 ms  6.781 ms
8  et-10-0-0.107.rtr.clev.net.internet2.edu (198.71.45.9)  15.994 ms  16.263 ms  15.975 ms
9  nox1sumgw1-vl-112-nox-i2.net.harvard.edu (192.5.89.17)  29.523 ms  29.572 ms  29.569 ms
10  192.5.89.21 (192.5.89.21)  29.577 ms  29.559 ms  29.765 ms
11  192.5.89.186 (192.5.89.186)  29.474 ms  29.382 ms  29.525 ms
12  enrt078c-9k-bundle-ether-30.net.cen.ct.gov (207.210.141.137)  32.991 ms  33.007 ms  33.003 ms
13  enrt078h-9k-bundle-ether-10.net.cen.ct.gov (67.218.83.10)  34.522 ms  34.529 ms  34.463 ms
14  bdr-078c-hbl.net.uconn.edu (137.99.255.153)  32.707 ms  32.754 ms  32.750 ms
15  * * *
16  * * *
17  * * *
18  * * *
19  * * *
20  * * *
21  * * *
22  * * *
23  * * *
24  * * *
25  * * *
26  * * *
27  * * *
28  * * *
29  * * *
30  * * *
<div id='show_93023781' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_93023781'>[jha2@hansen-a045 ~]$

&#34;&#34;&#34;
It seems to me  user jobs failed while sending packet size greater than 1.5K  bytes.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha
</div><script type='text/javascript'>
        $('#show_93023781').click(function() {
            $('#detail_93023781').slideDown("normal");
            $('#show_93023781').hide();
            $('#hide_93023781').show();
        });
        $('#hide_93023781').click(function() {
            $('#detail_93023781').slideUp();
            $('#hide_93023781').hide();
            $('#show_93023781').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1401772870'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-03T05:21:10+00:00">Jun 3, 2014 05:21 AM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401772870">&nbsp;</a></div><pre>Hello Chris,

I have posted detailed diagnostic information in my last extended message,
and await further updates from the site managers on how to proceed.
Network connectivity issues have been eliminated, problem remains
unresolved.

-Richard J.

On Mon, Jun 2, 2014 at 1&#58;31 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401730298'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-06-02T17:31:38+00:00">Jun 2, 2014 05:31 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1401730298">&nbsp;</a></div><pre>Hello All,

Is there any new information on what might be causing the issues at the site? Please let me know if there is anything I can help with.

Thanks,
Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1401187511'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-27T10:45:11+00:00">May 27, 2014 10:45 AM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401187511">&nbsp;</a></div><pre>Hello Manoj, Majid,

That traceroute report looks normal.  I don&#39;t think the network is what is
causing the problems I am seeing. Are there any remaining concerns about
the network connectivity between our two sites?

-Richard J.

On Mon, May 26, 2014 at 11&#58;56 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401162971'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-27T03:56:11+00:00">May 27, 2014 03:56 AM UTC</time><a class="anchor" name="1401162971">&nbsp;</a></div><pre>HI Richard,

This is the output&#58;
-------------------------------------
marabgol@hansen-a045&#58;~ &#62; sudo traceroute -p 22 -T gremlin.phys.uconn.edu 1501
traceroute to gremlin.phys.uconn.edu (137.99.19.34), 30 hops max, 52 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.286 ms  0.363 ms  0.460 ms
2  math-g190-c6509e-02-t4-4.tcom.purdue.edu (172.17.0.81)  0.339 ms  0.423 ms math-g190-c6509e-02-t3-4.tcom.purdue.edu (172.17.0.73)  0.506 ms
3  math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  0.728 ms math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  0.825 ms  0.839 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.726 ms  0.770 ms  0.814 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.181 ms * *
6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.667 ms  1.649 ms  1.655 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  7.393 ms  7.517 ms  7.507 ms
8  et-10-0-0.107.rtr.clev.net.internet2.edu (198.71.45.9)  15.670 ms  15.969 ms  15.809 ms
9  nox1sumgw1-vl-112-nox-i2.net.harvard.edu (192.5.89.17)  29.361 ms  29.552 ms  29.197 ms
10  192.5.89.21 (192.5.89.21)  29.471 ms  29.053 ms  29.202 ms
11  192.5.89.186 (192.5.89.186)  28.851 ms  28.741 ms  28.563 ms
12  enrt078c-9k-bundle-ether-30.net.cen.ct.gov (207.210.141.137)  34.636 ms  34.599 ms  34.382 ms
13  enrt078h-9k-bundle-ether-10.net.cen.ct.gov (67.218.83.10)  32.608 ms  32.508 ms  32.108 ms
14  bdr-078c-hbl.net.uconn.edu (137.99.255.153)  31.940 ms  31.945 ms  31.624 ms
15  vrf-border-outside-t-1-4-13.net.uconn.edu (137.99.255.154)  33.498 ms  33.518 ms  34.012 ms
16  fw-msb-i-1-ch24.676.net.uconn.edu (137.99.255.177)  33.858 ms  33.524 ms  33.870 ms
17  * * *
18  gremlin.phys.uconn.edu (137.99.19.34)  32.067 ms  32.368 ms  32.685 ms

--------------------------------------

Regards,
-Majid

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=marabgol/CN=653155/CN=Majid Arabgol</pre></div><div class='update_description'><i onclick="document.location='20576#1401147010'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-26T23:30:10+00:00">May 26, 2014 11:30 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401147010">&nbsp;</a></div><pre>Hello Manoj,

Can you print the output from the following command, from one of the
problematic nodes?

sudo traceroute -p 22 -T gremlin.phys.uconn.edu 1501

thank you,
-Richard Jones

On Mon, May 26, 2014 at 6&#58;44 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401144233'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-26T22:43:53+00:00">May 26, 2014 10:43 PM UTC</time><a class="anchor" name="1401144233">&nbsp;</a></div><pre>The traceroute  command fails also without &#34;F&#34;  option.  Please see below.

&#34;&#34;&#34;

[jha2@hansen-a034 ~]$ traceroute  gremlin.phys.uconn.edu 1501
traceroute to gremlin.phys.uconn.edu (137.99.19.34), 30 hops max, 1501 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.308 ms  1.453 ms  2.689 ms
2  math-g190-c6509e-02-t4-4.tcom.purdue.edu (172.17.0.81)  0.621 ms  0.522 ms math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.397 ms
3  math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  0.700 ms  0.724 ms math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  0.785 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.826 ms  0.864 ms  0.917 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.194 ms * *
6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.782 ms  1.797 ms  1.946 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  16.569 ms  16.338 ms  16.564 ms
8  et-10-0-0.107.rtr.clev.net.internet2.edu (198.71.45.9)  16.233 ms  16.310 ms  16.487 ms
9  nox1sumgw1-vl-112-nox-i2.net.harvard.edu (192.5.89.17)  29.624 ms  29.570 ms  29.598 ms
10  192.5.89.21 (192.5.89.21)  29.215 ms  29.461 ms  29.108 ms
11  192.5.89.186 (192.5.89.186)  29.080 ms  29.178 ms  28.897 ms
12  enrt078c-9k-bundle-ether-30.net.cen.ct.gov (207.210.141.137)  34.775 ms  35.063 ms  34.907 ms
13  enrt078h-9k-bundle-ether-10.net.cen.ct.gov (67.218.83.10)  32.212 ms  32.193 ms  32.207 ms
14  bdr-078c-hbl.net.uconn.edu (137.99.255.153)  32.654 ms  32.263 ms  32.636 ms
15  * * *
16  * * *
17  * * *
18  * * *
19  * * *
20  * * *
21  * * *
22  * * *
23  * * *
24  * * *
25  * * *
26  * * *
27  * * *
28  * * *
29  * * *
<div id='show_422128389' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_422128389'>30  * * *
[jha2@hansen-a034 ~]$

&#34;&#34;&#34;

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha
</div><script type='text/javascript'>
        $('#show_422128389').click(function() {
            $('#detail_422128389').slideDown("normal");
            $('#show_422128389').hide();
            $('#hide_422128389').show();
        });
        $('#hide_422128389').click(function() {
            $('#detail_422128389').slideUp();
            $('#hide_422128389').hide();
            $('#show_422128389').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1401140170'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-26T21:36:10+00:00">May 26, 2014 09:36 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401140170">&nbsp;</a></div><pre>Hello Manoj,

What you are observing is the intended behavior, as far as I know.  The MTU
on our local campus network is 1500. The &#34;-F&#34; option to traceroute tells
your local machine to set the DF flag in the IP header of all probe packets
it sends out, right?  This flag means &#34;Don&#39;t Fragment&#34;, and instructs all
IP routers along the path of a tcp connection to drop any packets larger
than the MTU of the next link along the path.  That is what you are seeing.
On the other hand, if you just want to test tcp sockets between our two
endpoints, you don&#39;t want to set the -F flag.  Can you try the command
again without -F?

-Richard Jones

On Mon, May 26, 2014 at 4&#58;58 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1401137913'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-26T20:58:33+00:00">May 26, 2014 08:58 PM UTC</time><a class="anchor" name="1401137913">&nbsp;</a></div><pre>Hello Richard,
I tried to do traceroute to &#39;gremlin.phys.uconn.edu&#39;   from one of the worker nodes from which your job was failing.  I am able to do trace route  if the packet size is less than 1500 bytes.  If the packet size is greater than 1500 bytes, then traceroute  fails.

&#34;&#34;&#34;
[jha2@hansen-a034 ~]$ traceroute -F gremlin.phys.uconn.edu 1500
traceroute to gremlin.phys.uconn.edu (137.99.19.34), 30 hops max, 1500 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.312 ms  1.464 ms  2.702 ms
2  math-g190-c6509e-03-t3-4.tcom.purdue.edu (172.17.0.77)  0.552 ms math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.626 ms math-g190-c6509e-02-t4-4.tcom.purdue.edu (172.17.0.81)  0.440 ms
3  math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  0.740 ms  2.146 ms  0.753 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.762 ms  0.802 ms  0.850 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.203 ms * *
6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.807 ms  1.810 ms  1.945 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  6.359 ms  6.754 ms  6.836 ms
8  et-10-0-0.107.rtr.clev.net.internet2.edu (198.71.45.9)  15.942 ms  16.054 ms  16.180 ms
9  nox1sumgw1-vl-112-nox-i2.nox.org (192.5.89.17)  29.237 ms  29.290 ms  29.340 ms
10  192.5.89.21 (192.5.89.21)  29.904 ms  29.555 ms  29.549 ms
11  192.5.89.186 (192.5.89.186)  29.089 ms  28.943 ms  28.684 ms
12  enrt078c-9k-bundle-ether-30.net.cen.ct.gov (207.210.141.137)  32.490 ms  32.369 ms  32.401 ms
13  enrt078h-9k-bundle-ether-10.net.cen.ct.gov (67.218.83.10)  34.997 ms  34.982 ms  34.309 ms
14  bdr-078c-hbl.net.uconn.edu (137.99.255.153)  32.360 ms  31.825 ms  32.039 ms
15  vrf-border-outside-t-1-4-13.net.uconn.edu (137.99.255.154)  32.055 ms  31.805 ms  32.090 ms
16  fw-msb-i-1-ch24.676.net.uconn.edu (137.99.255.177)  32.043 ms  31.840 ms  31.540 ms
17  * * *
18  * * *
19  gremlin.phys.uconn.edu (137.99.19.34)  34.717 ms  34.575 ms  34.570 ms
[jha2@hansen-a034 ~]$
[jha2@hansen-a034 ~]$
[jha2@hansen-a034 ~]$
[jha2@hansen-a034 ~]$ traceroute -F gremlin.phys.uconn.edu 1501
traceroute to gremlin.phys.uconn.edu (137.99.19.34), 30 hops max, 1501 byte packets
1  math-g109-c7018-01-vlan1872.tcom.purdue.edu (172.18.72.1)  0.316 ms  1.463 ms  2.712 ms
2  math-g190-c6509e-02-t4-4.tcom.purdue.edu (172.17.0.81)  1.118 ms math-g190-c6509e-02-t3-4.tcom.purdue.edu (172.17.0.73)  1.215 ms math-g190-c6509e-03-t4-4.tcom.purdue.edu (172.17.0.85)  0.533 ms
3  math-g190-c9006-01-te0-0-0-0.tcom.purdue.edu (172.17.0.142)  0.738 ms math-g190-c9006-01-te0-0-0-1.tcom.purdue.edu (172.17.0.146)  0.792 ms  0.827 ms
4  tel-210-c9006-01-hu0-1-0-1.tcom.purdue.edu (192.5.40.56)  0.793 ms  0.833 ms  0.884 ms
5  tel-210-c9006-01-sa3.tcom.purdue.edu (172.28.252.105)  0.180 ms * *
<div id='show_482826130' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_482826130'>6  indiana-gigapop-ctc-internet2-research.tcom.purdue.edu (192.5.40.94)  1.812 ms  1.798 ms  1.822 ms
7  et-10-0-0.101.rtr.chic.net.internet2.edu (149.165.254.186)  6.435 ms  6.536 ms  6.843 ms
8  et-10-0-0.107.rtr.clev.net.internet2.edu (198.71.45.9)  15.728 ms  15.920 ms  16.377 ms
9  nox1sumgw1-vl-112-nox-i2.nox.org (192.5.89.17)  29.331 ms  29.342 ms  29.318 ms
10  192.5.89.21 (192.5.89.21)  29.208 ms  30.618 ms  30.705 ms
11  192.5.89.186 (192.5.89.186)  28.861 ms  28.914 ms  28.657 ms
12  enrt078c-9k-bundle-ether-30.net.cen.ct.gov (207.210.141.137)  32.225 ms  33.054 ms  31.987 ms
13  enrt078h-9k-bundle-ether-10.net.cen.ct.gov (67.218.83.10)  34.029 ms  34.644 ms  34.596 ms
14  bdr-078c-hbl.net.uconn.edu (137.99.255.153)  32.702 ms  32.708 ms  32.601 ms
15  * * *
16  * * *
17  * * *
18  * * *
19  * * *
20  * * *
21  * * *
22  * * *
23  * * *
24  * * *
25  * * *
26  * * *
27  * * *
28  * * *
29  * * *
30  * * *
[jha2@hansen-a034 ~]$

&#34;&#34;&#34;
Could you look into it ?

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha
</div><script type='text/javascript'>
        $('#show_482826130').click(function() {
            $('#detail_482826130').slideDown("normal");
            $('#show_482826130').hide();
            $('#hide_482826130').show();
        });
        $('#hide_482826130').click(function() {
            $('#detail_482826130').slideUp();
            $('#hide_482826130').hide();
            $('#show_482826130').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1401115329'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-26T14:42:09+00:00">May 26, 2014 02:42 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1401115329">&nbsp;</a></div><pre>Hello Manoj,

Summary of Gluex production so far on the Purdue site is as follows.  The
short summary is that problems reported at the beginning of this ticket
continue to occur more or less unabated.

- job submitted&#58; 11883 (started 5/22 13&#58;20)
- completed so far&#58; 526 (as of 5/26 8&#58;00)
- efficiency for completed jobs (cpu/wall time)&#58; 99.5%
- average cpu time for completed jobs (hr)&#58; 7&#58;05 or 3&#58;58, depending on
node type
- total wall time consumed so far&#58; 55421 hr
- total useful time consumed&#58; 2568 hr
- production efficiency&#58; 4.6%

The distribution of job run times is plotted at
<a href='http&#58;//gryphn.phys.uconn.edu/halld/gridwork/runinfo_744.png' target='_blank' rel='nofollow'>http&#58;//gryphn.phys.uconn.edu/halld/gridwork/runinfo_744.png</a>
Jobs that complete ok are plotted in green, jobs that fail to start for
some reason are yellow, and jobs that are killed by the worker node startd
are red.  No jobs so far have completed with error status, so all failures
result in jobs being either placed on hold or being requeued.  Jobs shown
in yellow mostly fail because of errors like the following.

007 (774.2642.000) 05/26 10&#58;00&#58;21 Shadow exception!
Error from glidein_5685@....&#58; Could not
initiate file transfer
007 (774.2315.000) 05/25 16&#58;35&#58;32 Shadow exception!
Error from glidein_10258@....&#58; Could not
initiate file transfer

Jobs shown in red fail to complete either because they are preempted by
another user with higher priority, or because of a configuration problem
that causes nodes to periodically dump all running jobs (CMS users may be
exempted from this problem, I have not parsed the condor var logic in
detail) and revert to OWNER state for a few seconds, and then recover.  See
<div id='show_385844632' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_385844632'>previous message in this ticket for documentation of this effect.  I
observed it both on the hansen and coates nodes.

Let me know if you would like me to break down the red jobs shown in this
plot into sub-categories&#58; preempted jobs, jobs killed by OWNER transitions,
network drops, other...  I have some data on these causes, but I have not
collected them systematically or analyzed them.  It will require some work,
so I will only do so if the experts think it might be useful.

-Richard Jones

On Fri, May 23, 2014 at 11&#58;54 AM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font>
</div><script type='text/javascript'>
        $('#show_385844632').click(function() {
            $('#detail_385844632').slideDown("normal");
            $('#show_385844632').hide();
            $('#hide_385844632').show();
        });
        $('#hide_385844632').click(function() {
            $('#detail_385844632').slideUp();
            $('#hide_385844632').hide();
            $('#show_385844632').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1400874920'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-23T19:55:20+00:00">May 23, 2014 07:55 PM UTC</time><a class="anchor" name="1400874920">&nbsp;</a></div><pre>Hi all,

Sorry, the Purdue admins told us in a different ticket this would become a rhel6 resource this week but we were slow to reflect the configuration change on the factory side.  Since I have made the change, I now see 300 gluex glideins running user jobs and counting from purdue.

Jeff
OSG Glidein Factory Operations

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jdost/CN=732648/CN=Jeffrey Michael Dost</pre></div><div class='update_description'><i onclick="document.location='20576#1400867463'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-23T17:51:03+00:00">May 23, 2014 05:51 PM UTC</time><a class="anchor" name="1400867463">&nbsp;</a></div><pre>The queue is busy with large  number of queued jobs from CMS.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1400860451'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-23T15:54:11+00:00">May 23, 2014 03:54 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1400860451">&nbsp;</a></div><pre>Hello Manoj,

They remain in the queues since I submitted them.  You should see 200 of
our Gluex glideins sitting in your queue on the CE called
CMS_T2_US_Purdue_hadoop.
As far as I know that is the one where our jobs are supposed to go.
None have accumulated any cpu time so far.

-Richard Jones

On Fri, May 23, 2014 at 11&#58;37 AM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1400859459'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-23T15:37:39+00:00">May 23, 2014 03:37 PM UTC</time><a class="anchor" name="1400859459">&nbsp;</a></div><pre>Hi Richard,

Submit your jobs again.  In case of any problem, send us the log files so that we can understand the problem in  better way.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1400809114'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-23T01:38:34+00:00">May 23, 2014 01:38 AM UTC</time><a class="anchor" name="1400809114">&nbsp;</a></div><pre>Site is suffering from Glexec problem.  We are working on to fix it.
<a href='https&#58;//ticket.grid.iu.edu/goc/21207' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/goc/21207</a>

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1400796550'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-22T22:09:10+00:00">May 22, 2014 10:09 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1400796550">&nbsp;</a></div><pre>Hello,

Have submitted a set of jobs, but so far nothing has been accepted at
Purdue after 6 hours.  Will continue to watch and wait.

-Richard J.

On Thu, May 22, 2014 at 10&#58;22 AM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1400768549'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-22T14:22:29+00:00">May 22, 2014 02:22 PM UTC</time><a class="anchor" name="1400768549">&nbsp;</a></div><pre>Network fix has been completed.  Richard can try again.

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1400760708'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-22T12:11:48+00:00">May 22, 2014 12:11 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1400760708">&nbsp;</a></div><pre>Hi Manoj,

Can you confirm that the network fix has been completed and it is ok for Richard to test again?

Thanks,
Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1400504888'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-19T13:08:08+00:00">May 19, 2014 01:08 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1400504888">&nbsp;</a></div><pre>Hi Manoj,

Thanks for the update. I will set this ticket to the 22nd and will prompt for an update at that time.

Regards,
Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1400261140'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-16T17:25:40+00:00">May 16, 2014 05:25 PM UTC</time><a class="anchor" name="1400261140">&nbsp;</a></div><pre>I would suggest user  to try again after May 21st.   We are applying some network fix to solve the routing problem at site.

-Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1400211130'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-16T03:32:10+00:00">May 16, 2014 03:32 AM UTC</time> by <b>GLUEX</b><a class="anchor" name="1400211130">&nbsp;</a></div><pre>Hello Chris,

I am ready to test now, or at any time.  I think the choice should be with
the site admins at Purdue.  If they are working on the problem and have
other tickets open that they consider redundant with this one, they can
consolidate and close this one out.

-Richard J.

On Thu, May 15, 2014 at 1&#58;05 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1400173514'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-15T17:05:14+00:00">May 15, 2014 05:05 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1400173514">&nbsp;</a></div><pre>Hi Richard,

Would you like to keep this ticket open until resolution or do you want to close it at this time and reopen when you are ready to test?

Thanks,
Chris</pre></div><div class='update_description'><i onclick="document.location='20576#1399477254'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-07T15:40:54+00:00">May 7, 2014 03:40 PM UTC</time><a class="anchor" name="1399477254">&nbsp;</a></div><pre>Hello,

For the time being, I have disabled our Gluex jobs from being sent to the purdue.rcac site, by introducing the following element in my frontend.xml file&#58;

&#60;factory query_expr=&#39;stringListMember(&#34;GLUEX&#34;,GLIDEIN_Supported_VOs)&amp;&amp;(regexp(&#34;Purdue&#34;,&#34;GLIDEIN_Site&#34;,&#34;i&#34;) =!= True)&#39;&#62;

This change was put in place this morning, and I restarted my frontend service.  I think it is the right thing to do at this point, to avoid further wasting of opportunistic resources at the Purdue site.  As soon as a better understanding of the underlying issues is reached, I would like to be given a chance to lift this restriction and check that our jobs are able to run there.

-Richard Jones

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1399234989'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-04T20:23:09+00:00">May 4, 2014 08:23 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1399234989">&nbsp;</a></div><pre>Mats,

The clause in the START expression that deals with &#34;Loadavg&#34; values is what
puts the &#34;worker condor&#34; into the OWNER state at these random times.  This
is what is triggering the evictions that are quenching my ability to
accomplish work on this site.  The value of the START expression on these
nodes involves comparing the Loadavg on the machine to a narrow window of
expected loads, which is too narrow for stable operation.  That much I have
determined to be true.

The setting of START can easily be changed to exclude that clause in the
formula based on Loadavg values.  That would prevent these random
transitions from happening and solve my problem, I believe.

-Richard J.

On Sun, May 4, 2014 at 1&#58;37 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1399225017'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-04T17:36:57+00:00">May 4, 2014 05:36 PM UTC</time><a class="anchor" name="1399225017">&nbsp;</a></div><pre>Richard,

I&#39;m not arguing that it is the START expression that puts the slot in OWNER state, but  that the START/OWNER is an effect, caused by something else. You might find more information in the HTCondor logs for the glidein, as well as the negotiator log for your pool.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Mats Rynge 45</pre></div><div class='update_description'><i onclick="document.location='20576#1399202591'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-04T11:23:11+00:00">May 4, 2014 11:23 AM UTC</time> by <b>GLUEX</b><a class="anchor" name="1399202591">&nbsp;</a></div><pre>Hello Mats,

All of what you say is correct.  Let me use the term &#34;worker condor&#34; when I
mean the HTCondor environment in the worker node that runs the glidein job,
and &#34;glidein condor&#34; when I mean the HTCondor environment inside the
glidein that runs my Gluex job.  When I say &#34;OWNER&#34;, I mean on the &#34;worker
condor&#34;.  The worker condor is reverting to OWNER machine state,
immediately kicking off the glidein job and killing any subprocesses
running inside, including my job process itself.  That shows up as a
disconnection event in my job log on the frontend submit host.

The two log files I posted earlier show the following.  On the frontend
side (osg17.log) the frontend shadow shows my job running in the glidein
condor has disconnected a 5&#58;35.  In the &#34;worker condor&#34; StartLog
(condorlogs.tgz) is recorded the simultaneous transition from IDLE to
OWNER, and the abrupt eviction of all jobs running on the node, including
all VO&#39;s, even CMS.  This is not a preemption event.  Preemptions are
happening, but those are not the problem that is preventing me from getting
work done on this site.

Such IDLE -&#62; OWNER transitions are recorded in these worker condor StartLog
files at fairly regular intervals.  This is triggered, as I explained
earlier, by a brief transit of the node Loadavg value above the expected
level based on the number of condor jobs running on the node. A couple of
minutes later, the Loadavg subsides and the node switches back OWNER -&#62;
IDLE and starts accepting jobs again.  From my frontend side, I see
hundreds of my jobs start up on the site, run for 1-2 hours, then
disconnect in clusters of a dozen at a time, and then 5 minutes later start
up again and run 1-2 hours, and so on. This way they use thousands of cpu
hours per day but never complete.

These OWNER transitions were a useful feature of HTcondor back in the
1990&#39;s, when it was commonly used to run jobs in the bg on end-user desktop
PC&#39;s.  It allowed people to loan the use of their desktop PC for
computation when they were away from the desk, and immediately kick all
<div id='show_251766819' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_251766819'>jobs off when they came back and started typing on the keyboard or using an
app.  You may not be familiar with this use of the START macro to control
switching between OWNER and IDLE states of the machine, in addition to
determining whether the machine is willing to start a job. Nowadays almost
nobody uses condor like that, and the behavior is mostly an annoyance.

-Richard J.

On Sun, May 4, 2014 at 12&#58;42 AM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font>
</div><script type='text/javascript'>
        $('#show_251766819').click(function() {
            $('#detail_251766819').slideDown("normal");
            $('#show_251766819').hide();
            $('#hide_251766819').show();
        });
        $('#hide_251766819').click(function() {
            $('#detail_251766819').slideUp();
            $('#hide_251766819').hide();
            $('#show_251766819').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1399178558'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-04T04:42:38+00:00">May 4, 2014 04:42 AM UTC</time><a class="anchor" name="1399178558">&nbsp;</a></div><pre>There are two levels of HTCondor. The first level is the HTCondor that is installed on the resource, and is configured and managed by Purdue.  The second level is the glidein HTCondor, and it is configured by a mix of stuff from the GlideinWMS factory and your GlideinWMS frontend. The first level starts the second level.

The Purdue level is what we have to worry about if we see glidein preemption. Past experience, and my first entry on this issue indicates that Purdue indeed has a fairly aggressive preemption policy. The way this usually show up on the submit side is errors like &#34;Job reconnection failed - Job disconnected too long&#58; JobLeaseDuration (1200 seconds) expired - Can not reconnect to ..., rescheduling job&#34;. The reason is that the site killed the glidein so quickly that no information about the preemption was sent back to your HTCondor pool.

The configuration of the first level is what determines when glideins are started and kicked off.

I could be wrong about this, but if you look at jobs submitted from your submit node and they are kicked off the glidein, but the glidein stays on the system and accepts more of your jobs, then the problem is in either the second level configuration (glidein configuration), or it could also be something like ulimits that is kills your job.

When you see &#34;OWNER&#34;, is that when you do a condor_status on your own submit node?

One thing you can try is to use condor_ssh_to_job to ssh to the glidein and tail logs/stdout/... as the jobs is being kicked off.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Mats Rynge 45</pre></div><div class='update_description'><i onclick="document.location='20576#1399159391'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-03T23:23:11+00:00">May 3, 2014 11:23 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1399159391">&nbsp;</a></div><pre>Mats,

It is the START expression for the Purdue HTCondor pool that is fed from
the hadoop.rcac CE.  I don&#39;t know if there are others HTCondor pools on the
purdue site, so I specify that.  In order to see the HTCondor variables, I
have to prefix my condor_config_val command with &#34;unset CONDOR_CONFIG&#34; in
the glidein monitor command, otherwise I just see the glidein START
expression, which is different.

-Richard J.

On Sat, May 3, 2014 at 5&#58;35 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1399152911'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-03T21:35:11+00:00">May 3, 2014 09:35 PM UTC</time><a class="anchor" name="1399152911">&nbsp;</a></div><pre>Richard,

So is the START expression you posted from the Purdue HTCondor pool, or the START expression of the glideins?

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Mats Rynge 45</pre></div><div class='update_description'><i onclick="document.location='20576#1399080270'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-03T01:24:30+00:00">May 3, 2014 01:24 AM UTC</time> by <b>GLUEX</b><a class="anchor" name="1399080270">&nbsp;</a></div><pre>Hello Mats and all,

You make some good points.  However, the main thing I want to point out is
that it is not preemption by CMS users that is costing me the bulk of the
problems.  It is the transition of the state machine from CLAIMED state
[running my job] to OWNER [kicking off all users and reverting to IDLE].
If that is not the START clause, which one is it?

-Richard J.

On Fri, May 2, 2014 at 6&#58;43 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1399070634'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-02T22:43:54+00:00">May 2, 2014 10:43 PM UTC</time><a class="anchor" name="1399070634">&nbsp;</a></div><pre>Richard,

I agree with you that debugging preemption remotely is difficult, but I just wanted to mention that the START expression is probably not the cause of this. START is only evaluated when the startd is considering to accept new jobs, not to kick jobs off. I looked at the output from condor_config_val on hadoop-osg.rcac.purdue.edu. Note that his might not be the configuration that is used for the negotiator, but if it is, there are some clues on what is going on. Consider these&#58;

RANK = (CMSJob =?= True ) * 2000 + (PriorityCMSJob =?= True) * 5000 + (localCMSJob =?= True) * 9000

Ok, this is normal project/VO prioritization. Any CMS jobs will preempt you. My bet is that this is the cause of the problem, together with a short MAXJOBRETIREMENTTIME.

SUSPEND = (( (KeyboardIdle &#60; 60) || ( (CpuBusyTime &#62; 2 * 60) && ifThenElse(JobStart =!= UNDEFINED, (time() - JobStart), 0) &#62; 90 ) )) && ( RemoteUser =!= &#34;cmsprod1@....&#34; && RemoteUser =!= &#34;uscms01@....&#34; && RemoteUser =!= &#34;cms*@rcac.purdue.edu&#34;    )
PREEMPT = (( ((Activity == &#34;Suspended&#34;) && ((time() - EnteredCurrentActivity) &#62; 10 * 60)) || (SUSPEND && (WANT_SUSPEND == False)) || ( TotalDisk &#60; 1000000 ) )) && ( RemoteUser =!= &#34;cmsprod1@....&#34; && RemoteUser =!= &#34;uscms01@....&#34; && RemoteUser =!= &#34;cms*@rcac.purdue.edu&#34;   )

Pretty standard stuff

MAXJOBRETIREMENTTIME = 24*3600*( RemoteUser =?= &#34;cmsprod1@....&#34; || RemoteUser =?= &#34;uscms01@....&#34; || RemoteUser =?= &#34;cms*@rcac.purdue.edu&#34;     )

Now, this is interesting. As a non-CMS user, your retirement time will be 0. Which means that your glidein and your user job will not be given any time cleanly preempt. I think an interesting experiment would be for Purdue to change MAXJOBRETIREMENTTIME to something bigger for non-CMS users, for example 1 hour. If that change would be implemented, we could do some testing and it could tell us if standard preemption is the cause of these problems.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Mats Rynge 45</pre></div><div class='update_description'><i onclick="document.location='20576#1399043266'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-02T15:07:46+00:00">May 2, 2014 03:07 PM UTC</time><a class="anchor" name="1399043266">&nbsp;</a></div><pre>The cause of the problem is the setting of the START condor variable on the worker nodes.

$ condor_config_val
( (KeyboardIdle &#62; 15 * 60) && ( ((LoadAvg - CondorLoadAvg) &#60;= 0.3) || (State != &#34;Unclaimed&#34; && State != &#34;Owner&#34;)) ) && ( False == False ) && TRUE && ( ( True =!= False ) && ( False =!= True ) )

This (LoadAvg - CondorLoadAvg) &#60;= 0.3 can be triggered by any number of things happening on the worker node, such as regular background cron jobs, etc.  It is happening on a regular basis, day and night, that this rule triggers the eviction of all jobs running on the machine.  This is not only affecting Gluex, but all vo&#39;s trying to run there, including CMS.

BTW, in my previous message I indicated an event that happened at 7&#58;08&#58;24 this morning on 172.18.47.1.  That one was just preemption by another user.  A better example is the one that takes place on the same node at 5&#58;35&#58;47 with a new set of jobs starting up again as soon as the loadavg went back down again.  I think this rule should have a larger threshold, like 3 or 5, or the condition on loadavg removed altogether.
-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1399036486'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-02T13:14:46+00:00">May 2, 2014 01:14 PM UTC</time><a class="anchor" name="1399036486">&nbsp;</a></div><pre>Major update on this issue&#58;

I have managed to isolate the problem, I believe.  What seems to be happening is that I am preempting myself on the purdue site.

View from my end at the uconn frontend schedd host&#58; see <a href='http&#58;//zeus.phys.uconn.edu/UConn-OSG/diagnose/osg17.log' target='_blank' rel='nofollow'>http&#58;//zeus.phys.uconn.edu/UConn-OSG/diagnose/osg17.log</a>
View from the worker node end at 172.18.47.1&#58; see log file StartLog in <a href='http&#58;//zeus.phys.uconn.edu/UConn-OSG/diagnose/condorlogs.tgz' target='_blank' rel='nofollow'>http&#58;//zeus.phys.uconn.edu/UConn-OSG/diagnose/condorlogs.tgz</a>,

Those condor logs were lifted from the worker node during a running job 694.82782 at 8&#58;10 on 5/2.  Consider what happens at around 07&#58;08&#58;24.  In the StartLog on the worker node, it helps to do &#34;grep -i preempt StartLog&#34;.  A massive preemption event takes place, where running jobs are kicked out and new jobs with a higher rank are started.  From looking at osg17.log, you can see that both the ejected jobs (show up as disconnection events in my schedd) and the new jobs starting up are both mine!  So it seems I am preempting my own jobs, which is counterproductive.  How can I stop doing that?

-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1399031600'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-05-02T11:53:20+00:00">May 2, 2014 11:53 AM UTC</time><a class="anchor" name="1399031600">&nbsp;</a></div><pre>Hello Manoj,

Symptoms are unchanged, same as originally reported.  Jobs are executing fine at first, and then after some time of smooth sailing, they suddenly disappear.  My best guess at this point is that they are being preempted by your condor negotiator, but that is difficult for me to diagnose from my end.  I am working to find ways to prove this is the case. I don&#39;t believe it is the intent of the site policy to see so much cpu time lost in this manner, right?

-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1398890738'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-30T20:45:38+00:00">Apr 30, 2014 08:45 PM UTC</time><a class="anchor" name="1398890738">&nbsp;</a></div><pre>Hi Richard,
Our network people has made some configurations changes.    Could you resubmit your jobs again ?

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398890521'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-30T20:42:01+00:00">Apr 30, 2014 08:42 PM UTC</time> by <b>echism</b><a class="anchor" name="1398890521">&nbsp;</a></div><pre>I&#39;m adding Chris to this ticket while I&#39;m out.

Thank you.</pre></div><div class='update_description'><i onclick="document.location='20576#1398853536'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-30T10:25:36+00:00">Apr 30, 2014 10:25 AM UTC</time><a class="anchor" name="1398853536">&nbsp;</a></div><pre>Hello,

Has there been any progress understanding this issue?  I am available to provide diagnostic information if that would help.

-Richard Jones

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1398522521'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-26T14:28:41+00:00">Apr 26, 2014 02:28 PM UTC</time><a class="anchor" name="1398522521">&nbsp;</a></div><pre>Hello Manoj,

As a stop-gap measure, could I ask that you set the value of /proc/sys/net/ipv4/tcp_mtu_probing to 1 on the workers?  With this set, when a packet is lost in a black hole due to suppression of ICMP packets by the firewall, the kernel automatically adjusts the mtu downward and tries to recover the ability to communicate over a socket.  Temporary setting (until the next reboot) for testing is enabled by the command performed once on each worker node.

echo 1 &#62;/proc/sys/net/ipv4/tcp_mtu_probing

-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1398518264'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-26T13:17:44+00:00">Apr 26, 2014 01:17 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398518264">&nbsp;</a></div><pre>Hello Manoj,

I think you have narrowed the problem down to the right area.  I see that
you have only one active network interface on these nodes, and you have set
it up to use jumbo frames (MTU=9000).  Are you sure this is going to work?
From my limited experience, people who want to use jumbo frames for local
traffic configure two nics on each machine, one for a LAN segment where all
hosts are configured with MTU=9000, and one for external internet traffic
configured with MTU=1500.  I am no expert, but I wonder if your
configuration has been validated by someone who is.

I am getting jumbo frames from you delivered all the way to me (route goes
over Internet 2).  See the example from &#39;tcpdump -v&#39; below.  My local MTU
is set to 1500, which may explain why my kernel has flagged all of these
packets as having a bad checksum (see &#39;incorrect checksum&#39; below).  All tcp
packets from your site with segment sizes &#62; 1460 are flagged as &#39;incorrect
checksum&#39;, and all packets with segment size 1460 or less are marked
&#39;correct checksum&#39;, which indicates that jumbo segments are somehow a
problem between us.  Also note that the IP header in these frames is marked
&#34;DF&#34; so there is no chance for the IP layer to fragment them down for
transport to me. Seeing this makes me wonder how the connection works at
all.

07&#58;48&#58;51.221083 IP (tos 0x0, ttl 45, id 15206, offset 0, flags [DF],
proto TCP (6), length 3696)
nat032.rcac.purdue.edu.17795 &#62; gremlin.phys.uconn.edu.9711&#58; Flags
[P.], cksum 0xc6db (incorrect -&#62; 0x3fad), seq 1&#58;3657, ack 250, win 10,
length 3656

-Richard Jones

-Richard Jones

On Fri, Apr 25, 2014 at 2&#58;44 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;
<div id='show_1679455566' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_1679455566'>
<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font>
</div><script type='text/javascript'>
        $('#show_1679455566').click(function() {
            $('#detail_1679455566').slideDown("normal");
            $('#show_1679455566').hide();
            $('#hide_1679455566').show();
        });
        $('#hide_1679455566').click(function() {
            $('#detail_1679455566').slideUp();
            $('#hide_1679455566').hide();
            $('#show_1679455566').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1398451440'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-25T18:44:00+00:00">Apr 25, 2014 06:44 PM UTC</time><a class="anchor" name="1398451440">&nbsp;</a></div><pre>When we traceroute to &#34;gremlin.phys.uconn.edu&#34; from our nodes, it ends successfully.  When the packet size gets increased to 1500, traceroute is not able to connect &#34;gremlin.phys.uconn.edu&#34;.  Now the problem is reproducible.  We have informed our network people.  Once it is fixed, we will soon get back to you.

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398451278'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-25T18:41:18+00:00">Apr 25, 2014 06:41 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398451278">&nbsp;</a></div><pre>Hello Dan and all,

I have done a life cycle trace of a few jobs that were ejected from running
on the purdue site, and can rule out options (2) and (3) that I proposed
earlier.  I am running continuous tcpdumps on all connections between my
frontend collector host and the purdue site where my glideins are running.
I have confirmed that the traffic between my collector node and the purdue
site is low enough that the fraction of lost packets is zero, and the
overhead introduced by tcpdump/promiscuous-mode operation while running
thousands of jobs to this and other sites is miniscule.  All of the
connections of interest are going through the following routers.

1. nat032.rcac.purdue.edu
2. nat033.rcac.purdue.edu
3. nat034.rcac.purdue.edu
4. nat035.rcac.purdue.edu
5. nat036.rcac.purdue.edu
6. nat037.rcac.purdue.edu
7. nat038.rcac.purdue.edu
8. nat039.rcac.purdue.edu

These connections are easy to trace with tcpdump because I have enabled the
&#34;libkeepalive.so&#34; preload library on these secondary collectors, which
makes them emit zero-length packets every 20 seconds over any open
connection.  So this is what a typical lifecycle of an aborted job looks
like in tcpdump, for the socket that were my collector communicates with
the startd daemon running in the glidein.  Gremlin.phys.uconn.edu is my
frontend collector host.

1. Syn packet from nat032 connects over port 96XX to one of my secondary
collectors on Gremlin
2. Gremlin returns Syn/Ack plus another answer/response -- connection
established
3. Many payload packet (tcp Push) exchanged between collector and
glidein behind nat032, each with correct Ack
<div id='show_1495896564' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_1495896564'>4. Connection traffic dies down after a few seconds of interchange, time
is now 10&#58;56&#58;42
5. Periodic packets every few minutes, connection mostly idle, with
zero-length packets sent from Gremlin end every 20 seconds (normal
libkeepalive.so behavior) and immediate Ack response from nat032.  The
packets with non-zero length seem to correspond to entries in the condor
logs where the job size is updated.
6. Job continues like this until 11&#58;30&#58;44, then suddenly
7. Tcp Fin packet sent from nat032 to Gremlin, not in response to
anything from Gremlin but out of the blue, and out of time with the
libkeepalive.so sequence.
8. Gremlin responds as it should, with Tcp Fin-Ack -- connection is
closed.

Of course, there is no chance for reconnection to succeed from Gremlin
because the nat firewall blocks all incoming attempts to reconnect to a
host behind the router.  That is all I can see from my end.  But I can
confirm that packets on other open connections continue to flow between
Gremlin and nat032, so it is not that the site is being blocked as a whole.
It seems that the firewall is just closing the connection -- did we
somehow trigger a firewall rule, and cause it to break the socket???

Another clue&#58; all of the jobs that are running on a given host at purdue,
which is typically 24 at a time, all dump at the same time.  Within a
second or so I see the Fin/Fin-Ack sequence exchanged between all of the
glideins that are running on that host.  So it does seem like it is a
host-specific thing, and not just depending on what the individual job was
doing at the time.  This behavior is not seen to any other site on the osg.

I hope this helps,
-Richard Jones

On Fri, Apr 25, 2014 at 1&#58;55 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font>
</div><script type='text/javascript'>
        $('#show_1495896564').click(function() {
            $('#detail_1495896564').slideDown("normal");
            $('#show_1495896564').hide();
            $('#hide_1495896564').show();
        });
        $('#hide_1495896564').click(function() {
            $('#detail_1495896564').slideUp();
            $('#hide_1495896564').hide();
            $('#show_1495896564').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1398448523'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-25T17:55:23+00:00">Apr 25, 2014 05:55 PM UTC</time><a class="anchor" name="1398448523">&nbsp;</a></div><pre>Hi,

Another point of interest for the admins, I think Richard is on the right track, and suspect 3, network issues affecting any network connections from the WNs.  Ever since the NAT fixes at purdue ( <a href='https&#58;//ticket.grid.iu.edu/goc/20489' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/goc/20489</a> ), all of the other clusters seem fine, except the one behind the new gatekeeper, hadoop-osg.rcac.purdue.edu

Is it possible that there is still some network tweaking that is needed for the  hadoop-osg.rcac.purdue.edu cluster only?

Thanks,
Jeff Dost
OSG Glidein Factory Operations

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jdost/CN=732648/CN=Jeffrey Michael Dost</pre></div><div class='update_description'><i onclick="document.location='20576#1398376748'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T21:59:08+00:00">Apr 24, 2014 09:59 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398376748">&nbsp;</a></div><pre>Dan and Manoj,

Your startd log is telling that the socket connection between my schedd
(runs on gremlin.phys.uconn.edu) and the worker node is going dead some
time during the job, and this makes the startd think that &#34;claim no longer
recognized by schedd [on gremlin.phys.uconn.edu]&#34; because the contact has
been lost.  So that is what is causing the jobs to be killed, not
preemption by another job.  It is good to eliminate that possibility, so
now I will focus on what is interrupting the connection.  I see three
possibilities I will try to distinguish&#58;

1. that just this one port connection is being blocked -- can be caused
by any number of factors, including even firewall issues on our end,
although our netops says it shouldn&#39;t be;
2. that all ports on that host on the purdue site are being cut off from
uconn;
3. that all connections to anywhere on the purdue network are being cut
off from uconn, including to your squid server -- which might explain other
symptoms we were seeing earlier.

Will be getting back to you shortly with evidence ruling out at least 2 of
these.

-Richard J.

On Thu, Apr 24, 2014 at 5&#58;21 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398374493'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T21:21:33+00:00">Apr 24, 2014 09:21 PM UTC</time><a class="anchor" name="1398374493">&nbsp;</a></div><pre>Hi Manoj,

From the factory side, we have no information about what the user job was doing. We only get back logs that describe the glidein processes; the user job is a black box to us. I think only Richard can help you here.

The closest I can come would be to give excerpts from the startd log, though I&#39;m not sure it&#39;ll tell us much more than Richard already knows&#58;

04/24/14 13&#58;54&#58;18 (pid&#58;19728) Remote owner is jonesrt@....
04/24/14 13&#58;54&#58;18 (pid&#58;19728) State change&#58; claiming protocol successful
04/24/14 13&#58;54&#58;18 (pid&#58;19728) Changing state&#58; Unclaimed -&#62; Claimed
...
04/24/14 13&#58;54&#58;19 (pid&#58;19728) Changing activity&#58; Idle -&#62; Busy
...
04/24/14 15&#58;00&#58;59 (pid&#58;19728) State change&#58; claim no longer recognized by the schedd - removing claim
04/24/14 15&#58;00&#58;59 (pid&#58;19728) Changing state and activity&#58; Claimed/Busy -&#62; Preempting/Killing
...
04/24/14 15&#58;01&#58;29 (pid&#58;19728) starter (pid 30603) is not responding to the request to hardkill its job.  The startd will now directly hard kill the starter and all its decendents.
04/24/14 15&#58;01&#58;29 (pid&#58;19728) Starter pid 30603 died on signal 9 (signal 9 (Killed))
04/24/14 15&#58;01&#58;29 (pid&#58;19728) State change&#58; starter exited
04/24/14 15&#58;01&#58;29 (pid&#58;19728) State change&#58; No preempting claim, returning to owner
04/24/14 15&#58;01&#58;29 (pid&#58;19728) Changing state and activity&#58; Preempting/Killing -&#62; Owner/Idle
04/24/14 15&#58;01&#58;29 (pid&#58;19728) State change&#58; IS_OWNER is false
04/24/14 15&#58;01&#58;29 (pid&#58;19728) Changing state&#58; Owner -&#62; Unclaimed
04/24/14 15&#58;03&#58;00 (pid&#58;19728) condor_write()&#58; Socket closed when trying to write 4096 bytes to collector gremlin.phys.uconn.edu&#58;9719, fd is 9, errno=110 Connection timed out
04/24/14 15&#58;03&#58;00 (pid&#58;19728) Buf&#58;&#58;write()&#58; condor_write() failed
04/24/14 15&#58;08&#58;20 (pid&#58;19728) The DaemonShutdown expression &#34;(DynamicSlot =!= True) && ((((GLIDEIN_ToDie =!= UNDEFINED) && (CurrentTime &#62; GLIDEIN_ToDie)) || (( (Slot1_Activity == &#34;Idle&#34;) && (((Slot1_TotalTimeUnclaimedIdle =!= UNDEFINED) && (GLIDEIN_Max_Idle =!= UNDEFINED) && (Slot1_TotalTimeUnclaimedIdle &#62; GLIDEIN_Max_Idle)) || ((GLIDEIN_ToRetire =!= UNDEFINED) && (CurrentTime &#62; GLIDEIN_ToRetire )) || ((Slot1_TotalTimeUnclaimedIdle =!= UNDEFINED) && (Slot1_TotalTimeClaimedBusy =!= UNDEFINED) && (GLIDEIN_Max_Tail =!= UNDEFINED) && (Slot1_TotalTimeUnclaimedIdle &#62; GLIDEIN_Max_Tail))) ) && ((PartitionableSlot =!= True) || (TotalSlots =?=1)))))&#34; evaluated to TRUE&#58; starting graceful shutdown
04/24/14 15&#58;08&#58;20 (pid&#58;19728) Got SIGTERM. Performing graceful shutdown.

Cheers,
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1398364690'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T18:38:10+00:00">Apr 24, 2014 06:38 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398364690">&nbsp;</a></div><pre>Hello Dan and Manoj,

I can record this information and pass it on to you.  What would you like
to see?  The executable that these jobs are running (for 85% of the run
time, covers the first 3 hours) is called &#34;hdgeant&#34;, a build of the Geant3
toolkit.  I can record the total (user, sys, wall) clock time used by
hdgeant in few-minute intervals up until the time that the job disconnects.
Would that be sufficient?  My job also generates output to a file, so I
can track the size of the output file as a function of time as well.  Other
job information can be logged.  Let me know what would be most useful.

-Richard J.

On Thu, Apr 24, 2014 at 2&#58;30 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398364231'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T18:30:31+00:00">Apr 24, 2014 06:30 PM UTC</time><a class="anchor" name="1398364231">&nbsp;</a></div><pre>Hi Dan,
Is it possible to know what job was doing when it failed ? If I can reproduce the problem using some simple  command, then we can debug it.  I am able to view the monitoring for GOC factory.

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398364150'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T18:29:10+00:00">Apr 24, 2014 06:29 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398364150">&nbsp;</a></div><pre>Hello Dan,

I have no user logs from these failures.  The only evidence I have that
this is happening is a notice in my condor submit log file (see below) that
the job has disconnected and has been requeued, and the fact that I have no
output and empty logs.

Here is a complete log history of one particular job in my condor submit
log.  This job ran successfully for more than one hour, before it was
ejected for no reason I can discover.  If the user job had errored out, it
would have a &#34;job terminated&#34; message in the condor log, perhaps with a
non-zero exit code.  -Richard Jones

...
000 (545.13205.000) 04/23 09&#58;58&#58;37 Job submitted from host&#58;
&#60;137.99.19.33&#58;9615?sock=3952_6ee8&#62;

...
001 (545.13205.000) 04/24 11&#58;11&#58;18 Job executing on host&#58;
&#60;172.18.73.118&#58;44435?CCBID=137.99.19.34&#58;9651#1460&noUDP&#62;

...
006 (545.13205.000) 04/24 11&#58;11&#58;27 Image size of job updated&#58; 2
3  -  MemoryUsage of job (MB)
2516  -  ResidentSetSize of job (KB)

[ many more of these Image Size updates omitted here ]

...
022 (545.13205.000) 04/24 12&#58;28&#58;15 Job disconnected, attempting to reconnect
Socket between submit and execute hosts closed unexpectedly
Trying to reconnect to glidein_2054@....
&#60;172.18.73.118&#58;44435?CCBID=137.99.19.34&#58;9651#1460&noUDP&#62;

...
<div id='show_1545839432' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_1545839432'>024 (545.13205.000) 04/24 12&#58;48&#58;15 Job reconnection failed
Job disconnected too long&#58; JobLeaseDuration (1200 seconds) expired
Can not reconnect to glidein_2054@....,
rescheduling job

...
001 (545.13205.000) 04/24 13&#58;06&#58;31 Job executing on host&#58;
&#60;172.18.41.65&#58;33999?CCBID=137.99.19.34&#58;9649#1385&noUDP&#62;

...
022 (545.13205.000) 04/24 13&#58;07&#58;18 Job disconnected, attempting to reconnect
Socket between submit and execute hosts closed unexpectedly
Trying to reconnect to glidein_17599@....
&#60;172.18.41.65&#58;33999?CCBID=137.99.19.34&#58;9649#1385&noUDP&#62;

...
024 (545.13205.000) 04/24 13&#58;27&#58;18 Job reconnection failed
Job disconnected too long&#58; JobLeaseDuration (1200 seconds) expired
Can not reconnect to glidein_17599@....,
rescheduling job

...
001 (545.13205.000) 04/24 13&#58;35&#58;43 Job executing on host&#58;
&#60;172.18.72.214&#58;58403?CCBID=137.99.19.34&#58;9637#1419&noUDP&#62;

...
022 (545.13205.000) 04/24 14&#58;16&#58;15 Job disconnected, attempting to reconnect
Socket between submit and execute hosts closed unexpectedly
Trying to reconnect to glidein_20928@....
&#60;172.18.72.214&#58;58403?CCBID=137.99.19.34&#58;9637#1419&noUDP&#62;

On Thu, Apr 24, 2014 at 1&#58;59 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font>
</div><script type='text/javascript'>
        $('#show_1545839432').click(function() {
            $('#detail_1545839432').slideDown("normal");
            $('#show_1545839432').hide();
            $('#hide_1545839432').show();
        });
        $('#hide_1545839432').click(function() {
            $('#detail_1545839432').slideUp();
            $('#hide_1545839432').hide();
            $('#show_1545839432').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='20576#1398362366'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-24T17:59:26+00:00">Apr 24, 2014 05:59 PM UTC</time><a class="anchor" name="1398362366">&nbsp;</a></div><pre>Hi Manoj,

It sounds like you want user job logs, not glidein logs, correct? If I have that wrong, let me know, and I can send you some factory logs too.

As far as glidein loads on the factories, you can track the number of running glideins from the monitoring pages&#58;
<a href='http&#58;//gfactory-1.t2.ucsd.edu/osg_gfactory/factoryStatus.html' target='_blank' rel='nofollow'>http&#58;//gfactory-1.t2.ucsd.edu/osg_gfactory/factoryStatus.html</a>
<a href='http&#58;//glidein.grid.iu.edu/osg_gfactory/factoryStatus.html' target='_blank' rel='nofollow'>http&#58;//glidein.grid.iu.edu/osg_gfactory/factoryStatus.html</a>

For other sorts of load (processor, network traffic, etc.) we do have online monitoring for the GOC factory, though I&#39;m not certain whether you&#39;ll be able to access it. See if you can see this page&#58;
<a href='https&#58;//munin.grid.iu.edu/munin/Production_Servers/glidein/index.html' target='_blank' rel='nofollow'>https&#58;//munin.grid.iu.edu/munin/Production_Servers/glidein/index.html</a>

Hope this helps!
-Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1398280825'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-23T19:20:25+00:00">Apr 23, 2014 07:20 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398280825">&nbsp;</a></div><pre>Hello Manoj,

As far as I understand it, no command in my job actually failed.  It was
correctly running the job, and something came along from the outside a did
a &#34;condor_vacate&#34; on the job, or equivalent.  The behavior is the same as
if the machine dropped off the network for 20 minutes and no packets were
send or received from that address for this period.  Of course I have no
idea if that actually happened, but from the side of my server, that is
what it says has happened.  A simpler explanation would be that the jobs
are being pre-empted and replaced by new jobs with a period of roughly one
hour, by a poorly formed policy in the site condor configuration.  It is
not that the worker node machine itself is necessarily becoming
unreachable, but just that the condor daemons that run inside the glidein
seem to have been killed off by something, which makes them drop any active
socket connections to my pool collector and causes the condor_startd on the
worker node to send a kill signal to all of my running processes.  That
would produce the effect I am seeing.

-Richard Jones

On Wed, Apr 23, 2014 at 2&#58;55 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398279317'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-23T18:55:17+00:00">Apr 23, 2014 06:55 PM UTC</time><a class="anchor" name="1398279317">&nbsp;</a></div><pre>Hello Richard,
Site can debug it further if we can reproduce the problem at our end.  Is it possible to know which command failed while job was running on worker node at the site ?

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398278659'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-23T18:44:19+00:00">Apr 23, 2014 06:44 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398278659">&nbsp;</a></div><pre>Hello Manoj,

I am not sure if this question is directed to me or to the gfactory admins.
From my side, there are no logs because the glidein simply disappears, and
my condor_shadow times out after 20 minutes of trying to reconnect.  Before
the disconnect, the jobs were executing properly, as I can see by
submitting commands to the glidein monitor.

-Richard J.

On Tue, Apr 22, 2014 at 7&#58;26 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398278588'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-23T18:43:08+00:00">Apr 23, 2014 06:43 PM UTC</time><a class="anchor" name="1398278588">&nbsp;</a></div><pre>Adding Bo to this thread; he is tracking a similar problem for vo=osg

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Chander Sehgal 478</pre></div><div class='update_description'><i onclick="document.location='20576#1398278471'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-23T18:41:11+00:00">Apr 23, 2014 06:41 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398278471">&nbsp;</a></div><pre>Update on Gluex jobs failing at purdue&#58;

We still have consistent failures with our glideins running at Purdue.  At
least some of the jobs are starting ok and running for 1-2 hours, and then
disconnecting.  This is the same observation as I had back when I posted
this ticket.  It seems that the problem behind these failures is still
unresolved.

-Richard J.

On Tue, Apr 22, 2014 at 6&#58;50 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398209179'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-22T23:26:19+00:00">Apr 22, 2014 11:26 PM UTC</time><a class="anchor" name="1398209179">&nbsp;</a></div><pre>Could it be possible to share log files for one of the failed jobs ?  We would like to know following things

1.  What was  the job doing when it failed ?
2.  Is it possible to know  the load on factory when job failed ?

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398207449'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-22T22:57:29+00:00">Apr 22, 2014 10:57 PM UTC</time><a class="anchor" name="1398207449">&nbsp;</a></div><pre>Hi,

I&#39;ll give an update from the factory side. I see that Gluex hasn&#39;t submitted any glideins to this site in the last 2-3 days. The last batch of glideins was unsccessful due to wget erors. Today, other VOs continue to see nearly 100% validation failures due to the same wget problems. Somehow, glideins are still failing to download the files they need using wget.

Best,
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1398207009'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-22T22:50:09+00:00">Apr 22, 2014 10:50 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1398207009">&nbsp;</a></div><pre>Hello Manoj,

As of Monday morning, yes the problem was still occurring.  At that time I
paused production to upgrade my SE, so that it could handle connections
from hosts with SHA-256 signed certs, which are now proliferating on the
OSG.  I am starting up again tonight, and will post a follow-up.

-Richard J.

On Tue, Apr 22, 2014 at 4&#58;45 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1398199533'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-22T20:45:33+00:00">Apr 22, 2014 08:45 PM UTC</time><a class="anchor" name="1398199533">&nbsp;</a></div><pre>It seems network people had fixed the problem.   Is the user still facing the problem ?

Thanks,
Manoj

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=jha/CN=618566/CN=Manoj Jha</pre></div><div class='update_description'><i onclick="document.location='20576#1398198639'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-22T20:30:39+00:00">Apr 22, 2014 08:30 PM UTC</time> by <b>echism</b><a class="anchor" name="1398198639">&nbsp;</a></div><pre>Hi Majid,

Do you have an update on the network issues?

Thank you.</pre></div><div class='update_description'><i onclick="document.location='20576#1397670964'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-16T17:56:04+00:00">Apr 16, 2014 05:56 PM UTC</time><a class="anchor" name="1397670964">&nbsp;</a></div><pre>Hi Richard,

I don&#39;t know whether you saw, but on the other ticket I linked below (<a href='https&#58;//ticket.grid.iu.edu/20489' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/20489</a>), Manoj reported that network communications from the worker nodes are failing for packet sizes above a certain threshold, and they&#39;re working on fixing it. It&#39;s possible your keepalive trick has prevented connections from getting lost while your jobs are in progress. But this won&#39;t help the glideins themselves, because they perform their own validation process (including testing wget) before they turn themselves over to your control.

As Majid mentioned, Purdue is in downtime today, which means that I don&#39;t have any really good monitoring/history info available right now. Once they come out of downtime, we can advise you better on how things look from the aggregate glidein level. But checking the logs by hand, it looks like ~100% of your glideins yesterday failed validation with wget problems. I agree with Majid that we should wait and see how the situation looks once the site is out of downtime, and the Purdue people have had a chance to tackle the network failures.

Best,
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1397661734'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-16T15:22:14+00:00">Apr 16, 2014 03:22 PM UTC</time><a class="anchor" name="1397661734">&nbsp;</a></div><pre>Hi Richard,

We have announced a downtime at Purdue doing some migration. The downtime should  end by end of today.
then we will look into the problem again.

Thanks,
-Majid

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=marabgol/CN=653155/CN=Majid Arabgol</pre></div><div class='update_description'><i onclick="document.location='20576#1397659154'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-16T14:39:14+00:00">Apr 16, 2014 02:39 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1397659154">&nbsp;</a></div><pre>Hello,
Is there an update on this issue?
-Richard Jones

On Tue, Apr 15, 2014 at 3&#58;06 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1397588812'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-15T19:06:52+00:00">Apr 15, 2014 07:06 PM UTC</time><a class="anchor" name="1397588812">&nbsp;</a></div><pre>Hello Dan and all,

On a hunch, last night at around 10&#58;00pm I introduced &#34;keepalives&#34; to all of the sockets between outside glideins and my CCB servers.  I did this using libkeepalive.so loaded using LD_PRELOAD and set the keepalive frequency to 10 seconds.  After that, it seemed that my jobs running on hansen suddenly started living to full job completion.  But now I see that my glideins are no longer running at purdue.  Is this so that you can look further into the problem?

-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1397511012'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T21:30:12+00:00">Apr 14, 2014 09:30 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1397511012">&nbsp;</a></div><pre>Dan,

I think that this is on the right track.  It makes sense that an
intermittent network blockage would explain all of these symptoms.  I have
checked on my end, and my netops folks claim that they are not blocking any
incoming traffic from purdue.

-Richard J.

On Mon, Apr 14, 2014 at 4&#58;48 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1397508508'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T20:48:28+00:00">Apr 14, 2014 08:48 PM UTC</time><a class="anchor" name="1397508508">&nbsp;</a></div><pre>Hi Richard,

I think you misunderstood what I was trying to tell you. But it&#39;s not important, because in the first place I misunderstood the symptoms you were reporting. After you explained your situation a little more, I get it now. I was reporting that &#62;90% of your glideins are failing before they even &#34;call home&#34; to get your user jobs from the frontend. But you&#39;re claiming that, of the end-user jobs that do get picked up, most are aborting partway through.

In fact, I do see some evidence of that occurring in the logs of those few glideins that don&#39;t fail validation. For example&#58;

04/14/14 11&#58;06&#58;38 (pid&#58;23510) Remote owner is jonesrt@....
04/14/14 11&#58;06&#58;38 (pid&#58;23510) State change&#58; claiming protocol successful
04/14/14 11&#58;06&#58;38 (pid&#58;23510) Changing state&#58; Unclaimed -&#62; Claimed
04/14/14 11&#58;06&#58;39 (pid&#58;23510) attempt to connect to &#60;137.99.19.33&#58;9615&#62; failed&#58; No route to host (connect errno = 113).
04/14/14 11&#58;06&#58;39 (pid&#58;23510) CCBListener&#58; failed to create reversed connection for request id 14359 to &#60;137.99.19.33&#58;9615?sock=32128_d514_1&#62;&#58; failed to connect
...
04/14/14 11&#58;16&#58;38 (pid&#58;23510) State change&#58; claim no longer recognized by the schedd - removing claim
...
04/14/14 11&#58;16&#58;38 (pid&#58;23510) Changing state&#58; Owner -&#62; Unclaimed
04/14/14 11&#58;30&#58;55 (pid&#58;23510) condor_write()&#58; Socket closed when trying to write 4096 bytes to collector gremlin.phys.uconn.edu&#58;9670, fd is 9, errno=110 Connection timed out
04/14/14 11&#58;30&#58;55 (pid&#58;23510) Buf&#58;&#58;write()&#58; condor_write() failed
04/14/14 11&#58;35&#58;53 (pid&#58;23510) No resources have been claimed for 1200 seconds
04/14/14 11&#58;35&#58;53 (pid&#58;23510) Shutting down Condor on this machine.

Based on this and several other logs, it looks like a bunch of the glideins that pass validation are later losing their connection to your frontend, and as a result, are booting your jobs out. If there really is some kind of network problem at Purdue, it could explain both your symptom and my wget failures.

To Manoj/Majid&#58; aside from wget, have you checked for/noticed any other symptoms of network connection issues? It sounds like the problem is not just with wget, but also all sorts of other connections opened by the glideins.

Thanks,
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1397502369'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T19:06:09+00:00">Apr 14, 2014 07:06 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1397502369">&nbsp;</a></div><pre>Hello Dan,

To be more precise, I have had 93239 job starts on rcac.purdue.edu workers
over the past 4 days, and exactly 11 of these have failed because of
repeated wget failures.  That really is a miniscule effect on me right now.

-Richard Jones

On Mon, Apr 14, 2014 at 2&#58;15 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1397499313'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T18:15:13+00:00">Apr 14, 2014 06:15 PM UTC</time> by <b>GLUEX</b><a class="anchor" name="1397499313">&nbsp;</a></div><pre>Hello Dan,

I do see that, but I don&#39;t think this is my major problem.  I have a retry
loop on those wget&#39;s, and they are succeeding on the second or third try.
My jobs have a retry count of 3, and a 2 minute wait between tries.  This
is succeeding in a large majority of cases.  Maybe a few percent are
failing after retries are exhausted, so it might be a good thing to sort
out at some point, but for the moment I can live with that.  What I am
seeing is that my jobs are starting up successfully (all of the wgets are
done at the beginning) and executing my Geant simulation code, which is the
primary consumer of cpu for these jobs.  They are virtually all in the
middle of running a Geant simulation when they are spontaneously aborted
and exit without saving logs or anything.  To check that out, you can send
a monitor command, &#34;pstree -pl gluex&#34; and you can see that all of them are
running hdgeant.

-Richard Jones

On Mon, Apr 14, 2014 at 1&#58;57 PM, Open Science Grid FootPrints &#60;
osg@....&#62; wrote&#58;

<font color='#7F7E6F'>&#62;  [Duplicate message snipped]</font></pre></div><div class='update_description'><i onclick="document.location='20576#1397498269'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T17:57:49+00:00">Apr 14, 2014 05:57 PM UTC</time><a class="anchor" name="1397498269">&nbsp;</a></div><pre>Hi Richard,

I have an inkling as to why your glideins aren&#39;t successfully running your user jobs. Right now, this CE is having massive problems with glideins failing validation due to apparent wget problems on the worker nodes. I have a ticket open with the site admins here&#58; <a href='https&#58;//ticket.grid.iu.edu/20489' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/20489</a>

You may wish to follow that discussion, since it seems you&#39;re bearing the brunt of these glidein failures.

Regards,
Dan Klein
UCSD Glidein Factory Operations

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dklein/CN=747387/CN=Daniel Klein</pre></div><div class='update_description'><i onclick="document.location='20576#1397483252'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-14T13:47:32+00:00">Apr 14, 2014 01:47 PM UTC</time><a class="anchor" name="1397483252">&nbsp;</a></div><pre>Hello,

Could I inquire about any progress with this request?  I continue to consume large amounts of cpu time on rcac.purdue with nearly 0% success, and can find so far no clues as to why [1] my jobs are being started in large numbers (&#62;1000 jobs running at once on average, continuing now) and [2] my jobs are never running to completion (8 hrs).  I can see that my executables are running fine, generating output, and consuming cpu.  I get back empty logs and no results when the jobs disconnect.  Losing some fraction of them to preemption would be normal, but 100% loss seems exceptional when they are being started in such large numbers.

-Richard J.

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><div class='update_description'><i onclick="document.location='20576#1397071143'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2014-04-09T19:19:03+00:00">Apr 9, 2014 07:19 PM UTC</time> by <b>OSG-GOC</b><a class="anchor" name="1397071143">&nbsp;</a></div><pre>Hello osg site admin at rcac.purdue.edu&#58;
Thank you for being willing to accept glideins from our osg vo called Gluex.  We are presently doing a data challenge exercise to get ready for startup of the experiment in the fall, so you probably see a steady stream of gwms glideins from the Gluex vo showing up on your ce.  We are seeing a large number of glideins starting up at rcac.purdue (~2000 at a time) mainly from the hansen and coates clusters, and we are consuming quite a lot of cpu time in these glideins, but virtually no work is being completed.  This is opportunistic running, so we understand that this may be normal, but I would just like to check.  Is there something systematic in our setup that is causing our glideins to disconnect after typically 30-50 minutes of running on coates nodes, and after typically 2-5 hours of running on hansen?  (our job completion time is around 8 hours)  If this is due to normal preemption policies that are cutting our run times short of job completion, that is perfectly fine, but since we are burning quite a bit of cpu time and (currently) getting less than 10% completion at rcac.purdue, I thought I would investigate.  All I see in my job logs is, &#34;glidein disconnected&#34; messages for the jobs that are cut short, either from hansen or from coates.  In view of this inefficiency, would you request that we stop submitting to your site?  There is nothing inconvenient for us to be massively preempted, because the jobs just recycle back to the idle queue, but from the point of view of your production efficiency perhaps it is not nice for us to continue to operate in this manner.

thank you, -Richard Jones, OSG contact person for Gluex vo

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Richard T. Jones 594</pre></div><legend>Similar Recent Tickets <small>modified within the last 30 days</small></legend><div id="similar_tickets"><p class="muted">No similar tickets found.</p></div>
</div>
<script type="text/javascript">
function reset_anchor() {
    $("#updates .selected").removeClass("selected");
    var urls = document.location.toString().split('#'); 
    var anchor = urls[1];
    if(anchor) {
        $("a[name='"+anchor+"']").parents(".update_description").addClass("selected");
    }
}
function submitspam(ticket_id) {
    myret = confirm("Would you like to close this ticket as a security ticket, and submit the ticket content to akismet?");
    if(myret == true) {
        $.ajax("viewer/processspam?id="+ticket_id).done(function() {
            window.location.reload();
        });
    }
}

$(function() {
    reset_anchor();
    var ADDITIONAL_COOKIE_NAME = 'gocticket';
    var options = { path: '/', expires: 365};

    if(window.opener && window.opener.name == "gocticket_list") {
        v = $.cookie("closewindow");
        if(!v) {
            $("#closewindow").attr("checked", "checked"); //on by default
        } else {
            if(v == "checked") {
                $("#closewindow").attr("checked", "checked");
            }
        }
        $("#closewindow").click(function() {
            $.cookie("closewindow", $(this).attr('checked'), options);
        });
    } else {
        $("#closewindow_area").hide();
    }
    function updateTimeago() {
        $("time").timeago();
        setTimeout(updateTimeago, 30*1000);
    }
    updateTimeago();
    $(".description").focus(expand_description);
});
</script>
<hr/>
<footer>
<p>GOC Ticket Version 2.2 | <a href="https://ticket.opensciencegrid.org/goc/submit?app_issue_check=on&amp;app_issue_type=goc&amp;app_goc_url=https%3A%2F%2Fticket.opensciencegrid.org%3A443%2F20576">Report Bugs</a>
 | <a href="https://github.com/opensciencegrid/operations/blob/master/docs/privacy.md">Privacy Policy</a>
</p>

<p> <img align="top" src="images/tag_orange.png"/> Copyright 2018 The Trustees of Indiana University - Developed for Open Science Grid</p>
</footer>


</div><!--container-fluid-->
<script src="https://ticket1.grid.iu.edu:8443/socket.io/socket.io.js"></script>
<script>
var chat = io.connect('https://ticket1.grid.iu.edu:8443');
chat.on('connect', function() {
    chat.emit('authenticate', {nodekey:'', ticketid: 20576});
});
chat.on('peers', function(peers) {
    $("#peers").html("");
    for(var pid in peers) {
        var peer = peers[pid];
        addPeer(pid, peer);
    }
});
chat.on('peer_disconnect', function(pid) {
    $("#peer_"+pid).hide("slow");
});
chat.on('peer_connected', function(peers) {
    //expect only 1 peer connecting, but..
    for(var pid in peers) {
        var peer = peers[pid];
        addPeer(pid, peer);
    }
});
chat.on('submit', function() {
    if(confirm("This ticket was updated. Do you want to refresh?")) {
        history.go(0);
    }
});

function addPeer(pid, peer) {
    var ipinfo = "";
    if(peer.ip != undefined) {
        ipinfo = "<span class=\"ip\">"+peer.ip+"</span>";
    }
    if(chat.io.engine.id == pid) {
        //don't display myself
        return;
    }
    var html = "<li class=\"new\" id=\"peer_"+pid+"\" class=\"peer\">"+peer.name+ipinfo+"</li>";
    $("#peers").prepend(html);
    $("#peers .new").animate({bottom: 0}, 1000, function() {$(this).removeClass("new")});
}

$(function() {
    $("#ticket_form").submit(function() {
        chat.emit('submit');
        return true;
    });
});
</script>
<script>
//used by searchbox
function parseValue(value) {
    var obj = new Object();
    var tokens = value.split("\t");
    obj.str = tokens[0];
    obj.count = tokens[1];
    return obj;
}

$(function() {
    //bootstrap-2.0.4 stuff
    $(".alert-message").alert();
    $(".dropdown-toggle").dropdown();
    $("span[rel='tooltip']").tooltip();
    $("a[rel=popover]").popover();

    //activate menu that user is currently on
    $("#menu_navigator").addClass("active"); 
    $("#submenu_").addClass("active"); 

    //translate zend validation error message to bootstrap
    $(".errors").addClass("alert").addClass("alert-error");

    //enable autocomplete for search box
    $("#search").autocomplete({
        source: function( request, response ) {
            $.ajax({
                url: "search/autocomplete",
                dataType: "text",
                data: {
                    //featureClass: "P",
                    //style: "full",
                    //maxRows: 12,
                    //name_startsWith: request.term
                    q: request.term
                },
                success: function( data ) {
                    response( $.map( data.split("\n"), function( item ) {
                        if(item == "") return null;
                        return {
                            value: item
                        }
                    }));
                }
            });
        },
        select: function(event, ui) {
            document.location = "search?q="+ui.item.value;
        }
    });
    
});
</script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-69012-13");
pageTracker._trackPageview();
} catch(err) {}
</script>

</body>
