<!DOCTYPE html>
<html lang="en">
  <head>
  <base href="">
    <title>[26367] HTCondor CE troubleshooting</title>    <meta charset="utf-8" />
    <meta name="verify-v1" content="na5IcAJsZVOfEkboRxuIiZ1zpZgnZiWra+nKcS7nA/o=" />
    <meta name="google-site-verification" content="DLrk3ft4s8b-S2TloLCL2LD_t6wcTjgSluf5pmiu2kA" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="" />
    <link href="https://ticket.opensciencegrid.org/rss" rel="alternate" type="application/rss+xml" title="GOC Ticket Update feed" />

    <style type="text/css">
      body {
        padding-top: 50px;
        padding-bottom: 40px;
      }
      .sidebar-nav {
        padding: 9px 0;
      }
     #search {
            width: 300px;
     }

    </style>

<script src="https://code.jquery.com/jquery-3.0.0.js"></script>
<script src="https://code.jquery.com/jquery-migrate-3.0.1.js"></script>

   <link href="https://netdna.bootstrapcdn.com/bootstrap/2.3.2/css/bootstrap.min.css" rel="stylesheet"/>
    <script src="https://netdna.bootstrapcdn.com/bootstrap/2.3.2/js/bootstrap.min.js"></script>

    <link href="https://netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet"/>
    <link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/themes/smoothness/jquery-ui.min.css" rel="stylesheet"/>
 <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>


    <link href="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.0-rc.2/css/select2.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.0-rc.2/js/select2.min.js"></script>

    <link href="css/ticket.css" rel="stylesheet" />
    <script src="lib/jquery.cookie.js"></script>

    <link href="images/tag_orange.png" rel="icon" type="image/png"/>
  </head>

  <body>
    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container-fluid">
            <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </a>

            <a class="brand" style="padding: 6px 0px 0px 6px;" href="http://opensciencegrid.org"><img src="images/osglogo.40x30.png"/></a>
            <ul class="nav">
                <li class="dropdown"><a href="https://ticket.opensciencegrid.org/#" class="dropdown-toggle" data-toggle="dropdown">GOC Ticket <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    <li><a href="https://my.opensciencegrid.org">MyOSG</a></li>
                    <li><a href="https://oim.opensciencegrid.org">OIM</a></li>
                    <li class="active"><a href="https://ticket.opensciencegrid.org/index">Ticket</a></li>
	<li class="divider"></li>
	<li><a href="http://repo.grid.iu.edu">Repo</a></li>
	<li class="divider"></li>
	<li><a href="http://blogs.grid.iu.edu">Blog</a></li>
                    <li><a href="http://display.grid.iu.edu">Display</a></li>
                    <li><a href="http://osggoc.blogspot.com/">News</a></li>
                    </ul>
                </li>
            </ul>
            <ul class="nav pull-right">
                <li><a href="https://ticket.opensciencegrid.org/sso/">Login</a></li>            </ul>

            <div class="nav-collapse">
                <ul class="nav">
			 <li id="menu_submit"><a href="https://ticket.opensciencegrid.org/submit">Submit</a></li><li id="menu_view" class="dropdown"><a href="https://ticket.opensciencegrid.org/\#" class="dropdown-toggle" data-toggle="dropdown">View <b class="caret"></b></a><ul class="dropdown-menu"><li id="submenu_listopen"><a href="https://ticket.opensciencegrid.org/list/open">Open Tickets</a></li><li id="submenu_listrecentclose"><a href="https://ticket.opensciencegrid.org/list/recentclose">Recently Closed Tickets</a></li><li class="divider"></li><li id="submenu_alltickets"><a href="https://ticket.opensciencegrid.org/search?q=&amp;sort=id">All Tickets</a></li></ul></li>                </ul>

                <form class="navbar-search pull-right" action="https://ticket.opensciencegrid.org/viewer">
                    <input id="search" type="text" name="id" class="search-query span2" placeholder="Search Ticket" value=""/>
                </form>
            </div>
        </div>
      </div>
    </div>

<script type='text/javascript' src='lib/jquery.timeago.js'></script>
<script type='text/javascript' src='lib/byte2size.js'></script>
<style>
#updates .toolbar {
position: relative;
margin-top: 0px;
top: -10px;
font-weight: normal;
}
#updates a.anchor {
position: relative;
top: -50px;
}
#updates .selected pre {
animation:selected 2s;
animation-iteration-count: 2;
animation-direction: alternate;
-webkit-animation:selected 2s; 
-webkit-animation-iteration-count: 2;
-webkit-animation-direction: alternate;
box-shadow: inset 1px 1px 20px #9ad;
border: 1px solid #9ab;
margin: 5px 0px;
padding-left: 10px;
}
@keyframes selected {
    from  {
        box-shadow: inset 1px 1px 20px #9ad;
        border: 1px solid #9ab;
    }
    to {
        box-shadow: inset 1px 1px 20px #05c;
        border: 1px solid #05c;
    }
}
@-webkit-keyframes selected {
    from  {
        box-shadow: inset 1px 1px 20px #9ad;
        border: 1px solid #9ad;
    }
    to {
        box-shadow: inset 1px 1px 20px #05c;
        border: 1px solid #05c;
    }
}
#updates pre {
background-color: inherit;
line-height: 15px;
padding: 5px;
}
#updates .header {
color: #999;
}
#updates .update_history pre {
background-color: #eee;
color: #666;
font-size: 85%;
}
#updates .clickable {
cursor: pointer;
}
#updates .clickable:hover {
color: #D98719;
}
#updates .meta_information pre {
background-color: #fed;
}
#similar_tickets {
max-height: 300px;
overflow-y: auto;
pointer-events: none;
padding: 5px;
background-color: #f4f4f4;
}
.btn-toolbar {
margin-bottom: 0;
height: 30px;
}
#peers {
position: fixed;
bottom: 0px;
right: 0px;
z-index: 100;
list-style: none;
padding: 5px 0px 0px 5px;
margin: 0px;
background-color: white;
box-shadow: 0px 0px 10px white;
}
#peers li {
background-color: #ccc;
color: #000;
display: inline-block;
padding: 5px 10px;
margin-right: 5px;
position: relative;
}
/*
#peers li:hover {
background-color: #999;
cursor: pointer;
}
*/
#peers span.ip {
padding-left: 5px;
color: #666;
}
#peers .new {
bottom: -30px;
}
/*
#peers .me {
background-color: red;
}
*/
</style>

<div class="container-fluid">
<ul id="peers"></ul>
<div class="alert alert-danger"><a class="close" href="https://ticket.opensciencegrid.org/#" data-dismiss="alert">&times;</a>By the end of May 2018, the ticketing system at https://ticket.opensciencegrid.org will be retired and support will be provided at https://support.opensciencegrid.org. Throughout this transition the support email (help@opensciencegrid.org) will be available as a point of contact.<br><br>                                                   
                                                                                                                                                                                   
Please see the service migration page for details: https://opensciencegrid.github.io/technology/policy/service-migrations-spring-2018/#ticket</div><div id="presence" class="pull-right"></div><div class="ticketgui"><script type="text/javascript" src="lib/checktab.js"></script>

<script>
var expanded = false;
function expand_description() {
    var desc = $(".description");
    if(!expanded) {
        expanded = true;
        //expand to minheight
        var min = 250;
        if(desc.height() < min) {
            desc.animate({height: min}, 200);
        }
    }
}

$(document).ready(function() {
    $("input[name='nad']").datepicker({
        dateFormat: 'yy-mm-dd'
    });
});

</script>



<style>
.form-horizontal .control-label {
padding-top: inherit;
font-size:90%;
color:#666;
}
label {
margin-bottom: 0px;
}
.controls {
line-height: 18px;
}
</style>
<form class="form-horizontal" action="https://ticket.opensciencegrid.org/viewer/updatebasic?id=26367" method="post">
<div class="page-header">
    <h3><span class="muted">26367</span> / HTCondor CE troubleshooting</h3>
</div>

<div class="row-fluid">
<div class="span5">
    <legend>Contact</legend>
    <div class="control-group">
        <label class="control-label">Full Name</label>
        <div class="controls">Daniel Caunt</div>
    </div>
    <div class="control-group">
        <label class="control-label">Email</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>
    <div class="control-group">
        <label class="control-label">Phone</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>
    <div class="control-group">
        <label class="control-label">CC</label>
        <div class="controls">
            <i class="icon-lock"></i>        </div>
    </div>

    <legend>Details</legend>
    <div class="control-group"><label class="control-label">Submitted Via</label><div class="controls">GOC Ticket/submit</div></div><div class="control-group"><label class="control-label">Submitter</label><div class="controls">Daniel Caunt</div></div><div class="control-group"><label class="control-label">Ticket Links</label><div class="controls"></div></div>
    <div class="control-group">
        <label class="control-label">Ticket Type</label>
        <div class="controls">Problem/Request</div>
    </div>
    <div class="control-group">
        <label class="control-label">Priority</label>
        <div class="controls">Normal</div>
    </div>
    <div class="control-group">
        <label class="control-label">Status</label>
        <div class="controls">
Closed</div>
    </div>
    <div class="control-group">
        <label class="control-label">Next Action</label>
        <div class="controls">Wait for user response</div>
    </div>
    <div class="control-group">
        <label class="control-label">Next Action Deadline</label>
        <div class="controls flag_red">2015-09-11</div>
    </div>

</div><!--span-->
<div class="span7">
    <legend>Assignees</legend>
    <div class="assignee" style="width: 60%">OSG RA <span class="muted"> / OSG GOC Support Team</span></div><div class="assignee" style="width: 60%">Software Support (Triage) <span class="muted"> / OSG Software Team</span></div><div class="assignee" style="width: 60%">Tim Cartwright <span class="muted"> / OSG Software Team</span></div><div class="assignee" style="width: 60%">Brian Lin <span class="muted"> / OSG Software Team</span></div><div class="assignee" style="width: 60%">Matyas Selmeci <span class="muted"> / OSG Software Team</span></div>    <br>

    <legend>Assignees</legend>
    TODO
    <br>

    <style>
legend.noborder {
border-bottom: none;
}
</style>

<div id="attachment-list"/>
<script>
$(function () {
    var first = true;
    $.getJSON("attachment/list/26367", function (files) {
        //console.dir(files);
        var html = "<table class=\"table table-condensed\">";
        $(files).each(function() {
            if(first) {
                first = false;
                html += "<legend class=\"noborder\">Attachmenets</legend>";
            }
            html += "<tr class=\"attachment\">";
            html += "<td><img src=\""+this.thumbnail_url+"\"/></td>";
            html += "<td><a href=\""+this.url+"\" target=\"_blank\">"+this.name+"</a></td>";
            html += "<td>"+bytesToSize(this.size, 1)+"</td>";
            html += "</tr>";
        });
        html += "</table>";
        $("#attachment-list").html(html);
    });
});

function download(url) {
    window.open(url, "_blank");
}
</script>


</div><!--span-->
</div><!--row-fluid-->


</form>

</div>
<div id="updates" style="clear: both;">
    <legend>Past Updates
    <div class="btn-toolbar pull-right toolbar">
    </div><!--btn-toolbar-->
    </legend>

    <div class='update_description'><i onclick="document.location='26367#1446674940'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-11-04T22:09:00+00:00">Nov 4, 2015 10:09 PM UTC</time><a class="anchor" name="1446674940">&nbsp;</a></div><pre>Hi Brian,

I&#39;m going to open a new ticket as suggested.  I don&#39;t have another host with the needed tools (voms-proxy-init, condor-ce-trace) so I&#39;m installing them now and a question arose.  I&#39;ll post this question in the new ticket.  Thanks.

Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1442936218'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-22T15:36:58+00:00">Sep 22, 2015 03:36 PM UTC</time><a class="anchor" name="1442936218">&nbsp;</a></div><pre>Hi Daniel,

Sorry for your loss.

There should be no problem reopening this ticket once you get back.  However, since so much focused on the now-solved auth issues, it may be beneficial to open a fresh one once you get back (tickets with long histories can get unwieldy).

Anyhow, it&#39;s up to you.  No rush; we can wait until you get back.

Brian

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=bbockelm/CN=659869/CN=Brian Paul Bockelman</pre></div><div class='update_description'><i onclick="document.location='26367#1442922336'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-22T11:45:36+00:00">Sep 22, 2015 11:45 AM UTC</time><a class="anchor" name="1442922336">&nbsp;</a></div><pre>I&#39;m sorry.  I have been (and still am) out of the office due to the loss of a close family member.  I still need to resolve this HTCondorCE problem, so if this ticket could be left open (or at least in some kind of &#34;hold&#34; status) I do still want to work on it when I return.  Thank you.

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1442341707'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-15T18:28:27+00:00">Sep 15, 2015 06:28 PM UTC</time> by <b>Neha Sharma</b><a class="anchor" name="1442341707">&nbsp;</a></div><pre>Daniel - I guess we are waiting for a confirmation from you on if this ticket can be closed &#58;-)

- Neha</pre></div><div class='update_description'><i onclick="document.location='26367#1441899347'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-10T15:35:47+00:00">Sep 10, 2015 03:35 PM UTC</time> by <b>Brian Lin</b><a class="anchor" name="1441899347">&nbsp;</a></div><pre>Daniel,

Glad to hear from you and that things are going well. I&#39;m going to close this ticket since the original problem has been solved but there are a few more things that you&#39;ll want to do to verify your HTCondor CE&#58;

1) Let the trace command finish. Once a job completes successfully, it will output the environment of the worker node that it lands on.
2) Whenever you have the time, install htcondor-ce-client on a separate host and run &#96;condor_ce_trace&#96; run from there. We will need to verify remote job submission before we can move forward with the glidein factories.

- Brian</pre></div><div class='update_description'><i onclick="document.location='26367#1441897744'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-10T15:09:04+00:00">Sep 10, 2015 03:09 PM UTC</time><a class="anchor" name="1441897744">&nbsp;</a></div><pre>Brian,

I&#39;m glad I could help with the testing of the network script.  Thanks for making helpful tools like that for us.

As for condor_ce_trace, I think you were also right about me forgetting to run voms-proxy-init before trying the trace.  Now it seems to be getting further&#58;

------
[dcaunt@net2 ~]$ condor_ce_trace --debug net2.rc.fas.harvard.edu
09/10/15 10&#58;59&#58;44 Result of reading /etc/issue&#58;  CentOS release 6.5 (Final)

09/10/15 10&#58;59&#58;44 Using IDs&#58; 16 processors, 8 CPUs, 8 HTs
09/10/15 10&#58;59&#58;44 Enumerating interfaces&#58; lo 127.0.0.1 up
09/10/15 10&#58;59&#58;44 Enumerating interfaces&#58; eth2 10.31.131.202 up
09/10/15 10&#58;59&#58;44 Enumerating interfaces&#58; eth3 140.247.179.131 up
09/10/15 10&#58;59&#58;44 Initializing Directory&#58; curr_dir = /usr/share/condor-ce/config.d
09/10/15 10&#58;59&#58;44 Initializing Directory&#58; curr_dir = /etc/condor-ce/config.d
Testing HTCondor-CE collector connectivity.
***** condor_ping output *****
Remote Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Local  Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Session ID&#58;                  net2&#58;16484&#58;1441897185&#58;115
Instruction&#58;                 READ
Command&#58;                     60020
Encryption&#58;                  none
Integrity&#58;                   none
Authentication&#58;              none
Remote Mapping&#58;              unauthenticated@unmapped
Authorized&#58;                  TRUE

********************
- Successful ping of collector on &#60;10.31.131.202&#58;9619&#62;.

09/10/15 10&#58;59&#58;45 Will use TCP to update collector net2.rc.fas.harvard.edu &#60;10.31.131.202&#58;9619&#62;
09/10/15 10&#58;59&#58;45 Trying to query collector &#60;10.31.131.202&#58;9619&#62;
09/10/15 10&#58;59&#58;45 IPVERIFY&#58; checking net2.rc.fas.harvard.edu against 10.31.131.202
<div id='show_334908173' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_334908173'>09/10/15 10&#58;59&#58;45 IPVERIFY&#58; matched 10.31.131.202 to 10.31.131.202
09/10/15 10&#58;59&#58;45 IPVERIFY&#58; ip found is 1
Testing HTCondor-CE schedd connectivity.
***** condor_ping output *****
Remote Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Local  Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Session ID&#58;                  net2&#58;16486&#58;1441897185&#58;113
Instruction&#58;                 WRITE
Command&#58;                     60021
Encryption&#58;                  none
Integrity&#58;                   MD5
Authenticated using&#58;         FS
All authentication methods&#58;  FS,GSI
Remote Mapping&#58;              dcaunt@....
Authorized&#58;                  TRUE

********************
- Successful ping of schedd on &#60;10.31.131.202&#58;9620?sock=16108_460f_4&#62;.

Job ad, pre-submit&#58;
[
Out = &#34;/n/home_rc/dcaunt/.stdout_11913_fbkGSE&#34;;
Log = &#34;/n/home_rc/dcaunt/.log_11913_5BQDHX&#34;;
x509UserProxyExpiration = 1441940195;
x509userproxysubject = &#34;/DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt/CN=proxy&#34;;
Args = &#34;&#34;;
Cmd = &#34;/usr/bin/env&#34;;
Err = &#34;/n/home_rc/dcaunt/.stderr_11913_CcLezU&#34;;
LeaveJobInQueue = ( StageOutFinish &#62; 0 ) isnt true;
x509userproxy = &#34;/tmp/x509up_u556792&#34;
]
Submitting job to schedd &#60;10.31.131.202&#58;9620?sock=16108_460f_4&#62;
09/10/15 10&#58;59&#58;45 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
09/10/15 10&#58;59&#58;45 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
- Successful submission; cluster ID 8
Resulting job ad&#58;
[
BufferSize = 524288;
NiceUser = false;
CoreSize = -1;
CumulativeSlotTime = 0;
OnExitHold = false;
RequestCpus = 1;
Err = &#34;_condor_stderr&#34;;
BufferBlockSize = 32768;
x509userproxy = &#34;/tmp/x509up_u556792&#34;;
TransferOutputRemaps = &#34;_condor_stdout=/n/home_rc/dcaunt/.stdout_11913_fbkGSE;_condor_stderr=/n/home_rc/dcaunt/.stderr_11913_CcLezU&#34;;
ImageSize = 100;
CurrentTime = time();
WantCheckpoint = false;
CommittedTime = 0;
TargetType = &#34;Machine&#34;;
WhenToTransferOutput = &#34;ON_EXIT&#34;;
Cmd = &#34;/usr/bin/env&#34;;
JobUniverse = 5;
ExitBySignal = false;
HoldReasonCode = 16;
Iwd = &#34;/n/home_rc/dcaunt&#34;;
NumRestarts = 0;
CommittedSuspensionTime = 0;
Owner = undefined;
NumSystemHolds = 0;
CumulativeSuspensionTime = 0;
RequestDisk = DiskUsage;
Requirements = true && TARGET.OPSYS == &#34;LINUX&#34; && TARGET.ARCH == &#34;X86_64&#34; && TARGET.HasFileTransfer && TARGET.Disk &#62;= RequestDisk && TARGET.Memory &#62;= RequestMemory;
MinHosts = 1;
JobNotification = 0;
NumCkpts = 0;
LastSuspensionTime = 0;
NumJobStarts = 0;
WantRemoteSyscalls = false;
JobPrio = 0;
RootDir = &#34;/&#34;;
CurrentHosts = 0;
x509UserProxyExpiration = 1441940195;
StreamOut = false;
WantRemoteIO = true;
OnExitRemove = true;
DiskUsage = 1;
In = &#34;/dev/null&#34;;
PeriodicRemove = false;
RemoteUserCpu = 0.0;
LocalUserCpu = 0.0;
LocalSysCpu = 0.0;
RemoteSysCpu = 0.0;
ClusterId = 8;
Log = &#34;/n/home_rc/dcaunt/.log_11913_5BQDHX&#34;;
CompletionDate = 0;
RemoteWallClockTime = 0.0;
LeaveJobInQueue = JobStatus == 4 && ( CompletionDate is UNDDEFINED || CompletionDate == 0 || ( ( time() - CompletionDate ) &#60; 864000 ) );
CondorVersion = &#34;$CondorVersion&#58; 8.2.8 Apr 08 2015 $&#34;;
MyType = &#34;Job&#34;;
StreamErr = false;
HoldReason = &#34;Spooling input data files&#34;;
PeriodicHold = false;
ProcId = 0;
Out = &#34;_condor_stdout&#34;;
JobStatus = 5;
PeriodicRelease = false;
RequestMemory = ifthenelse(MemoryUsage isnt undefined,MemoryUsage,( ImageSize + 1023 ) / 1024);
Args = &#34;&#34;;
MaxHosts = 1;
TotalSuspensions = 0;
CommittedSlotTime = 0;
x509userproxysubject = &#34;/DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt/CN=proxy&#34;;
CondorPlatform = &#34;$CondorPlatform&#58; X86_64-CentOS_6.6 $&#34;;
ShouldTransferFiles = &#34;YES&#34;;
ExitStatus = 0;
QDate = 1441897185;
EnteredCurrentStatus = 1441897185
]
Spooling cluster 8 files to schedd &#60;10.31.131.202&#58;9620?sock=16108_460f_4&#62;
09/10/15 10&#58;59&#58;45 SharedPortClient&#58; sent connection request to &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
09/10/15 10&#58;59&#58;45 entering FileTransfer&#58;&#58;SimpleInit
09/10/15 10&#58;59&#58;45 Input files&#58;
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; protocol &#34;http&#34; handled by &#34;/usr/libexec/condor/curl_plugin&#34;
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; protocol &#34;ftp&#34; handled by &#34;/usr/libexec/condor/curl_plugin&#34;
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; protocol &#34;file&#34; handled by &#34;/usr/libexec/condor/curl_plugin&#34;
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; protocol &#34;data&#34; handled by &#34;/usr/libexec/condor/data_plugin&#34;
09/10/15 10&#58;59&#58;45 entering FileTransfer&#58;&#58;UploadFiles (final_transfer=0)
09/10/15 10&#58;59&#58;45 entering FileTransfer&#58;&#58;Upload
09/10/15 10&#58;59&#58;45 entering FileTransfer&#58;&#58;DoUpload
09/10/15 10&#58;59&#58;45 DoUpload&#58; sending file /tmp/x509up_u556792
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; outgoing file_command is 4 for /tmp/x509up_u556792
09/10/15 10&#58;59&#58;45 Received GoAhead from peer to send /tmp/x509up_u556792 and all further files.
09/10/15 10&#58;59&#58;45 Sending GoAhead for 10.31.131.202 to receive /tmp/x509up_u556792 and all further files.
09/10/15 10&#58;59&#58;45 DoUpload&#58; put_x509_delegation() returned 0
09/10/15 10&#58;59&#58;45 DoUpload&#58; sending file /usr/bin/env
09/10/15 10&#58;59&#58;45 FILETRANSFER&#58; outgoing file_command is 1 for /usr/bin/env
09/10/15 10&#58;59&#58;45 ReliSock&#58;&#58;put_file_with_permissions()&#58; going to send permissions 100755
09/10/15 10&#58;59&#58;45 put_file&#58; going to send from filename /usr/bin/env
09/10/15 10&#58;59&#58;45 put_file&#58; Found file size 26368
09/10/15 10&#58;59&#58;45 put_file&#58; sending 26368 bytes
09/10/15 10&#58;59&#58;45 ReliSock&#58; put_file&#58; sent 26368 bytes
09/10/15 10&#58;59&#58;45 DoUpload&#58; exiting at 3335
- Successful spooling
Querying job status (1/600)
09/10/15 10&#58;59&#58;45 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Held
Querying job status (2/600)
09/10/15 10&#58;59&#58;46 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (3/600)
09/10/15 10&#58;59&#58;47 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (4/600)
09/10/15 10&#58;59&#58;48 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (5/600)
09/10/15 10&#58;59&#58;49 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (6/600)
09/10/15 10&#58;59&#58;50 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (7/600)
09/10/15 10&#58;59&#58;51 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (8/600)
09/10/15 10&#58;59&#58;52 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (9/600)
09/10/15 10&#58;59&#58;53 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (10/600)
09/10/15 10&#58;59&#58;54 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
Querying job status (11/600)
09/10/15 10&#58;59&#58;55 SharedPortClient&#58; sent connection request to schedd at &#60;10.31.131.202&#58;9620&#62; for shared port id 16108_460f_4
Job status&#58; Idle
^CTraceback (most recent call last)&#58;
File &#34;/usr/bin/condor_ce_trace&#34;, line 349, in &#60;module&#62;
main()
File &#34;/usr/bin/condor_ce_trace&#34;, line 342, in main
check_job_submit(job_info)
File &#34;/usr/bin/condor_ce_trace&#34;, line 288, in check_job_submit
time.sleep(1)
KeyboardInterrupt
-----

Since this looks like things are working, I&#39;m going to continue with the Condor-CE installation/configuration.  But if you notice anything unusual in the output, let me know.  I admit that I don&#39;t know what &#34;normal&#34; Condor-CE output looks like since this is my first time running it.  Sorry that I didn&#39;t have time to configure a remote host for the condor_ce_trace test but it seemed that the local test was working, and so it didn&#39;t seem like that test was needed anymore.

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt
</div><script type='text/javascript'>
        $('#show_334908173').click(function() {
            $('#detail_334908173').slideDown("normal");
            $('#show_334908173').hide();
            $('#hide_334908173').show();
        });
        $('#hide_334908173').click(function() {
            $('#detail_334908173').slideUp();
            $('#hide_334908173').hide();
            $('#show_334908173').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='26367#1441742455'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-08T20:00:55+00:00">Sep 8, 2015 08:00 PM UTC</time><a class="anchor" name="1441742455">&nbsp;</a></div><pre>Hi Daniel,

Separate from the condor_ce_trace stuff -

I&#39;d like to say a big thank you for testing out the network configuration testing script.  I think it now detects this particular failure mode well and will (hopefully) serve other sites!

Brian

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=bbockelm/CN=659869/CN=Brian Paul Bockelman</pre></div><div class='update_description'><i onclick="document.location='26367#1441734328'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-08T17:45:28+00:00">Sep 8, 2015 05:45 PM UTC</time> by <b>Brian Lin</b><a class="anchor" name="1441734328">&nbsp;</a></div><pre>Daniel,

Have you had the chance to run condor_ce_trace from an alternative host?

Thanks,
Brian</pre></div><div class='update_description'><i onclick="document.location='26367#1441379200'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-04T15:06:40+00:00">Sep 4, 2015 03:06 PM UTC</time> by <b>Brian Lin</b><a class="anchor" name="1441379200">&nbsp;</a></div><pre>Daniel,

Getting back to the X509 proxy issue with condor_ce_trace, did you run voms-proxy-init before running condor_ce_trace?

- Brian</pre></div><div class='update_description'><i onclick="document.location='26367#1441293648'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-03T15:20:48+00:00">Sep 3, 2015 03:20 PM UTC</time><a class="anchor" name="1441293648">&nbsp;</a></div><pre>Thanks for the updated script.  Here&#39;s the new output&#58;

Starting analysis of host networking for HTCondor-CE
System hostname&#58; net2.rc.fas.harvard.edu
FQDN matches hostname
Forward resolution of hostname net2.rc.fas.harvard.edu is 10.31.131.202.
Backward resolution of IPv4 10.31.131.202 is net2.rc.fas.harvard.edu.
Forward and backward resolution match!
HTCondor is considering all network interfaces and addresses.
HTCondor would pick address of 140.247.179.131 as primary address.
Backward of resolution of HTCondor address 140.247.179.131 matches default hostname of net2.rc.fas.harvard.edu.
HTCondor primary address 140.247.179.131 is not a valid address for default FQDN of net2.rc.fas.harvard.edu.
Host network configuration not expected to work with HTCondor-CE.

I still owe you the condor_ce_trace output from a different host.  I don&#39;t currently have another host configured to run that which is why it&#39;s taking a little bit of time.  I&#39;ll reply again as soon as I have it.

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1441223245'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-02T19:47:25+00:00">Sep 2, 2015 07:47 PM UTC</time> by <b>Matyas Selmeci</b><a class="anchor" name="1441223245">&nbsp;</a></div><pre>Sorry Dan, there needed to be a different change to fix the error you saw. Please redownload the script before you try again.
-Mat</pre></div><div class='update_description'><i onclick="document.location='26367#1441213636'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-02T17:07:16+00:00">Sep 2, 2015 05:07 PM UTC</time><a class="anchor" name="1441213636">&nbsp;</a></div><pre>Thanks Dan,

We have updated the script again (same URL this time) to take care of the error you observe below.

One more time please!

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=bbockelm/CN=659869/CN=Brian Paul Bockelman</pre></div><div class='update_description'><i onclick="document.location='26367#1441200190'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-02T13:23:10+00:00">Sep 2, 2015 01:23 PM UTC</time><a class="anchor" name="1441200190">&nbsp;</a></div><pre>Hi Brian,

I&#39;ll have to try the condor_ce_trace from a different host and get back to you with the results.  In the meantime, here&#39;s the output from the new script&#58;

----
Starting analysis of host networking for HTCondor-CE
System hostname&#58; net2.rc.fas.harvard.edu
FQDN matches hostname
Forward resolution of hostname net2.rc.fas.harvard.edu is 10.31.131.202.
Backward resolution of IPv4 10.31.131.202 is net2.rc.fas.harvard.edu.
Forward and backward resolution match!
HTCondor is considering all network interfaces and addresses.
Traceback (most recent call last)&#58;
File &#34;condor_ce_host_network_check2&#34;, line 318, in &#60;module&#62;
main()
File &#34;condor_ce_host_network_check2&#34;, line 263, in main
condor_addr = pick_condor_addr()
File &#34;condor_ce_host_network_check2&#34;, line 159, in pick_condor_addr
for ipv4_addr in ipv4_addrs&#58;
TypeError&#58; &#39;NoneType&#39; object is not iterable
----

I&#39;d be happy to run it again anytime.  I appreciate you building tools to help us out!

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1441126352'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-09-01T16:52:32+00:00">Sep 1, 2015 04:52 PM UTC</time><a class="anchor" name="1441126352">&nbsp;</a></div><pre>Hi Daniel,

I think the basic parts are working.  It would be useful to use condor_ce_trace from a different host to test your GSI authentication.  To do so, you&#39;ll need a valid user proxy (run voms-proxy-init prior to condor_ce_trace).

Additionally, I think I have improved the network check to better detect this particular issue.  Can you re-run this updated version&#58;

<a href='https&#58;//raw.githubusercontent.com/bbockelm/htcondor-ce/host_network_check_v2/src/condor_ce_host_network_check' target='_blank' rel='nofollow'>https&#58;//raw.githubusercontent.com/bbockelm/htcondor-ce/host_network_check_v2/src/condor_ce_host_network_check</a>

and post the output?  Thanks - I&#39;m sure future sysadmins will appreciate it!

Brian

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=bbockelm/CN=659869/CN=Brian Paul Bockelman</pre></div><div class='update_description'><i onclick="document.location='26367#1441054195'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-31T20:49:55+00:00">Aug 31, 2015 08:49 PM UTC</time><a class="anchor" name="1441054195">&nbsp;</a></div><pre>Thanks for testing the script!

Looks like it&#39;s not quite detecting this situation.  I&#39;ll run through the condor source code again and see if I can come up with a better replication.

The closer we can replicate the logic without having to get folks to dive through HTCondor logs, the better!

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=bbockelm/CN=659869/CN=Brian Paul Bockelman</pre></div><div class='update_description'><i onclick="document.location='26367#1441047449'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-31T18:57:29+00:00">Aug 31, 2015 06:57 PM UTC</time> by <b>boj@....</b><a class="anchor" name="1441047449">&nbsp;</a></div><pre>I am on vacation and will have no email access until September 7. For issues involving the OSG production support group, please send email to osg-prod-support@..... For CMS opportunistic computing, please send email to cms-comp-ops-opportunistic-workflows@....</pre></div><div class='update_description'><i onclick="document.location='26367#1441047371'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-31T18:56:11+00:00">Aug 31, 2015 06:56 PM UTC</time><a class="anchor" name="1441047371">&nbsp;</a></div><pre>Thanks, Mat!  And thanks to Brian for the script!  Here&#39;s the output from the script&#58;

----
Starting analysis of host networking for HTCondor-CE
System hostname&#58; net2.rc.fas.harvard.edu
FQDN matches hostname
Forward resolution of hostname net2.rc.fas.harvard.edu is 10.31.131.202.
Backward resolution of IPv4 10.31.131.202 is net2.rc.fas.harvard.edu.
Forward and backward resolution match!
Host network configuration should work with HTCondor-CE
----

I ran this after making the change to include &#34;FS&#34; in /etc/condor-ce/config.d/01-common-auth.conf

Making that change seems to have improved the situation.  I no longer get errors logs emailed to me when I start the condor-ce service on net2.  But here is what I&#39;m seeing when I run condor_ce_trace on the CE&#58;

----
[dcaunt@net2 ~]$ condor_ce_trace --debug net2.rc.fas.harvard.edu
08/28/15 13&#58;41&#58;56 Result of reading /etc/issue&#58;  CentOS release 6.5 (Final)

08/28/15 13&#58;41&#58;56 Using IDs&#58; 16 processors, 8 CPUs, 8 HTs
08/28/15 13&#58;41&#58;56 Enumerating interfaces&#58; lo 127.0.0.1 up
08/28/15 13&#58;41&#58;56 Enumerating interfaces&#58; eth2 10.31.131.202 up
08/28/15 13&#58;41&#58;56 Enumerating interfaces&#58; eth3 140.247.179.131 up
08/28/15 13&#58;41&#58;56 Initializing Directory&#58; curr_dir = /usr/share/condor-ce/config.d
08/28/15 13&#58;41&#58;56 Initializing Directory&#58; curr_dir = /etc/condor-ce/config.d
Testing HTCondor-CE collector connectivity.
***** condor_ping output *****
Remote Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Local  Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Session ID&#58;                  net2&#58;4526&#58;1440783716&#58;10
Instruction&#58;                 READ
Command&#58;                     60020
Encryption&#58;                  none
Integrity&#58;                   none
<div id='show_2118123689' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_2118123689'>Authentication&#58;              none
Remote Mapping&#58;              unauthenticated@unmapped
Authorized&#58;                  TRUE

********************
- Successful ping of collector on &#60;10.31.131.202&#58;9619&#62;.

08/28/15 13&#58;41&#58;56 Will use TCP to update collector net2.rc.fas.harvard.edu &#60;10.31.131.202&#58;9619&#62;
08/28/15 13&#58;41&#58;56 Trying to query collector &#60;10.31.131.202&#58;9619&#62;
08/28/15 13&#58;41&#58;56 IPVERIFY&#58; checking net2.rc.fas.harvard.edu against 10.31.131.202
08/28/15 13&#58;41&#58;56 IPVERIFY&#58; matched 10.31.131.202 to 10.31.131.202
08/28/15 13&#58;41&#58;56 IPVERIFY&#58; ip found is 1
Testing HTCondor-CE schedd connectivity.
***** condor_ping output *****
Remote Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Local  Version&#58;              $CondorVersion&#58; 8.2.8 Apr 08 2015 $
Session ID&#58;                  net2&#58;5781&#58;1440783716&#58;5
Instruction&#58;                 WRITE
Command&#58;                     60021
Encryption&#58;                  none
Integrity&#58;                   MD5
Authenticated using&#58;         FS
All authentication methods&#58;  FS,GSI
Remote Mapping&#58;              dcaunt@....
Authorized&#58;                  TRUE

********************
- Successful ping of schedd on &#60;10.31.131.202&#58;9620?sock=4356_61bf_4&#62;.

********************************************************************************
2015-08-28 13&#58;41&#58;56 Could not find an X509 proxy in /tmp/x509up_u556792
********************************************************************************
----

Everything looks good to me besides the last line about not finding an X509 proxy.  Should I be concerned about that?

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt
</div><script type='text/javascript'>
        $('#show_2118123689').click(function() {
            $('#detail_2118123689').slideDown("normal");
            $('#show_2118123689').hide();
            $('#hide_2118123689').show();
        });
        $('#hide_2118123689').click(function() {
            $('#detail_2118123689').slideUp();
            $('#hide_2118123689').hide();
            $('#show_2118123689').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='26367#1440712472'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-27T21:54:32+00:00">Aug 27, 2015 09:54 PM UTC</time> by <b>Matyas Selmeci</b><a class="anchor" name="1440712472">&nbsp;</a></div><pre>Also, Brian Bockelman (cc&#39;ed) wrote a script that diagnoses network settings that might interfere with HTCondor-CE, and we&#39;d appreciate it if you could give it a spin&#58;
<a href='https&#58;//raw.githubusercontent.com/bbockelm/htcondor-ce/host_network_check/src/condor_ce_host_network_check' target='_blank' rel='nofollow'>https&#58;//raw.githubusercontent.com/bbockelm/htcondor-ce/host_network_check/src/condor_ce_host_network_check</a>
If it&#39;s useful, we will include it in future versions of htcondor-ce.

Thanks,
-Mat</pre></div><div class='update_description'><i onclick="document.location='26367#1440705746'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-27T20:02:26+00:00">Aug 27, 2015 08:02 PM UTC</time> by <b>Matyas Selmeci</b><a class="anchor" name="1440705746">&nbsp;</a></div><pre>Hi Daniel,

To enable FS authentication for the CE, edit /etc/condor-ce/config.d/01-common-auth.conf and change the line
SEC_DEFAULT_AUTHENTICATION_METHODS = GSI
to
SEC_DEFAULT_AUTHENTICATION_METHODS = FS, GSI

You may run into further problems because of the forward DNS != reverse DNS issue, but we&#39;ll solve them when we get to them.

-Mat</pre></div><div class='update_description'><i onclick="document.location='26367#1440535165'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-25T20:39:25+00:00">Aug 25, 2015 08:39 PM UTC</time><a class="anchor" name="1440535165">&nbsp;</a></div><pre>Hi Mat,

I attached the logs as requested.  I had to append a .txt extension in order for the site to allow me to upload it.  Simply remove that extension, but let me know if it doesn&#39;t arrive intact.

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1440463835'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-25T00:50:35+00:00">Aug 25, 2015 12:50 AM UTC</time> by <b>Matyas Selmeci</b><a class="anchor" name="1440463835">&nbsp;</a></div><pre>Hi Daniel,
Nothing seems wrong with your config at first glance. I could use some additional debugging information though&#58; can you tar up and send us your condor-ce logs (contents of /var/log/condor-ce)?
Thanks,
-Mat</pre></div><div class='update_description'><i onclick="document.location='26367#1440430511'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-24T15:35:11+00:00">Aug 24, 2015 03:35 PM UTC</time><a class="anchor" name="1440430511">&nbsp;</a></div><pre>HI Mat,

Can you take a look and suggest which changes Daniel needs for FS authentication between the ce condor daemons?

by /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=People/CN=Edgar Mauricio Fajardo Hernandez 2020</pre></div><div class='update_description'><i onclick="document.location='26367#1439995268'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-19T14:41:08+00:00">Aug 19, 2015 02:41 PM UTC</time><a class="anchor" name="1439995268">&nbsp;</a></div><pre>Thanks for the detailed explanation, Tim.  This makes perfect sense.  I&#39;m attaching the tarball as requested.  It includes both the /etc/condor/config.d and /etc/condor-ce/config.d directories because I assumed you meant /etc/condor-ce/config.d.  We&#39;re not running Condor as the local batch system - we&#39;re still on LSF, though we&#39;ll eventually transition to SLURM.  You won&#39;t see much customization in the config files yet.  So far, following the HTCondor-CE installation documents (<a href='https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallHTCondorCE' target='_blank' rel='nofollow'>https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallHTCondorCE</a>) I&#39;ve only needed to add a SPOOL directory in 99-local.conf and a GRIDMAP entry in 01-common-auth.conf.  Thanks again for the help.

Dan

P.S. - The site doesn&#39;t allow tar or bzip files to be attached so I changed the name of the file from config.d.tar to config.d.txt.  Simply rename before you untar it.  Please let me know if the file didn&#39;t arrive intact.

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1439906422'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-18T14:00:22+00:00">Aug 18, 2015 02:00 PM UTC</time> by <b>Tim Cartwright</b><a class="anchor" name="1439906422">&nbsp;</a></div><pre>Dan&#58;

OK, I think we have a theory of what is going on and an approach for solving the underlying problem. The bad news is that we propose that you change some things in your HTCondor CE configuration, but the good news is that we understand these changes and they could even make your CE run a little more efficiently.

THE PROBLEM

As you pointed out, the CE host (net2.rc.fas.harvard.edu) has two network interfaces and hence the two IP addresses, 10.31.131.202 internally and 140.247.179.131 externally. It appears that you have an internal DNS system that resolves hostnames to their internal IP addresses, which is how the CE host is forward resolving to 10.31.131.202 with the host command.

When the HTCondor Master starts other HTCondor daemons (such as the Shared Port daemon), it selects an IP address (not hostname) to give to that child process, and in turn that child process tries to use that IP address to send messages back to the Master. As it happens, if there are multiple network interfaces, HTCondor tries to select the “least internal-looking” IP address, which in your case is the 140.247.179.131 one. By itself this is not a problem, but it appears that your HTCondor CE host is configured to use GSI authentication to secure all HTCondor communications, and GSI authentication requires that the host certificate’s hostname resolves to the right IP address and vice versa. But in your case, the hostname resolves to the 10.31.131.202 address, not the 140.247.179.131 one that is being used to contact the Master.

Most likely, all other HTCondor communications within your pool work just fine, because when going from host to host on the internal network, all of the hostnames resolve to their internal addresses. And communication with the CE from the outside probably works just fine, because your CE hostname resolves to the external IP address on the outside. So the core problem is that on the CE itself, there is the confusion with the one hostname and two IP addresses.

A SOLUTION

There are a variety of ways that we might handle this issue, but probably the easiest is to change your HTCondor configuration on the CE (at least) to use “filesystem” authentication for daemon-to-daemon communication *within the CE host itself*, and continue using GSI authentication for all communication between hosts. This is actually a fairly common configuration in the OSG, and it is what we have run ourselves here in Madison on our testing site.

The filesystem authentication mechanism is very simple, essentially allowing communications to happen from all daemons on the same host without further checking. It is safe, because it affects daemon-to-daemon communications on the host, and if someone can access your machine with the same privileges as your HTCondor daemons, you have bigger problems. One nice side benefit of switch to filesystem authentication within a host is that it eliminates the relatively computationally expensive GSI authentication process for routine, intra-host communications, which can cause a slight performance improvement for some HTCondor operations.

The configuration changes are not entirely trivial and beyond the scope of this response, but we would be happy to help with the details. To get started, please make a tarball of your /etc/condor/config.d directory and attach it to the ticket (using the web interface, as before). We will take a look and either ask follow-up questions or hopefully just suggest changes (in the form of patches). I have added Mat Selmeci to this ticket, because he is the OSG Software team member who did the most work on our own testing site, including the security configuration for the split GSI/filesystem authentication scheme. I have also added Greg Thain from the HTCondor development team, who graciously investigated the issue and explained a great deal to me; I have probably gotten some things wrong along the way here, and he is welcome to correct me as appropriate.

This is a lot of information for a single ticket response, so if you have further questions or would like to discuss things more deeply, we would be happy to schedule a phone call.</pre></div><div class='update_description'><i onclick="document.location='26367#1439581569'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-14T19:46:09+00:00">Aug 14, 2015 07:46 PM UTC</time><a class="anchor" name="1439581569">&nbsp;</a></div><pre>Thanks, Tim.  Here&#39;s the output you requested.  Also, in case it&#39;s helpful, I could list the steps I&#39;ve taken so far during the installation - perhaps I missed something.  If you think that would be useful, let me know.

Dan

[root@net2 ~]# host 10.31.131.202
202.131.31.10.in-addr.arpa domain name pointer net2.rc.fas.harvard.edu.
[root@net2 ~]# host 140.247.179.131
131.179.247.140.in-addr.arpa domain name pointer net2.rc.fas.harvard.edu.
[root@net2 ~]# host net2.rc.fas.harvard.edu
net2.rc.fas.harvard.edu has address 10.31.131.202
[root@net2 ~]#

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1439580595'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-14T19:29:55+00:00">Aug 14, 2015 07:29 PM UTC</time> by <b>Tim Cartwright</b><a class="anchor" name="1439580595">&nbsp;</a></div><pre>Dan, sorry for the long delay. After not getting any help from one developer, I ended up walking down the hallway till I got someone......

So most likely you are on the right track with debugging here, there is probably something going on with DNS and your hostname and the IP address that the CE is using. Could you run the following commands and send the output from each (clearly labeled)?

host 10.31.131.202
host 140.247.179.131
host net2.rc.fas.harvard.edu</pre></div><div class='update_description'><i onclick="document.location='26367#1439317246'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-11T18:20:46+00:00">Aug 11, 2015 06:20 PM UTC</time> by <b>Tim Cartwright</b><a class="anchor" name="1439317246">&nbsp;</a></div><pre>Not yet, waiting to get some time from one of the developers, who has been quite busy.</pre></div><div class='update_description'><i onclick="document.location='26367#1439314653'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-11T17:37:33+00:00">Aug 11, 2015 05:37 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1439314653">&nbsp;</a></div><pre>Hello All,

Is there an update on this from the HTCondor developers?

~Chris</pre></div><div class='update_description'><i onclick="document.location='26367#1438876452'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-06T15:54:12+00:00">Aug 6, 2015 03:54 PM UTC</time><a class="anchor" name="1438876452">&nbsp;</a></div><pre>Thanks.  In case it&#39;s useful, here is some network information.

[root@net2 ~]# netstat -ra
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
140.247.179.128 *               255.255.255.192 U         0 0          0 eth3
10.255.12.0     10.31.130.1     255.255.255.192 UG        0 0          0 eth2
10.31.130.0     *               255.255.254.0   U         0 0          0 eth2
10.242.0.0      10.31.130.1     255.255.0.0     UG        0 0          0 eth2
10.31.0.0       10.31.130.1     255.255.0.0     UG        0 0          0 eth2
default         140.247.179.129 0.0.0.0         UG        0 0          0 eth3
[root@net2 ~]# ifconfig -a
eth0      Link encap&#58;Ethernet  HWaddr 90&#58;B1&#58;1C&#58;1F&#58;9C&#58;77
BROADCAST MULTICAST  MTU&#58;1500  Metric&#58;1
RX packets&#58;0 errors&#58;0 dropped&#58;0 overruns&#58;0 frame&#58;0
TX packets&#58;0 errors&#58;0 dropped&#58;0 overruns&#58;0 carrier&#58;0
collisions&#58;0 txqueuelen&#58;1000
RX bytes&#58;0 (0.0 b)  TX bytes&#58;0 (0.0 b)

eth1      Link encap&#58;Ethernet  HWaddr 90&#58;B1&#58;1C&#58;1F&#58;9C&#58;78
BROADCAST MULTICAST  MTU&#58;1500  Metric&#58;1
RX packets&#58;0 errors&#58;0 dropped&#58;0 overruns&#58;0 frame&#58;0
TX packets&#58;0 errors&#58;0 dropped&#58;0 overruns&#58;0 carrier&#58;0
collisions&#58;0 txqueuelen&#58;1000
RX bytes&#58;0 (0.0 b)  TX bytes&#58;0 (0.0 b)

eth2      Link encap&#58;Ethernet  HWaddr 00&#58;1B&#58;21&#58;C6&#58;F8&#58;C8
inet addr&#58;10.31.131.202  Bcast&#58;10.31.131.255  Mask&#58;255.255.254.0
UP BROADCAST RUNNING MULTICAST  MTU&#58;1500  Metric&#58;1
RX packets&#58;105079394 errors&#58;27480 dropped&#58;0 overruns&#58;0 frame&#58;27480
TX packets&#58;408615326 errors&#58;0 dropped&#58;0 overruns&#58;0 carrier&#58;0
collisions&#58;0 txqueuelen&#58;1000
RX bytes&#58;71730231580 (66.8 GiB)  TX bytes&#58;539135214841 (502.1 GiB)

eth3      Link encap&#58;Ethernet  HWaddr 00&#58;1B&#58;21&#58;C6&#58;F8&#58;C9
<div id='show_1719963236' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_1719963236'>inet addr&#58;140.247.179.131  Bcast&#58;140.247.179.191  Mask&#58;255.255.255.192
UP BROADCAST RUNNING MULTICAST  MTU&#58;1500  Metric&#58;1
RX packets&#58;19127279 errors&#58;1051 dropped&#58;0 overruns&#58;0 frame&#58;1051
TX packets&#58;28203556 errors&#58;0 dropped&#58;0 overruns&#58;0 carrier&#58;0
collisions&#58;0 txqueuelen&#58;1000
RX bytes&#58;33904941103 (31.5 GiB)  TX bytes&#58;26291684147 (24.4 GiB)

lo        Link encap&#58;Local Loopback
inet addr&#58;127.0.0.1  Mask&#58;255.0.0.0
UP LOOPBACK RUNNING  MTU&#58;16436  Metric&#58;1
RX packets&#58;1346121 errors&#58;0 dropped&#58;0 overruns&#58;0 frame&#58;0
TX packets&#58;1346121 errors&#58;0 dropped&#58;0 overruns&#58;0 carrier&#58;0
collisions&#58;0 txqueuelen&#58;0
RX bytes&#58;9693621507 (9.0 GiB)  TX bytes&#58;9693621507 (9.0 GiB)

[root@net2 ~]#

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt
</div><script type='text/javascript'>
        $('#show_1719963236').click(function() {
            $('#detail_1719963236').slideDown("normal");
            $('#show_1719963236').hide();
            $('#hide_1719963236').show();
        });
        $('#hide_1719963236').click(function() {
            $('#detail_1719963236').slideUp();
            $('#hide_1719963236').hide();
            $('#show_1719963236').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='26367#1438875763'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-06T15:42:43+00:00">Aug 6, 2015 03:42 PM UTC</time> by <b>Tim Cartwright</b><a class="anchor" name="1438875763">&nbsp;</a></div><pre>Dan&#58;

I will have one of the HTCondor developers take a look at the logs in a bit, but I suspect that your idea about the root cause of the problem is correct. I will see what else I can learn and get back to you soon.

— Tim</pre></div><div class='update_description'><i onclick="document.location='26367#1438786088'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-05T14:48:08+00:00">Aug 5, 2015 02:48 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1438786088">&nbsp;</a></div><pre>Hi Dan,

I see the attachment now, thanks.

Chris</pre></div><div class='update_description'><i onclick="document.location='26367#1438702844'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-04T15:40:44+00:00">Aug 4, 2015 03:40 PM UTC</time><a class="anchor" name="1438702844">&nbsp;</a></div><pre>Hi Chris,

That&#39;s what I did.  It&#39;s showing as an attachment on the ticket page for me.  You&#39;re not able to see it?  It&#39;s called osg-profile.txt.

Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1438701934'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-04T15:25:34+00:00">Aug 4, 2015 03:25 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1438701934">&nbsp;</a></div><pre>Hi Daniel,

If you tried to send that profile.txt via email attachment, it wont work. You&#39;ll have to go directly to the ticket <a href='https&#58;//ticket.grid.iu.edu/26367' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/26367</a>, login and click the green &#34;Attach files...&#34; button to upload the text. Sorry for the inconvenience.

Regards,
Chris</pre></div><div class='update_description'><i onclick="document.location='26367#1438633890'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-03T20:31:30+00:00">Aug 3, 2015 08:31 PM UTC</time><a class="anchor" name="1438633890">&nbsp;</a></div><pre>The osg-profile.txt file should now be attached.

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt</pre></div><div class='update_description'><i onclick="document.location='26367#1438631409'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-08-03T19:50:09+00:00">Aug 3, 2015 07:50 PM UTC</time> by <b>Christopher Pipes</b><a class="anchor" name="1438631409">&nbsp;</a></div><pre>The Software Team has been assigned for review.

Daniel could you please run the osg-system-profiler and attach osg-profile.txt to the ticket here <a href='https&#58;//ticket.grid.iu.edu/26367' target='_blank' rel='nofollow'>https&#58;//ticket.grid.iu.edu/26367</a></pre></div><div class='update_description'><i onclick="document.location='26367#1438367436'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-07-31T18:30:36+00:00">Jul 31, 2015 06:30 PM UTC</time><a class="anchor" name="1438367436">&nbsp;</a></div><pre>Hi again,

I&#39;m wondering if the dual NICs in this machine have anything to do with the problems I&#39;m seeing.  This message in the SharedPortLog is what gave me the idea&#58;

07/31/15 13&#58;42&#58;19 WARNING&#58; forward resolution of net2.rc.fas.harvard.edu doesn&#39;t match 140.247.179.131!

That&#39;s the external IP for this machine.  The internal one is 10.31.131.202.  However, that&#39;s just one warning message out of many that I&#39;m seeing.

Whenever I start the condor-ce service, I receive the following 4 emails&#58;

---- Email 1 -----------------------------------

&#34;/usr/libexec/condor/condor_shared_port&#34; on &#34;net2.rc.fas.harvard.edu&#34; exited with status 4.
Condor will automatically restart this process in 17 seconds.

*** Last 20 line(s) of file /var/log/condor-ce/SharedPortLog&#58;
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;52919&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;52919&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;52919&#62;.
07/31/15 14&#58;23&#58;49 WARNING&#58; forward resolution of net2.rc.fas.harvard.edu doesn&#39;t match 140.247.179.131!
07/31/15 14&#58;23&#58;49 SECMAN&#58; required authentication with daemon at &#60;140.247.179.131&#58;0&#62; failed, so aborting command DC_CHILDALIVE.
07/31/15 14&#58;23&#58;49 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;0&#62; (try 1 of 3)&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;40249&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;40249&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;40249&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;40249&#62;.
07/31/15 14&#58;23&#58;49 WARNING&#58; forward resolution of net2.rc.fas.harvard.edu doesn&#39;t match 140.247.179.131!
07/31/15 14&#58;23&#58;49 SECMAN&#58; required authentication with daemon at &#60;140.247.179.131&#58;0&#62; failed, so aborting command DC_CHILDALIVE.
07/31/15 14&#58;23&#58;49 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;0&#62; (try 2 of 3)&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.|AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name
check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;33478&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;33478&#62;.
07/31/15 14&#58;23&#58;49 SharedPortCliient read would block; waiting for result for SHARED_PORT_PASS_FD to /var/lock/condor-ce/daemon_sock/9070_521b as requested by &#60;140.247.179.131&#58;33478&#62;.
07/31/15 14&#58;23&#58;49 WARNING&#58; forward resolution of net2.rc.fas.harvard.edu doesn&#39;t match 140.247.179.131!
07/31/15 14&#58;23&#58;49 SECMAN&#58; required authentication with daemon at &#60;140.247.179.131&#58;0&#62; failed, so aborting command DC_CHILDALIVE.
<div id='show_369946553' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_369946553'>07/31/15 14&#58;23&#58;49 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;0&#62; (try 3 of 3)&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.|AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name
check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.|AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5008&#58;Failed to look up server host address for GSI connection to server with IP 140.247.179.131 and DN /DC=com/DC=DigiCert-Grid/O=Open Science Grid/OU=Services/CN=net2.rc.fas.harvard.edu.  Is DNS correctly configured?  This server name check can be bypassed by making GSI_SKIP_HOST_CHECK_CERT_REGEX match the DN, or by disabling all hostname checks by setting GSI_SKIP_HOST_CHECK=true or defining GSI_DAEMON_NAME.
07/31/15 14&#58;23&#58;49 ERROR &#34;FAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT &#60;140.247.179.131&#58;0?sock=9070_521b&#62;&#34; at line 9477 in file /builddir/build/BUILD/condor-8.2.8/src/condor_daemon_core.V6/daemon_core.cpp

*** End of file SharedPortLog

---- Email 2 -----------------------------------

&#34;/usr/sbin/condor_collector&#34; on &#34;net2.rc.fas.harvard.edu&#34; exited with status 4.
Condor will automatically restart this process in 17 seconds.

*** Last 20 line(s) of file /var/log/condor-ce/CollectorLog&#58;
07/31/15 14&#58;25&#58;11 DaemonCore&#58; command socket at &#60;140.247.179.131&#58;9620?sock=21085_3897&#62;
07/31/15 14&#58;25&#58;11 DaemonCore&#58; private command socket at &#60;140.247.179.131&#58;9620?sock=21085_3897&#62;
07/31/15 14&#58;25&#58;11 In ViewServer&#58;&#58;Init()
07/31/15 14&#58;25&#58;11 In CollectorDaemon&#58;&#58;Init()
07/31/15 14&#58;25&#58;11 In ViewServer&#58;&#58;Config()
07/31/15 14&#58;25&#58;11 In CollectorDaemon&#58;&#58;Config()
07/31/15 14&#58;25&#58;11 ABSENT_REQUIREMENTS = None
07/31/15 14&#58;25&#58;11 OfflineCollectorPlugin&#58;&#58;configure&#58; no persistent store was defined for off-line ads.
07/31/15 14&#58;25&#58;11 Will forward ads on to View Server collector1.opensciencegrid.org&#58;9619
07/31/15 14&#58;25&#58;11 Will forward ads on to View Server collector2.opensciencegrid.org&#58;9619
07/31/15 14&#58;25&#58;11 CONDOR_VIEW_CLASSAD_TYPES configured, will forward ad types&#58; Scheduler
07/31/15 14&#58;25&#58;11 enable&#58; Creating stats hash table
07/31/15 14&#58;25&#58;11 Enabling CCB Server.
07/31/15 14&#58;25&#58;11 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;11 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 1 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;11 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;11 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 2 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;11 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;11 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 3 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;11 ERROR &#34;FAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;&#34; at line 9477 in file /builddir/build/BUILD/condor-8.2.8/src/condor_daemon_core.V6/daemon_core.cpp

*** End of file CollectorLog

---- Email 3 -----------------------------------

&#34;/usr/libexec/condor/condor_job_router&#34; on &#34;net2.rc.fas.harvard.edu&#34; exited with status 4.
Condor will automatically restart this process in 17 seconds.

*** Last 20 line(s) of file /var/log/condor-ce/JobRouterLog&#58;
07/31/15 14&#58;25&#58;19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
07/31/15 14&#58;25&#58;19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
07/31/15 14&#58;25&#58;19    /etc/condor-ce/config.d/50-osg-configure.conf
07/31/15 14&#58;25&#58;19    /etc/condor-ce/config.d/99-local.conf
07/31/15 14&#58;25&#58;19    /usr/share/condor-ce/condor_ce_router_defaults|
07/31/15 14&#58;25&#58;19 config Macros = 140, Sorted = 140, StringBytes = 12440, TablesBytes = 5248
07/31/15 14&#58;25&#58;19 CLASSAD_CACHING is ENABLED
07/31/15 14&#58;25&#58;19 Daemon Log is logging&#58; D_ALWAYS D_ERROR
07/31/15 14&#58;25&#58;19 SharedPortEndpoint&#58; waiting for connections to named socket 9070_521b_29
07/31/15 14&#58;25&#58;19 DaemonCore&#58; command socket at &#60;140.247.179.131&#58;9620?sock=9070_521b_29&#62;
07/31/15 14&#58;25&#58;19 DaemonCore&#58; private command socket at &#60;140.247.179.131&#58;9620?sock=9070_521b_29&#62;
07/31/15 14&#58;25&#58;19 main_init() called
07/31/15 14&#58;25&#58;19 JobRouter Note&#58; adding new route &#39;[ eval_set_OnExitHold = ifThenElse(orig_OnExitHold isnt null,orig_OnExitHold,false) || ifThenElse(minWalltime isnt null && RemoteWallClockTime isnt null,RemoteWallClockTime &#60; 60 * minWallTime,false); set_InputRSL = ifThenElse(GlobusRSL is null,[  ],eval_rsl(GlobusRSL)); copy_OnExitHoldReason = &#34;orig_OnExitHoldReason&#34;; eval_set_remote_cerequirements = ifThenElse(InputRSL.maxWallTime isnt null,strcat(&#34;Walltime == &#34;,string(60 * InputRSL.maxWallTime),&#34; && CondorCE == 1&#34;),ifThenElse(maxWallTime isnt null,strcat(&#34;Walltime == &#34;,string(60 * maxWallTime),&#34; && CondorCE == 1&#34;),ifThenElse(default_maxWallTime isnt null,strcat(&#34;Walltime == &#34;,string(60 * default_maxWallTime),&#34; && CondorCE == 1&#34;),&#34;CondorCE == 1&#34;))); eval_set_remote_NodeNumber = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); eval_set_OnExitHoldReason = ifThenElse(( orig_OnExitHo
ld isnt null ) && orig_OnExitHold,ifThenElse(orig_OnExitHoldReason isnt null,orig_OnExitHoldReason,strcat(&#34;The on_exit_hold expression (&#34;,unparse(orig_OnExitHold),&#34;) evaluated to TRUE.&#34;)),ifThenElse(minWalltime isnt null && RemoteWallClockTime isnt null && ( RemoteWallClockTime &#60; 60 * minWallTime ),strcat(&#34;The job&#39;s wall clock time, &#34;,int(RemoteWallClockTime / 60),&#34;min, is less than the minimum specified by the job (&#34;,minWalltime,&#34;)&#34;),&#34;Job held for unknown reason.&#34;)); eval_set_RequestCpus = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); eval_set_RequestMemory = ifThenElse(InputRSL.maxMemory isnt null,InputRSL.maxMemory,ifThenElse(maxMemory isnt null,maxMemory,ifThenElse(default_maxMemory isnt null,default_maxMemory,2000))); delete_CondorCE = true; copy_OnExitHoldSubCode = &#34;orig_OnExitHoldSubCode&#34;; set_RoutedJob = true; delete_PeriodicRemove = true; TargetUniverse = 9; set_Condor
CECollectorHost = ifThenElse(regexp(&#34;&#58;&#34;,&#34;net2.rc.fas.harvard.edu&#58;9619&#34;),&#34;net2.rc.fas.harvard.edu&#58;9619&#34;,strcat(&#34;net2.rc.fas.harvard.edu&#58;9619&#34;,&#34;&#58;&#34;,9619)); eval_set_remote_queue = ifThenElse(InputRSL.queue isnt null,InputRSL.queue,ifThenElse(batch_queue isnt null,batch_queue,ifThenElse(queue isnt null,queue,ifThenElse(default_queue isnt null,default_queue,&#34;&#34;)))); GridResource = &#34;batch pbs&#34;; eval_set_remote_SMPGranularity = ifThenElse(InputRSL.xcount isnt null,InputRSL.xcount,ifThenElse(xcount isnt null,xcount,ifThenElse(default_xcount isnt null,default_xcount,1))); eval_set_environment = debug(strcat(&#34;HOME=&#34;,userHome(Owner,&#34;/&#34;),&#34; CONDORCE_COLLECTOR_HOST=&#34;,CondorCECollectorHost,&#34; &#34;,ifThenElse(orig_environment is undefined,osg_environment,strcat(osg_environment,&#34; &#34;,orig_environment)))); Requirements = true; set_osg_environment = &#34;OSG_GRID=&#39;/n/atlasgrid/osg-wn-client&#39; OSG_SQUID_LOCATION=&#39;net2.rc.fas.harvard.edu&#58;3128&#39; OSG_SITE_READ=&#39;None&#39; OSG_APP=&#39;/n/atlasgrid/osg/app&#39; OSG_GLEXEC_L
OCATION=&#39;None&#39; OSG_DATA=&#39;/n/atlasgrid/osg/data&#39; OSG_HOSTNAME=&#39;net2.rc.fas.harvard.edu&#39; OSG_STORAGE_ELEMENT=&#39;True&#39; OSG_SITE_NAME=&#39;NET2_HU&#39; ATLAS_LOCAL_AREA=&#39;/n/atlasgrid/osg/app/atlas_app/local&#39; GLOBUS_LOCATION=&#39;/usr&#39; OSG_WN_TMP=&#39;/scratch&#39; OSG_SITE_WRITE=&#39;None&#39; OSG_DEFAULT_SE=&#39;net2.rc.fas.harvard.edu&#39; OSG_JOB_CONTACT=&#39;net2.rc.fas.harvard.edu/jobmanager-lsf&#39;&#34;; MaxJobs = 10000; MaxIdleJobs = 2000; set_requirements = true; copy_OnExitHold = &#34;orig_OnExitHold&#34;; eval_set_OnExitHoldSubCode = ifThenElse(( orig_OnExitHold isnt null ) && orig_OnExitHold,ifThenElse(orig_OnExitHoldSubCode isnt null,orig_OnExitHoldSubCode,1),42); name = &#34;Local_PBS&#34;; copy_environment = &#34;orig_environment&#34; ]&#39;
07/31/15 14&#58;25&#58;19 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;19 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 1 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;19 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;19 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 2 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;19 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;19 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 3 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;19 ERROR &#34;FAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;&#34; at line 9477 in file /builddir/build/BUILD/condor-8.2.8/src/condor_daemon_core.V6/daemon_core.cpp

*** End of file JobRouterLog

---- Email 4 -----------------------------------

&#34;/usr/sbin/condor_schedd&#34; on &#34;net2.rc.fas.harvard.edu&#34; exited with status 4.
Condor will automatically restart this process in 17 seconds.

*** Last 20 line(s) of file /var/log/condor-ce/SchedLog&#58;
07/31/15 14&#58;25&#58;20    /etc/condor-ce/config.d/99-local.conf
07/31/15 14&#58;25&#58;20    /usr/share/condor-ce/condor_ce_router_defaults|
07/31/15 14&#58;25&#58;20 config Macros = 140, Sorted = 140, StringBytes = 12436, TablesBytes = 5248
07/31/15 14&#58;25&#58;20 CLASSAD_CACHING is ENABLED
07/31/15 14&#58;25&#58;20 Daemon Log is logging&#58; D_ALWAYS D_ERROR D_AUDIT
07/31/15 14&#58;25&#58;20 SharedPortEndpoint&#58; waiting for connections to named socket 9070_521b_30
07/31/15 14&#58;25&#58;20 DaemonCore&#58; command socket at &#60;140.247.179.131&#58;9620?sock=9070_521b_30&#62;
07/31/15 14&#58;25&#58;20 DaemonCore&#58; private command socket at &#60;140.247.179.131&#58;9620?sock=9070_521b_30&#62;
07/31/15 14&#58;25&#58;20 History file rotation is enabled.
07/31/15 14&#58;25&#58;20   Maximum history file size is&#58; 20971520 bytes
07/31/15 14&#58;25&#58;20   Number of rotated history files is&#58; 2
07/31/15 14&#58;25&#58;20 Logging per-job history files to&#58; /var/lib/gratia/condorce_data
07/31/15 14&#58;25&#58;20 Failed to execute /usr/sbin/condor_shadow.std, ignoring
07/31/15 14&#58;25&#58;20 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;20 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 1 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;20 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;20 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 2 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;20 attempt to connect to &#60;140.247.179.131&#58;9620&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 14&#58;25&#58;20 ChildAliveMsg&#58; failed to send DC_CHILDALIVE to parent daemon at &#60;140.247.179.131&#58;9620&#62; (try 3 of 3)&#58; CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;|CEDAR&#58;6001&#58;Failed to connect to &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;
07/31/15 14&#58;25&#58;20 ERROR &#34;FAILED TO SEND INITIAL KEEP ALIVE TO OUR PARENT &#60;140.247.179.131&#58;9620?sock=9070_521b&#62;&#34; at line 9477 in file /builddir/build/BUILD/condor-8.2.8/src/condor_daemon_core.V6/daemon_core.cpp

*** End of file SchedLog

------------------------

If you need more details, let me know.

Thanks.
Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt
</div><script type='text/javascript'>
        $('#show_369946553').click(function() {
            $('#detail_369946553').slideDown("normal");
            $('#show_369946553').hide();
            $('#hide_369946553').show();
        });
        $('#hide_369946553').click(function() {
            $('#detail_369946553').slideUp();
            $('#hide_369946553').hide();
            $('#show_369946553').show();
        });
        </script></pre></div><div class='update_description'><i onclick="document.location='26367#1438354370'; reset_anchor();" class="pull-right icon icon-share"></i><div class="header"><time datetime="2015-07-31T14:52:50+00:00">Jul 31, 2015 02:52 PM UTC</time> by <b>OSG-GOC</b><a class="anchor" name="1438354370">&nbsp;</a></div><pre>Hello,

I am in the process of migrating our CE from GRAM/LSF to HTCondorCE/LSF.  This is part of a larger migration to HTCondorCE/SLURM that we will undertake once HTCondorCE is successfully running with our existing LSF environment.

I have completed the steps found in this document&#58;
<a href='https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallHTCondorCE' target='_blank' rel='nofollow'>https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/InstallHTCondorCE</a>

And I am attempting to validate our new HTCondor CE but I am running into errors.  Following the troubleshooting guide here&#58;
<a href='https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/TroubleshootingHTCondorCE' target='_blank' rel='nofollow'>https&#58;//twiki.grid.iu.edu/bin/view/Documentation/Release3/TroubleshootingHTCondorCE</a>

I get the following output when running the troubleshooting commands from the CE itself.

[root@net2 ~]# condor_ce_trace --debug net2.rc.fas.harvard.edu
07/31/15 10&#58;48&#58;13 Result of reading /etc/issue&#58;  CentOS release 6.5 (Final)
07/31/15 10&#58;48&#58;13 Using IDs&#58; 16 processors, 8 CPUs, 8 HTs
07/31/15 10&#58;48&#58;13 Enumerating interfaces&#58; lo 127.0.0.1 up
07/31/15 10&#58;48&#58;13 Enumerating interfaces&#58; eth2 10.31.131.202 up
07/31/15 10&#58;48&#58;13 Enumerating interfaces&#58; eth3 140.247.179.131 up
07/31/15 10&#58;48&#58;13 Initializing Directory&#58; curr_dir = /usr/share/condor-ce/config.d
07/31/15 10&#58;48&#58;13 Initializing Directory&#58; curr_dir = /etc/condor-ce/config.d
Testing HTCondor-CE collector connectivity.
***** condor_ping output *****
READ failed!
CEDAR&#58;6001&#58;Failed to connect to &#60;10.31.131.202&#58;9619&#62;
********************
- Failed ping of collector on &#60;10.31.131.202&#58;9619&#62;.
********************************************************************************
2015-07-31 10&#58;48&#58;14 Failed to ping &#60;10.31.131.202&#58;9619&#62;&#58; Please contact the
site&#39;s system adminstrator to ensure that the CE you&#39;re trying to contact is
functional.
********************************************************************************
[root@net2 ~]# exit

[dcaunt@net2 ~]$ condor_submit test.sub
ERROR&#58; Can&#39;t find address of local schedd
<div id='show_2104873210' class=''><button class="btn">Show More</button></div><div class='detail hidden' id='detail_2104873210'>[dcaunt@net2 ~]$ sudo -i

[root@net2 ~]# condor_ce_ping -verbose WRITE
ERROR&#58; couldn&#39;t locate (null)!
[root@net2 ~]#

There seems to be a recurring set of errors in /var/log/condor-ce/MasterLog&#58;

07/31/15 10&#58;50&#58;53 Started DaemonCore process &#34;/usr/libexec/condor/condor_shared_port&#34;, pid and pgroup = 15713
07/31/15 10&#58;50&#58;53 Waiting for /var/lock/condor-ce/shared_port_ad to appear.
07/31/15 10&#58;50&#58;53 attempt to connect to &#60;10.31.131.202&#58;9619&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 10&#58;50&#58;53 ERROR&#58; SECMAN&#58;2003&#58;TCP connection to collector net2.rc.fas.harvard.edu&#58;9619 failed.
07/31/15 10&#58;50&#58;53 Failed to start non-blocking update to &#60;10.31.131.202&#58;9619&#62;.
07/31/15 10&#58;50&#58;53 DC_AUTHENTICATE&#58; required authentication of 140.247.179.131 failed&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5005&#58;Failed to authenticate with client.  Client does not trust our certificate.  You may want to check the GSI_DAEMON_NAME in the condor_config
07/31/15 10&#58;50&#58;53 DC_AUTHENTICATE&#58; required authentication of 140.247.179.131 failed&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5005&#58;Failed to authenticate with client.  Client does not trust our certificate.  You may want to check the GSI_DAEMON_NAME in the condor_config
07/31/15 10&#58;50&#58;53 DC_AUTHENTICATE&#58; required authentication of 140.247.179.131 failed&#58; AUTHENTICATE&#58;1003&#58;Failed to authenticate with any method|AUTHENTICATE&#58;1004&#58;Failed to authenticate using GSI|GSI&#58;5005&#58;Failed to authenticate with client.  Client does not trust our certificate.  You may want to check the GSI_DAEMON_NAME in the condor_config
07/31/15 10&#58;50&#58;53 DefaultReaper unexpectedly called on pid 15713, status 1024.
07/31/15 10&#58;50&#58;53 The SHARED_PORT (pid 15713) exited with status 4
07/31/15 10&#58;50&#58;53 restarting /usr/libexec/condor/condor_shared_port in 3600 seconds
07/31/15 10&#58;50&#58;53 attempt to connect to &#60;10.31.131.202&#58;9619&#62; failed&#58; Connection refused (connect errno = 111).
07/31/15 10&#58;50&#58;53 ERROR&#58; SECMAN&#58;2003&#58;TCP connection to collector net2.rc.fas.harvard.edu&#58;9619 failed.
07/31/15 10&#58;50&#58;53 Failed to start non-blocking update to &#60;10.31.131.202&#58;9619&#62;.

Did I miss a step in the configuration of HTCondor CE?

Dan

by /DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=dcaunt/CN=763648/CN=Daniel Caunt

</div><script type='text/javascript'>
        $('#show_2104873210').click(function() {
            $('#detail_2104873210').slideDown("normal");
            $('#show_2104873210').hide();
            $('#hide_2104873210').show();
        });
        $('#hide_2104873210').click(function() {
            $('#detail_2104873210').slideUp();
            $('#hide_2104873210').hide();
            $('#show_2104873210').show();
        });
        </script></pre></div>
</div>
<script type="text/javascript">
function reset_anchor() {
    $("#updates .selected").removeClass("selected");
    var urls = document.location.toString().split('#'); 
    var anchor = urls[1];
    if(anchor) {
        $("a[name='"+anchor+"']").parents(".update_description").addClass("selected");
    }
}
function submitspam(ticket_id) {
    myret = confirm("Would you like to close this ticket as a security ticket, and submit the ticket content to akismet?");
    if(myret == true) {
        $.ajax("viewer/processspam?id="+ticket_id).done(function() {
            window.location.reload();
        });
    }
}

$(function() {
    reset_anchor();
    var ADDITIONAL_COOKIE_NAME = 'gocticket';
    var options = { path: '/', expires: 365};

    if(window.opener && window.opener.name == "gocticket_list") {
        v = $.cookie("closewindow");
        if(!v) {
            $("#closewindow").attr("checked", "checked"); //on by default
        } else {
            if(v == "checked") {
                $("#closewindow").attr("checked", "checked");
            }
        }
        $("#closewindow").click(function() {
            $.cookie("closewindow", $(this).attr('checked'), options);
        });
    } else {
        $("#closewindow_area").hide();
    }
    function updateTimeago() {
        $("time").timeago();
        setTimeout(updateTimeago, 30*1000);
    }
    updateTimeago();
    $(".description").focus(expand_description);
});
</script>
<hr/>
<footer>
<p>GOC Ticket Version 2.2 | <a href="https://ticket.opensciencegrid.org/goc/submit?app_issue_check=on&amp;app_issue_type=goc&amp;app_goc_url=https%3A%2F%2Fticket.opensciencegrid.org%3A443%2F26367">Report Bugs</a>
 | <a href="https://github.com/opensciencegrid/operations/blob/master/docs/privacy.md">Privacy Policy</a>
</p>

<p> <img align="top" src="images/tag_orange.png"/> Copyright 2018 The Trustees of Indiana University - Developed for Open Science Grid</p>
</footer>


</div><!--container-fluid-->
<script>
//used by searchbox
function parseValue(value) {
    var obj = new Object();
    var tokens = value.split("\t");
    obj.str = tokens[0];
    obj.count = tokens[1];
    return obj;
}

$(function() {
    //bootstrap-2.0.4 stuff
    $(".alert-message").alert();
    $(".dropdown-toggle").dropdown();
    $("span[rel='tooltip']").tooltip();
    $("a[rel=popover]").popover();

    //activate menu that user is currently on
    $("#menu_navigator").addClass("active"); 
    $("#submenu_").addClass("active"); 

    //translate zend validation error message to bootstrap
    $(".errors").addClass("alert").addClass("alert-error");

    //enable autocomplete for search box
    $("#search").autocomplete({
        source: function( request, response ) {
            $.ajax({
                url: "search/autocomplete",
                dataType: "text",
                data: {
                    //featureClass: "P",
                    //style: "full",
                    //maxRows: 12,
                    //name_startsWith: request.term
                    q: request.term
                },
                success: function( data ) {
                    response( $.map( data.split("\n"), function( item ) {
                        if(item == "") return null;
                        return {
                            value: item
                        }
                    }));
                }
            });
        },
        select: function(event, ui) {
            document.location = "search?q="+ui.item.value;
        }
    });
    
});
</script>


</body>
