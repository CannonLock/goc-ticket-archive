13084:09/12/17 16:30:10 Result of reading /etc/issue:  \S
13086:09/12/17 16:30:10 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
13088:09/12/17 16:30:10 Using IDs: 32 processors, 16 CPUs, 16 HTs
13089:09/12/17 16:30:10 Enumerating interfaces: lo 127.0.0.1 up
13090:09/12/17 16:30:10 Enumerating interfaces: eth0 10.36.162.46 up
13091:09/12/17 16:30:10 Enumerating interfaces: ib0 128.55.162.46 up
13092:09/12/17 16:30:10 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
13093:09/12/17 16:30:10 Initializing Directory: curr_dir = /etc/condor-ce/config.d
13094:09/12/17 16:30:10 ******************************************************
13095:09/12/17 16:30:10 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
13096:09/12/17 16:30:10 ** /usr/sbin/condor_gridmanager
13097:09/12/17 16:30:10 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
13098:09/12/17 16:30:10 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
13099:09/12/17 16:30:10 ** $CondorVersion: 8.4.12 Aug 07 2017 $
13100:09/12/17 16:30:10 ** $CondorPlatform: X86_64-CentOS_7.3 $
13101:09/12/17 16:30:10 ** PID = 63128
13102:09/12/17 16:30:10 ** Log last touched 9/8 17:08:57
13103:09/12/17 16:30:10 ******************************************************
13104:09/12/17 16:30:10 Using config source: /etc/condor-ce/condor_config
13105:09/12/17 16:30:10 Using local config sources: 
13106:09/12/17 16:30:10    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
13107:09/12/17 16:30:10    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
13108:09/12/17 16:30:10    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
13109:09/12/17 16:30:10    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
13110:09/12/17 16:30:10    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
13111:09/12/17 16:30:10    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
13112:09/12/17 16:30:10    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
13113:09/12/17 16:30:10    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
13114:09/12/17 16:30:10    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
13115:09/12/17 16:30:10    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
13116:09/12/17 16:30:10    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
13117:09/12/17 16:30:10    /etc/condor-ce/config.d/01-ce-auth.conf
13118:09/12/17 16:30:10    /etc/condor-ce/config.d/01-ce-router.conf
13119:09/12/17 16:30:10    /etc/condor-ce/config.d/01-common-auth.conf
13120:09/12/17 16:30:10    /etc/condor-ce/config.d/02-ce-slurm.conf
13121:09/12/17 16:30:10    /etc/condor-ce/config.d/03-ce-shared-port.conf
13122:09/12/17 16:30:10    /etc/condor-ce/config.d/03-managed-fork.conf
13123:09/12/17 16:30:10    /etc/condor-ce/config.d/05-ce-health.conf
13124:09/12/17 16:30:10    /etc/condor-ce/config.d/05-ce-view.conf
13125:09/12/17 16:30:10    /etc/condor-ce/config.d/10-ce-collector-generated.conf
13126:09/12/17 16:30:10    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
13127:09/12/17 16:30:10    /etc/condor-ce/config.d/50-osg-configure-present.conf
13128:09/12/17 16:30:10    /etc/condor-ce/config.d/50-osg-configure.conf
13129:09/12/17 16:30:10    /etc/condor-ce/config.d/99-local.conf
13130:09/12/17 16:30:10    /usr/share/condor-ce/condor_ce_router_defaults|
13131:09/12/17 16:30:10 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
13132:09/12/17 16:30:10 CLASSAD_CACHING is ENABLED
13133:09/12/17 16:30:10 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
13134:09/12/17 16:30:10 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_10
13135:09/12/17 16:30:10 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_10>
13136:09/12/17 16:30:10 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_10>
13137:09/12/17 16:30:10 Setting maximum accepts per cycle 8.
13138:09/12/17 16:30:10 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13139:09/12/17 16:30:10 [63128] Welcome to the all-singing, all dancing, "amazing" GridManager!
13140:09/12/17 16:30:10 [63128] DaemonCore: No more children processes to reap.
13141:09/12/17 16:30:10 [63128] DaemonCore: in SendAliveToParent()
13142:09/12/17 16:30:10 [63128] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13143:09/12/17 16:30:10 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13144:09/12/17 16:30:10 [63128] IPVERIFY: ip found is 1
13145:09/12/17 16:30:10 [63128] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13146:09/12/17 16:30:10 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13147:09/12/17 16:30:10 [63128] IPVERIFY: ip found is 1
13148:09/12/17 16:30:10 [63128] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13149:09/12/17 16:30:10 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13150:09/12/17 16:30:10 [63128] IPVERIFY: ip found is 1
13151:09/12/17 16:30:10 [63128] IPVERIFY: checking mc0151-ib against 128.55.162.46
13152:09/12/17 16:30:10 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13153:09/12/17 16:30:10 [63128] IPVERIFY: ip found is 1
13154:09/12/17 16:30:10 [63128] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
13155:09/12/17 16:30:10 [63128] DaemonCore: Leaving SendAliveToParent() - success
13156:09/12/17 16:30:10 [63128] Checking proxies
13157:09/12/17 16:30:13 [63128] Received ADD_JOBS signal
13158:09/12/17 16:30:13 [63128] in doContactSchedd()
13159:09/12/17 16:30:13 [63128] querying for new jobs
13160:09/12/17 16:30:13 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
13161:09/12/17 16:30:13 [63128] Using job type INFNBatch for job 396.0
13162:09/12/17 16:30:13 [63128] (396.0) SetJobLeaseTimers()
13163:09/12/17 16:30:13 [63128] Found job 396.0 --- inserting
13164:09/12/17 16:30:13 [63128] Fetched 1 new job ads from schedd
13165:09/12/17 16:30:13 [63128] querying for removed/held jobs
13166:09/12/17 16:30:13 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13167:09/12/17 16:30:13 [63128] Fetched 0 job ads from schedd
13168:09/12/17 16:30:13 [63128] leaving doContactSchedd()
13169:09/12/17 16:30:13 [63128] gahp server not up yet, delaying ping
13170:09/12/17 16:30:13 [63128] *** UpdateLeases called
13171:09/12/17 16:30:13 [63128]     Leases not supported, cancelling timer
13172:09/12/17 16:30:13 [63128] BaseResource::UpdateResource: 
13192:09/12/17 16:30:13 [63128] Trying to update collector <128.55.162.46:9619>
13193:09/12/17 16:30:13 [63128] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13194:09/12/17 16:30:13 [63128] File descriptor limits: max 4096, safe 3277
13195:09/12/17 16:30:13 [63128] (396.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13196:09/12/17 16:30:13 [63128] GAHP server pid = 63130
13197:09/12/17 16:30:13 [63128] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
13198:09/12/17 16:30:13 [63128] GAHP[63130] <- 'COMMANDS'
13199:09/12/17 16:30:13 [63128] GAHP[63130] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
13200:09/12/17 16:30:13 [63128] GAHP[63130] <- 'ASYNC_MODE_ON'
13201:09/12/17 16:30:13 [63128] GAHP[63130] -> 'S' 'Async mode on'
13202:09/12/17 16:30:13 [63128] (396.0) gm state change: GM_INIT -> GM_START
13203:09/12/17 16:30:13 [63128] (396.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13204:09/12/17 16:30:13 [63128] (396.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13205:09/12/17 16:30:13 [63128] (396.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13206:09/12/17 16:30:13 [63128] This process has a valid certificate & key
13207:09/12/17 16:30:13 [63128] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13208:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13209:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13210:09/12/17 16:30:13 [63128] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13211:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13212:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13213:09/12/17 16:30:13 [63128] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13214:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13215:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13216:09/12/17 16:30:13 [63128] IPVERIFY: checking mc0151-ib against 128.55.162.46
13217:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13218:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13219:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13220:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13221:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13222:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13223:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13224:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13225:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
13226:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
13227:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
13228:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
13229:09/12/17 16:30:13 [63128] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
13230:09/12/17 16:30:13 [63128] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
13231:09/12/17 16:30:13 [63128] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13232:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13233:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13234:09/12/17 16:30:13 [63128] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13235:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13236:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13237:09/12/17 16:30:13 [63128] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13238:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13239:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13240:09/12/17 16:30:13 [63128] IPVERIFY: checking mc0151-ib against 128.55.162.46
13241:09/12/17 16:30:13 [63128] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13242:09/12/17 16:30:13 [63128] IPVERIFY: ip found is 1
13243:09/12/17 16:30:15 [63128] Evaluating staleness of remote job statuses.
13244:09/12/17 16:30:18 [63128] resource  is now up
13245:09/12/17 16:30:18 [63128] in doContactSchedd()
13246:09/12/17 16:30:18 [63128] querying for removed/held jobs
13247:09/12/17 16:30:18 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13248:09/12/17 16:30:18 [63128] Fetched 0 job ads from schedd
13249:09/12/17 16:30:18 [63128] Updating classad values for 396.0:
13250:09/12/17 16:30:18 [63128]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#396.0#1505259007"
13251:09/12/17 16:30:18 [63128]    LastRemoteStatusUpdate = 1505259013
13252:09/12/17 16:30:18 [63128] leaving doContactSchedd()
13253:09/12/17 16:30:18 [63128] (396.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
13254:09/12/17 16:30:18 [63128] (396.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
13255:09/12/17 16:30:18 [63128] (396.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13256:09/12/17 16:30:18 [63128] GAHP[63130] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#396.0#1505259007";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/395/0/cluster395.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/395/0/cluster395.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/395/0/cluster395.proc0.subproc0/test.sh"\ ]'
13257:09/12/17 16:30:18 [63128] GAHP[63130] -> 'S'
13258:09/12/17 16:30:19 [63128] GAHP[63130] <- 'RESULTS'
13259:09/12/17 16:30:19 [63128] GAHP[63130] -> 'R'
13260:09/12/17 16:30:19 [63128] GAHP[63130] -> 'S' '1'
13261:09/12/17 16:30:19 [63128] GAHP[63130] -> '2' '0' 'No error' 'slurm/20170912/161690'
13262:09/12/17 16:30:19 [63128] (396.0) doEvaluateState called: gmState GM_SUBMIT, remoteState 0
13263:09/12/17 16:30:19 [63128] (396.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
13264:09/12/17 16:30:23 [63128] in doContactSchedd()
13265:09/12/17 16:30:23 [63128] querying for removed/held jobs
13266:09/12/17 16:30:23 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13267:09/12/17 16:30:23 [63128] Fetched 0 job ads from schedd
13268:09/12/17 16:30:23 [63128] Updating classad values for 396.0:
13269:09/12/17 16:30:23 [63128]    DelegatedProxyExpiration = 1505570326
13270:09/12/17 16:30:23 [63128]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#396.0#1505259007 slurm/20170912/161690"
13271:09/12/17 16:30:23 [63128] leaving doContactSchedd()
13272:09/12/17 16:30:23 [63128] (396.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState 0
13273:09/12/17 16:30:23 [63128] (396.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
13274:09/12/17 16:31:10 [63128] Received CHECK_LEASES signal
13275:09/12/17 16:31:10 [63128] in doContactSchedd()
13276:09/12/17 16:31:10 [63128] querying for renewed leases
13277:09/12/17 16:31:10 [63128] querying for removed/held jobs
13278:09/12/17 16:31:10 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13279:09/12/17 16:31:10 [63128] Fetched 0 job ads from schedd
13280:09/12/17 16:31:10 [63128] leaving doContactSchedd()
13281:09/12/17 16:31:13 [63128] GAHP[63130] <- 'RESULTS'
13282:09/12/17 16:31:13 [63128] GAHP[63130] -> 'S' '0'
13283:09/12/17 16:31:15 [63128] Evaluating staleness of remote job statuses.
13284:09/12/17 16:31:23 [63128] (396.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState 0
13285:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
13286:09/12/17 16:31:23 [63128] GAHP[63130] <- 'BLAH_JOB_STATUS 3 slurm/20170912/161690'
13287:09/12/17 16:31:23 [63128] GAHP[63130] -> 'S'
13288:09/12/17 16:31:23 [63128] GAHP[63130] <- 'RESULTS'
13289:09/12/17 16:31:23 [63128] GAHP[63130] -> 'R'
13290:09/12/17 16:31:23 [63128] GAHP[63130] -> 'S' '1'
13291:09/12/17 16:31:23 [63128] GAHP[63130] -> '3' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161690"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
13292:09/12/17 16:31:23 [63128] (396.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState 0
13293:09/12/17 16:31:23 [63128] (396.0) ***ProcessRemoteAd
13294:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
13295:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
13296:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
13297:09/12/17 16:31:23 [63128] in doContactSchedd()
13298:09/12/17 16:31:23 [63128] querying for removed/held jobs
13299:09/12/17 16:31:23 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13300:09/12/17 16:31:23 [63128] Fetched 0 job ads from schedd
13301:09/12/17 16:31:23 [63128] Updating classad values for 396.0:
13302:09/12/17 16:31:23 [63128]    EnteredCurrentStatus = 1505259083
13303:09/12/17 16:31:23 [63128]    ExitCode = 0
13304:09/12/17 16:31:23 [63128]    GridJobStatus = "COMPLETED"
13305:09/12/17 16:31:23 [63128]    ImageSize = 0
13306:09/12/17 16:31:23 [63128]    JobStatus = 4
13307:09/12/17 16:31:23 [63128]    LastRemoteStatusUpdate = 1505259083
13308:09/12/17 16:31:23 [63128]    RemoteUserCpu = 0
13309:09/12/17 16:31:23 [63128]    RemoteWallClockTime = 0.0
13310:09/12/17 16:31:23 [63128] leaving doContactSchedd()
13311:09/12/17 16:31:23 [63128] (396.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
13312:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
13313:09/12/17 16:31:23 [63128] (396.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
13314:09/12/17 16:31:23 [63128] Initializing Directory: curr_dir = /global/homes/a/alicesgm
13315:09/12/17 16:31:24 [63128] (396.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
13316:09/12/17 16:31:28 [63128] in doContactSchedd()
13317:09/12/17 16:31:28 [63128] querying for removed/held jobs
13318:09/12/17 16:31:28 [63128] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13319:09/12/17 16:31:28 [63128] Fetched 1 job ads from schedd
13320:09/12/17 16:31:28 [63128] Updating classad values for 396.0:
13321:09/12/17 16:31:28 [63128]    CurrentStatusUnknown = false
13322:09/12/17 16:31:28 [63128]    GridJobId = undefined
13323:09/12/17 16:31:28 [63128]    LastRemoteStatusUpdate = 0
13324:09/12/17 16:31:28 [63128]    Managed = "ScheddDone"
13325:09/12/17 16:31:28 [63128] Deleting job 396.0 from schedd
13326:09/12/17 16:31:28 [63128] No jobs left, shutting down
13327:09/12/17 16:31:28 [63128] leaving doContactSchedd()
13328:09/12/17 16:31:28 [63128] Got SIGTERM. Performing graceful shutdown.
13329:09/12/17 16:31:28 [63128] Started timer to call main_shutdown_fast in 1800 seconds
13330:09/12/17 16:31:28 [63128] **** condor_gridmanager (condor_GRIDMANAGER) pid 63128 EXITING WITH STATUS 0
13331:09/12/17 16:34:20 Result of reading /etc/issue:  \S
13333:09/12/17 16:34:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
13335:09/12/17 16:34:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
13336:09/12/17 16:34:20 Enumerating interfaces: lo 127.0.0.1 up
13337:09/12/17 16:34:20 Enumerating interfaces: eth0 10.36.162.46 up
13338:09/12/17 16:34:20 Enumerating interfaces: ib0 128.55.162.46 up
13339:09/12/17 16:34:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
13340:09/12/17 16:34:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
13341:09/12/17 16:34:20 ******************************************************
13342:09/12/17 16:34:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
13343:09/12/17 16:34:20 ** /usr/sbin/condor_gridmanager
13344:09/12/17 16:34:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
13345:09/12/17 16:34:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
13346:09/12/17 16:34:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
13347:09/12/17 16:34:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
13348:09/12/17 16:34:20 ** PID = 63324
13349:09/12/17 16:34:20 ** Log last touched 9/12 16:31:28
13350:09/12/17 16:34:20 ******************************************************
13351:09/12/17 16:34:20 Using config source: /etc/condor-ce/condor_config
13352:09/12/17 16:34:20 Using local config sources: 
13353:09/12/17 16:34:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
13354:09/12/17 16:34:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
13355:09/12/17 16:34:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
13356:09/12/17 16:34:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
13357:09/12/17 16:34:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
13358:09/12/17 16:34:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
13359:09/12/17 16:34:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
13360:09/12/17 16:34:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
13361:09/12/17 16:34:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
13362:09/12/17 16:34:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
13363:09/12/17 16:34:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
13364:09/12/17 16:34:20    /etc/condor-ce/config.d/01-ce-auth.conf
13365:09/12/17 16:34:20    /etc/condor-ce/config.d/01-ce-router.conf
13366:09/12/17 16:34:20    /etc/condor-ce/config.d/01-common-auth.conf
13367:09/12/17 16:34:20    /etc/condor-ce/config.d/02-ce-slurm.conf
13368:09/12/17 16:34:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
13369:09/12/17 16:34:20    /etc/condor-ce/config.d/03-managed-fork.conf
13370:09/12/17 16:34:20    /etc/condor-ce/config.d/05-ce-health.conf
13371:09/12/17 16:34:20    /etc/condor-ce/config.d/05-ce-view.conf
13372:09/12/17 16:34:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
13373:09/12/17 16:34:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
13374:09/12/17 16:34:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
13375:09/12/17 16:34:20    /etc/condor-ce/config.d/50-osg-configure.conf
13376:09/12/17 16:34:20    /etc/condor-ce/config.d/99-local.conf
13377:09/12/17 16:34:20    /usr/share/condor-ce/condor_ce_router_defaults|
13378:09/12/17 16:34:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
13379:09/12/17 16:34:20 CLASSAD_CACHING is ENABLED
13380:09/12/17 16:34:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
13381:09/12/17 16:34:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_13
13382:09/12/17 16:34:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_13>
13383:09/12/17 16:34:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_13>
13384:09/12/17 16:34:20 Setting maximum accepts per cycle 8.
13385:09/12/17 16:34:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13386:09/12/17 16:34:20 [63324] Welcome to the all-singing, all dancing, "amazing" GridManager!
13387:09/12/17 16:34:20 [63324] DaemonCore: No more children processes to reap.
13388:09/12/17 16:34:20 [63324] DaemonCore: in SendAliveToParent()
13389:09/12/17 16:34:20 [63324] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13390:09/12/17 16:34:20 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13391:09/12/17 16:34:20 [63324] IPVERIFY: ip found is 1
13392:09/12/17 16:34:20 [63324] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13393:09/12/17 16:34:20 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13394:09/12/17 16:34:20 [63324] IPVERIFY: ip found is 1
13395:09/12/17 16:34:20 [63324] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13396:09/12/17 16:34:20 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13397:09/12/17 16:34:20 [63324] IPVERIFY: ip found is 1
13398:09/12/17 16:34:20 [63324] IPVERIFY: checking mc0151-ib against 128.55.162.46
13399:09/12/17 16:34:20 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13400:09/12/17 16:34:20 [63324] IPVERIFY: ip found is 1
13401:09/12/17 16:34:20 [63324] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
13402:09/12/17 16:34:20 [63324] DaemonCore: Leaving SendAliveToParent() - success
13403:09/12/17 16:34:20 [63324] Checking proxies
13404:09/12/17 16:34:23 [63324] Received ADD_JOBS signal
13405:09/12/17 16:34:23 [63324] in doContactSchedd()
13406:09/12/17 16:34:23 [63324] querying for new jobs
13407:09/12/17 16:34:23 [63324] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
13408:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 423.0
13409:09/12/17 16:34:23 [63324] (423.0) SetJobLeaseTimers()
13410:09/12/17 16:34:23 [63324] Found job 423.0 --- inserting
13411:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 422.0
13412:09/12/17 16:34:23 [63324] (422.0) SetJobLeaseTimers()
13413:09/12/17 16:34:23 [63324] Found job 422.0 --- inserting
13414:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 421.0
13415:09/12/17 16:34:23 [63324] (421.0) SetJobLeaseTimers()
13416:09/12/17 16:34:23 [63324] Found job 421.0 --- inserting
13417:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 420.0
13418:09/12/17 16:34:23 [63324] (420.0) SetJobLeaseTimers()
13419:09/12/17 16:34:23 [63324] Found job 420.0 --- inserting
13420:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 419.0
13421:09/12/17 16:34:23 [63324] (419.0) SetJobLeaseTimers()
13422:09/12/17 16:34:23 [63324] Found job 419.0 --- inserting
13423:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 418.0
13424:09/12/17 16:34:23 [63324] (418.0) SetJobLeaseTimers()
13425:09/12/17 16:34:23 [63324] Found job 418.0 --- inserting
13426:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 417.0
13427:09/12/17 16:34:23 [63324] (417.0) SetJobLeaseTimers()
13428:09/12/17 16:34:23 [63324] Found job 417.0 --- inserting
13429:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 436.0
13430:09/12/17 16:34:23 [63324] (436.0) SetJobLeaseTimers()
13431:09/12/17 16:34:23 [63324] Found job 436.0 --- inserting
13432:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 435.0
13433:09/12/17 16:34:23 [63324] (435.0) SetJobLeaseTimers()
13434:09/12/17 16:34:23 [63324] Found job 435.0 --- inserting
13435:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 434.0
13436:09/12/17 16:34:23 [63324] (434.0) SetJobLeaseTimers()
13437:09/12/17 16:34:23 [63324] Found job 434.0 --- inserting
13438:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 433.0
13439:09/12/17 16:34:23 [63324] (433.0) SetJobLeaseTimers()
13440:09/12/17 16:34:23 [63324] Found job 433.0 --- inserting
13441:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 432.0
13442:09/12/17 16:34:23 [63324] (432.0) SetJobLeaseTimers()
13443:09/12/17 16:34:23 [63324] Found job 432.0 --- inserting
13444:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 431.0
13445:09/12/17 16:34:23 [63324] (431.0) SetJobLeaseTimers()
13446:09/12/17 16:34:23 [63324] Found job 431.0 --- inserting
13447:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 430.0
13448:09/12/17 16:34:23 [63324] (430.0) SetJobLeaseTimers()
13449:09/12/17 16:34:23 [63324] Found job 430.0 --- inserting
13450:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 429.0
13451:09/12/17 16:34:23 [63324] (429.0) SetJobLeaseTimers()
13452:09/12/17 16:34:23 [63324] Found job 429.0 --- inserting
13453:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 428.0
13454:09/12/17 16:34:23 [63324] (428.0) SetJobLeaseTimers()
13455:09/12/17 16:34:23 [63324] Found job 428.0 --- inserting
13456:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 427.0
13457:09/12/17 16:34:23 [63324] (427.0) SetJobLeaseTimers()
13458:09/12/17 16:34:23 [63324] Found job 427.0 --- inserting
13459:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 426.0
13460:09/12/17 16:34:23 [63324] (426.0) SetJobLeaseTimers()
13461:09/12/17 16:34:23 [63324] Found job 426.0 --- inserting
13462:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 425.0
13463:09/12/17 16:34:23 [63324] (425.0) SetJobLeaseTimers()
13464:09/12/17 16:34:23 [63324] Found job 425.0 --- inserting
13465:09/12/17 16:34:23 [63324] Using job type INFNBatch for job 424.0
13466:09/12/17 16:34:23 [63324] (424.0) SetJobLeaseTimers()
13467:09/12/17 16:34:23 [63324] Found job 424.0 --- inserting
13468:09/12/17 16:34:23 [63324] Fetched 20 new job ads from schedd
13469:09/12/17 16:34:23 [63324] querying for removed/held jobs
13470:09/12/17 16:34:23 [63324] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13471:09/12/17 16:34:23 [63324] Fetched 0 job ads from schedd
13472:09/12/17 16:34:23 [63324] leaving doContactSchedd()
13473:09/12/17 16:34:23 [63324] gahp server not up yet, delaying ping
13474:09/12/17 16:34:23 [63324] *** UpdateLeases called
13475:09/12/17 16:34:23 [63324]     Leases not supported, cancelling timer
13476:09/12/17 16:34:23 [63324] BaseResource::UpdateResource: 
13496:09/12/17 16:34:23 [63324] Trying to update collector <128.55.162.46:9619>
13497:09/12/17 16:34:23 [63324] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13498:09/12/17 16:34:23 [63324] File descriptor limits: max 4096, safe 3277
13499:09/12/17 16:34:23 [63324] (423.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13500:09/12/17 16:34:23 [63324] GAHP server pid = 63327
13501:09/12/17 16:34:23 [63324] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
13502:09/12/17 16:34:23 [63324] GAHP[63327] <- 'COMMANDS'
13503:09/12/17 16:34:23 [63324] GAHP[63327] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
13504:09/12/17 16:34:23 [63324] GAHP[63327] <- 'ASYNC_MODE_ON'
13505:09/12/17 16:34:23 [63324] GAHP[63327] -> 'S' 'Async mode on'
13506:09/12/17 16:34:23 [63324] (423.0) gm state change: GM_INIT -> GM_START
13507:09/12/17 16:34:23 [63324] (423.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13508:09/12/17 16:34:23 [63324] (423.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13509:09/12/17 16:34:23 [63324] (423.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13510:09/12/17 16:34:23 [63324] (422.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13511:09/12/17 16:34:23 [63324] (422.0) gm state change: GM_INIT -> GM_START
13512:09/12/17 16:34:23 [63324] (422.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13513:09/12/17 16:34:23 [63324] (422.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13514:09/12/17 16:34:23 [63324] (422.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13515:09/12/17 16:34:23 [63324] (421.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13516:09/12/17 16:34:23 [63324] (421.0) gm state change: GM_INIT -> GM_START
13517:09/12/17 16:34:23 [63324] (421.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13518:09/12/17 16:34:23 [63324] (421.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13519:09/12/17 16:34:23 [63324] (421.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13520:09/12/17 16:34:23 [63324] (420.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13521:09/12/17 16:34:23 [63324] (420.0) gm state change: GM_INIT -> GM_START
13522:09/12/17 16:34:23 [63324] (420.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13523:09/12/17 16:34:23 [63324] (420.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13524:09/12/17 16:34:23 [63324] (420.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13525:09/12/17 16:34:23 [63324] (419.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13526:09/12/17 16:34:23 [63324] (419.0) gm state change: GM_INIT -> GM_START
13527:09/12/17 16:34:23 [63324] (419.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13528:09/12/17 16:34:23 [63324] (419.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13529:09/12/17 16:34:23 [63324] (419.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13530:09/12/17 16:34:23 [63324] (418.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13531:09/12/17 16:34:23 [63324] (418.0) gm state change: GM_INIT -> GM_START
13532:09/12/17 16:34:23 [63324] (418.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13533:09/12/17 16:34:23 [63324] (418.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13534:09/12/17 16:34:23 [63324] (418.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13535:09/12/17 16:34:23 [63324] (417.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13536:09/12/17 16:34:23 [63324] (417.0) gm state change: GM_INIT -> GM_START
13537:09/12/17 16:34:23 [63324] (417.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13538:09/12/17 16:34:23 [63324] (417.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13539:09/12/17 16:34:23 [63324] (417.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13540:09/12/17 16:34:23 [63324] (436.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13541:09/12/17 16:34:23 [63324] (436.0) gm state change: GM_INIT -> GM_START
13542:09/12/17 16:34:23 [63324] (436.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13543:09/12/17 16:34:23 [63324] (436.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13544:09/12/17 16:34:23 [63324] (436.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13545:09/12/17 16:34:23 [63324] This process has a valid certificate & key
13546:09/12/17 16:34:23 [63324] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13547:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13548:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13549:09/12/17 16:34:23 [63324] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13550:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13551:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13552:09/12/17 16:34:23 [63324] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13553:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13554:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13555:09/12/17 16:34:23 [63324] IPVERIFY: checking mc0151-ib against 128.55.162.46
13556:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13557:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13558:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13559:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13560:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13561:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13562:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13563:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
13564:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
13565:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
13566:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
13567:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
13568:09/12/17 16:34:23 [63324] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
13569:09/12/17 16:34:23 [63324] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
13570:09/12/17 16:34:23 [63324] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13571:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13572:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13573:09/12/17 16:34:23 [63324] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13574:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13575:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13576:09/12/17 16:34:23 [63324] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13577:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13578:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13579:09/12/17 16:34:23 [63324] IPVERIFY: checking mc0151-ib against 128.55.162.46
13580:09/12/17 16:34:23 [63324] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13581:09/12/17 16:34:23 [63324] IPVERIFY: ip found is 1
13582:09/12/17 16:34:23 [63324] (435.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13583:09/12/17 16:34:23 [63324] (435.0) gm state change: GM_INIT -> GM_START
13584:09/12/17 16:34:23 [63324] (435.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13585:09/12/17 16:34:23 [63324] (435.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13586:09/12/17 16:34:23 [63324] (435.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13587:09/12/17 16:34:23 [63324] (434.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13588:09/12/17 16:34:23 [63324] (434.0) gm state change: GM_INIT -> GM_START
13589:09/12/17 16:34:23 [63324] (434.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13590:09/12/17 16:34:23 [63324] (434.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13591:09/12/17 16:34:23 [63324] (434.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13592:09/12/17 16:34:23 [63324] (433.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13593:09/12/17 16:34:23 [63324] (433.0) gm state change: GM_INIT -> GM_START
13594:09/12/17 16:34:23 [63324] (433.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13595:09/12/17 16:34:23 [63324] (433.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13596:09/12/17 16:34:23 [63324] (433.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13597:09/12/17 16:34:23 [63324] (432.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13598:09/12/17 16:34:23 [63324] (432.0) gm state change: GM_INIT -> GM_START
13599:09/12/17 16:34:23 [63324] (432.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13600:09/12/17 16:34:23 [63324] (432.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13601:09/12/17 16:34:23 [63324] (432.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13602:09/12/17 16:34:23 [63324] (431.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13603:09/12/17 16:34:23 [63324] (431.0) gm state change: GM_INIT -> GM_START
13604:09/12/17 16:34:23 [63324] (431.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13605:09/12/17 16:34:23 [63324] (431.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13606:09/12/17 16:34:23 [63324] (431.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13607:09/12/17 16:34:23 [63324] (430.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13608:09/12/17 16:34:23 [63324] (430.0) gm state change: GM_INIT -> GM_START
13609:09/12/17 16:34:23 [63324] (430.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13610:09/12/17 16:34:23 [63324] (430.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13611:09/12/17 16:34:23 [63324] (430.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13612:09/12/17 16:34:23 [63324] (429.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13613:09/12/17 16:34:23 [63324] (429.0) gm state change: GM_INIT -> GM_START
13614:09/12/17 16:34:23 [63324] (429.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13615:09/12/17 16:34:23 [63324] (429.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13616:09/12/17 16:34:23 [63324] (429.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13617:09/12/17 16:34:23 [63324] (428.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13618:09/12/17 16:34:23 [63324] (428.0) gm state change: GM_INIT -> GM_START
13619:09/12/17 16:34:23 [63324] (428.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13620:09/12/17 16:34:23 [63324] (428.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13621:09/12/17 16:34:23 [63324] (428.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13622:09/12/17 16:34:23 [63324] (427.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13623:09/12/17 16:34:23 [63324] (427.0) gm state change: GM_INIT -> GM_START
13624:09/12/17 16:34:23 [63324] (427.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13625:09/12/17 16:34:23 [63324] (427.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13626:09/12/17 16:34:23 [63324] (427.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13627:09/12/17 16:34:23 [63324] (426.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13628:09/12/17 16:34:23 [63324] (426.0) gm state change: GM_INIT -> GM_START
13629:09/12/17 16:34:23 [63324] (426.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13630:09/12/17 16:34:23 [63324] (426.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13631:09/12/17 16:34:23 [63324] (426.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13632:09/12/17 16:34:23 [63324] (425.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13633:09/12/17 16:34:23 [63324] (425.0) gm state change: GM_INIT -> GM_START
13634:09/12/17 16:34:23 [63324] (425.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13635:09/12/17 16:34:23 [63324] (425.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13636:09/12/17 16:34:23 [63324] (425.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13637:09/12/17 16:34:23 [63324] (424.0) doEvaluateState called: gmState GM_INIT, remoteState 0
13638:09/12/17 16:34:23 [63324] (424.0) gm state change: GM_INIT -> GM_START
13639:09/12/17 16:34:23 [63324] (424.0) gm state change: GM_START -> GM_CLEAR_REQUEST
13640:09/12/17 16:34:23 [63324] (424.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
13641:09/12/17 16:34:23 [63324] (424.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
13642:09/12/17 16:34:25 [63324] Evaluating staleness of remote job statuses.
13643:09/12/17 16:34:28 [63324] resource  is now up
13644:09/12/17 16:34:28 [63324] in doContactSchedd()
13645:09/12/17 16:34:28 [63324] querying for removed/held jobs
13646:09/12/17 16:34:28 [63324] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13647:09/12/17 16:34:28 [63324] Fetched 0 job ads from schedd
13648:09/12/17 16:34:28 [63324] Updating classad values for 434.0:
13649:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#434.0#1505259258"
13650:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13651:09/12/17 16:34:28 [63324] Updating classad values for 435.0:
13652:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#435.0#1505259258"
13653:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13654:09/12/17 16:34:28 [63324] Updating classad values for 436.0:
13655:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#436.0#1505259258"
13656:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13657:09/12/17 16:34:28 [63324] Updating classad values for 417.0:
13658:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#417.0#1505259258"
13659:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13660:09/12/17 16:34:28 [63324] Updating classad values for 418.0:
13661:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#418.0#1505259258"
13662:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13663:09/12/17 16:34:28 [63324] Updating classad values for 419.0:
13664:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#419.0#1505259258"
13665:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13666:09/12/17 16:34:28 [63324] Updating classad values for 420.0:
13667:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#420.0#1505259258"
13668:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13669:09/12/17 16:34:28 [63324] Updating classad values for 421.0:
13670:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#421.0#1505259258"
13671:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13672:09/12/17 16:34:28 [63324] Updating classad values for 422.0:
13673:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#422.0#1505259258"
13674:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13675:09/12/17 16:34:28 [63324] Updating classad values for 423.0:
13676:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#423.0#1505259258"
13677:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13678:09/12/17 16:34:28 [63324] Updating classad values for 424.0:
13679:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#424.0#1505259258"
13680:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13681:09/12/17 16:34:28 [63324] Updating classad values for 425.0:
13682:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#425.0#1505259258"
13683:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13684:09/12/17 16:34:28 [63324] Updating classad values for 426.0:
13685:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#426.0#1505259258"
13686:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13687:09/12/17 16:34:28 [63324] Updating classad values for 427.0:
13688:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#427.0#1505259258"
13689:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13690:09/12/17 16:34:28 [63324] Updating classad values for 428.0:
13691:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#428.0#1505259258"
13692:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13693:09/12/17 16:34:28 [63324] Updating classad values for 429.0:
13694:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#429.0#1505259258"
13695:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13696:09/12/17 16:34:28 [63324] Updating classad values for 430.0:
13697:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#430.0#1505259258"
13698:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13699:09/12/17 16:34:28 [63324] Updating classad values for 431.0:
13700:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#431.0#1505259258"
13701:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13702:09/12/17 16:34:28 [63324] Updating classad values for 432.0:
13703:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#432.0#1505259258"
13704:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13705:09/12/17 16:34:28 [63324] Updating classad values for 433.0:
13706:09/12/17 16:34:28 [63324]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#433.0#1505259258"
13707:09/12/17 16:34:28 [63324]    LastRemoteStatusUpdate = 1505259263
13708:09/12/17 16:34:28 [63324] leaving doContactSchedd()
13709:09/12/17 16:34:28 [63324] (434.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
13710:09/12/17 16:34:28 [63324] (434.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
13711:09/12/17 16:34:28 [63324] (434.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13712:09/12/17 16:34:28 [63324] GAHP[63327] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#434.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0/test.sh"\ ]'
13713:09/12/17 16:34:28 [63324] GAHP[63327] -> 'S'
13714:09/12/17 16:34:28 [63324] (435.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
13715:09/12/17 16:34:28 [63324] (435.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
13716:09/12/17 16:34:28 [63324] (435.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13717:09/12/17 16:34:28 [63324] GAHP[63327] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#435.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0/test.sh"\ ]'
13718:09/12/17 16:34:28 [63324] GAHP[63327] -> 'S'
13719:09/12/17 16:34:28 [63324] (436.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
13720:09/12/17 16:34:28 [63324] (436.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
13721:09/12/17 16:34:28 [63324] (436.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13722:09/12/17 16:34:28 [63324] GAHP[63327] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#436.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0/test.sh"\ ]'
13723:09/12/17 16:34:28 [63324] GAHP[63327] -> 'S'
13724:09/12/17 16:34:28 [63324] (417.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
13725:09/12/17 16:34:28 [63324] (417.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
13726:09/12/17 16:34:28 [63324] (417.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13727:09/12/17 16:34:28 [63324] GAHP[63327] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#417.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0/test.sh"\ ]'
13728:09/12/17 16:34:28 [63324] GAHP[63327] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
13729:09/12/17 16:34:28 [63324] GAHP[63327] -> EOF
13730:09/12/17 16:34:28 [63324] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
13731:09/12/17 16:39:20 Result of reading /etc/issue:  \S
13733:09/12/17 16:39:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
13735:09/12/17 16:39:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
13736:09/12/17 16:39:20 Enumerating interfaces: lo 127.0.0.1 up
13737:09/12/17 16:39:20 Enumerating interfaces: eth0 10.36.162.46 up
13738:09/12/17 16:39:20 Enumerating interfaces: ib0 128.55.162.46 up
13739:09/12/17 16:39:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
13740:09/12/17 16:39:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
13741:09/12/17 16:39:20 ******************************************************
13742:09/12/17 16:39:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
13743:09/12/17 16:39:20 ** /usr/sbin/condor_gridmanager
13744:09/12/17 16:39:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
13745:09/12/17 16:39:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
13746:09/12/17 16:39:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
13747:09/12/17 16:39:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
13748:09/12/17 16:39:20 ** PID = 63374
13749:09/12/17 16:39:20 ** Log last touched 9/12 16:34:28
13750:09/12/17 16:39:20 ******************************************************
13751:09/12/17 16:39:20 Using config source: /etc/condor-ce/condor_config
13752:09/12/17 16:39:20 Using local config sources: 
13753:09/12/17 16:39:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
13754:09/12/17 16:39:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
13755:09/12/17 16:39:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
13756:09/12/17 16:39:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
13757:09/12/17 16:39:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
13758:09/12/17 16:39:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
13759:09/12/17 16:39:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
13760:09/12/17 16:39:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
13761:09/12/17 16:39:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
13762:09/12/17 16:39:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
13763:09/12/17 16:39:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
13764:09/12/17 16:39:20    /etc/condor-ce/config.d/01-ce-auth.conf
13765:09/12/17 16:39:20    /etc/condor-ce/config.d/01-ce-router.conf
13766:09/12/17 16:39:20    /etc/condor-ce/config.d/01-common-auth.conf
13767:09/12/17 16:39:20    /etc/condor-ce/config.d/02-ce-slurm.conf
13768:09/12/17 16:39:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
13769:09/12/17 16:39:20    /etc/condor-ce/config.d/03-managed-fork.conf
13770:09/12/17 16:39:20    /etc/condor-ce/config.d/05-ce-health.conf
13771:09/12/17 16:39:20    /etc/condor-ce/config.d/05-ce-view.conf
13772:09/12/17 16:39:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
13773:09/12/17 16:39:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
13774:09/12/17 16:39:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
13775:09/12/17 16:39:20    /etc/condor-ce/config.d/50-osg-configure.conf
13776:09/12/17 16:39:20    /etc/condor-ce/config.d/99-local.conf
13777:09/12/17 16:39:20    /usr/share/condor-ce/condor_ce_router_defaults|
13778:09/12/17 16:39:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
13779:09/12/17 16:39:20 CLASSAD_CACHING is ENABLED
13780:09/12/17 16:39:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
13781:09/12/17 16:39:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_16
13782:09/12/17 16:39:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_16>
13783:09/12/17 16:39:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_16>
13784:09/12/17 16:39:20 Setting maximum accepts per cycle 8.
13785:09/12/17 16:39:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13786:09/12/17 16:39:20 [63374] Welcome to the all-singing, all dancing, "amazing" GridManager!
13787:09/12/17 16:39:20 [63374] DaemonCore: No more children processes to reap.
13788:09/12/17 16:39:20 [63374] DaemonCore: in SendAliveToParent()
13789:09/12/17 16:39:20 [63374] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13790:09/12/17 16:39:20 [63374] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13791:09/12/17 16:39:20 [63374] IPVERIFY: ip found is 1
13792:09/12/17 16:39:20 [63374] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13793:09/12/17 16:39:20 [63374] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13794:09/12/17 16:39:20 [63374] IPVERIFY: ip found is 1
13795:09/12/17 16:39:20 [63374] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13796:09/12/17 16:39:20 [63374] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13797:09/12/17 16:39:20 [63374] IPVERIFY: ip found is 1
13798:09/12/17 16:39:20 [63374] IPVERIFY: checking mc0151-ib against 128.55.162.46
13799:09/12/17 16:39:20 [63374] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13800:09/12/17 16:39:20 [63374] IPVERIFY: ip found is 1
13801:09/12/17 16:39:20 [63374] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
13802:09/12/17 16:39:20 [63374] DaemonCore: Leaving SendAliveToParent() - success
13803:09/12/17 16:39:20 [63374] Checking proxies
13804:09/12/17 16:39:23 [63374] Received ADD_JOBS signal
13805:09/12/17 16:39:23 [63374] in doContactSchedd()
13806:09/12/17 16:39:23 [63374] querying for new jobs
13807:09/12/17 16:39:23 [63374] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
13808:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 423.0
13809:09/12/17 16:39:23 [63374] (423.0) SetJobLeaseTimers()
13810:09/12/17 16:39:23 [63374] Found job 423.0 --- inserting
13811:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 422.0
13812:09/12/17 16:39:23 [63374] (422.0) SetJobLeaseTimers()
13813:09/12/17 16:39:23 [63374] Found job 422.0 --- inserting
13814:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 421.0
13815:09/12/17 16:39:23 [63374] (421.0) SetJobLeaseTimers()
13816:09/12/17 16:39:23 [63374] Found job 421.0 --- inserting
13817:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 420.0
13818:09/12/17 16:39:23 [63374] (420.0) SetJobLeaseTimers()
13819:09/12/17 16:39:23 [63374] Found job 420.0 --- inserting
13820:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 419.0
13821:09/12/17 16:39:23 [63374] (419.0) SetJobLeaseTimers()
13822:09/12/17 16:39:23 [63374] Found job 419.0 --- inserting
13823:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 418.0
13824:09/12/17 16:39:23 [63374] (418.0) SetJobLeaseTimers()
13825:09/12/17 16:39:23 [63374] Found job 418.0 --- inserting
13826:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 417.0
13827:09/12/17 16:39:23 [63374] (417.0) SetJobLeaseTimers()
13828:09/12/17 16:39:23 [63374] Found job 417.0 --- inserting
13829:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 436.0
13830:09/12/17 16:39:23 [63374] (436.0) SetJobLeaseTimers()
13831:09/12/17 16:39:23 [63374] Found job 436.0 --- inserting
13832:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 435.0
13833:09/12/17 16:39:23 [63374] (435.0) SetJobLeaseTimers()
13834:09/12/17 16:39:23 [63374] Found job 435.0 --- inserting
13835:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 434.0
13836:09/12/17 16:39:23 [63374] (434.0) SetJobLeaseTimers()
13837:09/12/17 16:39:23 [63374] Found job 434.0 --- inserting
13838:09/12/17 16:39:23 [63374] Using job type INFNBatch for job 433.0
13839:09/12/17 16:39:24 [63374] (433.0) SetJobLeaseTimers()
13840:09/12/17 16:39:24 [63374] Found job 433.0 --- inserting
13841:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 432.0
13842:09/12/17 16:39:24 [63374] (432.0) SetJobLeaseTimers()
13843:09/12/17 16:39:24 [63374] Found job 432.0 --- inserting
13844:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 431.0
13845:09/12/17 16:39:24 [63374] (431.0) SetJobLeaseTimers()
13846:09/12/17 16:39:24 [63374] Found job 431.0 --- inserting
13847:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 430.0
13848:09/12/17 16:39:24 [63374] (430.0) SetJobLeaseTimers()
13849:09/12/17 16:39:24 [63374] Found job 430.0 --- inserting
13850:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 429.0
13851:09/12/17 16:39:24 [63374] (429.0) SetJobLeaseTimers()
13852:09/12/17 16:39:24 [63374] Found job 429.0 --- inserting
13853:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 428.0
13854:09/12/17 16:39:24 [63374] (428.0) SetJobLeaseTimers()
13855:09/12/17 16:39:24 [63374] Found job 428.0 --- inserting
13856:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 427.0
13857:09/12/17 16:39:24 [63374] (427.0) SetJobLeaseTimers()
13858:09/12/17 16:39:24 [63374] Found job 427.0 --- inserting
13859:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 426.0
13860:09/12/17 16:39:24 [63374] (426.0) SetJobLeaseTimers()
13861:09/12/17 16:39:24 [63374] Found job 426.0 --- inserting
13862:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 425.0
13863:09/12/17 16:39:24 [63374] (425.0) SetJobLeaseTimers()
13864:09/12/17 16:39:24 [63374] Found job 425.0 --- inserting
13865:09/12/17 16:39:24 [63374] Using job type INFNBatch for job 424.0
13866:09/12/17 16:39:24 [63374] (424.0) SetJobLeaseTimers()
13867:09/12/17 16:39:24 [63374] Found job 424.0 --- inserting
13868:09/12/17 16:39:24 [63374] Fetched 20 new job ads from schedd
13869:09/12/17 16:39:24 [63374] querying for removed/held jobs
13870:09/12/17 16:39:24 [63374] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
13871:09/12/17 16:39:24 [63374] Fetched 0 job ads from schedd
13872:09/12/17 16:39:24 [63374] leaving doContactSchedd()
13873:09/12/17 16:39:24 [63374] gahp server not up yet, delaying ping
13874:09/12/17 16:39:24 [63374] *** UpdateLeases called
13875:09/12/17 16:39:24 [63374]     Leases not supported, cancelling timer
13876:09/12/17 16:39:24 [63374] BaseResource::UpdateResource: 
13896:09/12/17 16:39:24 [63374] Trying to update collector <128.55.162.46:9619>
13897:09/12/17 16:39:24 [63374] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13898:09/12/17 16:39:24 [63374] File descriptor limits: max 4096, safe 3277
13899:09/12/17 16:39:24 [63374] (423.0) doEvaluateState called: gmState GM_INIT, remoteState -1
13900:09/12/17 16:39:24 [63374] GAHP server pid = 63376
13901:09/12/17 16:39:24 [63374] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
13902:09/12/17 16:39:24 [63374] GAHP[63376] <- 'COMMANDS'
13903:09/12/17 16:39:24 [63374] GAHP[63376] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
13904:09/12/17 16:39:24 [63374] GAHP[63376] <- 'ASYNC_MODE_ON'
13905:09/12/17 16:39:24 [63374] GAHP[63376] -> 'S' 'Async mode on'
13906:09/12/17 16:39:24 [63374] (423.0) gm state change: GM_INIT -> GM_START
13907:09/12/17 16:39:24 [63374] (423.0) gm state change: GM_START -> GM_TRANSFER_INPUT
13908:09/12/17 16:39:24 [63374] (423.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13909:09/12/17 16:39:24 [63374] GAHP[63376] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#423.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0/test.sh"\ ]'
13910:09/12/17 16:39:24 [63374] GAHP[63376] -> 'S'
13911:09/12/17 16:39:24 [63374] (422.0) doEvaluateState called: gmState GM_INIT, remoteState -1
13912:09/12/17 16:39:24 [63374] (422.0) gm state change: GM_INIT -> GM_START
13913:09/12/17 16:39:24 [63374] (422.0) gm state change: GM_START -> GM_TRANSFER_INPUT
13914:09/12/17 16:39:24 [63374] (422.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13915:09/12/17 16:39:24 [63374] GAHP[63376] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#422.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0/test.sh"\ ]'
13916:09/12/17 16:39:24 [63374] GAHP[63376] -> 'S'
13917:09/12/17 16:39:24 [63374] (421.0) doEvaluateState called: gmState GM_INIT, remoteState -1
13918:09/12/17 16:39:24 [63374] (421.0) gm state change: GM_INIT -> GM_START
13919:09/12/17 16:39:24 [63374] (421.0) gm state change: GM_START -> GM_TRANSFER_INPUT
13920:09/12/17 16:39:24 [63374] (421.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13921:09/12/17 16:39:24 [63374] GAHP[63376] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#421.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0/test.sh"\ ]'
13922:09/12/17 16:39:24 [63374] GAHP[63376] -> 'S'
13923:09/12/17 16:39:24 [63374] (420.0) doEvaluateState called: gmState GM_INIT, remoteState -1
13924:09/12/17 16:39:24 [63374] (420.0) gm state change: GM_INIT -> GM_START
13925:09/12/17 16:39:24 [63374] (420.0) gm state change: GM_START -> GM_TRANSFER_INPUT
13926:09/12/17 16:39:24 [63374] (420.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
13927:09/12/17 16:39:24 [63374] GAHP[63376] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#420.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0/test.sh"\ ]'
13928:09/12/17 16:39:24 [63374] GAHP[63376] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
13929:09/12/17 16:39:24 [63374] GAHP[63376] -> EOF
13930:09/12/17 16:39:24 [63374] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
13931:09/12/17 16:44:22 Result of reading /etc/issue:  \S
13933:09/12/17 16:44:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
13935:09/12/17 16:44:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
13936:09/12/17 16:44:22 Enumerating interfaces: lo 127.0.0.1 up
13937:09/12/17 16:44:22 Enumerating interfaces: eth0 10.36.162.46 up
13938:09/12/17 16:44:22 Enumerating interfaces: ib0 128.55.162.46 up
13939:09/12/17 16:44:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
13940:09/12/17 16:44:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
13941:09/12/17 16:44:22 ******************************************************
13942:09/12/17 16:44:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
13943:09/12/17 16:44:22 ** /usr/sbin/condor_gridmanager
13944:09/12/17 16:44:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
13945:09/12/17 16:44:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
13946:09/12/17 16:44:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
13947:09/12/17 16:44:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
13948:09/12/17 16:44:22 ** PID = 63416
13949:09/12/17 16:44:22 ** Log last touched 9/12 16:39:24
13950:09/12/17 16:44:22 ******************************************************
13951:09/12/17 16:44:22 Using config source: /etc/condor-ce/condor_config
13952:09/12/17 16:44:22 Using local config sources: 
13953:09/12/17 16:44:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
13954:09/12/17 16:44:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
13955:09/12/17 16:44:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
13956:09/12/17 16:44:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
13957:09/12/17 16:44:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
13958:09/12/17 16:44:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
13959:09/12/17 16:44:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
13960:09/12/17 16:44:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
13961:09/12/17 16:44:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
13962:09/12/17 16:44:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
13963:09/12/17 16:44:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
13964:09/12/17 16:44:22    /etc/condor-ce/config.d/01-ce-auth.conf
13965:09/12/17 16:44:22    /etc/condor-ce/config.d/01-ce-router.conf
13966:09/12/17 16:44:22    /etc/condor-ce/config.d/01-common-auth.conf
13967:09/12/17 16:44:22    /etc/condor-ce/config.d/02-ce-slurm.conf
13968:09/12/17 16:44:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
13969:09/12/17 16:44:22    /etc/condor-ce/config.d/03-managed-fork.conf
13970:09/12/17 16:44:22    /etc/condor-ce/config.d/05-ce-health.conf
13971:09/12/17 16:44:22    /etc/condor-ce/config.d/05-ce-view.conf
13972:09/12/17 16:44:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
13973:09/12/17 16:44:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
13974:09/12/17 16:44:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
13975:09/12/17 16:44:22    /etc/condor-ce/config.d/50-osg-configure.conf
13976:09/12/17 16:44:22    /etc/condor-ce/config.d/99-local.conf
13977:09/12/17 16:44:22    /usr/share/condor-ce/condor_ce_router_defaults|
13978:09/12/17 16:44:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
13979:09/12/17 16:44:22 CLASSAD_CACHING is ENABLED
13980:09/12/17 16:44:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
13981:09/12/17 16:44:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_18
13982:09/12/17 16:44:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_18>
13983:09/12/17 16:44:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_18>
13984:09/12/17 16:44:22 Setting maximum accepts per cycle 8.
13985:09/12/17 16:44:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
13986:09/12/17 16:44:22 [63416] Welcome to the all-singing, all dancing, "amazing" GridManager!
13987:09/12/17 16:44:22 [63416] DaemonCore: No more children processes to reap.
13988:09/12/17 16:44:22 [63416] DaemonCore: in SendAliveToParent()
13989:09/12/17 16:44:22 [63416] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
13990:09/12/17 16:44:22 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13991:09/12/17 16:44:22 [63416] IPVERIFY: ip found is 1
13992:09/12/17 16:44:22 [63416] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
13993:09/12/17 16:44:22 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13994:09/12/17 16:44:22 [63416] IPVERIFY: ip found is 1
13995:09/12/17 16:44:22 [63416] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
13996:09/12/17 16:44:22 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
13997:09/12/17 16:44:22 [63416] IPVERIFY: ip found is 1
13998:09/12/17 16:44:22 [63416] IPVERIFY: checking mc0151-ib against 128.55.162.46
13999:09/12/17 16:44:22 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14000:09/12/17 16:44:22 [63416] IPVERIFY: ip found is 1
14001:09/12/17 16:44:22 [63416] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
14002:09/12/17 16:44:22 [63416] DaemonCore: Leaving SendAliveToParent() - success
14003:09/12/17 16:44:22 [63416] Checking proxies
14004:09/12/17 16:44:24 [63416] Received ADD_JOBS signal
14005:09/12/17 16:44:24 [63416] in doContactSchedd()
14006:09/12/17 16:44:24 [63416] querying for new jobs
14007:09/12/17 16:44:24 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
14008:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 423.0
14009:09/12/17 16:44:24 [63416] (423.0) SetJobLeaseTimers()
14010:09/12/17 16:44:24 [63416] Found job 423.0 --- inserting
14011:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 422.0
14012:09/12/17 16:44:24 [63416] (422.0) SetJobLeaseTimers()
14013:09/12/17 16:44:24 [63416] Found job 422.0 --- inserting
14014:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 421.0
14015:09/12/17 16:44:24 [63416] (421.0) SetJobLeaseTimers()
14016:09/12/17 16:44:24 [63416] Found job 421.0 --- inserting
14017:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 420.0
14018:09/12/17 16:44:24 [63416] (420.0) SetJobLeaseTimers()
14019:09/12/17 16:44:24 [63416] Found job 420.0 --- inserting
14020:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 419.0
14021:09/12/17 16:44:24 [63416] (419.0) SetJobLeaseTimers()
14022:09/12/17 16:44:24 [63416] Found job 419.0 --- inserting
14023:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 418.0
14024:09/12/17 16:44:24 [63416] (418.0) SetJobLeaseTimers()
14025:09/12/17 16:44:24 [63416] Found job 418.0 --- inserting
14026:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 417.0
14027:09/12/17 16:44:24 [63416] (417.0) SetJobLeaseTimers()
14028:09/12/17 16:44:24 [63416] Found job 417.0 --- inserting
14029:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 436.0
14030:09/12/17 16:44:24 [63416] (436.0) SetJobLeaseTimers()
14031:09/12/17 16:44:24 [63416] Found job 436.0 --- inserting
14032:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 435.0
14033:09/12/17 16:44:24 [63416] (435.0) SetJobLeaseTimers()
14034:09/12/17 16:44:24 [63416] Found job 435.0 --- inserting
14035:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 434.0
14036:09/12/17 16:44:24 [63416] (434.0) SetJobLeaseTimers()
14037:09/12/17 16:44:24 [63416] Found job 434.0 --- inserting
14038:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 433.0
14039:09/12/17 16:44:24 [63416] (433.0) SetJobLeaseTimers()
14040:09/12/17 16:44:24 [63416] Found job 433.0 --- inserting
14041:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 432.0
14042:09/12/17 16:44:24 [63416] (432.0) SetJobLeaseTimers()
14043:09/12/17 16:44:24 [63416] Found job 432.0 --- inserting
14044:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 431.0
14045:09/12/17 16:44:24 [63416] (431.0) SetJobLeaseTimers()
14046:09/12/17 16:44:24 [63416] Found job 431.0 --- inserting
14047:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 430.0
14048:09/12/17 16:44:24 [63416] (430.0) SetJobLeaseTimers()
14049:09/12/17 16:44:24 [63416] Found job 430.0 --- inserting
14050:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 429.0
14051:09/12/17 16:44:24 [63416] (429.0) SetJobLeaseTimers()
14052:09/12/17 16:44:24 [63416] Found job 429.0 --- inserting
14053:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 428.0
14054:09/12/17 16:44:24 [63416] (428.0) SetJobLeaseTimers()
14055:09/12/17 16:44:24 [63416] Found job 428.0 --- inserting
14056:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 427.0
14057:09/12/17 16:44:24 [63416] (427.0) SetJobLeaseTimers()
14058:09/12/17 16:44:24 [63416] Found job 427.0 --- inserting
14059:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 426.0
14060:09/12/17 16:44:24 [63416] (426.0) SetJobLeaseTimers()
14061:09/12/17 16:44:24 [63416] Found job 426.0 --- inserting
14062:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 425.0
14063:09/12/17 16:44:24 [63416] (425.0) SetJobLeaseTimers()
14064:09/12/17 16:44:24 [63416] Found job 425.0 --- inserting
14065:09/12/17 16:44:24 [63416] Using job type INFNBatch for job 424.0
14066:09/12/17 16:44:24 [63416] (424.0) SetJobLeaseTimers()
14067:09/12/17 16:44:24 [63416] Found job 424.0 --- inserting
14068:09/12/17 16:44:24 [63416] Fetched 20 new job ads from schedd
14069:09/12/17 16:44:24 [63416] querying for removed/held jobs
14070:09/12/17 16:44:24 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14071:09/12/17 16:44:24 [63416] Fetched 0 job ads from schedd
14072:09/12/17 16:44:24 [63416] leaving doContactSchedd()
14073:09/12/17 16:44:24 [63416] gahp server not up yet, delaying ping
14074:09/12/17 16:44:24 [63416] *** UpdateLeases called
14075:09/12/17 16:44:24 [63416]     Leases not supported, cancelling timer
14076:09/12/17 16:44:24 [63416] BaseResource::UpdateResource: 
14096:09/12/17 16:44:24 [63416] Trying to update collector <128.55.162.46:9619>
14097:09/12/17 16:44:24 [63416] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
14098:09/12/17 16:44:24 [63416] File descriptor limits: max 4096, safe 3277
14099:09/12/17 16:44:24 [63416] (423.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14100:09/12/17 16:44:24 [63416] GAHP server pid = 63418
14101:09/12/17 16:44:24 [63416] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
14102:09/12/17 16:44:24 [63416] GAHP[63418] <- 'COMMANDS'
14103:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
14104:09/12/17 16:44:24 [63416] GAHP[63418] <- 'ASYNC_MODE_ON'
14105:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S' 'Async mode on'
14106:09/12/17 16:44:24 [63416] (423.0) gm state change: GM_INIT -> GM_START
14107:09/12/17 16:44:24 [63416] (423.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14108:09/12/17 16:44:24 [63416] (423.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14109:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#423.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/397/0/cluster397.proc0.subproc0/test.sh"\ ]'
14110:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14111:09/12/17 16:44:24 [63416] (422.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14112:09/12/17 16:44:24 [63416] (422.0) gm state change: GM_INIT -> GM_START
14113:09/12/17 16:44:24 [63416] (422.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14114:09/12/17 16:44:24 [63416] (422.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14115:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#422.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/409/0/cluster409.proc0.subproc0/test.sh"\ ]'
14116:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14117:09/12/17 16:44:24 [63416] (421.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14118:09/12/17 16:44:24 [63416] (421.0) gm state change: GM_INIT -> GM_START
14119:09/12/17 16:44:24 [63416] (421.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14120:09/12/17 16:44:24 [63416] (421.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14121:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#421.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/408/0/cluster408.proc0.subproc0/test.sh"\ ]'
14122:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14123:09/12/17 16:44:24 [63416] (420.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14124:09/12/17 16:44:24 [63416] (420.0) gm state change: GM_INIT -> GM_START
14125:09/12/17 16:44:24 [63416] (420.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14126:09/12/17 16:44:24 [63416] (420.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14127:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#420.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/407/0/cluster407.proc0.subproc0/test.sh"\ ]'
14128:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14129:09/12/17 16:44:24 [63416] (419.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14130:09/12/17 16:44:24 [63416] (419.0) gm state change: GM_INIT -> GM_START
14131:09/12/17 16:44:24 [63416] (419.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14132:09/12/17 16:44:24 [63416] (419.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14133:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#419.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/416/0/cluster416.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/416/0/cluster416.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/416/0/cluster416.proc0.subproc0/test.sh"\ ]'
14134:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14135:09/12/17 16:44:24 [63416] This process has a valid certificate & key
14136:09/12/17 16:44:24 [63416] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
14137:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14138:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14139:09/12/17 16:44:24 [63416] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
14140:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14141:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14142:09/12/17 16:44:24 [63416] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
14143:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14144:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14145:09/12/17 16:44:24 [63416] IPVERIFY: checking mc0151-ib against 128.55.162.46
14146:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14147:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14148:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14149:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14150:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14151:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14152:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14153:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
14154:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
14155:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
14156:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
14157:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
14158:09/12/17 16:44:24 [63416] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
14159:09/12/17 16:44:24 [63416] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
14160:09/12/17 16:44:24 [63416] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
14161:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14162:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14163:09/12/17 16:44:24 [63416] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
14164:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14165:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14166:09/12/17 16:44:24 [63416] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
14167:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14168:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14169:09/12/17 16:44:24 [63416] IPVERIFY: checking mc0151-ib against 128.55.162.46
14170:09/12/17 16:44:24 [63416] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
14171:09/12/17 16:44:24 [63416] IPVERIFY: ip found is 1
14172:09/12/17 16:44:24 [63416] (418.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14173:09/12/17 16:44:24 [63416] (418.0) gm state change: GM_INIT -> GM_START
14174:09/12/17 16:44:24 [63416] (418.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14175:09/12/17 16:44:24 [63416] (418.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14176:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 7 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#418.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/406/0/cluster406.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/406/0/cluster406.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/406/0/cluster406.proc0.subproc0/test.sh"\ ]'
14177:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14178:09/12/17 16:44:24 [63416] (417.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14179:09/12/17 16:44:24 [63416] (417.0) gm state change: GM_INIT -> GM_START
14180:09/12/17 16:44:24 [63416] (417.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14181:09/12/17 16:44:24 [63416] (417.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14182:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 8 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#417.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/415/0/cluster415.proc0.subproc0/test.sh"\ ]'
14183:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14184:09/12/17 16:44:24 [63416] (436.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14185:09/12/17 16:44:24 [63416] (436.0) gm state change: GM_INIT -> GM_START
14186:09/12/17 16:44:24 [63416] (436.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14187:09/12/17 16:44:24 [63416] (436.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14188:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 9 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#436.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/405/0/cluster405.proc0.subproc0/test.sh"\ ]'
14189:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14190:09/12/17 16:44:24 [63416] (435.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14191:09/12/17 16:44:24 [63416] (435.0) gm state change: GM_INIT -> GM_START
14192:09/12/17 16:44:24 [63416] (435.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14193:09/12/17 16:44:24 [63416] (435.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14194:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 10 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#435.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/414/0/cluster414.proc0.subproc0/test.sh"\ ]'
14195:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14196:09/12/17 16:44:24 [63416] (434.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14197:09/12/17 16:44:24 [63416] (434.0) gm state change: GM_INIT -> GM_START
14198:09/12/17 16:44:24 [63416] (434.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14199:09/12/17 16:44:24 [63416] (434.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14200:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 11 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#434.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/404/0/cluster404.proc0.subproc0/test.sh"\ ]'
14201:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14202:09/12/17 16:44:24 [63416] (433.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14203:09/12/17 16:44:24 [63416] (433.0) gm state change: GM_INIT -> GM_START
14204:09/12/17 16:44:24 [63416] (433.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14205:09/12/17 16:44:24 [63416] (433.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14206:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 12 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#433.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/413/0/cluster413.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/413/0/cluster413.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/413/0/cluster413.proc0.subproc0/test.sh"\ ]'
14207:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14208:09/12/17 16:44:24 [63416] (432.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14209:09/12/17 16:44:24 [63416] (432.0) gm state change: GM_INIT -> GM_START
14210:09/12/17 16:44:24 [63416] (432.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14211:09/12/17 16:44:24 [63416] (432.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14212:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 13 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#432.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/403/0/cluster403.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/403/0/cluster403.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/403/0/cluster403.proc0.subproc0/test.sh"\ ]'
14213:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14214:09/12/17 16:44:24 [63416] (431.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14215:09/12/17 16:44:24 [63416] (431.0) gm state change: GM_INIT -> GM_START
14216:09/12/17 16:44:24 [63416] (431.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14217:09/12/17 16:44:24 [63416] (431.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14218:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 14 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#431.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/412/0/cluster412.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/412/0/cluster412.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/412/0/cluster412.proc0.subproc0/test.sh"\ ]'
14219:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14220:09/12/17 16:44:24 [63416] (430.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14221:09/12/17 16:44:24 [63416] (430.0) gm state change: GM_INIT -> GM_START
14222:09/12/17 16:44:24 [63416] (430.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14223:09/12/17 16:44:24 [63416] (430.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14224:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 15 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#430.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/402/0/cluster402.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/402/0/cluster402.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/402/0/cluster402.proc0.subproc0/test.sh"\ ]'
14225:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14226:09/12/17 16:44:24 [63416] (429.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14227:09/12/17 16:44:24 [63416] (429.0) gm state change: GM_INIT -> GM_START
14228:09/12/17 16:44:24 [63416] (429.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14229:09/12/17 16:44:24 [63416] (429.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14230:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 16 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#429.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/411/0/cluster411.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/411/0/cluster411.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/411/0/cluster411.proc0.subproc0/test.sh"\ ]'
14231:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14232:09/12/17 16:44:24 [63416] (428.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14233:09/12/17 16:44:24 [63416] (428.0) gm state change: GM_INIT -> GM_START
14234:09/12/17 16:44:24 [63416] (428.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14235:09/12/17 16:44:24 [63416] (428.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14236:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 17 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#428.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/401/0/cluster401.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/401/0/cluster401.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/401/0/cluster401.proc0.subproc0/test.sh"\ ]'
14237:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14238:09/12/17 16:44:24 [63416] (427.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14239:09/12/17 16:44:24 [63416] (427.0) gm state change: GM_INIT -> GM_START
14240:09/12/17 16:44:24 [63416] (427.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14241:09/12/17 16:44:24 [63416] (427.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14242:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 18 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#427.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/410/0/cluster410.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/410/0/cluster410.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/410/0/cluster410.proc0.subproc0/test.sh"\ ]'
14243:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14244:09/12/17 16:44:24 [63416] (426.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14245:09/12/17 16:44:24 [63416] (426.0) gm state change: GM_INIT -> GM_START
14246:09/12/17 16:44:24 [63416] (426.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14247:09/12/17 16:44:24 [63416] (426.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14248:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 19 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#426.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/400/0/cluster400.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/400/0/cluster400.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/400/0/cluster400.proc0.subproc0/test.sh"\ ]'
14249:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14250:09/12/17 16:44:24 [63416] (425.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14251:09/12/17 16:44:24 [63416] (425.0) gm state change: GM_INIT -> GM_START
14252:09/12/17 16:44:24 [63416] (425.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14253:09/12/17 16:44:24 [63416] (425.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14254:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 20 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#425.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/399/0/cluster399.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/399/0/cluster399.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/399/0/cluster399.proc0.subproc0/test.sh"\ ]'
14255:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14256:09/12/17 16:44:24 [63416] (424.0) doEvaluateState called: gmState GM_INIT, remoteState -1
14257:09/12/17 16:44:24 [63416] (424.0) gm state change: GM_INIT -> GM_START
14258:09/12/17 16:44:24 [63416] (424.0) gm state change: GM_START -> GM_TRANSFER_INPUT
14259:09/12/17 16:44:24 [63416] (424.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
14260:09/12/17 16:44:24 [63416] GAHP[63418] <- 'BLAH_JOB_SUBMIT 21 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#424.0#1505259258";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/398/0/cluster398.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/398/0/cluster398.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/398/0/cluster398.proc0.subproc0/test.sh"\ ]'
14261:09/12/17 16:44:24 [63416] GAHP[63418] -> 'S'
14262:09/12/17 16:44:26 [63416] GAHP[63418] <- 'RESULTS'
14263:09/12/17 16:44:26 [63416] GAHP[63418] -> 'R'
14264:09/12/17 16:44:26 [63416] GAHP[63418] -> 'S' '1'
14265:09/12/17 16:44:26 [63416] GAHP[63418] -> '5' '0' 'No error' 'slurm/20170912/161691'
14266:09/12/17 16:44:26 [63416] (420.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14267:09/12/17 16:44:26 [63416] (420.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14268:09/12/17 16:44:27 [63416] Evaluating staleness of remote job statuses.
14269:09/12/17 16:44:27 [63416] GAHP[63418] <- 'RESULTS'
14270:09/12/17 16:44:27 [63416] GAHP[63418] -> 'R'
14271:09/12/17 16:44:27 [63416] GAHP[63418] -> 'S' '1'
14272:09/12/17 16:44:27 [63416] GAHP[63418] -> '2' '0' 'No error' 'slurm/20170912/161693'
14273:09/12/17 16:44:27 [63416] (423.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14274:09/12/17 16:44:27 [63416] (423.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14275:09/12/17 16:44:27 [63416] GAHP[63418] <- 'RESULTS'
14276:09/12/17 16:44:27 [63416] GAHP[63418] -> 'R'
14277:09/12/17 16:44:27 [63416] GAHP[63418] -> 'S' '1'
14278:09/12/17 16:44:27 [63416] GAHP[63418] -> '15' '0' 'No error' 'slurm/20170912/161694'
14279:09/12/17 16:44:27 [63416] (430.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14280:09/12/17 16:44:27 [63416] (430.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14281:09/12/17 16:44:27 [63416] GAHP[63418] <- 'RESULTS'
14282:09/12/17 16:44:27 [63416] GAHP[63418] -> 'R'
14283:09/12/17 16:44:27 [63416] GAHP[63418] -> 'S' '1'
14284:09/12/17 16:44:27 [63416] GAHP[63418] -> '8' '0' 'No error' 'slurm/20170912/161692'
14285:09/12/17 16:44:27 [63416] (417.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14286:09/12/17 16:44:27 [63416] (417.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14287:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14288:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14289:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14290:09/12/17 16:44:28 [63416] GAHP[63418] -> '18' '0' 'No error' 'slurm/20170912/161696'
14291:09/12/17 16:44:28 [63416] (427.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14292:09/12/17 16:44:28 [63416] (427.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14293:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14294:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14295:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14296:09/12/17 16:44:28 [63416] GAHP[63418] -> '17' '0' 'No error' 'slurm/20170912/161697'
14297:09/12/17 16:44:28 [63416] (428.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14298:09/12/17 16:44:28 [63416] (428.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14299:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14300:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14301:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14302:09/12/17 16:44:28 [63416] GAHP[63418] -> '14' '0' 'No error' 'slurm/20170912/161698'
14303:09/12/17 16:44:28 [63416] (431.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14304:09/12/17 16:44:28 [63416] (431.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14305:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14306:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14307:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14308:09/12/17 16:44:28 [63416] GAHP[63418] -> '6' '0' 'No error' 'slurm/20170912/161699'
14309:09/12/17 16:44:28 [63416] (419.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14310:09/12/17 16:44:28 [63416] (419.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14311:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14312:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14313:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14314:09/12/17 16:44:28 [63416] GAHP[63418] -> '7' '0' 'No error' 'slurm/20170912/161700'
14315:09/12/17 16:44:28 [63416] (418.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14316:09/12/17 16:44:28 [63416] (418.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14317:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14318:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14319:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14320:09/12/17 16:44:28 [63416] GAHP[63418] -> '16' '0' 'No error' 'slurm/20170912/161702'
14321:09/12/17 16:44:28 [63416] (429.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14322:09/12/17 16:44:28 [63416] (429.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14323:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14324:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14325:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14326:09/12/17 16:44:28 [63416] GAHP[63418] -> '4' '0' 'No error' 'slurm/20170912/161703'
14327:09/12/17 16:44:28 [63416] (421.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14328:09/12/17 16:44:28 [63416] (421.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14329:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14330:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14331:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14332:09/12/17 16:44:28 [63416] GAHP[63418] -> '10' '0' 'No error' 'slurm/20170912/161705'
14333:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14334:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14335:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14336:09/12/17 16:44:28 [63416] GAHP[63418] -> '9' '0' 'No error' 'slurm/20170912/161706'
14337:09/12/17 16:44:28 [63416] (435.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14338:09/12/17 16:44:28 [63416] (435.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14339:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14340:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14341:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14342:09/12/17 16:44:28 [63416] GAHP[63418] -> '19' '0' 'No error' 'slurm/20170912/161707'
14343:09/12/17 16:44:28 [63416] (436.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14344:09/12/17 16:44:28 [63416] (436.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14345:09/12/17 16:44:28 [63416] (426.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14346:09/12/17 16:44:28 [63416] (426.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14347:09/12/17 16:44:28 [63416] GAHP[63418] <- 'RESULTS'
14348:09/12/17 16:44:28 [63416] GAHP[63418] -> 'R'
14349:09/12/17 16:44:28 [63416] GAHP[63418] -> 'S' '1'
14350:09/12/17 16:44:28 [63416] GAHP[63418] -> '11' '0' 'No error' 'slurm/20170912/161695'
14351:09/12/17 16:44:28 [63416] (434.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14352:09/12/17 16:44:28 [63416] (434.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14353:09/12/17 16:44:29 [63416] resource  is now up
14354:09/12/17 16:44:29 [63416] in doContactSchedd()
14355:09/12/17 16:44:29 [63416] querying for removed/held jobs
14356:09/12/17 16:44:29 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14357:09/12/17 16:44:29 [63416] Fetched 0 job ads from schedd
14358:09/12/17 16:44:29 [63416] Updating classad values for 434.0:
14359:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14360:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#434.0#1505259258 slurm/20170912/161695"
14361:09/12/17 16:44:29 [63416] Updating classad values for 435.0:
14362:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14363:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#435.0#1505259258 slurm/20170912/161705"
14364:09/12/17 16:44:29 [63416] Updating classad values for 436.0:
14365:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14366:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#436.0#1505259258 slurm/20170912/161706"
14367:09/12/17 16:44:29 [63416] Updating classad values for 417.0:
14368:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14369:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#417.0#1505259258 slurm/20170912/161692"
14370:09/12/17 16:44:29 [63416] Updating classad values for 418.0:
14371:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14372:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#418.0#1505259258 slurm/20170912/161700"
14373:09/12/17 16:44:29 [63416] Updating classad values for 419.0:
14374:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14375:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#419.0#1505259258 slurm/20170912/161699"
14376:09/12/17 16:44:29 [63416] Updating classad values for 420.0:
14377:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14378:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#420.0#1505259258 slurm/20170912/161691"
14379:09/12/17 16:44:29 [63416] Updating classad values for 421.0:
14380:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14381:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#421.0#1505259258 slurm/20170912/161703"
14382:09/12/17 16:44:29 [63416] Updating classad values for 423.0:
14383:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14384:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#423.0#1505259258 slurm/20170912/161693"
14385:09/12/17 16:44:29 [63416] Updating classad values for 426.0:
14386:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14387:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#426.0#1505259258 slurm/20170912/161707"
14388:09/12/17 16:44:29 [63416] Updating classad values for 427.0:
14389:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14390:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#427.0#1505259258 slurm/20170912/161696"
14391:09/12/17 16:44:29 [63416] Updating classad values for 428.0:
14392:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14393:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#428.0#1505259258 slurm/20170912/161697"
14394:09/12/17 16:44:29 [63416] Updating classad values for 429.0:
14395:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14396:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#429.0#1505259258 slurm/20170912/161702"
14397:09/12/17 16:44:29 [63416] Updating classad values for 430.0:
14398:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14399:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#430.0#1505259258 slurm/20170912/161694"
14400:09/12/17 16:44:29 [63416] Updating classad values for 431.0:
14401:09/12/17 16:44:29 [63416]    DelegatedProxyExpiration = 1505570326
14402:09/12/17 16:44:29 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#431.0#1505259258 slurm/20170912/161698"
14403:09/12/17 16:44:29 [63416] leaving doContactSchedd()
14404:09/12/17 16:44:29 [63416] GAHP[63418] <- 'RESULTS'
14405:09/12/17 16:44:29 [63416] GAHP[63418] -> 'R'
14406:09/12/17 16:44:29 [63416] GAHP[63418] -> 'S' '1'
14407:09/12/17 16:44:29 [63416] GAHP[63418] -> '13' '0' 'No error' 'slurm/20170912/161701'
14408:09/12/17 16:44:29 [63416] (422.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14409:09/12/17 16:44:29 [63416] (433.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14410:09/12/17 16:44:29 [63416] (425.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14411:09/12/17 16:44:29 [63416] (424.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14412:09/12/17 16:44:29 [63416] (434.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14413:09/12/17 16:44:29 [63416] (434.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14414:09/12/17 16:44:29 [63416] (435.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14415:09/12/17 16:44:29 [63416] (435.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14416:09/12/17 16:44:29 [63416] (436.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14417:09/12/17 16:44:29 [63416] (436.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14418:09/12/17 16:44:29 [63416] (417.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14419:09/12/17 16:44:29 [63416] (417.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14420:09/12/17 16:44:29 [63416] (418.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14421:09/12/17 16:44:29 [63416] (418.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14422:09/12/17 16:44:29 [63416] (419.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14423:09/12/17 16:44:29 [63416] (419.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14424:09/12/17 16:44:29 [63416] (420.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14425:09/12/17 16:44:29 [63416] (420.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14426:09/12/17 16:44:29 [63416] (421.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14427:09/12/17 16:44:29 [63416] (421.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14428:09/12/17 16:44:29 [63416] (423.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14429:09/12/17 16:44:29 [63416] (423.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14430:09/12/17 16:44:29 [63416] (426.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14431:09/12/17 16:44:29 [63416] (426.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14432:09/12/17 16:44:29 [63416] (427.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14433:09/12/17 16:44:29 [63416] (427.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14434:09/12/17 16:44:29 [63416] (428.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14435:09/12/17 16:44:29 [63416] (428.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14436:09/12/17 16:44:29 [63416] (429.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14437:09/12/17 16:44:29 [63416] (429.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14438:09/12/17 16:44:29 [63416] (430.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14439:09/12/17 16:44:29 [63416] (430.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14440:09/12/17 16:44:29 [63416] (431.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14441:09/12/17 16:44:29 [63416] (431.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14442:09/12/17 16:44:29 [63416] (432.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14443:09/12/17 16:44:29 [63416] (432.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14444:09/12/17 16:44:29 [63416] GAHP[63418] <- 'RESULTS'
14445:09/12/17 16:44:29 [63416] GAHP[63418] -> 'R'
14446:09/12/17 16:44:29 [63416] GAHP[63418] -> 'S' '1'
14447:09/12/17 16:44:29 [63416] GAHP[63418] -> '3' '0' 'No error' 'slurm/20170912/161704'
14448:09/12/17 16:44:29 [63416] (422.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14449:09/12/17 16:44:29 [63416] (422.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14450:09/12/17 16:44:29 [63416] GAHP[63418] <- 'RESULTS'
14451:09/12/17 16:44:29 [63416] GAHP[63418] -> 'R'
14452:09/12/17 16:44:29 [63416] GAHP[63418] -> 'S' '1'
14453:09/12/17 16:44:29 [63416] GAHP[63418] -> '12' '0' 'No error' 'slurm/20170912/161708'
14454:09/12/17 16:44:29 [63416] (433.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14455:09/12/17 16:44:29 [63416] (433.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14456:09/12/17 16:44:29 [63416] GAHP[63418] <- 'RESULTS'
14457:09/12/17 16:44:29 [63416] GAHP[63418] -> 'R'
14458:09/12/17 16:44:29 [63416] GAHP[63418] -> 'S' '2'
14459:09/12/17 16:44:29 [63416] GAHP[63418] -> '21' '0' 'No error' 'slurm/20170912/161709'
14460:09/12/17 16:44:29 [63416] GAHP[63418] -> '20' '0' 'No error' 'slurm/20170912/161710'
14461:09/12/17 16:44:29 [63416] (424.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14462:09/12/17 16:44:29 [63416] (424.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14463:09/12/17 16:44:29 [63416] (425.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
14464:09/12/17 16:44:29 [63416] (425.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
14465:09/12/17 16:44:34 [63416] in doContactSchedd()
14466:09/12/17 16:44:34 [63416] querying for removed/held jobs
14467:09/12/17 16:44:34 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14468:09/12/17 16:44:34 [63416] Fetched 0 job ads from schedd
14469:09/12/17 16:44:34 [63416] Updating classad values for 422.0:
14470:09/12/17 16:44:34 [63416]    DelegatedProxyExpiration = 1505570326
14471:09/12/17 16:44:34 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#422.0#1505259258 slurm/20170912/161704"
14472:09/12/17 16:44:34 [63416] Updating classad values for 424.0:
14473:09/12/17 16:44:34 [63416]    DelegatedProxyExpiration = 1505570326
14474:09/12/17 16:44:34 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#424.0#1505259258 slurm/20170912/161709"
14475:09/12/17 16:44:34 [63416] Updating classad values for 425.0:
14476:09/12/17 16:44:34 [63416]    DelegatedProxyExpiration = 1505570326
14477:09/12/17 16:44:34 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#425.0#1505259258 slurm/20170912/161710"
14478:09/12/17 16:44:34 [63416] Updating classad values for 432.0:
14479:09/12/17 16:44:34 [63416]    DelegatedProxyExpiration = 1505570326
14480:09/12/17 16:44:34 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#432.0#1505259258 slurm/20170912/161701"
14481:09/12/17 16:44:34 [63416] Updating classad values for 433.0:
14482:09/12/17 16:44:34 [63416]    DelegatedProxyExpiration = 1505570326
14483:09/12/17 16:44:34 [63416]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#433.0#1505259258 slurm/20170912/161708"
14484:09/12/17 16:44:34 [63416] leaving doContactSchedd()
14485:09/12/17 16:44:34 [63416] (422.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14486:09/12/17 16:44:34 [63416] (422.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14487:09/12/17 16:44:34 [63416] (424.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14488:09/12/17 16:44:34 [63416] (424.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14489:09/12/17 16:44:34 [63416] (425.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14490:09/12/17 16:44:34 [63416] (425.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14491:09/12/17 16:44:34 [63416] (432.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14492:09/12/17 16:44:34 [63416] (432.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14493:09/12/17 16:44:34 [63416] (433.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
14494:09/12/17 16:44:34 [63416] (433.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
14495:09/12/17 16:45:22 [63416] Received CHECK_LEASES signal
14496:09/12/17 16:45:22 [63416] in doContactSchedd()
14497:09/12/17 16:45:22 [63416] querying for renewed leases
14498:09/12/17 16:45:22 [63416] querying for removed/held jobs
14499:09/12/17 16:45:22 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14500:09/12/17 16:45:22 [63416] Fetched 0 job ads from schedd
14501:09/12/17 16:45:22 [63416] leaving doContactSchedd()
14502:09/12/17 16:45:24 [63416] GAHP[63418] <- 'RESULTS'
14503:09/12/17 16:45:24 [63416] GAHP[63418] -> 'S' '0'
14504:09/12/17 16:45:27 [63416] Evaluating staleness of remote job statuses.
14505:09/12/17 16:45:29 [63416] (434.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14506:09/12/17 16:45:29 [63416] (434.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14507:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 22 slurm/20170912/161695'
14508:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14509:09/12/17 16:45:29 [63416] (435.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14510:09/12/17 16:45:29 [63416] (435.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14511:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 23 slurm/20170912/161705'
14512:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14513:09/12/17 16:45:29 [63416] (436.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14514:09/12/17 16:45:29 [63416] (436.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14515:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 24 slurm/20170912/161706'
14516:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14517:09/12/17 16:45:29 [63416] (417.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14518:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14519:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 25 slurm/20170912/161692'
14520:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14521:09/12/17 16:45:29 [63416] (418.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14522:09/12/17 16:45:29 [63416] (418.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14523:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 26 slurm/20170912/161700'
14524:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14525:09/12/17 16:45:29 [63416] (419.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14526:09/12/17 16:45:29 [63416] (419.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14527:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 27 slurm/20170912/161699'
14528:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14529:09/12/17 16:45:29 [63416] (420.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14530:09/12/17 16:45:29 [63416] (420.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14531:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 28 slurm/20170912/161691'
14532:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14533:09/12/17 16:45:29 [63416] (421.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14534:09/12/17 16:45:29 [63416] (421.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14535:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 29 slurm/20170912/161703'
14536:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14537:09/12/17 16:45:29 [63416] (423.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14538:09/12/17 16:45:29 [63416] (423.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14539:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 30 slurm/20170912/161693'
14540:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14541:09/12/17 16:45:29 [63416] (426.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14542:09/12/17 16:45:29 [63416] (426.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14543:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 31 slurm/20170912/161707'
14544:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14545:09/12/17 16:45:29 [63416] (427.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14546:09/12/17 16:45:29 [63416] (427.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14547:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 32 slurm/20170912/161696'
14548:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14549:09/12/17 16:45:29 [63416] (428.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14550:09/12/17 16:45:29 [63416] (428.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14551:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 33 slurm/20170912/161697'
14552:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14553:09/12/17 16:45:29 [63416] (429.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14554:09/12/17 16:45:29 [63416] (429.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14555:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 34 slurm/20170912/161702'
14556:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14557:09/12/17 16:45:29 [63416] (430.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14558:09/12/17 16:45:29 [63416] (430.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14559:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 35 slurm/20170912/161694'
14560:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14561:09/12/17 16:45:29 [63416] (431.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14562:09/12/17 16:45:29 [63416] (431.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14563:09/12/17 16:45:29 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 36 slurm/20170912/161698'
14564:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S'
14565:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14566:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14567:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14568:09/12/17 16:45:29 [63416] GAHP[63418] -> '25' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161692"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
14569:09/12/17 16:45:29 [63416] (417.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14570:09/12/17 16:45:29 [63416] (417.0) ***ProcessRemoteAd
14571:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14572:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14573:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14574:09/12/17 16:45:29 [63416] in doContactSchedd()
14575:09/12/17 16:45:29 [63416] querying for removed/held jobs
14576:09/12/17 16:45:29 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14577:09/12/17 16:45:29 [63416] Fetched 0 job ads from schedd
14578:09/12/17 16:45:29 [63416] Updating classad values for 417.0:
14579:09/12/17 16:45:29 [63416]    EnteredCurrentStatus = 1505259929
14580:09/12/17 16:45:29 [63416]    ExitCode = 0
14581:09/12/17 16:45:29 [63416]    GridJobStatus = "COMPLETED"
14582:09/12/17 16:45:29 [63416]    ImageSize = 0
14583:09/12/17 16:45:29 [63416]    JobStatus = 4
14584:09/12/17 16:45:29 [63416]    LastRemoteStatusUpdate = 1505259929
14585:09/12/17 16:45:29 [63416]    RemoteUserCpu = 0
14586:09/12/17 16:45:29 [63416]    RemoteWallClockTime = 0.0
14587:09/12/17 16:45:29 [63416] leaving doContactSchedd()
14588:09/12/17 16:45:29 [63416] (417.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14589:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14590:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14591:09/12/17 16:45:29 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14592:09/12/17 16:45:29 [63416] (417.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14593:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14594:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14595:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14596:09/12/17 16:45:29 [63416] GAHP[63418] -> '26' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161700"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14597:09/12/17 16:45:29 [63416] (418.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14598:09/12/17 16:45:29 [63416] (418.0) ***ProcessRemoteAd
14599:09/12/17 16:45:29 [63416] (418.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14600:09/12/17 16:45:29 [63416] (418.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14601:09/12/17 16:45:29 [63416] (418.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14602:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14603:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14604:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14605:09/12/17 16:45:29 [63416] GAHP[63418] -> '31' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161707"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14606:09/12/17 16:45:29 [63416] (426.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14607:09/12/17 16:45:29 [63416] (426.0) ***ProcessRemoteAd
14608:09/12/17 16:45:29 [63416] (426.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14609:09/12/17 16:45:29 [63416] (426.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14610:09/12/17 16:45:29 [63416] (426.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14611:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14612:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14613:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14614:09/12/17 16:45:29 [63416] GAHP[63418] -> '28' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161691"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
14615:09/12/17 16:45:29 [63416] (420.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14616:09/12/17 16:45:29 [63416] (420.0) ***ProcessRemoteAd
14617:09/12/17 16:45:29 [63416] (420.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14618:09/12/17 16:45:29 [63416] (420.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14619:09/12/17 16:45:29 [63416] (420.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14620:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14621:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14622:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14623:09/12/17 16:45:29 [63416] GAHP[63418] -> '24' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161706"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14624:09/12/17 16:45:29 [63416] (436.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14625:09/12/17 16:45:29 [63416] (436.0) ***ProcessRemoteAd
14626:09/12/17 16:45:29 [63416] (436.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14627:09/12/17 16:45:29 [63416] (436.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14628:09/12/17 16:45:29 [63416] (436.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14629:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14630:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14631:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14632:09/12/17 16:45:29 [63416] GAHP[63418] -> '36' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161698"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14633:09/12/17 16:45:29 [63416] (431.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14634:09/12/17 16:45:29 [63416] (431.0) ***ProcessRemoteAd
14635:09/12/17 16:45:29 [63416] (431.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14636:09/12/17 16:45:29 [63416] (431.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14637:09/12/17 16:45:29 [63416] (431.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14638:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14639:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14640:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14641:09/12/17 16:45:29 [63416] GAHP[63418] -> '33' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161697"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14642:09/12/17 16:45:29 [63416] (428.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14643:09/12/17 16:45:29 [63416] (428.0) ***ProcessRemoteAd
14644:09/12/17 16:45:29 [63416] (428.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14645:09/12/17 16:45:29 [63416] (428.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14646:09/12/17 16:45:29 [63416] (428.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14647:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14648:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14649:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14650:09/12/17 16:45:29 [63416] GAHP[63418] -> '32' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161696"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14651:09/12/17 16:45:29 [63416] (427.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14652:09/12/17 16:45:29 [63416] (427.0) ***ProcessRemoteAd
14653:09/12/17 16:45:29 [63416] (427.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14654:09/12/17 16:45:29 [63416] (427.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14655:09/12/17 16:45:29 [63416] (427.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14656:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14657:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14658:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14659:09/12/17 16:45:29 [63416] GAHP[63418] -> '30' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161693"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
14660:09/12/17 16:45:29 [63416] (423.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14661:09/12/17 16:45:29 [63416] (423.0) ***ProcessRemoteAd
14662:09/12/17 16:45:29 [63416] (423.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14663:09/12/17 16:45:29 [63416] (423.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14664:09/12/17 16:45:29 [63416] (423.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14665:09/12/17 16:45:29 [63416] GAHP[63418] <- 'RESULTS'
14666:09/12/17 16:45:29 [63416] GAHP[63418] -> 'R'
14667:09/12/17 16:45:29 [63416] GAHP[63418] -> 'S' '1'
14668:09/12/17 16:45:29 [63416] GAHP[63418] -> '27' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161699"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14669:09/12/17 16:45:29 [63416] (419.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14670:09/12/17 16:45:29 [63416] (419.0) ***ProcessRemoteAd
14671:09/12/17 16:45:29 [63416] (419.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14672:09/12/17 16:45:29 [63416] (419.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14673:09/12/17 16:45:29 [63416] (419.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14674:09/12/17 16:45:30 [63416] GAHP[63418] <- 'RESULTS'
14675:09/12/17 16:45:30 [63416] GAHP[63418] -> 'R'
14676:09/12/17 16:45:30 [63416] GAHP[63418] -> 'S' '1'
14677:09/12/17 16:45:30 [63416] GAHP[63418] -> '34' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161702"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14678:09/12/17 16:45:30 [63416] (429.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14679:09/12/17 16:45:30 [63416] (429.0) ***ProcessRemoteAd
14680:09/12/17 16:45:30 [63416] (429.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14681:09/12/17 16:45:30 [63416] (429.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14682:09/12/17 16:45:30 [63416] (429.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14683:09/12/17 16:45:30 [63416] GAHP[63418] <- 'RESULTS'
14684:09/12/17 16:45:30 [63416] GAHP[63418] -> 'R'
14685:09/12/17 16:45:30 [63416] GAHP[63418] -> 'S' '1'
14686:09/12/17 16:45:30 [63416] GAHP[63418] -> '22' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161695"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14687:09/12/17 16:45:30 [63416] (434.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14688:09/12/17 16:45:30 [63416] (434.0) ***ProcessRemoteAd
14689:09/12/17 16:45:30 [63416] (434.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14690:09/12/17 16:45:30 [63416] (434.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14691:09/12/17 16:45:30 [63416] (434.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14692:09/12/17 16:45:31 [63416] GAHP[63418] <- 'RESULTS'
14693:09/12/17 16:45:31 [63416] GAHP[63418] -> 'R'
14694:09/12/17 16:45:31 [63416] GAHP[63418] -> 'S' '1'
14695:09/12/17 16:45:31 [63416] GAHP[63418] -> '35' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161694"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14696:09/12/17 16:45:31 [63416] (430.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14697:09/12/17 16:45:31 [63416] (430.0) ***ProcessRemoteAd
14698:09/12/17 16:45:31 [63416] (430.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14699:09/12/17 16:45:31 [63416] (430.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14700:09/12/17 16:45:31 [63416] (430.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14701:09/12/17 16:45:31 [63416] GAHP[63418] <- 'RESULTS'
14702:09/12/17 16:45:31 [63416] GAHP[63418] -> 'R'
14703:09/12/17 16:45:31 [63416] GAHP[63418] -> 'S' '1'
14704:09/12/17 16:45:31 [63416] GAHP[63418] -> '29' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161703"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14705:09/12/17 16:45:31 [63416] (421.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14706:09/12/17 16:45:31 [63416] (421.0) ***ProcessRemoteAd
14707:09/12/17 16:45:31 [63416] (421.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14708:09/12/17 16:45:31 [63416] (421.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14709:09/12/17 16:45:31 [63416] (421.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14710:09/12/17 16:45:31 [63416] GAHP[63418] <- 'RESULTS'
14711:09/12/17 16:45:31 [63416] GAHP[63418] -> 'R'
14712:09/12/17 16:45:31 [63416] GAHP[63418] -> 'S' '1'
14713:09/12/17 16:45:31 [63416] GAHP[63418] -> '23' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161705"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14714:09/12/17 16:45:31 [63416] (435.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14715:09/12/17 16:45:31 [63416] (435.0) ***ProcessRemoteAd
14716:09/12/17 16:45:31 [63416] (435.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14717:09/12/17 16:45:31 [63416] (435.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14718:09/12/17 16:45:31 [63416] (435.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14719:09/12/17 16:45:34 [63416] (422.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14720:09/12/17 16:45:34 [63416] (422.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14721:09/12/17 16:45:34 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 37 slurm/20170912/161704'
14722:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S'
14723:09/12/17 16:45:34 [63416] (424.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14724:09/12/17 16:45:34 [63416] (424.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14725:09/12/17 16:45:34 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 38 slurm/20170912/161709'
14726:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S'
14727:09/12/17 16:45:34 [63416] (425.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14728:09/12/17 16:45:34 [63416] (425.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14729:09/12/17 16:45:34 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 39 slurm/20170912/161710'
14730:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S'
14731:09/12/17 16:45:34 [63416] (432.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14732:09/12/17 16:45:34 [63416] (432.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14733:09/12/17 16:45:34 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 40 slurm/20170912/161701'
14734:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S'
14735:09/12/17 16:45:34 [63416] (433.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
14736:09/12/17 16:45:34 [63416] (433.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
14737:09/12/17 16:45:34 [63416] GAHP[63418] <- 'BLAH_JOB_STATUS 41 slurm/20170912/161708'
14738:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S'
14739:09/12/17 16:45:34 [63416] in doContactSchedd()
14740:09/12/17 16:45:34 [63416] querying for removed/held jobs
14741:09/12/17 16:45:34 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14742:09/12/17 16:45:34 [63416] Fetched 1 job ads from schedd
14743:09/12/17 16:45:34 [63416] Updating classad values for 434.0:
14744:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259930
14745:09/12/17 16:45:34 [63416]    ExitCode = 0
14746:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14747:09/12/17 16:45:34 [63416]    ImageSize = 0
14748:09/12/17 16:45:34 [63416]    JobStatus = 4
14749:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259930
14750:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14751:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14752:09/12/17 16:45:34 [63416] Updating classad values for 435.0:
14753:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259931
14754:09/12/17 16:45:34 [63416]    ExitCode = 0
14755:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14756:09/12/17 16:45:34 [63416]    ImageSize = 0
14757:09/12/17 16:45:34 [63416]    JobStatus = 4
14758:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259931
14759:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14760:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14761:09/12/17 16:45:34 [63416] Updating classad values for 436.0:
14762:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14763:09/12/17 16:45:34 [63416]    ExitCode = 0
14764:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14765:09/12/17 16:45:34 [63416]    ImageSize = 0
14766:09/12/17 16:45:34 [63416]    JobStatus = 4
14767:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14768:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14769:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14770:09/12/17 16:45:34 [63416] Updating classad values for 417.0:
14771:09/12/17 16:45:34 [63416]    CurrentStatusUnknown = false
14772:09/12/17 16:45:34 [63416]    GridJobId = undefined
14773:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 0
14774:09/12/17 16:45:34 [63416]    Managed = "ScheddDone"
14775:09/12/17 16:45:34 [63416] Updating classad values for 418.0:
14776:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14777:09/12/17 16:45:34 [63416]    ExitCode = 0
14778:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14779:09/12/17 16:45:34 [63416]    ImageSize = 0
14780:09/12/17 16:45:34 [63416]    JobStatus = 4
14781:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14782:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14783:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14784:09/12/17 16:45:34 [63416] Updating classad values for 419.0:
14785:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14786:09/12/17 16:45:34 [63416]    ExitCode = 0
14787:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14788:09/12/17 16:45:34 [63416]    ImageSize = 0
14789:09/12/17 16:45:34 [63416]    JobStatus = 4
14790:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14791:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14792:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14793:09/12/17 16:45:34 [63416] Updating classad values for 420.0:
14794:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14795:09/12/17 16:45:34 [63416]    ExitCode = 0
14796:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14797:09/12/17 16:45:34 [63416]    ImageSize = 0
14798:09/12/17 16:45:34 [63416]    JobStatus = 4
14799:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14800:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14801:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14802:09/12/17 16:45:34 [63416] Updating classad values for 421.0:
14803:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259931
14804:09/12/17 16:45:34 [63416]    ExitCode = 0
14805:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14806:09/12/17 16:45:34 [63416]    ImageSize = 0
14807:09/12/17 16:45:34 [63416]    JobStatus = 4
14808:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259931
14809:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14810:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14811:09/12/17 16:45:34 [63416] Updating classad values for 423.0:
14812:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14813:09/12/17 16:45:34 [63416]    ExitCode = 0
14814:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14815:09/12/17 16:45:34 [63416]    ImageSize = 0
14816:09/12/17 16:45:34 [63416]    JobStatus = 4
14817:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14818:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14819:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14820:09/12/17 16:45:34 [63416] Updating classad values for 426.0:
14821:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14822:09/12/17 16:45:34 [63416]    ExitCode = 0
14823:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14824:09/12/17 16:45:34 [63416]    ImageSize = 0
14825:09/12/17 16:45:34 [63416]    JobStatus = 4
14826:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14827:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14828:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14829:09/12/17 16:45:34 [63416] Updating classad values for 427.0:
14830:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14831:09/12/17 16:45:34 [63416]    ExitCode = 0
14832:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14833:09/12/17 16:45:34 [63416]    ImageSize = 0
14834:09/12/17 16:45:34 [63416]    JobStatus = 4
14835:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14836:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14837:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14838:09/12/17 16:45:34 [63416] Updating classad values for 428.0:
14839:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14840:09/12/17 16:45:34 [63416]    ExitCode = 0
14841:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14842:09/12/17 16:45:34 [63416]    ImageSize = 0
14843:09/12/17 16:45:34 [63416]    JobStatus = 4
14844:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14845:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14846:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14847:09/12/17 16:45:34 [63416] Updating classad values for 429.0:
14848:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259930
14849:09/12/17 16:45:34 [63416]    ExitCode = 0
14850:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14851:09/12/17 16:45:34 [63416]    ImageSize = 0
14852:09/12/17 16:45:34 [63416]    JobStatus = 4
14853:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259930
14854:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14855:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14856:09/12/17 16:45:34 [63416] Updating classad values for 430.0:
14857:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259931
14858:09/12/17 16:45:34 [63416]    ExitCode = 0
14859:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14860:09/12/17 16:45:34 [63416]    ImageSize = 0
14861:09/12/17 16:45:34 [63416]    JobStatus = 4
14862:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259931
14863:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14864:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14865:09/12/17 16:45:34 [63416] Updating classad values for 431.0:
14866:09/12/17 16:45:34 [63416]    EnteredCurrentStatus = 1505259929
14867:09/12/17 16:45:34 [63416]    ExitCode = 0
14868:09/12/17 16:45:34 [63416]    GridJobStatus = "COMPLETED"
14869:09/12/17 16:45:34 [63416]    ImageSize = 0
14870:09/12/17 16:45:34 [63416]    JobStatus = 4
14871:09/12/17 16:45:34 [63416]    LastRemoteStatusUpdate = 1505259929
14872:09/12/17 16:45:34 [63416]    RemoteUserCpu = 0
14873:09/12/17 16:45:34 [63416]    RemoteWallClockTime = 0.0
14874:09/12/17 16:45:34 [63416] Deleting job 417.0 from schedd
14875:09/12/17 16:45:34 [63416] leaving doContactSchedd()
14876:09/12/17 16:45:34 [63416] (434.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14877:09/12/17 16:45:34 [63416] (434.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14878:09/12/17 16:45:34 [63416] (434.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14879:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14880:09/12/17 16:45:34 [63416] (434.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14881:09/12/17 16:45:34 [63416] (435.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14882:09/12/17 16:45:34 [63416] (435.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14883:09/12/17 16:45:34 [63416] (435.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14884:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14885:09/12/17 16:45:34 [63416] (435.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14886:09/12/17 16:45:34 [63416] (436.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14887:09/12/17 16:45:34 [63416] (436.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14888:09/12/17 16:45:34 [63416] (436.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14889:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14890:09/12/17 16:45:34 [63416] (436.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14891:09/12/17 16:45:34 [63416] (418.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14892:09/12/17 16:45:34 [63416] (418.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14893:09/12/17 16:45:34 [63416] (418.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14894:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14895:09/12/17 16:45:34 [63416] (418.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14896:09/12/17 16:45:34 [63416] (419.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14897:09/12/17 16:45:34 [63416] (419.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14898:09/12/17 16:45:34 [63416] (419.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14899:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14900:09/12/17 16:45:34 [63416] (419.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14901:09/12/17 16:45:34 [63416] (420.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14902:09/12/17 16:45:34 [63416] (420.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14903:09/12/17 16:45:34 [63416] (420.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14904:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14905:09/12/17 16:45:34 [63416] (420.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14906:09/12/17 16:45:34 [63416] (421.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14907:09/12/17 16:45:34 [63416] (421.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14908:09/12/17 16:45:34 [63416] (421.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14909:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14910:09/12/17 16:45:34 [63416] (421.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14911:09/12/17 16:45:34 [63416] (423.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14912:09/12/17 16:45:34 [63416] (423.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14913:09/12/17 16:45:34 [63416] (423.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14914:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14915:09/12/17 16:45:34 [63416] (423.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14916:09/12/17 16:45:34 [63416] (426.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14917:09/12/17 16:45:34 [63416] (426.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14918:09/12/17 16:45:34 [63416] (426.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14919:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14920:09/12/17 16:45:34 [63416] (426.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14921:09/12/17 16:45:34 [63416] (427.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14922:09/12/17 16:45:34 [63416] (427.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14923:09/12/17 16:45:34 [63416] (427.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14924:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14925:09/12/17 16:45:34 [63416] (427.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14926:09/12/17 16:45:34 [63416] (428.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14927:09/12/17 16:45:34 [63416] (428.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14928:09/12/17 16:45:34 [63416] (428.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14929:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14930:09/12/17 16:45:34 [63416] (428.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14931:09/12/17 16:45:34 [63416] (429.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14932:09/12/17 16:45:34 [63416] (429.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14933:09/12/17 16:45:34 [63416] (429.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14934:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14935:09/12/17 16:45:34 [63416] (429.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14936:09/12/17 16:45:34 [63416] (430.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14937:09/12/17 16:45:34 [63416] (430.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14938:09/12/17 16:45:34 [63416] (430.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14939:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14940:09/12/17 16:45:34 [63416] (430.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14941:09/12/17 16:45:34 [63416] (431.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
14942:09/12/17 16:45:34 [63416] (431.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
14943:09/12/17 16:45:34 [63416] (431.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
14944:09/12/17 16:45:34 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
14945:09/12/17 16:45:34 [63416] (431.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
14946:09/12/17 16:45:34 [63416] GAHP[63418] <- 'RESULTS'
14947:09/12/17 16:45:34 [63416] GAHP[63418] -> 'R'
14948:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S' '2'
14949:09/12/17 16:45:34 [63416] GAHP[63418] -> '38' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161709"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14950:09/12/17 16:45:34 [63416] GAHP[63418] -> '41' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161708"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14951:09/12/17 16:45:34 [63416] (424.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14952:09/12/17 16:45:34 [63416] (424.0) ***ProcessRemoteAd
14953:09/12/17 16:45:34 [63416] (424.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14954:09/12/17 16:45:34 [63416] (424.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14955:09/12/17 16:45:34 [63416] (424.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14956:09/12/17 16:45:34 [63416] (433.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14957:09/12/17 16:45:34 [63416] (433.0) ***ProcessRemoteAd
14958:09/12/17 16:45:34 [63416] (433.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14959:09/12/17 16:45:34 [63416] (433.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14960:09/12/17 16:45:34 [63416] (433.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14961:09/12/17 16:45:34 [63416] GAHP[63418] <- 'RESULTS'
14962:09/12/17 16:45:34 [63416] GAHP[63418] -> 'R'
14963:09/12/17 16:45:34 [63416] GAHP[63418] -> 'S' '1'
14964:09/12/17 16:45:34 [63416] GAHP[63418] -> '40' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161701"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14965:09/12/17 16:45:34 [63416] (432.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14966:09/12/17 16:45:34 [63416] (432.0) ***ProcessRemoteAd
14967:09/12/17 16:45:34 [63416] (432.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14968:09/12/17 16:45:34 [63416] (432.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14969:09/12/17 16:45:34 [63416] (432.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14970:09/12/17 16:45:35 [63416] GAHP[63418] <- 'RESULTS'
14971:09/12/17 16:45:35 [63416] GAHP[63418] -> 'R'
14972:09/12/17 16:45:35 [63416] GAHP[63418] -> 'S' '1'
14973:09/12/17 16:45:35 [63416] GAHP[63418] -> '37' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161704"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14974:09/12/17 16:45:35 [63416] (422.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14975:09/12/17 16:45:35 [63416] (422.0) ***ProcessRemoteAd
14976:09/12/17 16:45:35 [63416] (422.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14977:09/12/17 16:45:35 [63416] (422.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14978:09/12/17 16:45:35 [63416] (422.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14979:09/12/17 16:45:35 [63416] GAHP[63418] <- 'RESULTS'
14980:09/12/17 16:45:35 [63416] GAHP[63418] -> 'R'
14981:09/12/17 16:45:35 [63416] GAHP[63418] -> 'S' '1'
14982:09/12/17 16:45:35 [63416] GAHP[63418] -> '39' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161710"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
14983:09/12/17 16:45:35 [63416] (425.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
14984:09/12/17 16:45:35 [63416] (425.0) ***ProcessRemoteAd
14985:09/12/17 16:45:35 [63416] (425.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
14986:09/12/17 16:45:35 [63416] (425.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
14987:09/12/17 16:45:35 [63416] (425.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
14988:09/12/17 16:45:39 [63416] in doContactSchedd()
14989:09/12/17 16:45:39 [63416] querying for removed/held jobs
14990:09/12/17 16:45:39 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
14991:09/12/17 16:45:39 [63416] Fetched 14 job ads from schedd
14992:09/12/17 16:45:39 [63416] Updating classad values for 434.0:
14993:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
14994:09/12/17 16:45:39 [63416]    GridJobId = undefined
14995:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
14996:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
14997:09/12/17 16:45:39 [63416] Updating classad values for 435.0:
14998:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
14999:09/12/17 16:45:39 [63416]    GridJobId = undefined
15000:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15001:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15002:09/12/17 16:45:39 [63416] Updating classad values for 436.0:
15003:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15004:09/12/17 16:45:39 [63416]    GridJobId = undefined
15005:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15006:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15007:09/12/17 16:45:39 [63416] Updating classad values for 418.0:
15008:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15009:09/12/17 16:45:39 [63416]    GridJobId = undefined
15010:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15011:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15012:09/12/17 16:45:39 [63416] Updating classad values for 419.0:
15013:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15014:09/12/17 16:45:39 [63416]    GridJobId = undefined
15015:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15016:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15017:09/12/17 16:45:39 [63416] Updating classad values for 420.0:
15018:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15019:09/12/17 16:45:39 [63416]    GridJobId = undefined
15020:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15021:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15022:09/12/17 16:45:39 [63416] Updating classad values for 421.0:
15023:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15024:09/12/17 16:45:39 [63416]    GridJobId = undefined
15025:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15026:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15027:09/12/17 16:45:39 [63416] Updating classad values for 422.0:
15028:09/12/17 16:45:39 [63416]    EnteredCurrentStatus = 1505259935
15029:09/12/17 16:45:39 [63416]    ExitCode = 0
15030:09/12/17 16:45:39 [63416]    GridJobStatus = "COMPLETED"
15031:09/12/17 16:45:39 [63416]    ImageSize = 0
15032:09/12/17 16:45:39 [63416]    JobStatus = 4
15033:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 1505259935
15034:09/12/17 16:45:39 [63416]    RemoteUserCpu = 0
15035:09/12/17 16:45:39 [63416]    RemoteWallClockTime = 0.0
15036:09/12/17 16:45:39 [63416] Updating classad values for 423.0:
15037:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15038:09/12/17 16:45:39 [63416]    GridJobId = undefined
15039:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15040:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15041:09/12/17 16:45:39 [63416] Updating classad values for 424.0:
15042:09/12/17 16:45:39 [63416]    EnteredCurrentStatus = 1505259934
15043:09/12/17 16:45:39 [63416]    ExitCode = 0
15044:09/12/17 16:45:39 [63416]    GridJobStatus = "COMPLETED"
15045:09/12/17 16:45:39 [63416]    ImageSize = 0
15046:09/12/17 16:45:39 [63416]    JobStatus = 4
15047:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 1505259934
15048:09/12/17 16:45:39 [63416]    RemoteUserCpu = 0
15049:09/12/17 16:45:39 [63416]    RemoteWallClockTime = 0.0
15050:09/12/17 16:45:39 [63416] Updating classad values for 425.0:
15051:09/12/17 16:45:39 [63416]    EnteredCurrentStatus = 1505259935
15052:09/12/17 16:45:39 [63416]    ExitCode = 0
15053:09/12/17 16:45:39 [63416]    GridJobStatus = "COMPLETED"
15054:09/12/17 16:45:39 [63416]    ImageSize = 0
15055:09/12/17 16:45:39 [63416]    JobStatus = 4
15056:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 1505259935
15057:09/12/17 16:45:39 [63416]    RemoteUserCpu = 0
15058:09/12/17 16:45:39 [63416]    RemoteWallClockTime = 0.0
15059:09/12/17 16:45:39 [63416] Updating classad values for 426.0:
15060:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15061:09/12/17 16:45:39 [63416]    GridJobId = undefined
15062:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15063:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15064:09/12/17 16:45:39 [63416] Updating classad values for 427.0:
15065:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15066:09/12/17 16:45:39 [63416]    GridJobId = undefined
15067:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15068:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15069:09/12/17 16:45:39 [63416] Updating classad values for 428.0:
15070:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15071:09/12/17 16:45:39 [63416]    GridJobId = undefined
15072:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15073:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15074:09/12/17 16:45:39 [63416] Updating classad values for 429.0:
15075:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15076:09/12/17 16:45:39 [63416]    GridJobId = undefined
15077:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15078:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15079:09/12/17 16:45:39 [63416] Updating classad values for 430.0:
15080:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15081:09/12/17 16:45:39 [63416]    GridJobId = undefined
15082:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15083:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15084:09/12/17 16:45:39 [63416] Updating classad values for 431.0:
15085:09/12/17 16:45:39 [63416]    CurrentStatusUnknown = false
15086:09/12/17 16:45:39 [63416]    GridJobId = undefined
15087:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 0
15088:09/12/17 16:45:39 [63416]    Managed = "ScheddDone"
15089:09/12/17 16:45:39 [63416] Updating classad values for 432.0:
15090:09/12/17 16:45:39 [63416]    EnteredCurrentStatus = 1505259934
15091:09/12/17 16:45:39 [63416]    ExitCode = 0
15092:09/12/17 16:45:39 [63416]    GridJobStatus = "COMPLETED"
15093:09/12/17 16:45:39 [63416]    ImageSize = 0
15094:09/12/17 16:45:39 [63416]    JobStatus = 4
15095:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 1505259934
15096:09/12/17 16:45:39 [63416]    RemoteUserCpu = 0
15097:09/12/17 16:45:39 [63416]    RemoteWallClockTime = 0.0
15098:09/12/17 16:45:39 [63416] Updating classad values for 433.0:
15099:09/12/17 16:45:39 [63416]    EnteredCurrentStatus = 1505259934
15100:09/12/17 16:45:39 [63416]    ExitCode = 0
15101:09/12/17 16:45:39 [63416]    GridJobStatus = "COMPLETED"
15102:09/12/17 16:45:39 [63416]    ImageSize = 0
15103:09/12/17 16:45:39 [63416]    JobStatus = 4
15104:09/12/17 16:45:39 [63416]    LastRemoteStatusUpdate = 1505259934
15105:09/12/17 16:45:39 [63416]    RemoteUserCpu = 0
15106:09/12/17 16:45:39 [63416]    RemoteWallClockTime = 0.0
15107:09/12/17 16:45:39 [63416] Deleting job 434.0 from schedd
15108:09/12/17 16:45:39 [63416] Deleting job 435.0 from schedd
15109:09/12/17 16:45:39 [63416] Deleting job 436.0 from schedd
15110:09/12/17 16:45:39 [63416] Deleting job 418.0 from schedd
15111:09/12/17 16:45:39 [63416] Deleting job 419.0 from schedd
15112:09/12/17 16:45:39 [63416] Deleting job 420.0 from schedd
15113:09/12/17 16:45:39 [63416] Deleting job 421.0 from schedd
15114:09/12/17 16:45:39 [63416] Deleting job 423.0 from schedd
15115:09/12/17 16:45:39 [63416] Deleting job 426.0 from schedd
15116:09/12/17 16:45:39 [63416] Deleting job 427.0 from schedd
15117:09/12/17 16:45:39 [63416] Deleting job 428.0 from schedd
15118:09/12/17 16:45:39 [63416] Deleting job 429.0 from schedd
15119:09/12/17 16:45:39 [63416] Deleting job 430.0 from schedd
15120:09/12/17 16:45:39 [63416] Deleting job 431.0 from schedd
15121:09/12/17 16:45:39 [63416] leaving doContactSchedd()
15122:09/12/17 16:45:39 [63416] (422.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
15123:09/12/17 16:45:39 [63416] (422.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
15124:09/12/17 16:45:39 [63416] (422.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
15125:09/12/17 16:45:39 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
15126:09/12/17 16:45:40 [63416] (422.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
15127:09/12/17 16:45:40 [63416] (424.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
15128:09/12/17 16:45:40 [63416] (424.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
15129:09/12/17 16:45:40 [63416] (424.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
15130:09/12/17 16:45:40 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
15131:09/12/17 16:45:40 [63416] (424.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
15132:09/12/17 16:45:40 [63416] (425.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
15133:09/12/17 16:45:40 [63416] (425.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
15134:09/12/17 16:45:40 [63416] (425.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
15135:09/12/17 16:45:40 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
15136:09/12/17 16:45:40 [63416] (425.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
15137:09/12/17 16:45:40 [63416] (432.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
15138:09/12/17 16:45:40 [63416] (432.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
15139:09/12/17 16:45:40 [63416] (432.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
15140:09/12/17 16:45:40 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
15141:09/12/17 16:45:40 [63416] (432.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
15142:09/12/17 16:45:40 [63416] (433.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
15143:09/12/17 16:45:40 [63416] (433.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
15144:09/12/17 16:45:40 [63416] (433.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
15145:09/12/17 16:45:40 [63416] Initializing Directory: curr_dir = /global/homes/a/alicesgm
15146:09/12/17 16:45:40 [63416] (433.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
15147:09/12/17 16:45:44 [63416] in doContactSchedd()
15148:09/12/17 16:45:44 [63416] querying for removed/held jobs
15149:09/12/17 16:45:44 [63416] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
15150:09/12/17 16:45:44 [63416] Fetched 5 job ads from schedd
15151:09/12/17 16:45:44 [63416] Updating classad values for 422.0:
15152:09/12/17 16:45:44 [63416]    CurrentStatusUnknown = false
15153:09/12/17 16:45:44 [63416]    GridJobId = undefined
15154:09/12/17 16:45:44 [63416]    LastRemoteStatusUpdate = 0
15155:09/12/17 16:45:44 [63416]    Managed = "ScheddDone"
15156:09/12/17 16:45:44 [63416] Updating classad values for 424.0:
15157:09/12/17 16:45:44 [63416]    CurrentStatusUnknown = false
15158:09/12/17 16:45:44 [63416]    GridJobId = undefined
15159:09/12/17 16:45:44 [63416]    LastRemoteStatusUpdate = 0
15160:09/12/17 16:45:44 [63416]    Managed = "ScheddDone"
15161:09/12/17 16:45:44 [63416] Updating classad values for 425.0:
15162:09/12/17 16:45:44 [63416]    CurrentStatusUnknown = false
15163:09/12/17 16:45:44 [63416]    GridJobId = undefined
15164:09/12/17 16:45:44 [63416]    LastRemoteStatusUpdate = 0
15165:09/12/17 16:45:44 [63416]    Managed = "ScheddDone"
15166:09/12/17 16:45:44 [63416] Updating classad values for 432.0:
15167:09/12/17 16:45:44 [63416]    CurrentStatusUnknown = false
15168:09/12/17 16:45:44 [63416]    GridJobId = undefined
15169:09/12/17 16:45:44 [63416]    LastRemoteStatusUpdate = 0
15170:09/12/17 16:45:44 [63416]    Managed = "ScheddDone"
15171:09/12/17 16:45:44 [63416] Updating classad values for 433.0:
15172:09/12/17 16:45:44 [63416]    CurrentStatusUnknown = false
15173:09/12/17 16:45:44 [63416]    GridJobId = undefined
15174:09/12/17 16:45:44 [63416]    LastRemoteStatusUpdate = 0
15175:09/12/17 16:45:44 [63416]    Managed = "ScheddDone"
15176:09/12/17 16:45:44 [63416] Deleting job 422.0 from schedd
15177:09/12/17 16:45:44 [63416] Deleting job 424.0 from schedd
15178:09/12/17 16:45:44 [63416] Deleting job 425.0 from schedd
15179:09/12/17 16:45:44 [63416] Deleting job 432.0 from schedd
15180:09/12/17 16:45:44 [63416] Deleting job 433.0 from schedd
15181:09/12/17 16:45:44 [63416] No jobs left, shutting down
15182:09/12/17 16:45:44 [63416] leaving doContactSchedd()
15183:09/12/17 16:45:44 [63416] Got SIGTERM. Performing graceful shutdown.
15184:09/12/17 16:45:44 [63416] Started timer to call main_shutdown_fast in 1800 seconds
15185:09/12/17 16:45:44 [63416] **** condor_gridmanager (condor_GRIDMANAGER) pid 63416 EXITING WITH STATUS 0
15186:09/12/17 17:05:15 Result of reading /etc/issue:  \S
15188:09/12/17 17:05:15 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
15190:09/12/17 17:05:15 Using IDs: 32 processors, 16 CPUs, 16 HTs
15191:09/12/17 17:05:15 Enumerating interfaces: lo 127.0.0.1 up
15192:09/12/17 17:05:15 Enumerating interfaces: eth0 10.36.162.46 up
15193:09/12/17 17:05:15 Enumerating interfaces: ib0 128.55.162.46 up
15194:09/12/17 17:05:15 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
15195:09/12/17 17:05:15 Initializing Directory: curr_dir = /etc/condor-ce/config.d
15196:09/12/17 17:05:15 ******************************************************
15197:09/12/17 17:05:15 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
15198:09/12/17 17:05:15 ** /usr/sbin/condor_gridmanager
15199:09/12/17 17:05:15 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
15200:09/12/17 17:05:15 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
15201:09/12/17 17:05:15 ** $CondorVersion: 8.4.12 Aug 07 2017 $
15202:09/12/17 17:05:15 ** $CondorPlatform: X86_64-CentOS_7.3 $
15203:09/12/17 17:05:15 ** PID = 64929
15204:09/12/17 17:05:15 ** Log last touched 9/12 16:45:44
15205:09/12/17 17:05:15 ******************************************************
15206:09/12/17 17:05:15 Using config source: /etc/condor-ce/condor_config
15207:09/12/17 17:05:15 Using local config sources: 
15208:09/12/17 17:05:15    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
15209:09/12/17 17:05:15    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
15210:09/12/17 17:05:15    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
15211:09/12/17 17:05:15    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
15212:09/12/17 17:05:15    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
15213:09/12/17 17:05:15    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
15214:09/12/17 17:05:15    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
15215:09/12/17 17:05:15    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
15216:09/12/17 17:05:15    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
15217:09/12/17 17:05:15    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
15218:09/12/17 17:05:15    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
15219:09/12/17 17:05:15    /etc/condor-ce/config.d/01-ce-auth.conf
15220:09/12/17 17:05:15    /etc/condor-ce/config.d/01-ce-router.conf
15221:09/12/17 17:05:15    /etc/condor-ce/config.d/01-common-auth.conf
15222:09/12/17 17:05:15    /etc/condor-ce/config.d/02-ce-slurm.conf
15223:09/12/17 17:05:15    /etc/condor-ce/config.d/03-ce-shared-port.conf
15224:09/12/17 17:05:15    /etc/condor-ce/config.d/03-managed-fork.conf
15225:09/12/17 17:05:15    /etc/condor-ce/config.d/05-ce-health.conf
15226:09/12/17 17:05:15    /etc/condor-ce/config.d/05-ce-view.conf
15227:09/12/17 17:05:15    /etc/condor-ce/config.d/10-ce-collector-generated.conf
15228:09/12/17 17:05:15    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
15229:09/12/17 17:05:15    /etc/condor-ce/config.d/50-osg-configure-present.conf
15230:09/12/17 17:05:15    /etc/condor-ce/config.d/50-osg-configure.conf
15231:09/12/17 17:05:15    /etc/condor-ce/config.d/99-local.conf
15232:09/12/17 17:05:15    /usr/share/condor-ce/condor_ce_router_defaults|
15233:09/12/17 17:05:15 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
15234:09/12/17 17:05:15 CLASSAD_CACHING is ENABLED
15235:09/12/17 17:05:15 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
15236:09/12/17 17:05:15 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_26
15237:09/12/17 17:05:15 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_26>
15238:09/12/17 17:05:15 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_26>
15239:09/12/17 17:05:15 Setting maximum accepts per cycle 8.
15240:09/12/17 17:05:15 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
15241:09/12/17 17:05:15 [64929] Welcome to the all-singing, all dancing, "amazing" GridManager!
15242:09/12/17 17:05:15 [64929] DaemonCore: No more children processes to reap.
15243:09/12/17 17:05:15 [64929] DaemonCore: in SendAliveToParent()
15244:09/12/17 17:05:15 [64929] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
15245:09/12/17 17:05:15 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15246:09/12/17 17:05:15 [64929] IPVERIFY: ip found is 1
15247:09/12/17 17:05:15 [64929] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
15248:09/12/17 17:05:15 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15249:09/12/17 17:05:15 [64929] IPVERIFY: ip found is 1
15250:09/12/17 17:05:15 [64929] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
15251:09/12/17 17:05:15 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15252:09/12/17 17:05:15 [64929] IPVERIFY: ip found is 1
15253:09/12/17 17:05:15 [64929] IPVERIFY: checking mc0151-ib against 128.55.162.46
15254:09/12/17 17:05:15 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15255:09/12/17 17:05:15 [64929] IPVERIFY: ip found is 1
15256:09/12/17 17:05:15 [64929] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
15257:09/12/17 17:05:15 [64929] DaemonCore: Leaving SendAliveToParent() - success
15258:09/12/17 17:05:15 [64929] Checking proxies
15259:09/12/17 17:05:18 [64929] Received ADD_JOBS signal
15260:09/12/17 17:05:18 [64929] in doContactSchedd()
15261:09/12/17 17:05:18 [64929] querying for new jobs
15262:09/12/17 17:05:18 [64929] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
15263:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 510.0
15264:09/12/17 17:05:18 [64929] (510.0) SetJobLeaseTimers()
15265:09/12/17 17:05:18 [64929] Found job 510.0 --- inserting
15266:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 509.0
15267:09/12/17 17:05:18 [64929] (509.0) SetJobLeaseTimers()
15268:09/12/17 17:05:18 [64929] Found job 509.0 --- inserting
15269:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 508.0
15270:09/12/17 17:05:18 [64929] (508.0) SetJobLeaseTimers()
15271:09/12/17 17:05:18 [64929] Found job 508.0 --- inserting
15272:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 507.0
15273:09/12/17 17:05:18 [64929] (507.0) SetJobLeaseTimers()
15274:09/12/17 17:05:18 [64929] Found job 507.0 --- inserting
15275:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 506.0
15276:09/12/17 17:05:18 [64929] (506.0) SetJobLeaseTimers()
15277:09/12/17 17:05:18 [64929] Found job 506.0 --- inserting
15278:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 505.0
15279:09/12/17 17:05:18 [64929] (505.0) SetJobLeaseTimers()
15280:09/12/17 17:05:18 [64929] Found job 505.0 --- inserting
15281:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 504.0
15282:09/12/17 17:05:18 [64929] (504.0) SetJobLeaseTimers()
15283:09/12/17 17:05:18 [64929] Found job 504.0 --- inserting
15284:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 503.0
15285:09/12/17 17:05:18 [64929] (503.0) SetJobLeaseTimers()
15286:09/12/17 17:05:18 [64929] Found job 503.0 --- inserting
15287:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 502.0
15288:09/12/17 17:05:18 [64929] (502.0) SetJobLeaseTimers()
15289:09/12/17 17:05:18 [64929] Found job 502.0 --- inserting
15290:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 501.0
15291:09/12/17 17:05:18 [64929] (501.0) SetJobLeaseTimers()
15292:09/12/17 17:05:18 [64929] Found job 501.0 --- inserting
15293:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 500.0
15294:09/12/17 17:05:18 [64929] (500.0) SetJobLeaseTimers()
15295:09/12/17 17:05:18 [64929] Found job 500.0 --- inserting
15296:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 499.0
15297:09/12/17 17:05:18 [64929] (499.0) SetJobLeaseTimers()
15298:09/12/17 17:05:18 [64929] Found job 499.0 --- inserting
15299:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 498.0
15300:09/12/17 17:05:18 [64929] (498.0) SetJobLeaseTimers()
15301:09/12/17 17:05:18 [64929] Found job 498.0 --- inserting
15302:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 497.0
15303:09/12/17 17:05:18 [64929] (497.0) SetJobLeaseTimers()
15304:09/12/17 17:05:18 [64929] Found job 497.0 --- inserting
15305:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 496.0
15306:09/12/17 17:05:18 [64929] (496.0) SetJobLeaseTimers()
15307:09/12/17 17:05:18 [64929] Found job 496.0 --- inserting
15308:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 495.0
15309:09/12/17 17:05:18 [64929] (495.0) SetJobLeaseTimers()
15310:09/12/17 17:05:18 [64929] Found job 495.0 --- inserting
15311:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 494.0
15312:09/12/17 17:05:18 [64929] (494.0) SetJobLeaseTimers()
15313:09/12/17 17:05:18 [64929] Found job 494.0 --- inserting
15314:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 493.0
15315:09/12/17 17:05:18 [64929] (493.0) SetJobLeaseTimers()
15316:09/12/17 17:05:18 [64929] Found job 493.0 --- inserting
15317:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 492.0
15318:09/12/17 17:05:18 [64929] (492.0) SetJobLeaseTimers()
15319:09/12/17 17:05:18 [64929] Found job 492.0 --- inserting
15320:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 491.0
15321:09/12/17 17:05:18 [64929] (491.0) SetJobLeaseTimers()
15322:09/12/17 17:05:18 [64929] Found job 491.0 --- inserting
15323:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 490.0
15324:09/12/17 17:05:18 [64929] (490.0) SetJobLeaseTimers()
15325:09/12/17 17:05:18 [64929] Found job 490.0 --- inserting
15326:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 489.0
15327:09/12/17 17:05:18 [64929] (489.0) SetJobLeaseTimers()
15328:09/12/17 17:05:18 [64929] Found job 489.0 --- inserting
15329:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 488.0
15330:09/12/17 17:05:18 [64929] (488.0) SetJobLeaseTimers()
15331:09/12/17 17:05:18 [64929] Found job 488.0 --- inserting
15332:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 487.0
15333:09/12/17 17:05:18 [64929] (487.0) SetJobLeaseTimers()
15334:09/12/17 17:05:18 [64929] Found job 487.0 --- inserting
15335:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 486.0
15336:09/12/17 17:05:18 [64929] (486.0) SetJobLeaseTimers()
15337:09/12/17 17:05:18 [64929] Found job 486.0 --- inserting
15338:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 485.0
15339:09/12/17 17:05:18 [64929] (485.0) SetJobLeaseTimers()
15340:09/12/17 17:05:18 [64929] Found job 485.0 --- inserting
15341:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 484.0
15342:09/12/17 17:05:18 [64929] (484.0) SetJobLeaseTimers()
15343:09/12/17 17:05:18 [64929] Found job 484.0 --- inserting
15344:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 483.0
15345:09/12/17 17:05:18 [64929] (483.0) SetJobLeaseTimers()
15346:09/12/17 17:05:18 [64929] Found job 483.0 --- inserting
15347:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 482.0
15348:09/12/17 17:05:18 [64929] (482.0) SetJobLeaseTimers()
15349:09/12/17 17:05:18 [64929] Found job 482.0 --- inserting
15350:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 481.0
15351:09/12/17 17:05:18 [64929] (481.0) SetJobLeaseTimers()
15352:09/12/17 17:05:18 [64929] Found job 481.0 --- inserting
15353:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 480.0
15354:09/12/17 17:05:18 [64929] (480.0) SetJobLeaseTimers()
15355:09/12/17 17:05:18 [64929] Found job 480.0 --- inserting
15356:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 516.0
15357:09/12/17 17:05:18 [64929] (516.0) SetJobLeaseTimers()
15358:09/12/17 17:05:18 [64929] Found job 516.0 --- inserting
15359:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 479.0
15360:09/12/17 17:05:18 [64929] (479.0) SetJobLeaseTimers()
15361:09/12/17 17:05:18 [64929] Found job 479.0 --- inserting
15362:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 515.0
15363:09/12/17 17:05:18 [64929] (515.0) SetJobLeaseTimers()
15364:09/12/17 17:05:18 [64929] Found job 515.0 --- inserting
15365:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 478.0
15366:09/12/17 17:05:18 [64929] (478.0) SetJobLeaseTimers()
15367:09/12/17 17:05:18 [64929] Found job 478.0 --- inserting
15368:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 514.0
15369:09/12/17 17:05:18 [64929] (514.0) SetJobLeaseTimers()
15370:09/12/17 17:05:18 [64929] Found job 514.0 --- inserting
15371:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 477.0
15372:09/12/17 17:05:18 [64929] (477.0) SetJobLeaseTimers()
15373:09/12/17 17:05:18 [64929] Found job 477.0 --- inserting
15374:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 513.0
15375:09/12/17 17:05:18 [64929] (513.0) SetJobLeaseTimers()
15376:09/12/17 17:05:18 [64929] Found job 513.0 --- inserting
15377:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 512.0
15378:09/12/17 17:05:18 [64929] (512.0) SetJobLeaseTimers()
15379:09/12/17 17:05:18 [64929] Found job 512.0 --- inserting
15380:09/12/17 17:05:18 [64929] Using job type INFNBatch for job 511.0
15381:09/12/17 17:05:18 [64929] (511.0) SetJobLeaseTimers()
15382:09/12/17 17:05:18 [64929] Found job 511.0 --- inserting
15383:09/12/17 17:05:18 [64929] Fetched 40 new job ads from schedd
15384:09/12/17 17:05:18 [64929] querying for removed/held jobs
15385:09/12/17 17:05:18 [64929] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
15386:09/12/17 17:05:18 [64929] Fetched 0 job ads from schedd
15387:09/12/17 17:05:18 [64929] leaving doContactSchedd()
15388:09/12/17 17:05:18 [64929] gahp server not up yet, delaying ping
15389:09/12/17 17:05:18 [64929] *** UpdateLeases called
15390:09/12/17 17:05:18 [64929]     Leases not supported, cancelling timer
15391:09/12/17 17:05:18 [64929] BaseResource::UpdateResource: 
15411:09/12/17 17:05:18 [64929] Trying to update collector <128.55.162.46:9619>
15412:09/12/17 17:05:18 [64929] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
15413:09/12/17 17:05:18 [64929] File descriptor limits: max 4096, safe 3277
15414:09/12/17 17:05:18 [64929] (510.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15415:09/12/17 17:05:18 [64929] GAHP server pid = 64933
15416:09/12/17 17:05:18 [64929] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
15417:09/12/17 17:05:18 [64929] GAHP[64933] <- 'COMMANDS'
15418:09/12/17 17:05:18 [64929] GAHP[64933] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
15419:09/12/17 17:05:18 [64929] GAHP[64933] <- 'ASYNC_MODE_ON'
15420:09/12/17 17:05:18 [64929] GAHP[64933] -> 'S' 'Async mode on'
15421:09/12/17 17:05:18 [64929] (510.0) gm state change: GM_INIT -> GM_START
15422:09/12/17 17:05:18 [64929] (510.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15423:09/12/17 17:05:18 [64929] (510.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15424:09/12/17 17:05:18 [64929] (510.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15425:09/12/17 17:05:18 [64929] (509.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15426:09/12/17 17:05:18 [64929] (509.0) gm state change: GM_INIT -> GM_START
15427:09/12/17 17:05:18 [64929] (509.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15428:09/12/17 17:05:18 [64929] (509.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15429:09/12/17 17:05:18 [64929] (509.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15430:09/12/17 17:05:18 [64929] (508.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15431:09/12/17 17:05:18 [64929] (508.0) gm state change: GM_INIT -> GM_START
15432:09/12/17 17:05:18 [64929] (508.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15433:09/12/17 17:05:18 [64929] (508.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15434:09/12/17 17:05:18 [64929] (508.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15435:09/12/17 17:05:18 [64929] (507.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15436:09/12/17 17:05:18 [64929] (507.0) gm state change: GM_INIT -> GM_START
15437:09/12/17 17:05:18 [64929] (507.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15438:09/12/17 17:05:18 [64929] (507.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15439:09/12/17 17:05:18 [64929] (507.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15440:09/12/17 17:05:18 [64929] (506.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15441:09/12/17 17:05:18 [64929] (506.0) gm state change: GM_INIT -> GM_START
15442:09/12/17 17:05:18 [64929] (506.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15443:09/12/17 17:05:18 [64929] (506.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15444:09/12/17 17:05:18 [64929] (506.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15445:09/12/17 17:05:18 [64929] This process has a valid certificate & key
15446:09/12/17 17:05:18 [64929] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
15447:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15448:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15449:09/12/17 17:05:18 [64929] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
15450:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15451:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15452:09/12/17 17:05:18 [64929] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
15453:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15454:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15455:09/12/17 17:05:18 [64929] IPVERIFY: checking mc0151-ib against 128.55.162.46
15456:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15457:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15458:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15459:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15460:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15461:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15462:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15463:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
15464:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
15465:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
15466:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
15467:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
15468:09/12/17 17:05:18 [64929] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
15469:09/12/17 17:05:18 [64929] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
15470:09/12/17 17:05:18 [64929] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
15471:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15472:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15473:09/12/17 17:05:18 [64929] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
15474:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15475:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15476:09/12/17 17:05:18 [64929] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
15477:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15478:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15479:09/12/17 17:05:18 [64929] IPVERIFY: checking mc0151-ib against 128.55.162.46
15480:09/12/17 17:05:18 [64929] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15481:09/12/17 17:05:18 [64929] IPVERIFY: ip found is 1
15482:09/12/17 17:05:18 [64929] (505.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15483:09/12/17 17:05:18 [64929] (505.0) gm state change: GM_INIT -> GM_START
15484:09/12/17 17:05:18 [64929] (505.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15485:09/12/17 17:05:18 [64929] (505.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15486:09/12/17 17:05:18 [64929] (505.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15487:09/12/17 17:05:18 [64929] (504.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15488:09/12/17 17:05:18 [64929] (504.0) gm state change: GM_INIT -> GM_START
15489:09/12/17 17:05:18 [64929] (504.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15490:09/12/17 17:05:18 [64929] (504.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15491:09/12/17 17:05:18 [64929] (504.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15492:09/12/17 17:05:18 [64929] (503.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15493:09/12/17 17:05:18 [64929] (503.0) gm state change: GM_INIT -> GM_START
15494:09/12/17 17:05:18 [64929] (503.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15495:09/12/17 17:05:18 [64929] (503.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15496:09/12/17 17:05:18 [64929] (503.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15497:09/12/17 17:05:18 [64929] (502.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15498:09/12/17 17:05:18 [64929] (502.0) gm state change: GM_INIT -> GM_START
15499:09/12/17 17:05:18 [64929] (502.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15500:09/12/17 17:05:18 [64929] (502.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15501:09/12/17 17:05:18 [64929] (502.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15502:09/12/17 17:05:18 [64929] (501.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15503:09/12/17 17:05:18 [64929] (501.0) gm state change: GM_INIT -> GM_START
15504:09/12/17 17:05:18 [64929] (501.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15505:09/12/17 17:05:18 [64929] (501.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15506:09/12/17 17:05:18 [64929] (501.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15507:09/12/17 17:05:18 [64929] (500.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15508:09/12/17 17:05:18 [64929] (500.0) gm state change: GM_INIT -> GM_START
15509:09/12/17 17:05:18 [64929] (500.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15510:09/12/17 17:05:18 [64929] (500.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15511:09/12/17 17:05:18 [64929] (500.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15512:09/12/17 17:05:18 [64929] (499.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15513:09/12/17 17:05:18 [64929] (499.0) gm state change: GM_INIT -> GM_START
15514:09/12/17 17:05:18 [64929] (499.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15515:09/12/17 17:05:18 [64929] (499.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15516:09/12/17 17:05:18 [64929] (499.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15517:09/12/17 17:05:18 [64929] (498.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15518:09/12/17 17:05:18 [64929] (498.0) gm state change: GM_INIT -> GM_START
15519:09/12/17 17:05:18 [64929] (498.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15520:09/12/17 17:05:18 [64929] (498.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15521:09/12/17 17:05:18 [64929] (498.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15522:09/12/17 17:05:18 [64929] (497.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15523:09/12/17 17:05:18 [64929] (497.0) gm state change: GM_INIT -> GM_START
15524:09/12/17 17:05:18 [64929] (497.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15525:09/12/17 17:05:18 [64929] (497.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15526:09/12/17 17:05:18 [64929] (497.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15527:09/12/17 17:05:18 [64929] (496.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15528:09/12/17 17:05:18 [64929] (496.0) gm state change: GM_INIT -> GM_START
15529:09/12/17 17:05:18 [64929] (496.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15530:09/12/17 17:05:18 [64929] (496.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15531:09/12/17 17:05:18 [64929] (496.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15532:09/12/17 17:05:18 [64929] (495.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15533:09/12/17 17:05:18 [64929] (495.0) gm state change: GM_INIT -> GM_START
15534:09/12/17 17:05:18 [64929] (495.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15535:09/12/17 17:05:18 [64929] (495.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15536:09/12/17 17:05:18 [64929] (495.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15537:09/12/17 17:05:18 [64929] (494.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15538:09/12/17 17:05:18 [64929] (494.0) gm state change: GM_INIT -> GM_START
15539:09/12/17 17:05:18 [64929] (494.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15540:09/12/17 17:05:18 [64929] (494.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15541:09/12/17 17:05:18 [64929] (494.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15542:09/12/17 17:05:18 [64929] (493.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15543:09/12/17 17:05:18 [64929] (493.0) gm state change: GM_INIT -> GM_START
15544:09/12/17 17:05:18 [64929] (493.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15545:09/12/17 17:05:18 [64929] (493.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15546:09/12/17 17:05:18 [64929] (493.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15547:09/12/17 17:05:18 [64929] (492.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15548:09/12/17 17:05:18 [64929] (492.0) gm state change: GM_INIT -> GM_START
15549:09/12/17 17:05:18 [64929] (492.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15550:09/12/17 17:05:18 [64929] (492.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15551:09/12/17 17:05:18 [64929] (492.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15552:09/12/17 17:05:18 [64929] (491.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15553:09/12/17 17:05:18 [64929] (491.0) gm state change: GM_INIT -> GM_START
15554:09/12/17 17:05:18 [64929] (491.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15555:09/12/17 17:05:18 [64929] (491.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15556:09/12/17 17:05:18 [64929] (491.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15557:09/12/17 17:05:18 [64929] (490.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15558:09/12/17 17:05:18 [64929] (490.0) gm state change: GM_INIT -> GM_START
15559:09/12/17 17:05:18 [64929] (490.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15560:09/12/17 17:05:18 [64929] (490.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15561:09/12/17 17:05:18 [64929] (490.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15562:09/12/17 17:05:18 [64929] (489.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15563:09/12/17 17:05:18 [64929] (489.0) gm state change: GM_INIT -> GM_START
15564:09/12/17 17:05:18 [64929] (489.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15565:09/12/17 17:05:18 [64929] (489.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15566:09/12/17 17:05:18 [64929] (489.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15567:09/12/17 17:05:18 [64929] (488.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15568:09/12/17 17:05:18 [64929] (488.0) gm state change: GM_INIT -> GM_START
15569:09/12/17 17:05:18 [64929] (488.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15570:09/12/17 17:05:18 [64929] (488.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15571:09/12/17 17:05:18 [64929] (488.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15572:09/12/17 17:05:18 [64929] (487.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15573:09/12/17 17:05:18 [64929] (487.0) gm state change: GM_INIT -> GM_START
15574:09/12/17 17:05:18 [64929] (487.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15575:09/12/17 17:05:18 [64929] (487.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15576:09/12/17 17:05:18 [64929] (487.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15577:09/12/17 17:05:18 [64929] (486.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15578:09/12/17 17:05:18 [64929] (486.0) gm state change: GM_INIT -> GM_START
15579:09/12/17 17:05:18 [64929] (486.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15580:09/12/17 17:05:18 [64929] (486.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15581:09/12/17 17:05:18 [64929] (486.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15582:09/12/17 17:05:18 [64929] (485.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15583:09/12/17 17:05:18 [64929] (485.0) gm state change: GM_INIT -> GM_START
15584:09/12/17 17:05:18 [64929] (485.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15585:09/12/17 17:05:18 [64929] (485.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15586:09/12/17 17:05:18 [64929] (485.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15587:09/12/17 17:05:18 [64929] (484.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15588:09/12/17 17:05:18 [64929] (484.0) gm state change: GM_INIT -> GM_START
15589:09/12/17 17:05:18 [64929] (484.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15590:09/12/17 17:05:18 [64929] (484.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15591:09/12/17 17:05:18 [64929] (484.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15592:09/12/17 17:05:18 [64929] (483.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15593:09/12/17 17:05:18 [64929] (483.0) gm state change: GM_INIT -> GM_START
15594:09/12/17 17:05:18 [64929] (483.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15595:09/12/17 17:05:18 [64929] (483.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15596:09/12/17 17:05:18 [64929] (483.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15597:09/12/17 17:05:18 [64929] (482.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15598:09/12/17 17:05:18 [64929] (482.0) gm state change: GM_INIT -> GM_START
15599:09/12/17 17:05:18 [64929] (482.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15600:09/12/17 17:05:18 [64929] (482.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15601:09/12/17 17:05:18 [64929] (482.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15602:09/12/17 17:05:18 [64929] (481.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15603:09/12/17 17:05:18 [64929] (481.0) gm state change: GM_INIT -> GM_START
15604:09/12/17 17:05:18 [64929] (481.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15605:09/12/17 17:05:18 [64929] (481.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15606:09/12/17 17:05:18 [64929] (481.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15607:09/12/17 17:05:18 [64929] (480.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15608:09/12/17 17:05:18 [64929] (480.0) gm state change: GM_INIT -> GM_START
15609:09/12/17 17:05:18 [64929] (480.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15610:09/12/17 17:05:18 [64929] (480.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15611:09/12/17 17:05:18 [64929] (480.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15612:09/12/17 17:05:18 [64929] (516.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15613:09/12/17 17:05:18 [64929] (516.0) gm state change: GM_INIT -> GM_START
15614:09/12/17 17:05:18 [64929] (516.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15615:09/12/17 17:05:18 [64929] (516.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15616:09/12/17 17:05:18 [64929] (516.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15617:09/12/17 17:05:18 [64929] (479.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15618:09/12/17 17:05:18 [64929] (479.0) gm state change: GM_INIT -> GM_START
15619:09/12/17 17:05:18 [64929] (479.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15620:09/12/17 17:05:18 [64929] (479.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15621:09/12/17 17:05:18 [64929] (479.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15622:09/12/17 17:05:18 [64929] (515.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15623:09/12/17 17:05:18 [64929] (515.0) gm state change: GM_INIT -> GM_START
15624:09/12/17 17:05:18 [64929] (515.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15625:09/12/17 17:05:18 [64929] (515.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15626:09/12/17 17:05:18 [64929] (515.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15627:09/12/17 17:05:18 [64929] (478.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15628:09/12/17 17:05:18 [64929] (478.0) gm state change: GM_INIT -> GM_START
15629:09/12/17 17:05:18 [64929] (478.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15630:09/12/17 17:05:18 [64929] (478.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15631:09/12/17 17:05:18 [64929] (478.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15632:09/12/17 17:05:18 [64929] (514.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15633:09/12/17 17:05:18 [64929] (514.0) gm state change: GM_INIT -> GM_START
15634:09/12/17 17:05:18 [64929] (514.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15635:09/12/17 17:05:18 [64929] (514.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15636:09/12/17 17:05:18 [64929] (514.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15637:09/12/17 17:05:18 [64929] (477.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15638:09/12/17 17:05:18 [64929] (477.0) gm state change: GM_INIT -> GM_START
15639:09/12/17 17:05:18 [64929] (477.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15640:09/12/17 17:05:18 [64929] (477.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15641:09/12/17 17:05:18 [64929] (477.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15642:09/12/17 17:05:18 [64929] (513.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15643:09/12/17 17:05:18 [64929] (513.0) gm state change: GM_INIT -> GM_START
15644:09/12/17 17:05:18 [64929] (513.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15645:09/12/17 17:05:18 [64929] (513.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15646:09/12/17 17:05:18 [64929] (513.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15647:09/12/17 17:05:18 [64929] (512.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15648:09/12/17 17:05:18 [64929] (512.0) gm state change: GM_INIT -> GM_START
15649:09/12/17 17:05:18 [64929] (512.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15650:09/12/17 17:05:18 [64929] (512.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15651:09/12/17 17:05:18 [64929] (512.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15652:09/12/17 17:05:18 [64929] (511.0) doEvaluateState called: gmState GM_INIT, remoteState 0
15653:09/12/17 17:05:18 [64929] (511.0) gm state change: GM_INIT -> GM_START
15654:09/12/17 17:05:18 [64929] (511.0) gm state change: GM_START -> GM_CLEAR_REQUEST
15655:09/12/17 17:05:18 [64929] (511.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
15656:09/12/17 17:05:18 [64929] (511.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
15657:09/12/17 17:05:20 [64929] Evaluating staleness of remote job statuses.
15658:09/12/17 17:05:23 [64929] resource  is now up
15659:09/12/17 17:05:23 [64929] in doContactSchedd()
15660:09/12/17 17:05:23 [64929] querying for removed/held jobs
15661:09/12/17 17:05:23 [64929] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
15662:09/12/17 17:05:23 [64929] Fetched 0 job ads from schedd
15663:09/12/17 17:05:23 [64929] Updating classad values for 504.0:
15664:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#504.0#1505261111"
15665:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15666:09/12/17 17:05:23 [64929] Updating classad values for 505.0:
15667:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111"
15668:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15669:09/12/17 17:05:23 [64929] Updating classad values for 506.0:
15670:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111"
15671:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15672:09/12/17 17:05:23 [64929] Updating classad values for 507.0:
15673:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112"
15674:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15675:09/12/17 17:05:23 [64929] Updating classad values for 508.0:
15676:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112"
15677:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15678:09/12/17 17:05:23 [64929] Updating classad values for 509.0:
15679:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112"
15680:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15681:09/12/17 17:05:23 [64929] Updating classad values for 510.0:
15682:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112"
15683:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15684:09/12/17 17:05:23 [64929] Updating classad values for 511.0:
15685:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#511.0#1505261112"
15686:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15687:09/12/17 17:05:23 [64929] Updating classad values for 512.0:
15688:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#512.0#1505261112"
15689:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15690:09/12/17 17:05:23 [64929] Updating classad values for 513.0:
15691:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#513.0#1505261112"
15692:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15693:09/12/17 17:05:23 [64929] Updating classad values for 514.0:
15694:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#514.0#1505261112"
15695:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15696:09/12/17 17:05:23 [64929] Updating classad values for 515.0:
15697:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#515.0#1505261112"
15698:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15699:09/12/17 17:05:23 [64929] Updating classad values for 516.0:
15700:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#516.0#1505261112"
15701:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15702:09/12/17 17:05:23 [64929] Updating classad values for 477.0:
15703:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#477.0#1505261111"
15704:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15705:09/12/17 17:05:23 [64929] Updating classad values for 478.0:
15706:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#478.0#1505261111"
15707:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15708:09/12/17 17:05:23 [64929] Updating classad values for 479.0:
15709:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#479.0#1505261111"
15710:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15711:09/12/17 17:05:23 [64929] Updating classad values for 480.0:
15712:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#480.0#1505261111"
15713:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15714:09/12/17 17:05:23 [64929] Updating classad values for 481.0:
15715:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#481.0#1505261111"
15716:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15717:09/12/17 17:05:23 [64929] Updating classad values for 482.0:
15718:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#482.0#1505261111"
15719:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15720:09/12/17 17:05:23 [64929] Updating classad values for 483.0:
15721:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#483.0#1505261111"
15722:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15723:09/12/17 17:05:23 [64929] Updating classad values for 484.0:
15724:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#484.0#1505261111"
15725:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15726:09/12/17 17:05:23 [64929] Updating classad values for 485.0:
15727:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#485.0#1505261111"
15728:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15729:09/12/17 17:05:23 [64929] Updating classad values for 486.0:
15730:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#486.0#1505261111"
15731:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15732:09/12/17 17:05:23 [64929] Updating classad values for 487.0:
15733:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#487.0#1505261111"
15734:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15735:09/12/17 17:05:23 [64929] Updating classad values for 488.0:
15736:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#488.0#1505261111"
15737:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15738:09/12/17 17:05:23 [64929] Updating classad values for 489.0:
15739:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#489.0#1505261111"
15740:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15741:09/12/17 17:05:23 [64929] Updating classad values for 490.0:
15742:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#490.0#1505261111"
15743:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15744:09/12/17 17:05:23 [64929] Updating classad values for 491.0:
15745:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#491.0#1505261111"
15746:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15747:09/12/17 17:05:23 [64929] Updating classad values for 492.0:
15748:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#492.0#1505261111"
15749:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15750:09/12/17 17:05:23 [64929] Updating classad values for 493.0:
15751:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#493.0#1505261111"
15752:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15753:09/12/17 17:05:23 [64929] Updating classad values for 494.0:
15754:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#494.0#1505261111"
15755:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15756:09/12/17 17:05:23 [64929] Updating classad values for 495.0:
15757:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#495.0#1505261111"
15758:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15759:09/12/17 17:05:23 [64929] Updating classad values for 496.0:
15760:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#496.0#1505261111"
15761:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15762:09/12/17 17:05:23 [64929] Updating classad values for 497.0:
15763:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#497.0#1505261111"
15764:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15765:09/12/17 17:05:23 [64929] Updating classad values for 498.0:
15766:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#498.0#1505261111"
15767:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15768:09/12/17 17:05:23 [64929] Updating classad values for 499.0:
15769:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#499.0#1505261111"
15770:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15771:09/12/17 17:05:23 [64929] Updating classad values for 500.0:
15772:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#500.0#1505261111"
15773:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15774:09/12/17 17:05:23 [64929] Updating classad values for 501.0:
15775:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#501.0#1505261111"
15776:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15777:09/12/17 17:05:23 [64929] Updating classad values for 502.0:
15778:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#502.0#1505261111"
15779:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15780:09/12/17 17:05:23 [64929] Updating classad values for 503.0:
15781:09/12/17 17:05:23 [64929]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#503.0#1505261111"
15782:09/12/17 17:05:23 [64929]    LastRemoteStatusUpdate = 1505261118
15783:09/12/17 17:05:23 [64929] leaving doContactSchedd()
15784:09/12/17 17:05:23 [64929] (504.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
15785:09/12/17 17:05:23 [64929] (504.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
15786:09/12/17 17:05:23 [64929] (504.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
15787:09/12/17 17:05:23 [64929] GAHP[64933] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#504.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0/test.sh"\ ]'
15788:09/12/17 17:05:23 [64929] GAHP[64933] -> 'S'
15789:09/12/17 17:05:23 [64929] (505.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
15790:09/12/17 17:05:23 [64929] (505.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
15791:09/12/17 17:05:23 [64929] (505.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
15792:09/12/17 17:05:23 [64929] GAHP[64933] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/test.sh"\ ]'
15793:09/12/17 17:05:23 [64929] GAHP[64933] -> 'S'
15794:09/12/17 17:05:23 [64929] (506.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
15795:09/12/17 17:05:23 [64929] (506.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
15796:09/12/17 17:05:23 [64929] (506.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
15797:09/12/17 17:05:23 [64929] GAHP[64933] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/test.sh"\ ]'
15798:09/12/17 17:05:23 [64929] GAHP[64933] -> 'S'
15799:09/12/17 17:05:23 [64929] (507.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
15800:09/12/17 17:05:23 [64929] (507.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
15801:09/12/17 17:05:23 [64929] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
15802:09/12/17 17:05:23 [64929] GAHP[64933] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
15803:09/12/17 17:05:23 [64929] GAHP[64933] -> 'S'
15804:09/12/17 17:05:23 [64929] (508.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
15805:09/12/17 17:05:23 [64929] (508.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
15806:09/12/17 17:05:23 [64929] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
15807:09/12/17 17:05:23 [64929] GAHP[64933] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
15808:09/12/17 17:05:23 [64929] GAHP[64933] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
15809:09/12/17 17:05:23 [64929] GAHP[64933] -> EOF
15810:09/12/17 17:05:23 [64929] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
15811:09/12/17 17:10:16 Result of reading /etc/issue:  \S
15813:09/12/17 17:10:16 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
15815:09/12/17 17:10:16 Using IDs: 32 processors, 16 CPUs, 16 HTs
15816:09/12/17 17:10:16 Enumerating interfaces: lo 127.0.0.1 up
15817:09/12/17 17:10:16 Enumerating interfaces: eth0 10.36.162.46 up
15818:09/12/17 17:10:16 Enumerating interfaces: ib0 128.55.162.46 up
15819:09/12/17 17:10:16 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
15820:09/12/17 17:10:16 Initializing Directory: curr_dir = /etc/condor-ce/config.d
15821:09/12/17 17:10:16 ******************************************************
15822:09/12/17 17:10:16 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
15823:09/12/17 17:10:16 ** /usr/sbin/condor_gridmanager
15824:09/12/17 17:10:16 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
15825:09/12/17 17:10:16 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
15826:09/12/17 17:10:16 ** $CondorVersion: 8.4.12 Aug 07 2017 $
15827:09/12/17 17:10:16 ** $CondorPlatform: X86_64-CentOS_7.3 $
15828:09/12/17 17:10:16 ** PID = 64981
15829:09/12/17 17:10:16 ** Log last touched 9/12 17:05:23
15830:09/12/17 17:10:16 ******************************************************
15831:09/12/17 17:10:16 Using config source: /etc/condor-ce/condor_config
15832:09/12/17 17:10:16 Using local config sources: 
15833:09/12/17 17:10:16    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
15834:09/12/17 17:10:16    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
15835:09/12/17 17:10:16    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
15836:09/12/17 17:10:16    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
15837:09/12/17 17:10:16    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
15838:09/12/17 17:10:16    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
15839:09/12/17 17:10:16    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
15840:09/12/17 17:10:16    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
15841:09/12/17 17:10:16    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
15842:09/12/17 17:10:16    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
15843:09/12/17 17:10:16    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
15844:09/12/17 17:10:16    /etc/condor-ce/config.d/01-ce-auth.conf
15845:09/12/17 17:10:16    /etc/condor-ce/config.d/01-ce-router.conf
15846:09/12/17 17:10:16    /etc/condor-ce/config.d/01-common-auth.conf
15847:09/12/17 17:10:16    /etc/condor-ce/config.d/02-ce-slurm.conf
15848:09/12/17 17:10:16    /etc/condor-ce/config.d/03-ce-shared-port.conf
15849:09/12/17 17:10:16    /etc/condor-ce/config.d/03-managed-fork.conf
15850:09/12/17 17:10:16    /etc/condor-ce/config.d/05-ce-health.conf
15851:09/12/17 17:10:16    /etc/condor-ce/config.d/05-ce-view.conf
15852:09/12/17 17:10:16    /etc/condor-ce/config.d/10-ce-collector-generated.conf
15853:09/12/17 17:10:16    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
15854:09/12/17 17:10:16    /etc/condor-ce/config.d/50-osg-configure-present.conf
15855:09/12/17 17:10:16    /etc/condor-ce/config.d/50-osg-configure.conf
15856:09/12/17 17:10:16    /etc/condor-ce/config.d/99-local.conf
15857:09/12/17 17:10:16    /usr/share/condor-ce/condor_ce_router_defaults|
15858:09/12/17 17:10:16 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
15859:09/12/17 17:10:16 CLASSAD_CACHING is ENABLED
15860:09/12/17 17:10:16 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
15861:09/12/17 17:10:16 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_29
15862:09/12/17 17:10:16 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_29>
15863:09/12/17 17:10:16 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_29>
15864:09/12/17 17:10:16 Setting maximum accepts per cycle 8.
15865:09/12/17 17:10:16 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
15866:09/12/17 17:10:16 [64981] Welcome to the all-singing, all dancing, "amazing" GridManager!
15867:09/12/17 17:10:16 [64981] DaemonCore: No more children processes to reap.
15868:09/12/17 17:10:16 [64981] DaemonCore: in SendAliveToParent()
15869:09/12/17 17:10:16 [64981] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
15870:09/12/17 17:10:16 [64981] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15871:09/12/17 17:10:16 [64981] IPVERIFY: ip found is 1
15872:09/12/17 17:10:16 [64981] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
15873:09/12/17 17:10:16 [64981] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15874:09/12/17 17:10:16 [64981] IPVERIFY: ip found is 1
15875:09/12/17 17:10:16 [64981] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
15876:09/12/17 17:10:16 [64981] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15877:09/12/17 17:10:16 [64981] IPVERIFY: ip found is 1
15878:09/12/17 17:10:16 [64981] IPVERIFY: checking mc0151-ib against 128.55.162.46
15879:09/12/17 17:10:16 [64981] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
15880:09/12/17 17:10:16 [64981] IPVERIFY: ip found is 1
15881:09/12/17 17:10:16 [64981] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
15882:09/12/17 17:10:16 [64981] DaemonCore: Leaving SendAliveToParent() - success
15883:09/12/17 17:10:16 [64981] Checking proxies
15884:09/12/17 17:10:19 [64981] Received ADD_JOBS signal
15885:09/12/17 17:10:19 [64981] in doContactSchedd()
15886:09/12/17 17:10:19 [64981] querying for new jobs
15887:09/12/17 17:10:19 [64981] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
15888:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 510.0
15889:09/12/17 17:10:19 [64981] (510.0) SetJobLeaseTimers()
15890:09/12/17 17:10:19 [64981] Found job 510.0 --- inserting
15891:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 509.0
15892:09/12/17 17:10:19 [64981] (509.0) SetJobLeaseTimers()
15893:09/12/17 17:10:19 [64981] Found job 509.0 --- inserting
15894:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 508.0
15895:09/12/17 17:10:19 [64981] (508.0) SetJobLeaseTimers()
15896:09/12/17 17:10:19 [64981] Found job 508.0 --- inserting
15897:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 507.0
15898:09/12/17 17:10:19 [64981] (507.0) SetJobLeaseTimers()
15899:09/12/17 17:10:19 [64981] Found job 507.0 --- inserting
15900:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 506.0
15901:09/12/17 17:10:19 [64981] (506.0) SetJobLeaseTimers()
15902:09/12/17 17:10:19 [64981] Found job 506.0 --- inserting
15903:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 505.0
15904:09/12/17 17:10:19 [64981] (505.0) SetJobLeaseTimers()
15905:09/12/17 17:10:19 [64981] Found job 505.0 --- inserting
15906:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 504.0
15907:09/12/17 17:10:19 [64981] (504.0) SetJobLeaseTimers()
15908:09/12/17 17:10:19 [64981] Found job 504.0 --- inserting
15909:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 503.0
15910:09/12/17 17:10:19 [64981] (503.0) SetJobLeaseTimers()
15911:09/12/17 17:10:19 [64981] Found job 503.0 --- inserting
15912:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 502.0
15913:09/12/17 17:10:19 [64981] (502.0) SetJobLeaseTimers()
15914:09/12/17 17:10:19 [64981] Found job 502.0 --- inserting
15915:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 501.0
15916:09/12/17 17:10:19 [64981] (501.0) SetJobLeaseTimers()
15917:09/12/17 17:10:19 [64981] Found job 501.0 --- inserting
15918:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 500.0
15919:09/12/17 17:10:19 [64981] (500.0) SetJobLeaseTimers()
15920:09/12/17 17:10:19 [64981] Found job 500.0 --- inserting
15921:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 499.0
15922:09/12/17 17:10:19 [64981] (499.0) SetJobLeaseTimers()
15923:09/12/17 17:10:19 [64981] Found job 499.0 --- inserting
15924:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 498.0
15925:09/12/17 17:10:19 [64981] (498.0) SetJobLeaseTimers()
15926:09/12/17 17:10:19 [64981] Found job 498.0 --- inserting
15927:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 497.0
15928:09/12/17 17:10:19 [64981] (497.0) SetJobLeaseTimers()
15929:09/12/17 17:10:19 [64981] Found job 497.0 --- inserting
15930:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 496.0
15931:09/12/17 17:10:19 [64981] (496.0) SetJobLeaseTimers()
15932:09/12/17 17:10:19 [64981] Found job 496.0 --- inserting
15933:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 495.0
15934:09/12/17 17:10:19 [64981] (495.0) SetJobLeaseTimers()
15935:09/12/17 17:10:19 [64981] Found job 495.0 --- inserting
15936:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 494.0
15937:09/12/17 17:10:19 [64981] (494.0) SetJobLeaseTimers()
15938:09/12/17 17:10:19 [64981] Found job 494.0 --- inserting
15939:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 493.0
15940:09/12/17 17:10:19 [64981] (493.0) SetJobLeaseTimers()
15941:09/12/17 17:10:19 [64981] Found job 493.0 --- inserting
15942:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 492.0
15943:09/12/17 17:10:19 [64981] (492.0) SetJobLeaseTimers()
15944:09/12/17 17:10:19 [64981] Found job 492.0 --- inserting
15945:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 491.0
15946:09/12/17 17:10:19 [64981] (491.0) SetJobLeaseTimers()
15947:09/12/17 17:10:19 [64981] Found job 491.0 --- inserting
15948:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 490.0
15949:09/12/17 17:10:19 [64981] (490.0) SetJobLeaseTimers()
15950:09/12/17 17:10:19 [64981] Found job 490.0 --- inserting
15951:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 489.0
15952:09/12/17 17:10:19 [64981] (489.0) SetJobLeaseTimers()
15953:09/12/17 17:10:19 [64981] Found job 489.0 --- inserting
15954:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 488.0
15955:09/12/17 17:10:19 [64981] (488.0) SetJobLeaseTimers()
15956:09/12/17 17:10:19 [64981] Found job 488.0 --- inserting
15957:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 487.0
15958:09/12/17 17:10:19 [64981] (487.0) SetJobLeaseTimers()
15959:09/12/17 17:10:19 [64981] Found job 487.0 --- inserting
15960:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 486.0
15961:09/12/17 17:10:19 [64981] (486.0) SetJobLeaseTimers()
15962:09/12/17 17:10:19 [64981] Found job 486.0 --- inserting
15963:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 485.0
15964:09/12/17 17:10:19 [64981] (485.0) SetJobLeaseTimers()
15965:09/12/17 17:10:19 [64981] Found job 485.0 --- inserting
15966:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 484.0
15967:09/12/17 17:10:19 [64981] (484.0) SetJobLeaseTimers()
15968:09/12/17 17:10:19 [64981] Found job 484.0 --- inserting
15969:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 483.0
15970:09/12/17 17:10:19 [64981] (483.0) SetJobLeaseTimers()
15971:09/12/17 17:10:19 [64981] Found job 483.0 --- inserting
15972:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 482.0
15973:09/12/17 17:10:19 [64981] (482.0) SetJobLeaseTimers()
15974:09/12/17 17:10:19 [64981] Found job 482.0 --- inserting
15975:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 481.0
15976:09/12/17 17:10:19 [64981] (481.0) SetJobLeaseTimers()
15977:09/12/17 17:10:19 [64981] Found job 481.0 --- inserting
15978:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 480.0
15979:09/12/17 17:10:19 [64981] (480.0) SetJobLeaseTimers()
15980:09/12/17 17:10:19 [64981] Found job 480.0 --- inserting
15981:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 516.0
15982:09/12/17 17:10:19 [64981] (516.0) SetJobLeaseTimers()
15983:09/12/17 17:10:19 [64981] Found job 516.0 --- inserting
15984:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 479.0
15985:09/12/17 17:10:19 [64981] (479.0) SetJobLeaseTimers()
15986:09/12/17 17:10:19 [64981] Found job 479.0 --- inserting
15987:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 515.0
15988:09/12/17 17:10:19 [64981] (515.0) SetJobLeaseTimers()
15989:09/12/17 17:10:19 [64981] Found job 515.0 --- inserting
15990:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 478.0
15991:09/12/17 17:10:19 [64981] (478.0) SetJobLeaseTimers()
15992:09/12/17 17:10:19 [64981] Found job 478.0 --- inserting
15993:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 514.0
15994:09/12/17 17:10:19 [64981] (514.0) SetJobLeaseTimers()
15995:09/12/17 17:10:19 [64981] Found job 514.0 --- inserting
15996:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 477.0
15997:09/12/17 17:10:19 [64981] (477.0) SetJobLeaseTimers()
15998:09/12/17 17:10:19 [64981] Found job 477.0 --- inserting
15999:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 513.0
16000:09/12/17 17:10:19 [64981] (513.0) SetJobLeaseTimers()
16001:09/12/17 17:10:19 [64981] Found job 513.0 --- inserting
16002:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 512.0
16003:09/12/17 17:10:19 [64981] (512.0) SetJobLeaseTimers()
16004:09/12/17 17:10:19 [64981] Found job 512.0 --- inserting
16005:09/12/17 17:10:19 [64981] Using job type INFNBatch for job 511.0
16006:09/12/17 17:10:19 [64981] (511.0) SetJobLeaseTimers()
16007:09/12/17 17:10:19 [64981] Found job 511.0 --- inserting
16008:09/12/17 17:10:19 [64981] Fetched 40 new job ads from schedd
16009:09/12/17 17:10:19 [64981] querying for removed/held jobs
16010:09/12/17 17:10:19 [64981] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
16011:09/12/17 17:10:19 [64981] Fetched 0 job ads from schedd
16012:09/12/17 17:10:19 [64981] leaving doContactSchedd()
16013:09/12/17 17:10:19 [64981] gahp server not up yet, delaying ping
16014:09/12/17 17:10:19 [64981] *** UpdateLeases called
16015:09/12/17 17:10:19 [64981]     Leases not supported, cancelling timer
16016:09/12/17 17:10:19 [64981] BaseResource::UpdateResource: 
16036:09/12/17 17:10:19 [64981] Trying to update collector <128.55.162.46:9619>
16037:09/12/17 17:10:19 [64981] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16038:09/12/17 17:10:19 [64981] File descriptor limits: max 4096, safe 3277
16039:09/12/17 17:10:19 [64981] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16040:09/12/17 17:10:19 [64981] GAHP server pid = 64984
16041:09/12/17 17:10:19 [64981] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
16042:09/12/17 17:10:19 [64981] GAHP[64984] <- 'COMMANDS'
16043:09/12/17 17:10:19 [64981] GAHP[64984] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
16044:09/12/17 17:10:19 [64981] GAHP[64984] <- 'ASYNC_MODE_ON'
16045:09/12/17 17:10:19 [64981] GAHP[64984] -> 'S' 'Async mode on'
16046:09/12/17 17:10:19 [64981] (510.0) gm state change: GM_INIT -> GM_START
16047:09/12/17 17:10:19 [64981] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16048:09/12/17 17:10:19 [64981] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16049:09/12/17 17:10:19 [64981] GAHP[64984] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
16050:09/12/17 17:10:19 [64981] GAHP[64984] -> 'S'
16051:09/12/17 17:10:19 [64981] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16052:09/12/17 17:10:19 [64981] (509.0) gm state change: GM_INIT -> GM_START
16053:09/12/17 17:10:19 [64981] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16054:09/12/17 17:10:19 [64981] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16055:09/12/17 17:10:19 [64981] GAHP[64984] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
16056:09/12/17 17:10:19 [64981] GAHP[64984] -> 'S'
16057:09/12/17 17:10:19 [64981] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16058:09/12/17 17:10:19 [64981] (508.0) gm state change: GM_INIT -> GM_START
16059:09/12/17 17:10:19 [64981] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16060:09/12/17 17:10:19 [64981] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16061:09/12/17 17:10:19 [64981] GAHP[64984] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
16062:09/12/17 17:10:19 [64981] GAHP[64984] -> 'S'
16063:09/12/17 17:10:19 [64981] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16064:09/12/17 17:10:19 [64981] (507.0) gm state change: GM_INIT -> GM_START
16065:09/12/17 17:10:19 [64981] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16066:09/12/17 17:10:19 [64981] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16067:09/12/17 17:10:19 [64981] GAHP[64984] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
16068:09/12/17 17:10:19 [64981] GAHP[64984] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
16069:09/12/17 17:10:19 [64981] GAHP[64984] -> EOF
16070:09/12/17 17:10:19 [64981] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
16071:09/12/17 17:15:16 Result of reading /etc/issue:  \S
16073:09/12/17 17:15:16 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
16075:09/12/17 17:15:16 Using IDs: 32 processors, 16 CPUs, 16 HTs
16076:09/12/17 17:15:16 Enumerating interfaces: lo 127.0.0.1 up
16077:09/12/17 17:15:16 Enumerating interfaces: eth0 10.36.162.46 up
16078:09/12/17 17:15:16 Enumerating interfaces: ib0 128.55.162.46 up
16079:09/12/17 17:15:16 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
16080:09/12/17 17:15:16 Initializing Directory: curr_dir = /etc/condor-ce/config.d
16081:09/12/17 17:15:16 ******************************************************
16082:09/12/17 17:15:16 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
16083:09/12/17 17:15:16 ** /usr/sbin/condor_gridmanager
16084:09/12/17 17:15:16 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
16085:09/12/17 17:15:16 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
16086:09/12/17 17:15:16 ** $CondorVersion: 8.4.12 Aug 07 2017 $
16087:09/12/17 17:15:16 ** $CondorPlatform: X86_64-CentOS_7.3 $
16088:09/12/17 17:15:16 ** PID = 65022
16089:09/12/17 17:15:16 ** Log last touched 9/12 17:10:19
16090:09/12/17 17:15:16 ******************************************************
16091:09/12/17 17:15:16 Using config source: /etc/condor-ce/condor_config
16092:09/12/17 17:15:16 Using local config sources: 
16093:09/12/17 17:15:16    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
16094:09/12/17 17:15:16    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
16095:09/12/17 17:15:16    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
16096:09/12/17 17:15:16    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
16097:09/12/17 17:15:16    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
16098:09/12/17 17:15:16    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
16099:09/12/17 17:15:16    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
16100:09/12/17 17:15:16    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
16101:09/12/17 17:15:16    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
16102:09/12/17 17:15:16    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
16103:09/12/17 17:15:16    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
16104:09/12/17 17:15:16    /etc/condor-ce/config.d/01-ce-auth.conf
16105:09/12/17 17:15:16    /etc/condor-ce/config.d/01-ce-router.conf
16106:09/12/17 17:15:16    /etc/condor-ce/config.d/01-common-auth.conf
16107:09/12/17 17:15:16    /etc/condor-ce/config.d/02-ce-slurm.conf
16108:09/12/17 17:15:16    /etc/condor-ce/config.d/03-ce-shared-port.conf
16109:09/12/17 17:15:16    /etc/condor-ce/config.d/03-managed-fork.conf
16110:09/12/17 17:15:16    /etc/condor-ce/config.d/05-ce-health.conf
16111:09/12/17 17:15:16    /etc/condor-ce/config.d/05-ce-view.conf
16112:09/12/17 17:15:16    /etc/condor-ce/config.d/10-ce-collector-generated.conf
16113:09/12/17 17:15:16    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
16114:09/12/17 17:15:16    /etc/condor-ce/config.d/50-osg-configure-present.conf
16115:09/12/17 17:15:16    /etc/condor-ce/config.d/50-osg-configure.conf
16116:09/12/17 17:15:16    /etc/condor-ce/config.d/99-local.conf
16117:09/12/17 17:15:16    /usr/share/condor-ce/condor_ce_router_defaults|
16118:09/12/17 17:15:16 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
16119:09/12/17 17:15:16 CLASSAD_CACHING is ENABLED
16120:09/12/17 17:15:16 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
16121:09/12/17 17:15:16 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_31
16122:09/12/17 17:15:16 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_31>
16123:09/12/17 17:15:16 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_31>
16124:09/12/17 17:15:16 Setting maximum accepts per cycle 8.
16125:09/12/17 17:15:16 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16126:09/12/17 17:15:16 [65022] Welcome to the all-singing, all dancing, "amazing" GridManager!
16127:09/12/17 17:15:16 [65022] DaemonCore: No more children processes to reap.
16128:09/12/17 17:15:16 [65022] DaemonCore: in SendAliveToParent()
16129:09/12/17 17:15:16 [65022] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
16130:09/12/17 17:15:16 [65022] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16131:09/12/17 17:15:16 [65022] IPVERIFY: ip found is 1
16132:09/12/17 17:15:16 [65022] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
16133:09/12/17 17:15:16 [65022] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16134:09/12/17 17:15:16 [65022] IPVERIFY: ip found is 1
16135:09/12/17 17:15:16 [65022] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
16136:09/12/17 17:15:16 [65022] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16137:09/12/17 17:15:16 [65022] IPVERIFY: ip found is 1
16138:09/12/17 17:15:16 [65022] IPVERIFY: checking mc0151-ib against 128.55.162.46
16139:09/12/17 17:15:16 [65022] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16140:09/12/17 17:15:16 [65022] IPVERIFY: ip found is 1
16141:09/12/17 17:15:16 [65022] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
16142:09/12/17 17:15:16 [65022] DaemonCore: Leaving SendAliveToParent() - success
16143:09/12/17 17:15:16 [65022] Checking proxies
16144:09/12/17 17:15:19 [65022] Received ADD_JOBS signal
16145:09/12/17 17:15:19 [65022] in doContactSchedd()
16146:09/12/17 17:15:19 [65022] querying for new jobs
16147:09/12/17 17:15:19 [65022] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
16148:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 510.0
16149:09/12/17 17:15:19 [65022] (510.0) SetJobLeaseTimers()
16150:09/12/17 17:15:19 [65022] Found job 510.0 --- inserting
16151:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 509.0
16152:09/12/17 17:15:19 [65022] (509.0) SetJobLeaseTimers()
16153:09/12/17 17:15:19 [65022] Found job 509.0 --- inserting
16154:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 508.0
16155:09/12/17 17:15:19 [65022] (508.0) SetJobLeaseTimers()
16156:09/12/17 17:15:19 [65022] Found job 508.0 --- inserting
16157:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 507.0
16158:09/12/17 17:15:19 [65022] (507.0) SetJobLeaseTimers()
16159:09/12/17 17:15:19 [65022] Found job 507.0 --- inserting
16160:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 506.0
16161:09/12/17 17:15:19 [65022] (506.0) SetJobLeaseTimers()
16162:09/12/17 17:15:19 [65022] Found job 506.0 --- inserting
16163:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 505.0
16164:09/12/17 17:15:19 [65022] (505.0) SetJobLeaseTimers()
16165:09/12/17 17:15:19 [65022] Found job 505.0 --- inserting
16166:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 504.0
16167:09/12/17 17:15:19 [65022] (504.0) SetJobLeaseTimers()
16168:09/12/17 17:15:19 [65022] Found job 504.0 --- inserting
16169:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 503.0
16170:09/12/17 17:15:19 [65022] (503.0) SetJobLeaseTimers()
16171:09/12/17 17:15:19 [65022] Found job 503.0 --- inserting
16172:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 502.0
16173:09/12/17 17:15:19 [65022] (502.0) SetJobLeaseTimers()
16174:09/12/17 17:15:19 [65022] Found job 502.0 --- inserting
16175:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 501.0
16176:09/12/17 17:15:19 [65022] (501.0) SetJobLeaseTimers()
16177:09/12/17 17:15:19 [65022] Found job 501.0 --- inserting
16178:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 500.0
16179:09/12/17 17:15:19 [65022] (500.0) SetJobLeaseTimers()
16180:09/12/17 17:15:19 [65022] Found job 500.0 --- inserting
16181:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 499.0
16182:09/12/17 17:15:19 [65022] (499.0) SetJobLeaseTimers()
16183:09/12/17 17:15:19 [65022] Found job 499.0 --- inserting
16184:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 498.0
16185:09/12/17 17:15:19 [65022] (498.0) SetJobLeaseTimers()
16186:09/12/17 17:15:19 [65022] Found job 498.0 --- inserting
16187:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 497.0
16188:09/12/17 17:15:19 [65022] (497.0) SetJobLeaseTimers()
16189:09/12/17 17:15:19 [65022] Found job 497.0 --- inserting
16190:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 496.0
16191:09/12/17 17:15:19 [65022] (496.0) SetJobLeaseTimers()
16192:09/12/17 17:15:19 [65022] Found job 496.0 --- inserting
16193:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 495.0
16194:09/12/17 17:15:19 [65022] (495.0) SetJobLeaseTimers()
16195:09/12/17 17:15:19 [65022] Found job 495.0 --- inserting
16196:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 494.0
16197:09/12/17 17:15:19 [65022] (494.0) SetJobLeaseTimers()
16198:09/12/17 17:15:19 [65022] Found job 494.0 --- inserting
16199:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 493.0
16200:09/12/17 17:15:19 [65022] (493.0) SetJobLeaseTimers()
16201:09/12/17 17:15:19 [65022] Found job 493.0 --- inserting
16202:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 492.0
16203:09/12/17 17:15:19 [65022] (492.0) SetJobLeaseTimers()
16204:09/12/17 17:15:19 [65022] Found job 492.0 --- inserting
16205:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 491.0
16206:09/12/17 17:15:19 [65022] (491.0) SetJobLeaseTimers()
16207:09/12/17 17:15:19 [65022] Found job 491.0 --- inserting
16208:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 490.0
16209:09/12/17 17:15:19 [65022] (490.0) SetJobLeaseTimers()
16210:09/12/17 17:15:19 [65022] Found job 490.0 --- inserting
16211:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 489.0
16212:09/12/17 17:15:19 [65022] (489.0) SetJobLeaseTimers()
16213:09/12/17 17:15:19 [65022] Found job 489.0 --- inserting
16214:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 488.0
16215:09/12/17 17:15:19 [65022] (488.0) SetJobLeaseTimers()
16216:09/12/17 17:15:19 [65022] Found job 488.0 --- inserting
16217:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 487.0
16218:09/12/17 17:15:19 [65022] (487.0) SetJobLeaseTimers()
16219:09/12/17 17:15:19 [65022] Found job 487.0 --- inserting
16220:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 486.0
16221:09/12/17 17:15:19 [65022] (486.0) SetJobLeaseTimers()
16222:09/12/17 17:15:19 [65022] Found job 486.0 --- inserting
16223:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 485.0
16224:09/12/17 17:15:19 [65022] (485.0) SetJobLeaseTimers()
16225:09/12/17 17:15:19 [65022] Found job 485.0 --- inserting
16226:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 484.0
16227:09/12/17 17:15:19 [65022] (484.0) SetJobLeaseTimers()
16228:09/12/17 17:15:19 [65022] Found job 484.0 --- inserting
16229:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 483.0
16230:09/12/17 17:15:19 [65022] (483.0) SetJobLeaseTimers()
16231:09/12/17 17:15:19 [65022] Found job 483.0 --- inserting
16232:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 482.0
16233:09/12/17 17:15:19 [65022] (482.0) SetJobLeaseTimers()
16234:09/12/17 17:15:19 [65022] Found job 482.0 --- inserting
16235:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 481.0
16236:09/12/17 17:15:19 [65022] (481.0) SetJobLeaseTimers()
16237:09/12/17 17:15:19 [65022] Found job 481.0 --- inserting
16238:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 480.0
16239:09/12/17 17:15:19 [65022] (480.0) SetJobLeaseTimers()
16240:09/12/17 17:15:19 [65022] Found job 480.0 --- inserting
16241:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 516.0
16242:09/12/17 17:15:19 [65022] (516.0) SetJobLeaseTimers()
16243:09/12/17 17:15:19 [65022] Found job 516.0 --- inserting
16244:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 479.0
16245:09/12/17 17:15:19 [65022] (479.0) SetJobLeaseTimers()
16246:09/12/17 17:15:19 [65022] Found job 479.0 --- inserting
16247:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 515.0
16248:09/12/17 17:15:19 [65022] (515.0) SetJobLeaseTimers()
16249:09/12/17 17:15:19 [65022] Found job 515.0 --- inserting
16250:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 478.0
16251:09/12/17 17:15:19 [65022] (478.0) SetJobLeaseTimers()
16252:09/12/17 17:15:19 [65022] Found job 478.0 --- inserting
16253:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 514.0
16254:09/12/17 17:15:19 [65022] (514.0) SetJobLeaseTimers()
16255:09/12/17 17:15:19 [65022] Found job 514.0 --- inserting
16256:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 477.0
16257:09/12/17 17:15:19 [65022] (477.0) SetJobLeaseTimers()
16258:09/12/17 17:15:19 [65022] Found job 477.0 --- inserting
16259:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 513.0
16260:09/12/17 17:15:19 [65022] (513.0) SetJobLeaseTimers()
16261:09/12/17 17:15:19 [65022] Found job 513.0 --- inserting
16262:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 512.0
16263:09/12/17 17:15:19 [65022] (512.0) SetJobLeaseTimers()
16264:09/12/17 17:15:19 [65022] Found job 512.0 --- inserting
16265:09/12/17 17:15:19 [65022] Using job type INFNBatch for job 511.0
16266:09/12/17 17:15:19 [65022] (511.0) SetJobLeaseTimers()
16267:09/12/17 17:15:19 [65022] Found job 511.0 --- inserting
16268:09/12/17 17:15:19 [65022] Fetched 40 new job ads from schedd
16269:09/12/17 17:15:19 [65022] querying for removed/held jobs
16270:09/12/17 17:15:19 [65022] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
16271:09/12/17 17:15:19 [65022] Fetched 0 job ads from schedd
16272:09/12/17 17:15:19 [65022] leaving doContactSchedd()
16273:09/12/17 17:15:19 [65022] gahp server not up yet, delaying ping
16274:09/12/17 17:15:19 [65022] *** UpdateLeases called
16275:09/12/17 17:15:19 [65022]     Leases not supported, cancelling timer
16276:09/12/17 17:15:19 [65022] BaseResource::UpdateResource: 
16296:09/12/17 17:15:19 [65022] Trying to update collector <128.55.162.46:9619>
16297:09/12/17 17:15:19 [65022] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16298:09/12/17 17:15:19 [65022] File descriptor limits: max 4096, safe 3277
16299:09/12/17 17:15:19 [65022] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16300:09/12/17 17:15:19 [65022] GAHP server pid = 65027
16301:09/12/17 17:15:19 [65022] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
16302:09/12/17 17:15:19 [65022] GAHP[65027] <- 'COMMANDS'
16303:09/12/17 17:15:19 [65022] GAHP[65027] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
16304:09/12/17 17:15:19 [65022] GAHP[65027] <- 'ASYNC_MODE_ON'
16305:09/12/17 17:15:19 [65022] GAHP[65027] -> 'S' 'Async mode on'
16306:09/12/17 17:15:19 [65022] (510.0) gm state change: GM_INIT -> GM_START
16307:09/12/17 17:15:19 [65022] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16308:09/12/17 17:15:19 [65022] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16309:09/12/17 17:15:19 [65022] GAHP[65027] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
16310:09/12/17 17:15:19 [65022] GAHP[65027] -> 'S'
16311:09/12/17 17:15:19 [65022] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16312:09/12/17 17:15:19 [65022] (509.0) gm state change: GM_INIT -> GM_START
16313:09/12/17 17:15:19 [65022] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16314:09/12/17 17:15:19 [65022] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16315:09/12/17 17:15:19 [65022] GAHP[65027] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
16316:09/12/17 17:15:19 [65022] GAHP[65027] -> 'S'
16317:09/12/17 17:15:19 [65022] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16318:09/12/17 17:15:19 [65022] (508.0) gm state change: GM_INIT -> GM_START
16319:09/12/17 17:15:19 [65022] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16320:09/12/17 17:15:19 [65022] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16321:09/12/17 17:15:19 [65022] GAHP[65027] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
16322:09/12/17 17:15:19 [65022] GAHP[65027] -> 'S'
16323:09/12/17 17:15:19 [65022] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16324:09/12/17 17:15:19 [65022] (507.0) gm state change: GM_INIT -> GM_START
16325:09/12/17 17:15:19 [65022] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16326:09/12/17 17:15:19 [65022] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16327:09/12/17 17:15:19 [65022] GAHP[65027] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
16328:09/12/17 17:15:19 [65022] GAHP[65027] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
16329:09/12/17 17:15:19 [65022] GAHP[65027] -> EOF
16330:09/12/17 17:15:19 [65022] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
16331:09/12/17 17:20:16 Result of reading /etc/issue:  \S
16333:09/12/17 17:20:16 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
16335:09/12/17 17:20:16 Using IDs: 32 processors, 16 CPUs, 16 HTs
16336:09/12/17 17:20:16 Enumerating interfaces: lo 127.0.0.1 up
16337:09/12/17 17:20:16 Enumerating interfaces: eth0 10.36.162.46 up
16338:09/12/17 17:20:16 Enumerating interfaces: ib0 128.55.162.46 up
16339:09/12/17 17:20:16 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
16340:09/12/17 17:20:16 Initializing Directory: curr_dir = /etc/condor-ce/config.d
16341:09/12/17 17:20:16 ******************************************************
16342:09/12/17 17:20:16 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
16343:09/12/17 17:20:16 ** /usr/sbin/condor_gridmanager
16344:09/12/17 17:20:16 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
16345:09/12/17 17:20:16 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
16346:09/12/17 17:20:16 ** $CondorVersion: 8.4.12 Aug 07 2017 $
16347:09/12/17 17:20:16 ** $CondorPlatform: X86_64-CentOS_7.3 $
16348:09/12/17 17:20:16 ** PID = 65064
16349:09/12/17 17:20:16 ** Log last touched 9/12 17:15:19
16350:09/12/17 17:20:16 ******************************************************
16351:09/12/17 17:20:16 Using config source: /etc/condor-ce/condor_config
16352:09/12/17 17:20:16 Using local config sources: 
16353:09/12/17 17:20:16    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
16354:09/12/17 17:20:16    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
16355:09/12/17 17:20:16    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
16356:09/12/17 17:20:16    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
16357:09/12/17 17:20:16    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
16358:09/12/17 17:20:16    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
16359:09/12/17 17:20:16    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
16360:09/12/17 17:20:16    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
16361:09/12/17 17:20:16    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
16362:09/12/17 17:20:16    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
16363:09/12/17 17:20:16    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
16364:09/12/17 17:20:16    /etc/condor-ce/config.d/01-ce-auth.conf
16365:09/12/17 17:20:16    /etc/condor-ce/config.d/01-ce-router.conf
16366:09/12/17 17:20:16    /etc/condor-ce/config.d/01-common-auth.conf
16367:09/12/17 17:20:16    /etc/condor-ce/config.d/02-ce-slurm.conf
16368:09/12/17 17:20:16    /etc/condor-ce/config.d/03-ce-shared-port.conf
16369:09/12/17 17:20:16    /etc/condor-ce/config.d/03-managed-fork.conf
16370:09/12/17 17:20:16    /etc/condor-ce/config.d/05-ce-health.conf
16371:09/12/17 17:20:16    /etc/condor-ce/config.d/05-ce-view.conf
16372:09/12/17 17:20:16    /etc/condor-ce/config.d/10-ce-collector-generated.conf
16373:09/12/17 17:20:16    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
16374:09/12/17 17:20:16    /etc/condor-ce/config.d/50-osg-configure-present.conf
16375:09/12/17 17:20:16    /etc/condor-ce/config.d/50-osg-configure.conf
16376:09/12/17 17:20:16    /etc/condor-ce/config.d/99-local.conf
16377:09/12/17 17:20:16    /usr/share/condor-ce/condor_ce_router_defaults|
16378:09/12/17 17:20:16 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
16379:09/12/17 17:20:16 CLASSAD_CACHING is ENABLED
16380:09/12/17 17:20:16 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
16381:09/12/17 17:20:16 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_34
16382:09/12/17 17:20:16 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_34>
16383:09/12/17 17:20:16 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_34>
16384:09/12/17 17:20:16 Setting maximum accepts per cycle 8.
16385:09/12/17 17:20:16 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16386:09/12/17 17:20:16 [65064] Welcome to the all-singing, all dancing, "amazing" GridManager!
16387:09/12/17 17:20:16 [65064] DaemonCore: No more children processes to reap.
16388:09/12/17 17:20:16 [65064] DaemonCore: in SendAliveToParent()
16389:09/12/17 17:20:16 [65064] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
16390:09/12/17 17:20:16 [65064] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16391:09/12/17 17:20:16 [65064] IPVERIFY: ip found is 1
16392:09/12/17 17:20:16 [65064] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
16393:09/12/17 17:20:16 [65064] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16394:09/12/17 17:20:16 [65064] IPVERIFY: ip found is 1
16395:09/12/17 17:20:16 [65064] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
16396:09/12/17 17:20:16 [65064] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16397:09/12/17 17:20:16 [65064] IPVERIFY: ip found is 1
16398:09/12/17 17:20:16 [65064] IPVERIFY: checking mc0151-ib against 128.55.162.46
16399:09/12/17 17:20:16 [65064] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16400:09/12/17 17:20:16 [65064] IPVERIFY: ip found is 1
16401:09/12/17 17:20:16 [65064] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
16402:09/12/17 17:20:16 [65064] DaemonCore: Leaving SendAliveToParent() - success
16403:09/12/17 17:20:16 [65064] Checking proxies
16404:09/12/17 17:20:19 [65064] Received ADD_JOBS signal
16405:09/12/17 17:20:19 [65064] in doContactSchedd()
16406:09/12/17 17:20:19 [65064] querying for new jobs
16407:09/12/17 17:20:19 [65064] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
16408:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 510.0
16409:09/12/17 17:20:19 [65064] (510.0) SetJobLeaseTimers()
16410:09/12/17 17:20:19 [65064] Found job 510.0 --- inserting
16411:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 509.0
16412:09/12/17 17:20:19 [65064] (509.0) SetJobLeaseTimers()
16413:09/12/17 17:20:19 [65064] Found job 509.0 --- inserting
16414:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 508.0
16415:09/12/17 17:20:19 [65064] (508.0) SetJobLeaseTimers()
16416:09/12/17 17:20:19 [65064] Found job 508.0 --- inserting
16417:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 507.0
16418:09/12/17 17:20:19 [65064] (507.0) SetJobLeaseTimers()
16419:09/12/17 17:20:19 [65064] Found job 507.0 --- inserting
16420:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 506.0
16421:09/12/17 17:20:19 [65064] (506.0) SetJobLeaseTimers()
16422:09/12/17 17:20:19 [65064] Found job 506.0 --- inserting
16423:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 505.0
16424:09/12/17 17:20:19 [65064] (505.0) SetJobLeaseTimers()
16425:09/12/17 17:20:19 [65064] Found job 505.0 --- inserting
16426:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 504.0
16427:09/12/17 17:20:19 [65064] (504.0) SetJobLeaseTimers()
16428:09/12/17 17:20:19 [65064] Found job 504.0 --- inserting
16429:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 503.0
16430:09/12/17 17:20:19 [65064] (503.0) SetJobLeaseTimers()
16431:09/12/17 17:20:19 [65064] Found job 503.0 --- inserting
16432:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 502.0
16433:09/12/17 17:20:19 [65064] (502.0) SetJobLeaseTimers()
16434:09/12/17 17:20:19 [65064] Found job 502.0 --- inserting
16435:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 501.0
16436:09/12/17 17:20:19 [65064] (501.0) SetJobLeaseTimers()
16437:09/12/17 17:20:19 [65064] Found job 501.0 --- inserting
16438:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 500.0
16439:09/12/17 17:20:19 [65064] (500.0) SetJobLeaseTimers()
16440:09/12/17 17:20:19 [65064] Found job 500.0 --- inserting
16441:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 499.0
16442:09/12/17 17:20:19 [65064] (499.0) SetJobLeaseTimers()
16443:09/12/17 17:20:19 [65064] Found job 499.0 --- inserting
16444:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 498.0
16445:09/12/17 17:20:19 [65064] (498.0) SetJobLeaseTimers()
16446:09/12/17 17:20:19 [65064] Found job 498.0 --- inserting
16447:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 497.0
16448:09/12/17 17:20:19 [65064] (497.0) SetJobLeaseTimers()
16449:09/12/17 17:20:19 [65064] Found job 497.0 --- inserting
16450:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 496.0
16451:09/12/17 17:20:19 [65064] (496.0) SetJobLeaseTimers()
16452:09/12/17 17:20:19 [65064] Found job 496.0 --- inserting
16453:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 495.0
16454:09/12/17 17:20:19 [65064] (495.0) SetJobLeaseTimers()
16455:09/12/17 17:20:19 [65064] Found job 495.0 --- inserting
16456:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 494.0
16457:09/12/17 17:20:19 [65064] (494.0) SetJobLeaseTimers()
16458:09/12/17 17:20:19 [65064] Found job 494.0 --- inserting
16459:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 493.0
16460:09/12/17 17:20:19 [65064] (493.0) SetJobLeaseTimers()
16461:09/12/17 17:20:19 [65064] Found job 493.0 --- inserting
16462:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 492.0
16463:09/12/17 17:20:19 [65064] (492.0) SetJobLeaseTimers()
16464:09/12/17 17:20:19 [65064] Found job 492.0 --- inserting
16465:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 491.0
16466:09/12/17 17:20:19 [65064] (491.0) SetJobLeaseTimers()
16467:09/12/17 17:20:19 [65064] Found job 491.0 --- inserting
16468:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 490.0
16469:09/12/17 17:20:19 [65064] (490.0) SetJobLeaseTimers()
16470:09/12/17 17:20:19 [65064] Found job 490.0 --- inserting
16471:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 489.0
16472:09/12/17 17:20:19 [65064] (489.0) SetJobLeaseTimers()
16473:09/12/17 17:20:19 [65064] Found job 489.0 --- inserting
16474:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 488.0
16475:09/12/17 17:20:19 [65064] (488.0) SetJobLeaseTimers()
16476:09/12/17 17:20:19 [65064] Found job 488.0 --- inserting
16477:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 487.0
16478:09/12/17 17:20:19 [65064] (487.0) SetJobLeaseTimers()
16479:09/12/17 17:20:19 [65064] Found job 487.0 --- inserting
16480:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 486.0
16481:09/12/17 17:20:19 [65064] (486.0) SetJobLeaseTimers()
16482:09/12/17 17:20:19 [65064] Found job 486.0 --- inserting
16483:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 485.0
16484:09/12/17 17:20:19 [65064] (485.0) SetJobLeaseTimers()
16485:09/12/17 17:20:19 [65064] Found job 485.0 --- inserting
16486:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 484.0
16487:09/12/17 17:20:19 [65064] (484.0) SetJobLeaseTimers()
16488:09/12/17 17:20:19 [65064] Found job 484.0 --- inserting
16489:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 483.0
16490:09/12/17 17:20:19 [65064] (483.0) SetJobLeaseTimers()
16491:09/12/17 17:20:19 [65064] Found job 483.0 --- inserting
16492:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 482.0
16493:09/12/17 17:20:19 [65064] (482.0) SetJobLeaseTimers()
16494:09/12/17 17:20:19 [65064] Found job 482.0 --- inserting
16495:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 481.0
16496:09/12/17 17:20:19 [65064] (481.0) SetJobLeaseTimers()
16497:09/12/17 17:20:19 [65064] Found job 481.0 --- inserting
16498:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 480.0
16499:09/12/17 17:20:19 [65064] (480.0) SetJobLeaseTimers()
16500:09/12/17 17:20:19 [65064] Found job 480.0 --- inserting
16501:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 516.0
16502:09/12/17 17:20:19 [65064] (516.0) SetJobLeaseTimers()
16503:09/12/17 17:20:19 [65064] Found job 516.0 --- inserting
16504:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 479.0
16505:09/12/17 17:20:19 [65064] (479.0) SetJobLeaseTimers()
16506:09/12/17 17:20:19 [65064] Found job 479.0 --- inserting
16507:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 515.0
16508:09/12/17 17:20:19 [65064] (515.0) SetJobLeaseTimers()
16509:09/12/17 17:20:19 [65064] Found job 515.0 --- inserting
16510:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 478.0
16511:09/12/17 17:20:19 [65064] (478.0) SetJobLeaseTimers()
16512:09/12/17 17:20:19 [65064] Found job 478.0 --- inserting
16513:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 514.0
16514:09/12/17 17:20:19 [65064] (514.0) SetJobLeaseTimers()
16515:09/12/17 17:20:19 [65064] Found job 514.0 --- inserting
16516:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 477.0
16517:09/12/17 17:20:19 [65064] (477.0) SetJobLeaseTimers()
16518:09/12/17 17:20:19 [65064] Found job 477.0 --- inserting
16519:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 513.0
16520:09/12/17 17:20:19 [65064] (513.0) SetJobLeaseTimers()
16521:09/12/17 17:20:19 [65064] Found job 513.0 --- inserting
16522:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 512.0
16523:09/12/17 17:20:19 [65064] (512.0) SetJobLeaseTimers()
16524:09/12/17 17:20:19 [65064] Found job 512.0 --- inserting
16525:09/12/17 17:20:19 [65064] Using job type INFNBatch for job 511.0
16526:09/12/17 17:20:19 [65064] (511.0) SetJobLeaseTimers()
16527:09/12/17 17:20:19 [65064] Found job 511.0 --- inserting
16528:09/12/17 17:20:19 [65064] Fetched 40 new job ads from schedd
16529:09/12/17 17:20:19 [65064] querying for removed/held jobs
16530:09/12/17 17:20:19 [65064] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
16531:09/12/17 17:20:19 [65064] Fetched 0 job ads from schedd
16532:09/12/17 17:20:19 [65064] leaving doContactSchedd()
16533:09/12/17 17:20:19 [65064] gahp server not up yet, delaying ping
16534:09/12/17 17:20:19 [65064] *** UpdateLeases called
16535:09/12/17 17:20:19 [65064]     Leases not supported, cancelling timer
16536:09/12/17 17:20:19 [65064] BaseResource::UpdateResource: 
16556:09/12/17 17:20:19 [65064] Trying to update collector <128.55.162.46:9619>
16557:09/12/17 17:20:19 [65064] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16558:09/12/17 17:20:19 [65064] File descriptor limits: max 4096, safe 3277
16559:09/12/17 17:20:19 [65064] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16560:09/12/17 17:20:19 [65064] GAHP server pid = 65067
16561:09/12/17 17:20:19 [65064] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
16562:09/12/17 17:20:19 [65064] GAHP[65067] <- 'COMMANDS'
16563:09/12/17 17:20:19 [65064] GAHP[65067] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
16564:09/12/17 17:20:19 [65064] GAHP[65067] <- 'ASYNC_MODE_ON'
16565:09/12/17 17:20:19 [65064] GAHP[65067] -> 'S' 'Async mode on'
16566:09/12/17 17:20:19 [65064] (510.0) gm state change: GM_INIT -> GM_START
16567:09/12/17 17:20:19 [65064] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16568:09/12/17 17:20:19 [65064] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16569:09/12/17 17:20:19 [65064] GAHP[65067] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
16570:09/12/17 17:20:19 [65064] GAHP[65067] -> 'S'
16571:09/12/17 17:20:19 [65064] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16572:09/12/17 17:20:19 [65064] (509.0) gm state change: GM_INIT -> GM_START
16573:09/12/17 17:20:19 [65064] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16574:09/12/17 17:20:19 [65064] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16575:09/12/17 17:20:19 [65064] GAHP[65067] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
16576:09/12/17 17:20:19 [65064] GAHP[65067] -> 'S'
16577:09/12/17 17:20:19 [65064] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16578:09/12/17 17:20:19 [65064] (508.0) gm state change: GM_INIT -> GM_START
16579:09/12/17 17:20:19 [65064] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16580:09/12/17 17:20:19 [65064] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16581:09/12/17 17:20:19 [65064] GAHP[65067] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
16582:09/12/17 17:20:19 [65064] GAHP[65067] -> 'S'
16583:09/12/17 17:20:19 [65064] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16584:09/12/17 17:20:19 [65064] (507.0) gm state change: GM_INIT -> GM_START
16585:09/12/17 17:20:19 [65064] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16586:09/12/17 17:20:19 [65064] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16587:09/12/17 17:20:19 [65064] GAHP[65067] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
16588:09/12/17 17:20:19 [65064] GAHP[65067] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
16589:09/12/17 17:20:19 [65064] GAHP[65067] -> EOF
16590:09/12/17 17:20:19 [65064] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
16591:09/12/17 17:25:17 Result of reading /etc/issue:  \S
16593:09/12/17 17:25:17 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
16595:09/12/17 17:25:17 Using IDs: 32 processors, 16 CPUs, 16 HTs
16596:09/12/17 17:25:17 Enumerating interfaces: lo 127.0.0.1 up
16597:09/12/17 17:25:17 Enumerating interfaces: eth0 10.36.162.46 up
16598:09/12/17 17:25:17 Enumerating interfaces: ib0 128.55.162.46 up
16599:09/12/17 17:25:17 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
16600:09/12/17 17:25:17 Initializing Directory: curr_dir = /etc/condor-ce/config.d
16601:09/12/17 17:25:17 ******************************************************
16602:09/12/17 17:25:17 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
16603:09/12/17 17:25:17 ** /usr/sbin/condor_gridmanager
16604:09/12/17 17:25:17 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
16605:09/12/17 17:25:17 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
16606:09/12/17 17:25:17 ** $CondorVersion: 8.4.12 Aug 07 2017 $
16607:09/12/17 17:25:17 ** $CondorPlatform: X86_64-CentOS_7.3 $
16608:09/12/17 17:25:17 ** PID = 65116
16609:09/12/17 17:25:17 ** Log last touched 9/12 17:20:19
16610:09/12/17 17:25:17 ******************************************************
16611:09/12/17 17:25:17 Using config source: /etc/condor-ce/condor_config
16612:09/12/17 17:25:17 Using local config sources: 
16613:09/12/17 17:25:17    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
16614:09/12/17 17:25:17    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
16615:09/12/17 17:25:17    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
16616:09/12/17 17:25:17    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
16617:09/12/17 17:25:17    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
16618:09/12/17 17:25:17    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
16619:09/12/17 17:25:17    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
16620:09/12/17 17:25:17    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
16621:09/12/17 17:25:17    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
16622:09/12/17 17:25:17    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
16623:09/12/17 17:25:17    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
16624:09/12/17 17:25:17    /etc/condor-ce/config.d/01-ce-auth.conf
16625:09/12/17 17:25:17    /etc/condor-ce/config.d/01-ce-router.conf
16626:09/12/17 17:25:17    /etc/condor-ce/config.d/01-common-auth.conf
16627:09/12/17 17:25:17    /etc/condor-ce/config.d/02-ce-slurm.conf
16628:09/12/17 17:25:17    /etc/condor-ce/config.d/03-ce-shared-port.conf
16629:09/12/17 17:25:17    /etc/condor-ce/config.d/03-managed-fork.conf
16630:09/12/17 17:25:17    /etc/condor-ce/config.d/05-ce-health.conf
16631:09/12/17 17:25:17    /etc/condor-ce/config.d/05-ce-view.conf
16632:09/12/17 17:25:17    /etc/condor-ce/config.d/10-ce-collector-generated.conf
16633:09/12/17 17:25:17    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
16634:09/12/17 17:25:17    /etc/condor-ce/config.d/50-osg-configure-present.conf
16635:09/12/17 17:25:17    /etc/condor-ce/config.d/50-osg-configure.conf
16636:09/12/17 17:25:17    /etc/condor-ce/config.d/99-local.conf
16637:09/12/17 17:25:17    /usr/share/condor-ce/condor_ce_router_defaults|
16638:09/12/17 17:25:17 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
16639:09/12/17 17:25:17 CLASSAD_CACHING is ENABLED
16640:09/12/17 17:25:17 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
16641:09/12/17 17:25:17 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_37
16642:09/12/17 17:25:17 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_37>
16643:09/12/17 17:25:17 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_37>
16644:09/12/17 17:25:17 Setting maximum accepts per cycle 8.
16645:09/12/17 17:25:17 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16646:09/12/17 17:25:17 [65116] Welcome to the all-singing, all dancing, "amazing" GridManager!
16647:09/12/17 17:25:17 [65116] DaemonCore: No more children processes to reap.
16648:09/12/17 17:25:17 [65116] DaemonCore: in SendAliveToParent()
16649:09/12/17 17:25:17 [65116] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
16650:09/12/17 17:25:17 [65116] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16651:09/12/17 17:25:17 [65116] IPVERIFY: ip found is 1
16652:09/12/17 17:25:17 [65116] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
16653:09/12/17 17:25:17 [65116] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16654:09/12/17 17:25:17 [65116] IPVERIFY: ip found is 1
16655:09/12/17 17:25:17 [65116] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
16656:09/12/17 17:25:17 [65116] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16657:09/12/17 17:25:17 [65116] IPVERIFY: ip found is 1
16658:09/12/17 17:25:17 [65116] IPVERIFY: checking mc0151-ib against 128.55.162.46
16659:09/12/17 17:25:17 [65116] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16660:09/12/17 17:25:17 [65116] IPVERIFY: ip found is 1
16661:09/12/17 17:25:17 [65116] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
16662:09/12/17 17:25:17 [65116] DaemonCore: Leaving SendAliveToParent() - success
16663:09/12/17 17:25:17 [65116] Checking proxies
16664:09/12/17 17:25:20 [65116] Received ADD_JOBS signal
16665:09/12/17 17:25:20 [65116] in doContactSchedd()
16666:09/12/17 17:25:20 [65116] querying for new jobs
16667:09/12/17 17:25:20 [65116] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
16668:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 510.0
16669:09/12/17 17:25:20 [65116] (510.0) SetJobLeaseTimers()
16670:09/12/17 17:25:20 [65116] Found job 510.0 --- inserting
16671:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 509.0
16672:09/12/17 17:25:20 [65116] (509.0) SetJobLeaseTimers()
16673:09/12/17 17:25:20 [65116] Found job 509.0 --- inserting
16674:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 508.0
16675:09/12/17 17:25:20 [65116] (508.0) SetJobLeaseTimers()
16676:09/12/17 17:25:20 [65116] Found job 508.0 --- inserting
16677:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 507.0
16678:09/12/17 17:25:20 [65116] (507.0) SetJobLeaseTimers()
16679:09/12/17 17:25:20 [65116] Found job 507.0 --- inserting
16680:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 506.0
16681:09/12/17 17:25:20 [65116] (506.0) SetJobLeaseTimers()
16682:09/12/17 17:25:20 [65116] Found job 506.0 --- inserting
16683:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 505.0
16684:09/12/17 17:25:20 [65116] (505.0) SetJobLeaseTimers()
16685:09/12/17 17:25:20 [65116] Found job 505.0 --- inserting
16686:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 504.0
16687:09/12/17 17:25:20 [65116] (504.0) SetJobLeaseTimers()
16688:09/12/17 17:25:20 [65116] Found job 504.0 --- inserting
16689:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 503.0
16690:09/12/17 17:25:20 [65116] (503.0) SetJobLeaseTimers()
16691:09/12/17 17:25:20 [65116] Found job 503.0 --- inserting
16692:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 502.0
16693:09/12/17 17:25:20 [65116] (502.0) SetJobLeaseTimers()
16694:09/12/17 17:25:20 [65116] Found job 502.0 --- inserting
16695:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 501.0
16696:09/12/17 17:25:20 [65116] (501.0) SetJobLeaseTimers()
16697:09/12/17 17:25:20 [65116] Found job 501.0 --- inserting
16698:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 500.0
16699:09/12/17 17:25:20 [65116] (500.0) SetJobLeaseTimers()
16700:09/12/17 17:25:20 [65116] Found job 500.0 --- inserting
16701:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 499.0
16702:09/12/17 17:25:20 [65116] (499.0) SetJobLeaseTimers()
16703:09/12/17 17:25:20 [65116] Found job 499.0 --- inserting
16704:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 498.0
16705:09/12/17 17:25:20 [65116] (498.0) SetJobLeaseTimers()
16706:09/12/17 17:25:20 [65116] Found job 498.0 --- inserting
16707:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 497.0
16708:09/12/17 17:25:20 [65116] (497.0) SetJobLeaseTimers()
16709:09/12/17 17:25:20 [65116] Found job 497.0 --- inserting
16710:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 496.0
16711:09/12/17 17:25:20 [65116] (496.0) SetJobLeaseTimers()
16712:09/12/17 17:25:20 [65116] Found job 496.0 --- inserting
16713:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 495.0
16714:09/12/17 17:25:20 [65116] (495.0) SetJobLeaseTimers()
16715:09/12/17 17:25:20 [65116] Found job 495.0 --- inserting
16716:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 494.0
16717:09/12/17 17:25:20 [65116] (494.0) SetJobLeaseTimers()
16718:09/12/17 17:25:20 [65116] Found job 494.0 --- inserting
16719:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 493.0
16720:09/12/17 17:25:20 [65116] (493.0) SetJobLeaseTimers()
16721:09/12/17 17:25:20 [65116] Found job 493.0 --- inserting
16722:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 492.0
16723:09/12/17 17:25:20 [65116] (492.0) SetJobLeaseTimers()
16724:09/12/17 17:25:20 [65116] Found job 492.0 --- inserting
16725:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 491.0
16726:09/12/17 17:25:20 [65116] (491.0) SetJobLeaseTimers()
16727:09/12/17 17:25:20 [65116] Found job 491.0 --- inserting
16728:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 490.0
16729:09/12/17 17:25:20 [65116] (490.0) SetJobLeaseTimers()
16730:09/12/17 17:25:20 [65116] Found job 490.0 --- inserting
16731:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 489.0
16732:09/12/17 17:25:20 [65116] (489.0) SetJobLeaseTimers()
16733:09/12/17 17:25:20 [65116] Found job 489.0 --- inserting
16734:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 488.0
16735:09/12/17 17:25:20 [65116] (488.0) SetJobLeaseTimers()
16736:09/12/17 17:25:20 [65116] Found job 488.0 --- inserting
16737:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 487.0
16738:09/12/17 17:25:20 [65116] (487.0) SetJobLeaseTimers()
16739:09/12/17 17:25:20 [65116] Found job 487.0 --- inserting
16740:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 486.0
16741:09/12/17 17:25:20 [65116] (486.0) SetJobLeaseTimers()
16742:09/12/17 17:25:20 [65116] Found job 486.0 --- inserting
16743:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 485.0
16744:09/12/17 17:25:20 [65116] (485.0) SetJobLeaseTimers()
16745:09/12/17 17:25:20 [65116] Found job 485.0 --- inserting
16746:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 484.0
16747:09/12/17 17:25:20 [65116] (484.0) SetJobLeaseTimers()
16748:09/12/17 17:25:20 [65116] Found job 484.0 --- inserting
16749:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 483.0
16750:09/12/17 17:25:20 [65116] (483.0) SetJobLeaseTimers()
16751:09/12/17 17:25:20 [65116] Found job 483.0 --- inserting
16752:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 482.0
16753:09/12/17 17:25:20 [65116] (482.0) SetJobLeaseTimers()
16754:09/12/17 17:25:20 [65116] Found job 482.0 --- inserting
16755:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 481.0
16756:09/12/17 17:25:20 [65116] (481.0) SetJobLeaseTimers()
16757:09/12/17 17:25:20 [65116] Found job 481.0 --- inserting
16758:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 480.0
16759:09/12/17 17:25:20 [65116] (480.0) SetJobLeaseTimers()
16760:09/12/17 17:25:20 [65116] Found job 480.0 --- inserting
16761:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 516.0
16762:09/12/17 17:25:20 [65116] (516.0) SetJobLeaseTimers()
16763:09/12/17 17:25:20 [65116] Found job 516.0 --- inserting
16764:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 479.0
16765:09/12/17 17:25:20 [65116] (479.0) SetJobLeaseTimers()
16766:09/12/17 17:25:20 [65116] Found job 479.0 --- inserting
16767:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 515.0
16768:09/12/17 17:25:20 [65116] (515.0) SetJobLeaseTimers()
16769:09/12/17 17:25:20 [65116] Found job 515.0 --- inserting
16770:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 478.0
16771:09/12/17 17:25:20 [65116] (478.0) SetJobLeaseTimers()
16772:09/12/17 17:25:20 [65116] Found job 478.0 --- inserting
16773:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 514.0
16774:09/12/17 17:25:20 [65116] (514.0) SetJobLeaseTimers()
16775:09/12/17 17:25:20 [65116] Found job 514.0 --- inserting
16776:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 477.0
16777:09/12/17 17:25:20 [65116] (477.0) SetJobLeaseTimers()
16778:09/12/17 17:25:20 [65116] Found job 477.0 --- inserting
16779:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 513.0
16780:09/12/17 17:25:20 [65116] (513.0) SetJobLeaseTimers()
16781:09/12/17 17:25:20 [65116] Found job 513.0 --- inserting
16782:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 512.0
16783:09/12/17 17:25:20 [65116] (512.0) SetJobLeaseTimers()
16784:09/12/17 17:25:20 [65116] Found job 512.0 --- inserting
16785:09/12/17 17:25:20 [65116] Using job type INFNBatch for job 511.0
16786:09/12/17 17:25:20 [65116] (511.0) SetJobLeaseTimers()
16787:09/12/17 17:25:20 [65116] Found job 511.0 --- inserting
16788:09/12/17 17:25:20 [65116] Fetched 40 new job ads from schedd
16789:09/12/17 17:25:20 [65116] querying for removed/held jobs
16790:09/12/17 17:25:20 [65116] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
16791:09/12/17 17:25:20 [65116] Fetched 0 job ads from schedd
16792:09/12/17 17:25:20 [65116] leaving doContactSchedd()
16793:09/12/17 17:25:20 [65116] gahp server not up yet, delaying ping
16794:09/12/17 17:25:20 [65116] *** UpdateLeases called
16795:09/12/17 17:25:20 [65116]     Leases not supported, cancelling timer
16796:09/12/17 17:25:20 [65116] BaseResource::UpdateResource: 
16816:09/12/17 17:25:20 [65116] Trying to update collector <128.55.162.46:9619>
16817:09/12/17 17:25:20 [65116] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16818:09/12/17 17:25:20 [65116] File descriptor limits: max 4096, safe 3277
16819:09/12/17 17:25:20 [65116] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16820:09/12/17 17:25:20 [65116] GAHP server pid = 65119
16821:09/12/17 17:25:20 [65116] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
16822:09/12/17 17:25:20 [65116] GAHP[65119] <- 'COMMANDS'
16823:09/12/17 17:25:20 [65116] GAHP[65119] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
16824:09/12/17 17:25:20 [65116] GAHP[65119] <- 'ASYNC_MODE_ON'
16825:09/12/17 17:25:20 [65116] GAHP[65119] -> 'S' 'Async mode on'
16826:09/12/17 17:25:20 [65116] (510.0) gm state change: GM_INIT -> GM_START
16827:09/12/17 17:25:20 [65116] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16828:09/12/17 17:25:20 [65116] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16829:09/12/17 17:25:20 [65116] GAHP[65119] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
16830:09/12/17 17:25:20 [65116] GAHP[65119] -> 'S'
16831:09/12/17 17:25:20 [65116] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16832:09/12/17 17:25:20 [65116] (509.0) gm state change: GM_INIT -> GM_START
16833:09/12/17 17:25:20 [65116] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16834:09/12/17 17:25:20 [65116] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16835:09/12/17 17:25:20 [65116] GAHP[65119] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
16836:09/12/17 17:25:20 [65116] GAHP[65119] -> 'S'
16837:09/12/17 17:25:20 [65116] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
16838:09/12/17 17:25:20 [65116] (508.0) gm state change: GM_INIT -> GM_START
16839:09/12/17 17:25:20 [65116] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
16840:09/12/17 17:25:20 [65116] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
16841:09/12/17 17:25:20 [65116] GAHP[65119] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
16842:09/12/17 17:25:20 [65116] GAHP[65119] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
16843:09/12/17 17:25:20 [65116] GAHP[65119] -> EOF
16844:09/12/17 17:25:20 [65116] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
16845:09/12/17 17:30:17 Result of reading /etc/issue:  \S
16847:09/12/17 17:30:17 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
16849:09/12/17 17:30:17 Using IDs: 32 processors, 16 CPUs, 16 HTs
16850:09/12/17 17:30:17 Enumerating interfaces: lo 127.0.0.1 up
16851:09/12/17 17:30:17 Enumerating interfaces: eth0 10.36.162.46 up
16852:09/12/17 17:30:17 Enumerating interfaces: ib0 128.55.162.46 up
16853:09/12/17 17:30:17 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
16854:09/12/17 17:30:17 Initializing Directory: curr_dir = /etc/condor-ce/config.d
16855:09/12/17 17:30:17 ******************************************************
16856:09/12/17 17:30:17 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
16857:09/12/17 17:30:17 ** /usr/sbin/condor_gridmanager
16858:09/12/17 17:30:17 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
16859:09/12/17 17:30:17 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
16860:09/12/17 17:30:17 ** $CondorVersion: 8.4.12 Aug 07 2017 $
16861:09/12/17 17:30:17 ** $CondorPlatform: X86_64-CentOS_7.3 $
16862:09/12/17 17:30:17 ** PID = 65163
16863:09/12/17 17:30:17 ** Log last touched 9/12 17:25:20
16864:09/12/17 17:30:17 ******************************************************
16865:09/12/17 17:30:17 Using config source: /etc/condor-ce/condor_config
16866:09/12/17 17:30:17 Using local config sources: 
16867:09/12/17 17:30:17    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
16868:09/12/17 17:30:17    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
16869:09/12/17 17:30:17    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
16870:09/12/17 17:30:17    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
16871:09/12/17 17:30:17    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
16872:09/12/17 17:30:17    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
16873:09/12/17 17:30:17    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
16874:09/12/17 17:30:17    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
16875:09/12/17 17:30:17    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
16876:09/12/17 17:30:17    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
16877:09/12/17 17:30:17    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
16878:09/12/17 17:30:17    /etc/condor-ce/config.d/01-ce-auth.conf
16879:09/12/17 17:30:17    /etc/condor-ce/config.d/01-ce-router.conf
16880:09/12/17 17:30:17    /etc/condor-ce/config.d/01-common-auth.conf
16881:09/12/17 17:30:17    /etc/condor-ce/config.d/02-ce-slurm.conf
16882:09/12/17 17:30:17    /etc/condor-ce/config.d/03-ce-shared-port.conf
16883:09/12/17 17:30:17    /etc/condor-ce/config.d/03-managed-fork.conf
16884:09/12/17 17:30:17    /etc/condor-ce/config.d/05-ce-health.conf
16885:09/12/17 17:30:17    /etc/condor-ce/config.d/05-ce-view.conf
16886:09/12/17 17:30:17    /etc/condor-ce/config.d/10-ce-collector-generated.conf
16887:09/12/17 17:30:17    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
16888:09/12/17 17:30:17    /etc/condor-ce/config.d/50-osg-configure-present.conf
16889:09/12/17 17:30:17    /etc/condor-ce/config.d/50-osg-configure.conf
16890:09/12/17 17:30:17    /etc/condor-ce/config.d/99-local.conf
16891:09/12/17 17:30:17    /usr/share/condor-ce/condor_ce_router_defaults|
16892:09/12/17 17:30:17 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
16893:09/12/17 17:30:17 CLASSAD_CACHING is ENABLED
16894:09/12/17 17:30:17 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
16895:09/12/17 17:30:17 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_40
16896:09/12/17 17:30:17 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_40>
16897:09/12/17 17:30:17 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_40>
16898:09/12/17 17:30:17 Setting maximum accepts per cycle 8.
16899:09/12/17 17:30:17 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
16900:09/12/17 17:30:17 [65163] Welcome to the all-singing, all dancing, "amazing" GridManager!
16901:09/12/17 17:30:17 [65163] DaemonCore: No more children processes to reap.
16902:09/12/17 17:30:17 [65163] DaemonCore: in SendAliveToParent()
16903:09/12/17 17:30:17 [65163] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
16904:09/12/17 17:30:17 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16905:09/12/17 17:30:17 [65163] IPVERIFY: ip found is 1
16906:09/12/17 17:30:17 [65163] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
16907:09/12/17 17:30:17 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16908:09/12/17 17:30:17 [65163] IPVERIFY: ip found is 1
16909:09/12/17 17:30:17 [65163] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
16910:09/12/17 17:30:17 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16911:09/12/17 17:30:17 [65163] IPVERIFY: ip found is 1
16912:09/12/17 17:30:17 [65163] IPVERIFY: checking mc0151-ib against 128.55.162.46
16913:09/12/17 17:30:17 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
16914:09/12/17 17:30:17 [65163] IPVERIFY: ip found is 1
16915:09/12/17 17:30:17 [65163] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
16916:09/12/17 17:30:17 [65163] DaemonCore: Leaving SendAliveToParent() - success
16917:09/12/17 17:30:17 [65163] Checking proxies
16918:09/12/17 17:30:20 [65163] Received ADD_JOBS signal
16919:09/12/17 17:30:20 [65163] in doContactSchedd()
16920:09/12/17 17:30:20 [65163] querying for new jobs
16921:09/12/17 17:30:20 [65163] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
16922:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 510.0
16923:09/12/17 17:30:20 [65163] (510.0) SetJobLeaseTimers()
16924:09/12/17 17:30:20 [65163] Found job 510.0 --- inserting
16925:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 509.0
16926:09/12/17 17:30:20 [65163] (509.0) SetJobLeaseTimers()
16927:09/12/17 17:30:20 [65163] Found job 509.0 --- inserting
16928:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 508.0
16929:09/12/17 17:30:20 [65163] (508.0) SetJobLeaseTimers()
16930:09/12/17 17:30:20 [65163] Found job 508.0 --- inserting
16931:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 507.0
16932:09/12/17 17:30:20 [65163] (507.0) SetJobLeaseTimers()
16933:09/12/17 17:30:20 [65163] Found job 507.0 --- inserting
16934:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 506.0
16935:09/12/17 17:30:20 [65163] (506.0) SetJobLeaseTimers()
16936:09/12/17 17:30:20 [65163] Found job 506.0 --- inserting
16937:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 505.0
16938:09/12/17 17:30:20 [65163] (505.0) SetJobLeaseTimers()
16939:09/12/17 17:30:20 [65163] Found job 505.0 --- inserting
16940:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 504.0
16941:09/12/17 17:30:20 [65163] (504.0) SetJobLeaseTimers()
16942:09/12/17 17:30:20 [65163] Found job 504.0 --- inserting
16943:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 503.0
16944:09/12/17 17:30:20 [65163] (503.0) SetJobLeaseTimers()
16945:09/12/17 17:30:20 [65163] Found job 503.0 --- inserting
16946:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 502.0
16947:09/12/17 17:30:20 [65163] (502.0) SetJobLeaseTimers()
16948:09/12/17 17:30:20 [65163] Found job 502.0 --- inserting
16949:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 501.0
16950:09/12/17 17:30:20 [65163] (501.0) SetJobLeaseTimers()
16951:09/12/17 17:30:20 [65163] Found job 501.0 --- inserting
16952:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 500.0
16953:09/12/17 17:30:20 [65163] (500.0) SetJobLeaseTimers()
16954:09/12/17 17:30:20 [65163] Found job 500.0 --- inserting
16955:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 499.0
16956:09/12/17 17:30:20 [65163] (499.0) SetJobLeaseTimers()
16957:09/12/17 17:30:20 [65163] Found job 499.0 --- inserting
16958:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 498.0
16959:09/12/17 17:30:20 [65163] (498.0) SetJobLeaseTimers()
16960:09/12/17 17:30:20 [65163] Found job 498.0 --- inserting
16961:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 497.0
16962:09/12/17 17:30:20 [65163] (497.0) SetJobLeaseTimers()
16963:09/12/17 17:30:20 [65163] Found job 497.0 --- inserting
16964:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 496.0
16965:09/12/17 17:30:20 [65163] (496.0) SetJobLeaseTimers()
16966:09/12/17 17:30:20 [65163] Found job 496.0 --- inserting
16967:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 495.0
16968:09/12/17 17:30:20 [65163] (495.0) SetJobLeaseTimers()
16969:09/12/17 17:30:20 [65163] Found job 495.0 --- inserting
16970:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 494.0
16971:09/12/17 17:30:20 [65163] (494.0) SetJobLeaseTimers()
16972:09/12/17 17:30:20 [65163] Found job 494.0 --- inserting
16973:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 493.0
16974:09/12/17 17:30:20 [65163] (493.0) SetJobLeaseTimers()
16975:09/12/17 17:30:20 [65163] Found job 493.0 --- inserting
16976:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 492.0
16977:09/12/17 17:30:20 [65163] (492.0) SetJobLeaseTimers()
16978:09/12/17 17:30:20 [65163] Found job 492.0 --- inserting
16979:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 491.0
16980:09/12/17 17:30:20 [65163] (491.0) SetJobLeaseTimers()
16981:09/12/17 17:30:20 [65163] Found job 491.0 --- inserting
16982:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 490.0
16983:09/12/17 17:30:20 [65163] (490.0) SetJobLeaseTimers()
16984:09/12/17 17:30:20 [65163] Found job 490.0 --- inserting
16985:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 489.0
16986:09/12/17 17:30:20 [65163] (489.0) SetJobLeaseTimers()
16987:09/12/17 17:30:20 [65163] Found job 489.0 --- inserting
16988:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 488.0
16989:09/12/17 17:30:20 [65163] (488.0) SetJobLeaseTimers()
16990:09/12/17 17:30:20 [65163] Found job 488.0 --- inserting
16991:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 487.0
16992:09/12/17 17:30:20 [65163] (487.0) SetJobLeaseTimers()
16993:09/12/17 17:30:20 [65163] Found job 487.0 --- inserting
16994:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 486.0
16995:09/12/17 17:30:20 [65163] (486.0) SetJobLeaseTimers()
16996:09/12/17 17:30:20 [65163] Found job 486.0 --- inserting
16997:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 485.0
16998:09/12/17 17:30:20 [65163] (485.0) SetJobLeaseTimers()
16999:09/12/17 17:30:20 [65163] Found job 485.0 --- inserting
17000:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 484.0
17001:09/12/17 17:30:20 [65163] (484.0) SetJobLeaseTimers()
17002:09/12/17 17:30:20 [65163] Found job 484.0 --- inserting
17003:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 483.0
17004:09/12/17 17:30:20 [65163] (483.0) SetJobLeaseTimers()
17005:09/12/17 17:30:20 [65163] Found job 483.0 --- inserting
17006:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 482.0
17007:09/12/17 17:30:20 [65163] (482.0) SetJobLeaseTimers()
17008:09/12/17 17:30:20 [65163] Found job 482.0 --- inserting
17009:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 481.0
17010:09/12/17 17:30:20 [65163] (481.0) SetJobLeaseTimers()
17011:09/12/17 17:30:20 [65163] Found job 481.0 --- inserting
17012:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 480.0
17013:09/12/17 17:30:20 [65163] (480.0) SetJobLeaseTimers()
17014:09/12/17 17:30:20 [65163] Found job 480.0 --- inserting
17015:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 516.0
17016:09/12/17 17:30:20 [65163] (516.0) SetJobLeaseTimers()
17017:09/12/17 17:30:20 [65163] Found job 516.0 --- inserting
17018:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 479.0
17019:09/12/17 17:30:20 [65163] (479.0) SetJobLeaseTimers()
17020:09/12/17 17:30:20 [65163] Found job 479.0 --- inserting
17021:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 515.0
17022:09/12/17 17:30:20 [65163] (515.0) SetJobLeaseTimers()
17023:09/12/17 17:30:20 [65163] Found job 515.0 --- inserting
17024:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 478.0
17025:09/12/17 17:30:20 [65163] (478.0) SetJobLeaseTimers()
17026:09/12/17 17:30:20 [65163] Found job 478.0 --- inserting
17027:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 514.0
17028:09/12/17 17:30:20 [65163] (514.0) SetJobLeaseTimers()
17029:09/12/17 17:30:20 [65163] Found job 514.0 --- inserting
17030:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 477.0
17031:09/12/17 17:30:20 [65163] (477.0) SetJobLeaseTimers()
17032:09/12/17 17:30:20 [65163] Found job 477.0 --- inserting
17033:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 513.0
17034:09/12/17 17:30:20 [65163] (513.0) SetJobLeaseTimers()
17035:09/12/17 17:30:20 [65163] Found job 513.0 --- inserting
17036:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 512.0
17037:09/12/17 17:30:20 [65163] (512.0) SetJobLeaseTimers()
17038:09/12/17 17:30:20 [65163] Found job 512.0 --- inserting
17039:09/12/17 17:30:20 [65163] Using job type INFNBatch for job 511.0
17040:09/12/17 17:30:20 [65163] (511.0) SetJobLeaseTimers()
17041:09/12/17 17:30:20 [65163] Found job 511.0 --- inserting
17042:09/12/17 17:30:20 [65163] Fetched 40 new job ads from schedd
17043:09/12/17 17:30:20 [65163] querying for removed/held jobs
17044:09/12/17 17:30:20 [65163] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
17045:09/12/17 17:30:20 [65163] Fetched 0 job ads from schedd
17046:09/12/17 17:30:20 [65163] leaving doContactSchedd()
17047:09/12/17 17:30:20 [65163] gahp server not up yet, delaying ping
17048:09/12/17 17:30:20 [65163] *** UpdateLeases called
17049:09/12/17 17:30:20 [65163]     Leases not supported, cancelling timer
17050:09/12/17 17:30:20 [65163] BaseResource::UpdateResource: 
17070:09/12/17 17:30:20 [65163] Trying to update collector <128.55.162.46:9619>
17071:09/12/17 17:30:20 [65163] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17072:09/12/17 17:30:20 [65163] File descriptor limits: max 4096, safe 3277
17073:09/12/17 17:30:20 [65163] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17074:09/12/17 17:30:20 [65163] GAHP server pid = 65166
17075:09/12/17 17:30:20 [65163] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
17076:09/12/17 17:30:20 [65163] GAHP[65166] <- 'COMMANDS'
17077:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
17078:09/12/17 17:30:20 [65163] GAHP[65166] <- 'ASYNC_MODE_ON'
17079:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S' 'Async mode on'
17080:09/12/17 17:30:20 [65163] (510.0) gm state change: GM_INIT -> GM_START
17081:09/12/17 17:30:20 [65163] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17082:09/12/17 17:30:20 [65163] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17083:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
17084:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S'
17085:09/12/17 17:30:20 [65163] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17086:09/12/17 17:30:20 [65163] (509.0) gm state change: GM_INIT -> GM_START
17087:09/12/17 17:30:20 [65163] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17088:09/12/17 17:30:20 [65163] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17089:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
17090:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S'
17091:09/12/17 17:30:20 [65163] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17092:09/12/17 17:30:20 [65163] (508.0) gm state change: GM_INIT -> GM_START
17093:09/12/17 17:30:20 [65163] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17094:09/12/17 17:30:20 [65163] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17095:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
17096:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S'
17097:09/12/17 17:30:20 [65163] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17098:09/12/17 17:30:20 [65163] (507.0) gm state change: GM_INIT -> GM_START
17099:09/12/17 17:30:20 [65163] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17100:09/12/17 17:30:20 [65163] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17101:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
17102:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S'
17103:09/12/17 17:30:20 [65163] (506.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17104:09/12/17 17:30:20 [65163] (506.0) gm state change: GM_INIT -> GM_START
17105:09/12/17 17:30:20 [65163] (506.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17106:09/12/17 17:30:20 [65163] (506.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17107:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/test.sh"\ ]'
17108:09/12/17 17:30:20 [65163] GAHP[65166] -> 'S'
17109:09/12/17 17:30:20 [65163] This process has a valid certificate & key
17110:09/12/17 17:30:20 [65163] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17111:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17112:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17113:09/12/17 17:30:20 [65163] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17114:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17115:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17116:09/12/17 17:30:20 [65163] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17117:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17118:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17119:09/12/17 17:30:20 [65163] IPVERIFY: checking mc0151-ib against 128.55.162.46
17120:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17121:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17122:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17123:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17124:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17125:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17126:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17127:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17128:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
17129:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
17130:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
17131:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
17132:09/12/17 17:30:20 [65163] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
17133:09/12/17 17:30:20 [65163] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
17134:09/12/17 17:30:20 [65163] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17135:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17136:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17137:09/12/17 17:30:20 [65163] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17138:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17139:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17140:09/12/17 17:30:20 [65163] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17141:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17142:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17143:09/12/17 17:30:20 [65163] IPVERIFY: checking mc0151-ib against 128.55.162.46
17144:09/12/17 17:30:20 [65163] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17145:09/12/17 17:30:20 [65163] IPVERIFY: ip found is 1
17146:09/12/17 17:30:20 [65163] (505.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17147:09/12/17 17:30:20 [65163] (505.0) gm state change: GM_INIT -> GM_START
17148:09/12/17 17:30:20 [65163] (505.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17149:09/12/17 17:30:20 [65163] (505.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17150:09/12/17 17:30:20 [65163] GAHP[65166] <- 'BLAH_JOB_SUBMIT 7 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/test.sh"\ ]'
17151:09/12/17 17:30:20 [65163] GAHP[65166] (stderr) -> Assertion mutex->level > 0 failed in file globus_module.c at line 1147
17152:09/12/17 17:30:20 [65163] GAHP[65166] -> EOF
17153:09/12/17 17:30:20 [65163] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
17154:09/12/17 17:35:18 Result of reading /etc/issue:  \S
17156:09/12/17 17:35:18 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
17158:09/12/17 17:35:18 Using IDs: 32 processors, 16 CPUs, 16 HTs
17159:09/12/17 17:35:18 Enumerating interfaces: lo 127.0.0.1 up
17160:09/12/17 17:35:18 Enumerating interfaces: eth0 10.36.162.46 up
17161:09/12/17 17:35:18 Enumerating interfaces: ib0 128.55.162.46 up
17162:09/12/17 17:35:18 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
17163:09/12/17 17:35:18 Initializing Directory: curr_dir = /etc/condor-ce/config.d
17164:09/12/17 17:35:18 ******************************************************
17165:09/12/17 17:35:18 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
17166:09/12/17 17:35:18 ** /usr/sbin/condor_gridmanager
17167:09/12/17 17:35:18 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
17168:09/12/17 17:35:18 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
17169:09/12/17 17:35:18 ** $CondorVersion: 8.4.12 Aug 07 2017 $
17170:09/12/17 17:35:18 ** $CondorPlatform: X86_64-CentOS_7.3 $
17171:09/12/17 17:35:18 ** PID = 65218
17172:09/12/17 17:35:18 ** Log last touched 9/12 17:30:20
17173:09/12/17 17:35:18 ******************************************************
17174:09/12/17 17:35:18 Using config source: /etc/condor-ce/condor_config
17175:09/12/17 17:35:18 Using local config sources: 
17176:09/12/17 17:35:18    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
17177:09/12/17 17:35:18    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
17178:09/12/17 17:35:18    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
17179:09/12/17 17:35:18    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
17180:09/12/17 17:35:18    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
17181:09/12/17 17:35:18    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
17182:09/12/17 17:35:18    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
17183:09/12/17 17:35:18    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
17184:09/12/17 17:35:18    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
17185:09/12/17 17:35:18    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
17186:09/12/17 17:35:18    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
17187:09/12/17 17:35:18    /etc/condor-ce/config.d/01-ce-auth.conf
17188:09/12/17 17:35:18    /etc/condor-ce/config.d/01-ce-router.conf
17189:09/12/17 17:35:18    /etc/condor-ce/config.d/01-common-auth.conf
17190:09/12/17 17:35:18    /etc/condor-ce/config.d/02-ce-slurm.conf
17191:09/12/17 17:35:18    /etc/condor-ce/config.d/03-ce-shared-port.conf
17192:09/12/17 17:35:18    /etc/condor-ce/config.d/03-managed-fork.conf
17193:09/12/17 17:35:18    /etc/condor-ce/config.d/05-ce-health.conf
17194:09/12/17 17:35:18    /etc/condor-ce/config.d/05-ce-view.conf
17195:09/12/17 17:35:18    /etc/condor-ce/config.d/10-ce-collector-generated.conf
17196:09/12/17 17:35:18    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
17197:09/12/17 17:35:18    /etc/condor-ce/config.d/50-osg-configure-present.conf
17198:09/12/17 17:35:18    /etc/condor-ce/config.d/50-osg-configure.conf
17199:09/12/17 17:35:18    /etc/condor-ce/config.d/99-local.conf
17200:09/12/17 17:35:18    /usr/share/condor-ce/condor_ce_router_defaults|
17201:09/12/17 17:35:18 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
17202:09/12/17 17:35:18 CLASSAD_CACHING is ENABLED
17203:09/12/17 17:35:18 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
17204:09/12/17 17:35:18 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_42
17205:09/12/17 17:35:18 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_42>
17206:09/12/17 17:35:18 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_42>
17207:09/12/17 17:35:18 Setting maximum accepts per cycle 8.
17208:09/12/17 17:35:18 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17209:09/12/17 17:35:18 [65218] Welcome to the all-singing, all dancing, "amazing" GridManager!
17210:09/12/17 17:35:18 [65218] DaemonCore: No more children processes to reap.
17211:09/12/17 17:35:18 [65218] DaemonCore: in SendAliveToParent()
17212:09/12/17 17:35:18 [65218] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17213:09/12/17 17:35:18 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17214:09/12/17 17:35:18 [65218] IPVERIFY: ip found is 1
17215:09/12/17 17:35:18 [65218] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17216:09/12/17 17:35:18 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17217:09/12/17 17:35:18 [65218] IPVERIFY: ip found is 1
17218:09/12/17 17:35:18 [65218] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17219:09/12/17 17:35:18 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17220:09/12/17 17:35:18 [65218] IPVERIFY: ip found is 1
17221:09/12/17 17:35:18 [65218] IPVERIFY: checking mc0151-ib against 128.55.162.46
17222:09/12/17 17:35:18 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17223:09/12/17 17:35:18 [65218] IPVERIFY: ip found is 1
17224:09/12/17 17:35:18 [65218] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
17225:09/12/17 17:35:18 [65218] DaemonCore: Leaving SendAliveToParent() - success
17226:09/12/17 17:35:18 [65218] Checking proxies
17227:09/12/17 17:35:21 [65218] Received ADD_JOBS signal
17228:09/12/17 17:35:21 [65218] in doContactSchedd()
17229:09/12/17 17:35:21 [65218] querying for new jobs
17230:09/12/17 17:35:21 [65218] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
17231:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 510.0
17232:09/12/17 17:35:21 [65218] (510.0) SetJobLeaseTimers()
17233:09/12/17 17:35:21 [65218] Found job 510.0 --- inserting
17234:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 509.0
17235:09/12/17 17:35:21 [65218] (509.0) SetJobLeaseTimers()
17236:09/12/17 17:35:21 [65218] Found job 509.0 --- inserting
17237:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 508.0
17238:09/12/17 17:35:21 [65218] (508.0) SetJobLeaseTimers()
17239:09/12/17 17:35:21 [65218] Found job 508.0 --- inserting
17240:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 507.0
17241:09/12/17 17:35:21 [65218] (507.0) SetJobLeaseTimers()
17242:09/12/17 17:35:21 [65218] Found job 507.0 --- inserting
17243:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 506.0
17244:09/12/17 17:35:21 [65218] (506.0) SetJobLeaseTimers()
17245:09/12/17 17:35:21 [65218] Found job 506.0 --- inserting
17246:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 505.0
17247:09/12/17 17:35:21 [65218] (505.0) SetJobLeaseTimers()
17248:09/12/17 17:35:21 [65218] Found job 505.0 --- inserting
17249:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 504.0
17250:09/12/17 17:35:21 [65218] (504.0) SetJobLeaseTimers()
17251:09/12/17 17:35:21 [65218] Found job 504.0 --- inserting
17252:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 503.0
17253:09/12/17 17:35:21 [65218] (503.0) SetJobLeaseTimers()
17254:09/12/17 17:35:21 [65218] Found job 503.0 --- inserting
17255:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 502.0
17256:09/12/17 17:35:21 [65218] (502.0) SetJobLeaseTimers()
17257:09/12/17 17:35:21 [65218] Found job 502.0 --- inserting
17258:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 501.0
17259:09/12/17 17:35:21 [65218] (501.0) SetJobLeaseTimers()
17260:09/12/17 17:35:21 [65218] Found job 501.0 --- inserting
17261:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 500.0
17262:09/12/17 17:35:21 [65218] (500.0) SetJobLeaseTimers()
17263:09/12/17 17:35:21 [65218] Found job 500.0 --- inserting
17264:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 499.0
17265:09/12/17 17:35:21 [65218] (499.0) SetJobLeaseTimers()
17266:09/12/17 17:35:21 [65218] Found job 499.0 --- inserting
17267:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 498.0
17268:09/12/17 17:35:21 [65218] (498.0) SetJobLeaseTimers()
17269:09/12/17 17:35:21 [65218] Found job 498.0 --- inserting
17270:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 497.0
17271:09/12/17 17:35:21 [65218] (497.0) SetJobLeaseTimers()
17272:09/12/17 17:35:21 [65218] Found job 497.0 --- inserting
17273:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 496.0
17274:09/12/17 17:35:21 [65218] (496.0) SetJobLeaseTimers()
17275:09/12/17 17:35:21 [65218] Found job 496.0 --- inserting
17276:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 495.0
17277:09/12/17 17:35:21 [65218] (495.0) SetJobLeaseTimers()
17278:09/12/17 17:35:21 [65218] Found job 495.0 --- inserting
17279:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 494.0
17280:09/12/17 17:35:21 [65218] (494.0) SetJobLeaseTimers()
17281:09/12/17 17:35:21 [65218] Found job 494.0 --- inserting
17282:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 493.0
17283:09/12/17 17:35:21 [65218] (493.0) SetJobLeaseTimers()
17284:09/12/17 17:35:21 [65218] Found job 493.0 --- inserting
17285:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 492.0
17286:09/12/17 17:35:21 [65218] (492.0) SetJobLeaseTimers()
17287:09/12/17 17:35:21 [65218] Found job 492.0 --- inserting
17288:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 491.0
17289:09/12/17 17:35:21 [65218] (491.0) SetJobLeaseTimers()
17290:09/12/17 17:35:21 [65218] Found job 491.0 --- inserting
17291:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 490.0
17292:09/12/17 17:35:21 [65218] (490.0) SetJobLeaseTimers()
17293:09/12/17 17:35:21 [65218] Found job 490.0 --- inserting
17294:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 489.0
17295:09/12/17 17:35:21 [65218] (489.0) SetJobLeaseTimers()
17296:09/12/17 17:35:21 [65218] Found job 489.0 --- inserting
17297:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 488.0
17298:09/12/17 17:35:21 [65218] (488.0) SetJobLeaseTimers()
17299:09/12/17 17:35:21 [65218] Found job 488.0 --- inserting
17300:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 487.0
17301:09/12/17 17:35:21 [65218] (487.0) SetJobLeaseTimers()
17302:09/12/17 17:35:21 [65218] Found job 487.0 --- inserting
17303:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 486.0
17304:09/12/17 17:35:21 [65218] (486.0) SetJobLeaseTimers()
17305:09/12/17 17:35:21 [65218] Found job 486.0 --- inserting
17306:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 485.0
17307:09/12/17 17:35:21 [65218] (485.0) SetJobLeaseTimers()
17308:09/12/17 17:35:21 [65218] Found job 485.0 --- inserting
17309:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 484.0
17310:09/12/17 17:35:21 [65218] (484.0) SetJobLeaseTimers()
17311:09/12/17 17:35:21 [65218] Found job 484.0 --- inserting
17312:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 483.0
17313:09/12/17 17:35:21 [65218] (483.0) SetJobLeaseTimers()
17314:09/12/17 17:35:21 [65218] Found job 483.0 --- inserting
17315:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 482.0
17316:09/12/17 17:35:21 [65218] (482.0) SetJobLeaseTimers()
17317:09/12/17 17:35:21 [65218] Found job 482.0 --- inserting
17318:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 481.0
17319:09/12/17 17:35:21 [65218] (481.0) SetJobLeaseTimers()
17320:09/12/17 17:35:21 [65218] Found job 481.0 --- inserting
17321:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 480.0
17322:09/12/17 17:35:21 [65218] (480.0) SetJobLeaseTimers()
17323:09/12/17 17:35:21 [65218] Found job 480.0 --- inserting
17324:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 516.0
17325:09/12/17 17:35:21 [65218] (516.0) SetJobLeaseTimers()
17326:09/12/17 17:35:21 [65218] Found job 516.0 --- inserting
17327:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 479.0
17328:09/12/17 17:35:21 [65218] (479.0) SetJobLeaseTimers()
17329:09/12/17 17:35:21 [65218] Found job 479.0 --- inserting
17330:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 515.0
17331:09/12/17 17:35:21 [65218] (515.0) SetJobLeaseTimers()
17332:09/12/17 17:35:21 [65218] Found job 515.0 --- inserting
17333:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 478.0
17334:09/12/17 17:35:21 [65218] (478.0) SetJobLeaseTimers()
17335:09/12/17 17:35:21 [65218] Found job 478.0 --- inserting
17336:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 514.0
17337:09/12/17 17:35:21 [65218] (514.0) SetJobLeaseTimers()
17338:09/12/17 17:35:21 [65218] Found job 514.0 --- inserting
17339:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 477.0
17340:09/12/17 17:35:21 [65218] (477.0) SetJobLeaseTimers()
17341:09/12/17 17:35:21 [65218] Found job 477.0 --- inserting
17342:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 513.0
17343:09/12/17 17:35:21 [65218] (513.0) SetJobLeaseTimers()
17344:09/12/17 17:35:21 [65218] Found job 513.0 --- inserting
17345:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 512.0
17346:09/12/17 17:35:21 [65218] (512.0) SetJobLeaseTimers()
17347:09/12/17 17:35:21 [65218] Found job 512.0 --- inserting
17348:09/12/17 17:35:21 [65218] Using job type INFNBatch for job 511.0
17349:09/12/17 17:35:21 [65218] (511.0) SetJobLeaseTimers()
17350:09/12/17 17:35:21 [65218] Found job 511.0 --- inserting
17351:09/12/17 17:35:21 [65218] Fetched 40 new job ads from schedd
17352:09/12/17 17:35:21 [65218] querying for removed/held jobs
17353:09/12/17 17:35:21 [65218] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
17354:09/12/17 17:35:21 [65218] Fetched 0 job ads from schedd
17355:09/12/17 17:35:21 [65218] leaving doContactSchedd()
17356:09/12/17 17:35:21 [65218] gahp server not up yet, delaying ping
17357:09/12/17 17:35:21 [65218] *** UpdateLeases called
17358:09/12/17 17:35:21 [65218]     Leases not supported, cancelling timer
17359:09/12/17 17:35:21 [65218] BaseResource::UpdateResource: 
17379:09/12/17 17:35:21 [65218] Trying to update collector <128.55.162.46:9619>
17380:09/12/17 17:35:21 [65218] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17381:09/12/17 17:35:21 [65218] File descriptor limits: max 4096, safe 3277
17382:09/12/17 17:35:21 [65218] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17383:09/12/17 17:35:21 [65218] GAHP server pid = 65221
17384:09/12/17 17:35:21 [65218] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
17385:09/12/17 17:35:21 [65218] GAHP[65221] <- 'COMMANDS'
17386:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
17387:09/12/17 17:35:21 [65218] GAHP[65221] <- 'ASYNC_MODE_ON'
17388:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S' 'Async mode on'
17389:09/12/17 17:35:21 [65218] (510.0) gm state change: GM_INIT -> GM_START
17390:09/12/17 17:35:21 [65218] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17391:09/12/17 17:35:21 [65218] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17392:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
17393:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S'
17394:09/12/17 17:35:21 [65218] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17395:09/12/17 17:35:21 [65218] (509.0) gm state change: GM_INIT -> GM_START
17396:09/12/17 17:35:21 [65218] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17397:09/12/17 17:35:21 [65218] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17398:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
17399:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S'
17400:09/12/17 17:35:21 [65218] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17401:09/12/17 17:35:21 [65218] (508.0) gm state change: GM_INIT -> GM_START
17402:09/12/17 17:35:21 [65218] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17403:09/12/17 17:35:21 [65218] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17404:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
17405:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S'
17406:09/12/17 17:35:21 [65218] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17407:09/12/17 17:35:21 [65218] (507.0) gm state change: GM_INIT -> GM_START
17408:09/12/17 17:35:21 [65218] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17409:09/12/17 17:35:21 [65218] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17410:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
17411:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S'
17412:09/12/17 17:35:21 [65218] (506.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17413:09/12/17 17:35:21 [65218] (506.0) gm state change: GM_INIT -> GM_START
17414:09/12/17 17:35:21 [65218] (506.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17415:09/12/17 17:35:21 [65218] (506.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17416:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/test.sh"\ ]'
17417:09/12/17 17:35:21 [65218] GAHP[65221] -> 'S'
17418:09/12/17 17:35:21 [65218] This process has a valid certificate & key
17419:09/12/17 17:35:21 [65218] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17420:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17421:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17422:09/12/17 17:35:21 [65218] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17423:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17424:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17425:09/12/17 17:35:21 [65218] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17426:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17427:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17428:09/12/17 17:35:21 [65218] IPVERIFY: checking mc0151-ib against 128.55.162.46
17429:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17430:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17431:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17432:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17433:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17434:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17435:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17436:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
17437:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
17438:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
17439:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
17440:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
17441:09/12/17 17:35:21 [65218] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
17442:09/12/17 17:35:21 [65218] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
17443:09/12/17 17:35:21 [65218] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17444:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17445:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17446:09/12/17 17:35:21 [65218] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17447:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17448:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17449:09/12/17 17:35:21 [65218] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17450:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17451:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17452:09/12/17 17:35:21 [65218] IPVERIFY: checking mc0151-ib against 128.55.162.46
17453:09/12/17 17:35:21 [65218] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17454:09/12/17 17:35:21 [65218] IPVERIFY: ip found is 1
17455:09/12/17 17:35:21 [65218] (505.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17456:09/12/17 17:35:21 [65218] (505.0) gm state change: GM_INIT -> GM_START
17457:09/12/17 17:35:21 [65218] (505.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17458:09/12/17 17:35:21 [65218] (505.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17459:09/12/17 17:35:21 [65218] GAHP[65221] <- 'BLAH_JOB_SUBMIT 7 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/test.sh"\ ]'
17460:09/12/17 17:35:21 [65218] GAHP[65221] (stderr) -> Assertion mutex->level > 0 failed in file globus_module.c at line 1147
17461:09/12/17 17:35:21 [65218] GAHP[65221] -> EOF
17462:09/12/17 17:35:21 [65218] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
17463:09/12/17 17:40:18 Result of reading /etc/issue:  \S
17465:09/12/17 17:40:18 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
17467:09/12/17 17:40:18 Using IDs: 32 processors, 16 CPUs, 16 HTs
17468:09/12/17 17:40:18 Enumerating interfaces: lo 127.0.0.1 up
17469:09/12/17 17:40:18 Enumerating interfaces: eth0 10.36.162.46 up
17470:09/12/17 17:40:18 Enumerating interfaces: ib0 128.55.162.46 up
17471:09/12/17 17:40:18 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
17472:09/12/17 17:40:18 Initializing Directory: curr_dir = /etc/condor-ce/config.d
17473:09/12/17 17:40:18 ******************************************************
17474:09/12/17 17:40:18 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
17475:09/12/17 17:40:18 ** /usr/sbin/condor_gridmanager
17476:09/12/17 17:40:18 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
17477:09/12/17 17:40:18 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
17478:09/12/17 17:40:18 ** $CondorVersion: 8.4.12 Aug 07 2017 $
17479:09/12/17 17:40:18 ** $CondorPlatform: X86_64-CentOS_7.3 $
17480:09/12/17 17:40:18 ** PID = 65269
17481:09/12/17 17:40:18 ** Log last touched 9/12 17:35:21
17482:09/12/17 17:40:18 ******************************************************
17483:09/12/17 17:40:18 Using config source: /etc/condor-ce/condor_config
17484:09/12/17 17:40:18 Using local config sources: 
17485:09/12/17 17:40:18    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
17486:09/12/17 17:40:18    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
17487:09/12/17 17:40:18    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
17488:09/12/17 17:40:18    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
17489:09/12/17 17:40:18    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
17490:09/12/17 17:40:18    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
17491:09/12/17 17:40:18    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
17492:09/12/17 17:40:18    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
17493:09/12/17 17:40:18    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
17494:09/12/17 17:40:18    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
17495:09/12/17 17:40:18    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
17496:09/12/17 17:40:18    /etc/condor-ce/config.d/01-ce-auth.conf
17497:09/12/17 17:40:18    /etc/condor-ce/config.d/01-ce-router.conf
17498:09/12/17 17:40:18    /etc/condor-ce/config.d/01-common-auth.conf
17499:09/12/17 17:40:18    /etc/condor-ce/config.d/02-ce-slurm.conf
17500:09/12/17 17:40:18    /etc/condor-ce/config.d/03-ce-shared-port.conf
17501:09/12/17 17:40:18    /etc/condor-ce/config.d/03-managed-fork.conf
17502:09/12/17 17:40:18    /etc/condor-ce/config.d/05-ce-health.conf
17503:09/12/17 17:40:18    /etc/condor-ce/config.d/05-ce-view.conf
17504:09/12/17 17:40:18    /etc/condor-ce/config.d/10-ce-collector-generated.conf
17505:09/12/17 17:40:18    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
17506:09/12/17 17:40:18    /etc/condor-ce/config.d/50-osg-configure-present.conf
17507:09/12/17 17:40:18    /etc/condor-ce/config.d/50-osg-configure.conf
17508:09/12/17 17:40:18    /etc/condor-ce/config.d/99-local.conf
17509:09/12/17 17:40:18    /usr/share/condor-ce/condor_ce_router_defaults|
17510:09/12/17 17:40:18 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
17511:09/12/17 17:40:18 CLASSAD_CACHING is ENABLED
17512:09/12/17 17:40:18 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
17513:09/12/17 17:40:18 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_45
17514:09/12/17 17:40:18 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_45>
17515:09/12/17 17:40:18 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_45>
17516:09/12/17 17:40:18 Setting maximum accepts per cycle 8.
17517:09/12/17 17:40:18 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17518:09/12/17 17:40:18 [65269] Welcome to the all-singing, all dancing, "amazing" GridManager!
17519:09/12/17 17:40:18 [65269] DaemonCore: No more children processes to reap.
17520:09/12/17 17:40:18 [65269] DaemonCore: in SendAliveToParent()
17521:09/12/17 17:40:18 [65269] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17522:09/12/17 17:40:18 [65269] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17523:09/12/17 17:40:18 [65269] IPVERIFY: ip found is 1
17524:09/12/17 17:40:18 [65269] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17525:09/12/17 17:40:18 [65269] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17526:09/12/17 17:40:18 [65269] IPVERIFY: ip found is 1
17527:09/12/17 17:40:18 [65269] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17528:09/12/17 17:40:18 [65269] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17529:09/12/17 17:40:18 [65269] IPVERIFY: ip found is 1
17530:09/12/17 17:40:18 [65269] IPVERIFY: checking mc0151-ib against 128.55.162.46
17531:09/12/17 17:40:18 [65269] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17532:09/12/17 17:40:18 [65269] IPVERIFY: ip found is 1
17533:09/12/17 17:40:18 [65269] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
17534:09/12/17 17:40:18 [65269] DaemonCore: Leaving SendAliveToParent() - success
17535:09/12/17 17:40:18 [65269] Checking proxies
17536:09/12/17 17:40:21 [65269] Received ADD_JOBS signal
17537:09/12/17 17:40:21 [65269] in doContactSchedd()
17538:09/12/17 17:40:21 [65269] querying for new jobs
17539:09/12/17 17:40:21 [65269] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
17540:09/12/17 17:40:21 [65269] Using job type INFNBatch for job 510.0
17541:09/12/17 17:40:21 [65269] (510.0) SetJobLeaseTimers()
17542:09/12/17 17:40:21 [65269] Found job 510.0 --- inserting
17543:09/12/17 17:40:21 [65269] Using job type INFNBatch for job 509.0
17544:09/12/17 17:40:21 [65269] (509.0) SetJobLeaseTimers()
17545:09/12/17 17:40:21 [65269] Found job 509.0 --- inserting
17546:09/12/17 17:40:21 [65269] Using job type INFNBatch for job 508.0
17547:09/12/17 17:40:21 [65269] (508.0) SetJobLeaseTimers()
17548:09/12/17 17:40:21 [65269] Found job 508.0 --- inserting
17549:09/12/17 17:40:21 [65269] Using job type INFNBatch for job 507.0
17550:09/12/17 17:40:21 [65269] (507.0) SetJobLeaseTimers()
17551:09/12/17 17:40:21 [65269] Found job 507.0 --- inserting
17552:09/12/17 17:40:21 [65269] Using job type INFNBatch for job 506.0
17553:09/12/17 17:40:21 [65269] (506.0) SetJobLeaseTimers()
17554:09/12/17 17:40:22 [65269] Found job 506.0 --- inserting
17555:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 505.0
17556:09/12/17 17:40:22 [65269] (505.0) SetJobLeaseTimers()
17557:09/12/17 17:40:22 [65269] Found job 505.0 --- inserting
17558:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 504.0
17559:09/12/17 17:40:22 [65269] (504.0) SetJobLeaseTimers()
17560:09/12/17 17:40:22 [65269] Found job 504.0 --- inserting
17561:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 503.0
17562:09/12/17 17:40:22 [65269] (503.0) SetJobLeaseTimers()
17563:09/12/17 17:40:22 [65269] Found job 503.0 --- inserting
17564:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 502.0
17565:09/12/17 17:40:22 [65269] (502.0) SetJobLeaseTimers()
17566:09/12/17 17:40:22 [65269] Found job 502.0 --- inserting
17567:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 501.0
17568:09/12/17 17:40:22 [65269] (501.0) SetJobLeaseTimers()
17569:09/12/17 17:40:22 [65269] Found job 501.0 --- inserting
17570:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 500.0
17571:09/12/17 17:40:22 [65269] (500.0) SetJobLeaseTimers()
17572:09/12/17 17:40:22 [65269] Found job 500.0 --- inserting
17573:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 499.0
17574:09/12/17 17:40:22 [65269] (499.0) SetJobLeaseTimers()
17575:09/12/17 17:40:22 [65269] Found job 499.0 --- inserting
17576:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 498.0
17577:09/12/17 17:40:22 [65269] (498.0) SetJobLeaseTimers()
17578:09/12/17 17:40:22 [65269] Found job 498.0 --- inserting
17579:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 497.0
17580:09/12/17 17:40:22 [65269] (497.0) SetJobLeaseTimers()
17581:09/12/17 17:40:22 [65269] Found job 497.0 --- inserting
17582:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 496.0
17583:09/12/17 17:40:22 [65269] (496.0) SetJobLeaseTimers()
17584:09/12/17 17:40:22 [65269] Found job 496.0 --- inserting
17585:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 495.0
17586:09/12/17 17:40:22 [65269] (495.0) SetJobLeaseTimers()
17587:09/12/17 17:40:22 [65269] Found job 495.0 --- inserting
17588:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 494.0
17589:09/12/17 17:40:22 [65269] (494.0) SetJobLeaseTimers()
17590:09/12/17 17:40:22 [65269] Found job 494.0 --- inserting
17591:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 493.0
17592:09/12/17 17:40:22 [65269] (493.0) SetJobLeaseTimers()
17593:09/12/17 17:40:22 [65269] Found job 493.0 --- inserting
17594:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 492.0
17595:09/12/17 17:40:22 [65269] (492.0) SetJobLeaseTimers()
17596:09/12/17 17:40:22 [65269] Found job 492.0 --- inserting
17597:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 491.0
17598:09/12/17 17:40:22 [65269] (491.0) SetJobLeaseTimers()
17599:09/12/17 17:40:22 [65269] Found job 491.0 --- inserting
17600:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 490.0
17601:09/12/17 17:40:22 [65269] (490.0) SetJobLeaseTimers()
17602:09/12/17 17:40:22 [65269] Found job 490.0 --- inserting
17603:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 489.0
17604:09/12/17 17:40:22 [65269] (489.0) SetJobLeaseTimers()
17605:09/12/17 17:40:22 [65269] Found job 489.0 --- inserting
17606:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 488.0
17607:09/12/17 17:40:22 [65269] (488.0) SetJobLeaseTimers()
17608:09/12/17 17:40:22 [65269] Found job 488.0 --- inserting
17609:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 487.0
17610:09/12/17 17:40:22 [65269] (487.0) SetJobLeaseTimers()
17611:09/12/17 17:40:22 [65269] Found job 487.0 --- inserting
17612:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 486.0
17613:09/12/17 17:40:22 [65269] (486.0) SetJobLeaseTimers()
17614:09/12/17 17:40:22 [65269] Found job 486.0 --- inserting
17615:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 485.0
17616:09/12/17 17:40:22 [65269] (485.0) SetJobLeaseTimers()
17617:09/12/17 17:40:22 [65269] Found job 485.0 --- inserting
17618:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 484.0
17619:09/12/17 17:40:22 [65269] (484.0) SetJobLeaseTimers()
17620:09/12/17 17:40:22 [65269] Found job 484.0 --- inserting
17621:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 483.0
17622:09/12/17 17:40:22 [65269] (483.0) SetJobLeaseTimers()
17623:09/12/17 17:40:22 [65269] Found job 483.0 --- inserting
17624:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 482.0
17625:09/12/17 17:40:22 [65269] (482.0) SetJobLeaseTimers()
17626:09/12/17 17:40:22 [65269] Found job 482.0 --- inserting
17627:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 481.0
17628:09/12/17 17:40:22 [65269] (481.0) SetJobLeaseTimers()
17629:09/12/17 17:40:22 [65269] Found job 481.0 --- inserting
17630:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 480.0
17631:09/12/17 17:40:22 [65269] (480.0) SetJobLeaseTimers()
17632:09/12/17 17:40:22 [65269] Found job 480.0 --- inserting
17633:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 516.0
17634:09/12/17 17:40:22 [65269] (516.0) SetJobLeaseTimers()
17635:09/12/17 17:40:22 [65269] Found job 516.0 --- inserting
17636:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 479.0
17637:09/12/17 17:40:22 [65269] (479.0) SetJobLeaseTimers()
17638:09/12/17 17:40:22 [65269] Found job 479.0 --- inserting
17639:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 515.0
17640:09/12/17 17:40:22 [65269] (515.0) SetJobLeaseTimers()
17641:09/12/17 17:40:22 [65269] Found job 515.0 --- inserting
17642:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 478.0
17643:09/12/17 17:40:22 [65269] (478.0) SetJobLeaseTimers()
17644:09/12/17 17:40:22 [65269] Found job 478.0 --- inserting
17645:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 514.0
17646:09/12/17 17:40:22 [65269] (514.0) SetJobLeaseTimers()
17647:09/12/17 17:40:22 [65269] Found job 514.0 --- inserting
17648:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 477.0
17649:09/12/17 17:40:22 [65269] (477.0) SetJobLeaseTimers()
17650:09/12/17 17:40:22 [65269] Found job 477.0 --- inserting
17651:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 513.0
17652:09/12/17 17:40:22 [65269] (513.0) SetJobLeaseTimers()
17653:09/12/17 17:40:22 [65269] Found job 513.0 --- inserting
17654:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 512.0
17655:09/12/17 17:40:22 [65269] (512.0) SetJobLeaseTimers()
17656:09/12/17 17:40:22 [65269] Found job 512.0 --- inserting
17657:09/12/17 17:40:22 [65269] Using job type INFNBatch for job 511.0
17658:09/12/17 17:40:22 [65269] (511.0) SetJobLeaseTimers()
17659:09/12/17 17:40:22 [65269] Found job 511.0 --- inserting
17660:09/12/17 17:40:22 [65269] Fetched 40 new job ads from schedd
17661:09/12/17 17:40:22 [65269] querying for removed/held jobs
17662:09/12/17 17:40:22 [65269] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
17663:09/12/17 17:40:22 [65269] Fetched 0 job ads from schedd
17664:09/12/17 17:40:22 [65269] leaving doContactSchedd()
17665:09/12/17 17:40:22 [65269] gahp server not up yet, delaying ping
17666:09/12/17 17:40:22 [65269] *** UpdateLeases called
17667:09/12/17 17:40:22 [65269]     Leases not supported, cancelling timer
17668:09/12/17 17:40:22 [65269] BaseResource::UpdateResource: 
17688:09/12/17 17:40:22 [65269] Trying to update collector <128.55.162.46:9619>
17689:09/12/17 17:40:22 [65269] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17690:09/12/17 17:40:22 [65269] File descriptor limits: max 4096, safe 3277
17691:09/12/17 17:40:22 [65269] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17692:09/12/17 17:40:22 [65269] GAHP server pid = 65272
17693:09/12/17 17:40:22 [65269] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
17694:09/12/17 17:40:22 [65269] GAHP[65272] <- 'COMMANDS'
17695:09/12/17 17:40:22 [65269] GAHP[65272] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
17696:09/12/17 17:40:22 [65269] GAHP[65272] <- 'ASYNC_MODE_ON'
17697:09/12/17 17:40:22 [65269] GAHP[65272] -> 'S' 'Async mode on'
17698:09/12/17 17:40:22 [65269] (510.0) gm state change: GM_INIT -> GM_START
17699:09/12/17 17:40:22 [65269] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17700:09/12/17 17:40:22 [65269] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17701:09/12/17 17:40:22 [65269] GAHP[65272] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
17702:09/12/17 17:40:22 [65269] GAHP[65272] -> 'S'
17703:09/12/17 17:40:22 [65269] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17704:09/12/17 17:40:22 [65269] (509.0) gm state change: GM_INIT -> GM_START
17705:09/12/17 17:40:22 [65269] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17706:09/12/17 17:40:22 [65269] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17707:09/12/17 17:40:22 [65269] GAHP[65272] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
17708:09/12/17 17:40:22 [65269] GAHP[65272] -> 'S'
17709:09/12/17 17:40:22 [65269] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17710:09/12/17 17:40:22 [65269] (508.0) gm state change: GM_INIT -> GM_START
17711:09/12/17 17:40:22 [65269] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17712:09/12/17 17:40:22 [65269] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17713:09/12/17 17:40:22 [65269] GAHP[65272] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
17714:09/12/17 17:40:22 [65269] GAHP[65272] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
17715:09/12/17 17:40:22 [65269] GAHP[65272] -> EOF
17716:09/12/17 17:40:22 [65269] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
17717:09/12/17 17:45:19 Result of reading /etc/issue:  \S
17719:09/12/17 17:45:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
17721:09/12/17 17:45:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
17722:09/12/17 17:45:19 Enumerating interfaces: lo 127.0.0.1 up
17723:09/12/17 17:45:19 Enumerating interfaces: eth0 10.36.162.46 up
17724:09/12/17 17:45:19 Enumerating interfaces: ib0 128.55.162.46 up
17725:09/12/17 17:45:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
17726:09/12/17 17:45:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
17727:09/12/17 17:45:19 ******************************************************
17728:09/12/17 17:45:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
17729:09/12/17 17:45:19 ** /usr/sbin/condor_gridmanager
17730:09/12/17 17:45:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
17731:09/12/17 17:45:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
17732:09/12/17 17:45:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
17733:09/12/17 17:45:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
17734:09/12/17 17:45:19 ** PID = 65313
17735:09/12/17 17:45:19 ** Log last touched 9/12 17:40:22
17736:09/12/17 17:45:19 ******************************************************
17737:09/12/17 17:45:19 Using config source: /etc/condor-ce/condor_config
17738:09/12/17 17:45:19 Using local config sources: 
17739:09/12/17 17:45:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
17740:09/12/17 17:45:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
17741:09/12/17 17:45:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
17742:09/12/17 17:45:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
17743:09/12/17 17:45:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
17744:09/12/17 17:45:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
17745:09/12/17 17:45:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
17746:09/12/17 17:45:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
17747:09/12/17 17:45:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
17748:09/12/17 17:45:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
17749:09/12/17 17:45:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
17750:09/12/17 17:45:19    /etc/condor-ce/config.d/01-ce-auth.conf
17751:09/12/17 17:45:19    /etc/condor-ce/config.d/01-ce-router.conf
17752:09/12/17 17:45:19    /etc/condor-ce/config.d/01-common-auth.conf
17753:09/12/17 17:45:19    /etc/condor-ce/config.d/02-ce-slurm.conf
17754:09/12/17 17:45:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
17755:09/12/17 17:45:19    /etc/condor-ce/config.d/03-managed-fork.conf
17756:09/12/17 17:45:19    /etc/condor-ce/config.d/05-ce-health.conf
17757:09/12/17 17:45:19    /etc/condor-ce/config.d/05-ce-view.conf
17758:09/12/17 17:45:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
17759:09/12/17 17:45:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
17760:09/12/17 17:45:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
17761:09/12/17 17:45:19    /etc/condor-ce/config.d/50-osg-configure.conf
17762:09/12/17 17:45:19    /etc/condor-ce/config.d/99-local.conf
17763:09/12/17 17:45:19    /usr/share/condor-ce/condor_ce_router_defaults|
17764:09/12/17 17:45:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
17765:09/12/17 17:45:19 CLASSAD_CACHING is ENABLED
17766:09/12/17 17:45:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
17767:09/12/17 17:45:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_48
17768:09/12/17 17:45:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_48>
17769:09/12/17 17:45:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_48>
17770:09/12/17 17:45:19 Setting maximum accepts per cycle 8.
17771:09/12/17 17:45:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17772:09/12/17 17:45:19 [65313] Welcome to the all-singing, all dancing, "amazing" GridManager!
17773:09/12/17 17:45:19 [65313] DaemonCore: No more children processes to reap.
17774:09/12/17 17:45:19 [65313] DaemonCore: in SendAliveToParent()
17775:09/12/17 17:45:19 [65313] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
17776:09/12/17 17:45:19 [65313] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17777:09/12/17 17:45:19 [65313] IPVERIFY: ip found is 1
17778:09/12/17 17:45:19 [65313] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
17779:09/12/17 17:45:19 [65313] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17780:09/12/17 17:45:19 [65313] IPVERIFY: ip found is 1
17781:09/12/17 17:45:19 [65313] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
17782:09/12/17 17:45:19 [65313] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17783:09/12/17 17:45:19 [65313] IPVERIFY: ip found is 1
17784:09/12/17 17:45:19 [65313] IPVERIFY: checking mc0151-ib against 128.55.162.46
17785:09/12/17 17:45:19 [65313] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
17786:09/12/17 17:45:19 [65313] IPVERIFY: ip found is 1
17787:09/12/17 17:45:19 [65313] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
17788:09/12/17 17:45:19 [65313] DaemonCore: Leaving SendAliveToParent() - success
17789:09/12/17 17:45:19 [65313] Checking proxies
17790:09/12/17 17:45:22 [65313] Received ADD_JOBS signal
17791:09/12/17 17:45:22 [65313] in doContactSchedd()
17792:09/12/17 17:45:22 [65313] querying for new jobs
17793:09/12/17 17:45:22 [65313] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
17794:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 510.0
17795:09/12/17 17:45:22 [65313] (510.0) SetJobLeaseTimers()
17796:09/12/17 17:45:22 [65313] Found job 510.0 --- inserting
17797:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 509.0
17798:09/12/17 17:45:22 [65313] (509.0) SetJobLeaseTimers()
17799:09/12/17 17:45:22 [65313] Found job 509.0 --- inserting
17800:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 508.0
17801:09/12/17 17:45:22 [65313] (508.0) SetJobLeaseTimers()
17802:09/12/17 17:45:22 [65313] Found job 508.0 --- inserting
17803:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 507.0
17804:09/12/17 17:45:22 [65313] (507.0) SetJobLeaseTimers()
17805:09/12/17 17:45:22 [65313] Found job 507.0 --- inserting
17806:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 506.0
17807:09/12/17 17:45:22 [65313] (506.0) SetJobLeaseTimers()
17808:09/12/17 17:45:22 [65313] Found job 506.0 --- inserting
17809:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 505.0
17810:09/12/17 17:45:22 [65313] (505.0) SetJobLeaseTimers()
17811:09/12/17 17:45:22 [65313] Found job 505.0 --- inserting
17812:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 504.0
17813:09/12/17 17:45:22 [65313] (504.0) SetJobLeaseTimers()
17814:09/12/17 17:45:22 [65313] Found job 504.0 --- inserting
17815:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 503.0
17816:09/12/17 17:45:22 [65313] (503.0) SetJobLeaseTimers()
17817:09/12/17 17:45:22 [65313] Found job 503.0 --- inserting
17818:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 502.0
17819:09/12/17 17:45:22 [65313] (502.0) SetJobLeaseTimers()
17820:09/12/17 17:45:22 [65313] Found job 502.0 --- inserting
17821:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 501.0
17822:09/12/17 17:45:22 [65313] (501.0) SetJobLeaseTimers()
17823:09/12/17 17:45:22 [65313] Found job 501.0 --- inserting
17824:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 500.0
17825:09/12/17 17:45:22 [65313] (500.0) SetJobLeaseTimers()
17826:09/12/17 17:45:22 [65313] Found job 500.0 --- inserting
17827:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 499.0
17828:09/12/17 17:45:22 [65313] (499.0) SetJobLeaseTimers()
17829:09/12/17 17:45:22 [65313] Found job 499.0 --- inserting
17830:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 498.0
17831:09/12/17 17:45:22 [65313] (498.0) SetJobLeaseTimers()
17832:09/12/17 17:45:22 [65313] Found job 498.0 --- inserting
17833:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 497.0
17834:09/12/17 17:45:22 [65313] (497.0) SetJobLeaseTimers()
17835:09/12/17 17:45:22 [65313] Found job 497.0 --- inserting
17836:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 496.0
17837:09/12/17 17:45:22 [65313] (496.0) SetJobLeaseTimers()
17838:09/12/17 17:45:22 [65313] Found job 496.0 --- inserting
17839:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 495.0
17840:09/12/17 17:45:22 [65313] (495.0) SetJobLeaseTimers()
17841:09/12/17 17:45:22 [65313] Found job 495.0 --- inserting
17842:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 494.0
17843:09/12/17 17:45:22 [65313] (494.0) SetJobLeaseTimers()
17844:09/12/17 17:45:22 [65313] Found job 494.0 --- inserting
17845:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 493.0
17846:09/12/17 17:45:22 [65313] (493.0) SetJobLeaseTimers()
17847:09/12/17 17:45:22 [65313] Found job 493.0 --- inserting
17848:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 492.0
17849:09/12/17 17:45:22 [65313] (492.0) SetJobLeaseTimers()
17850:09/12/17 17:45:22 [65313] Found job 492.0 --- inserting
17851:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 491.0
17852:09/12/17 17:45:22 [65313] (491.0) SetJobLeaseTimers()
17853:09/12/17 17:45:22 [65313] Found job 491.0 --- inserting
17854:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 490.0
17855:09/12/17 17:45:22 [65313] (490.0) SetJobLeaseTimers()
17856:09/12/17 17:45:22 [65313] Found job 490.0 --- inserting
17857:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 489.0
17858:09/12/17 17:45:22 [65313] (489.0) SetJobLeaseTimers()
17859:09/12/17 17:45:22 [65313] Found job 489.0 --- inserting
17860:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 488.0
17861:09/12/17 17:45:22 [65313] (488.0) SetJobLeaseTimers()
17862:09/12/17 17:45:22 [65313] Found job 488.0 --- inserting
17863:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 487.0
17864:09/12/17 17:45:22 [65313] (487.0) SetJobLeaseTimers()
17865:09/12/17 17:45:22 [65313] Found job 487.0 --- inserting
17866:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 486.0
17867:09/12/17 17:45:22 [65313] (486.0) SetJobLeaseTimers()
17868:09/12/17 17:45:22 [65313] Found job 486.0 --- inserting
17869:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 485.0
17870:09/12/17 17:45:22 [65313] (485.0) SetJobLeaseTimers()
17871:09/12/17 17:45:22 [65313] Found job 485.0 --- inserting
17872:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 484.0
17873:09/12/17 17:45:22 [65313] (484.0) SetJobLeaseTimers()
17874:09/12/17 17:45:22 [65313] Found job 484.0 --- inserting
17875:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 483.0
17876:09/12/17 17:45:22 [65313] (483.0) SetJobLeaseTimers()
17877:09/12/17 17:45:22 [65313] Found job 483.0 --- inserting
17878:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 482.0
17879:09/12/17 17:45:22 [65313] (482.0) SetJobLeaseTimers()
17880:09/12/17 17:45:22 [65313] Found job 482.0 --- inserting
17881:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 481.0
17882:09/12/17 17:45:22 [65313] (481.0) SetJobLeaseTimers()
17883:09/12/17 17:45:22 [65313] Found job 481.0 --- inserting
17884:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 480.0
17885:09/12/17 17:45:22 [65313] (480.0) SetJobLeaseTimers()
17886:09/12/17 17:45:22 [65313] Found job 480.0 --- inserting
17887:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 516.0
17888:09/12/17 17:45:22 [65313] (516.0) SetJobLeaseTimers()
17889:09/12/17 17:45:22 [65313] Found job 516.0 --- inserting
17890:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 479.0
17891:09/12/17 17:45:22 [65313] (479.0) SetJobLeaseTimers()
17892:09/12/17 17:45:22 [65313] Found job 479.0 --- inserting
17893:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 515.0
17894:09/12/17 17:45:22 [65313] (515.0) SetJobLeaseTimers()
17895:09/12/17 17:45:22 [65313] Found job 515.0 --- inserting
17896:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 478.0
17897:09/12/17 17:45:22 [65313] (478.0) SetJobLeaseTimers()
17898:09/12/17 17:45:22 [65313] Found job 478.0 --- inserting
17899:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 514.0
17900:09/12/17 17:45:22 [65313] (514.0) SetJobLeaseTimers()
17901:09/12/17 17:45:22 [65313] Found job 514.0 --- inserting
17902:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 477.0
17903:09/12/17 17:45:22 [65313] (477.0) SetJobLeaseTimers()
17904:09/12/17 17:45:22 [65313] Found job 477.0 --- inserting
17905:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 513.0
17906:09/12/17 17:45:22 [65313] (513.0) SetJobLeaseTimers()
17907:09/12/17 17:45:22 [65313] Found job 513.0 --- inserting
17908:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 512.0
17909:09/12/17 17:45:22 [65313] (512.0) SetJobLeaseTimers()
17910:09/12/17 17:45:22 [65313] Found job 512.0 --- inserting
17911:09/12/17 17:45:22 [65313] Using job type INFNBatch for job 511.0
17912:09/12/17 17:45:22 [65313] (511.0) SetJobLeaseTimers()
17913:09/12/17 17:45:22 [65313] Found job 511.0 --- inserting
17914:09/12/17 17:45:22 [65313] Fetched 40 new job ads from schedd
17915:09/12/17 17:45:22 [65313] querying for removed/held jobs
17916:09/12/17 17:45:22 [65313] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
17917:09/12/17 17:45:22 [65313] Fetched 0 job ads from schedd
17918:09/12/17 17:45:22 [65313] leaving doContactSchedd()
17919:09/12/17 17:45:22 [65313] gahp server not up yet, delaying ping
17920:09/12/17 17:45:22 [65313] *** UpdateLeases called
17921:09/12/17 17:45:22 [65313]     Leases not supported, cancelling timer
17922:09/12/17 17:45:22 [65313] BaseResource::UpdateResource: 
17942:09/12/17 17:45:22 [65313] Trying to update collector <128.55.162.46:9619>
17943:09/12/17 17:45:22 [65313] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
17944:09/12/17 17:45:22 [65313] File descriptor limits: max 4096, safe 3277
17945:09/12/17 17:45:22 [65313] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17946:09/12/17 17:45:22 [65313] GAHP server pid = 65316
17947:09/12/17 17:45:22 [65313] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
17948:09/12/17 17:45:22 [65313] GAHP[65316] <- 'COMMANDS'
17949:09/12/17 17:45:22 [65313] GAHP[65316] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
17950:09/12/17 17:45:22 [65313] GAHP[65316] <- 'ASYNC_MODE_ON'
17951:09/12/17 17:45:22 [65313] GAHP[65316] -> 'S' 'Async mode on'
17952:09/12/17 17:45:22 [65313] (510.0) gm state change: GM_INIT -> GM_START
17953:09/12/17 17:45:22 [65313] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17954:09/12/17 17:45:22 [65313] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17955:09/12/17 17:45:22 [65313] GAHP[65316] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
17956:09/12/17 17:45:22 [65313] GAHP[65316] -> 'S'
17957:09/12/17 17:45:22 [65313] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17958:09/12/17 17:45:22 [65313] (509.0) gm state change: GM_INIT -> GM_START
17959:09/12/17 17:45:22 [65313] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17960:09/12/17 17:45:22 [65313] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17961:09/12/17 17:45:22 [65313] GAHP[65316] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
17962:09/12/17 17:45:22 [65313] GAHP[65316] -> 'S'
17963:09/12/17 17:45:22 [65313] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
17964:09/12/17 17:45:22 [65313] (508.0) gm state change: GM_INIT -> GM_START
17965:09/12/17 17:45:22 [65313] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
17966:09/12/17 17:45:22 [65313] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
17967:09/12/17 17:45:22 [65313] GAHP[65316] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
17968:09/12/17 17:45:22 [65313] GAHP[65316] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
17969:09/12/17 17:45:22 [65313] GAHP[65316] -> EOF
17970:09/12/17 17:45:22 [65313] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
17971:09/12/17 17:50:19 Result of reading /etc/issue:  \S
17973:09/12/17 17:50:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
17975:09/12/17 17:50:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
17976:09/12/17 17:50:19 Enumerating interfaces: lo 127.0.0.1 up
17977:09/12/17 17:50:19 Enumerating interfaces: eth0 10.36.162.46 up
17978:09/12/17 17:50:19 Enumerating interfaces: ib0 128.55.162.46 up
17979:09/12/17 17:50:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
17980:09/12/17 17:50:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
17981:09/12/17 17:50:19 ******************************************************
17982:09/12/17 17:50:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
17983:09/12/17 17:50:19 ** /usr/sbin/condor_gridmanager
17984:09/12/17 17:50:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
17985:09/12/17 17:50:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
17986:09/12/17 17:50:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
17987:09/12/17 17:50:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
17988:09/12/17 17:50:19 ** PID = 65355
17989:09/12/17 17:50:19 ** Log last touched 9/12 17:45:22
17990:09/12/17 17:50:19 ******************************************************
17991:09/12/17 17:50:19 Using config source: /etc/condor-ce/condor_config
17992:09/12/17 17:50:19 Using local config sources: 
17993:09/12/17 17:50:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
17994:09/12/17 17:50:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
17995:09/12/17 17:50:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
17996:09/12/17 17:50:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
17997:09/12/17 17:50:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
17998:09/12/17 17:50:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
17999:09/12/17 17:50:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
18000:09/12/17 17:50:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
18001:09/12/17 17:50:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
18002:09/12/17 17:50:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
18003:09/12/17 17:50:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
18004:09/12/17 17:50:19    /etc/condor-ce/config.d/01-ce-auth.conf
18005:09/12/17 17:50:19    /etc/condor-ce/config.d/01-ce-router.conf
18006:09/12/17 17:50:19    /etc/condor-ce/config.d/01-common-auth.conf
18007:09/12/17 17:50:19    /etc/condor-ce/config.d/02-ce-slurm.conf
18008:09/12/17 17:50:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
18009:09/12/17 17:50:19    /etc/condor-ce/config.d/03-managed-fork.conf
18010:09/12/17 17:50:19    /etc/condor-ce/config.d/05-ce-health.conf
18011:09/12/17 17:50:19    /etc/condor-ce/config.d/05-ce-view.conf
18012:09/12/17 17:50:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
18013:09/12/17 17:50:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
18014:09/12/17 17:50:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
18015:09/12/17 17:50:19    /etc/condor-ce/config.d/50-osg-configure.conf
18016:09/12/17 17:50:19    /etc/condor-ce/config.d/99-local.conf
18017:09/12/17 17:50:19    /usr/share/condor-ce/condor_ce_router_defaults|
18018:09/12/17 17:50:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
18019:09/12/17 17:50:19 CLASSAD_CACHING is ENABLED
18020:09/12/17 17:50:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
18021:09/12/17 17:50:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_50
18022:09/12/17 17:50:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_50>
18023:09/12/17 17:50:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_50>
18024:09/12/17 17:50:19 Setting maximum accepts per cycle 8.
18025:09/12/17 17:50:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18026:09/12/17 17:50:19 [65355] Welcome to the all-singing, all dancing, "amazing" GridManager!
18027:09/12/17 17:50:19 [65355] DaemonCore: No more children processes to reap.
18028:09/12/17 17:50:19 [65355] DaemonCore: in SendAliveToParent()
18029:09/12/17 17:50:19 [65355] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
18030:09/12/17 17:50:19 [65355] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18031:09/12/17 17:50:19 [65355] IPVERIFY: ip found is 1
18032:09/12/17 17:50:19 [65355] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
18033:09/12/17 17:50:19 [65355] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18034:09/12/17 17:50:19 [65355] IPVERIFY: ip found is 1
18035:09/12/17 17:50:19 [65355] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
18036:09/12/17 17:50:19 [65355] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18037:09/12/17 17:50:19 [65355] IPVERIFY: ip found is 1
18038:09/12/17 17:50:19 [65355] IPVERIFY: checking mc0151-ib against 128.55.162.46
18039:09/12/17 17:50:19 [65355] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18040:09/12/17 17:50:19 [65355] IPVERIFY: ip found is 1
18041:09/12/17 17:50:19 [65355] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
18042:09/12/17 17:50:19 [65355] DaemonCore: Leaving SendAliveToParent() - success
18043:09/12/17 17:50:19 [65355] Checking proxies
18044:09/12/17 17:50:22 [65355] Received ADD_JOBS signal
18045:09/12/17 17:50:22 [65355] in doContactSchedd()
18046:09/12/17 17:50:22 [65355] querying for new jobs
18047:09/12/17 17:50:22 [65355] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
18048:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 510.0
18049:09/12/17 17:50:22 [65355] (510.0) SetJobLeaseTimers()
18050:09/12/17 17:50:22 [65355] Found job 510.0 --- inserting
18051:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 509.0
18052:09/12/17 17:50:22 [65355] (509.0) SetJobLeaseTimers()
18053:09/12/17 17:50:22 [65355] Found job 509.0 --- inserting
18054:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 508.0
18055:09/12/17 17:50:22 [65355] (508.0) SetJobLeaseTimers()
18056:09/12/17 17:50:22 [65355] Found job 508.0 --- inserting
18057:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 507.0
18058:09/12/17 17:50:22 [65355] (507.0) SetJobLeaseTimers()
18059:09/12/17 17:50:22 [65355] Found job 507.0 --- inserting
18060:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 506.0
18061:09/12/17 17:50:22 [65355] (506.0) SetJobLeaseTimers()
18062:09/12/17 17:50:22 [65355] Found job 506.0 --- inserting
18063:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 505.0
18064:09/12/17 17:50:22 [65355] (505.0) SetJobLeaseTimers()
18065:09/12/17 17:50:22 [65355] Found job 505.0 --- inserting
18066:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 504.0
18067:09/12/17 17:50:22 [65355] (504.0) SetJobLeaseTimers()
18068:09/12/17 17:50:22 [65355] Found job 504.0 --- inserting
18069:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 503.0
18070:09/12/17 17:50:22 [65355] (503.0) SetJobLeaseTimers()
18071:09/12/17 17:50:22 [65355] Found job 503.0 --- inserting
18072:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 502.0
18073:09/12/17 17:50:22 [65355] (502.0) SetJobLeaseTimers()
18074:09/12/17 17:50:22 [65355] Found job 502.0 --- inserting
18075:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 501.0
18076:09/12/17 17:50:22 [65355] (501.0) SetJobLeaseTimers()
18077:09/12/17 17:50:22 [65355] Found job 501.0 --- inserting
18078:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 500.0
18079:09/12/17 17:50:22 [65355] (500.0) SetJobLeaseTimers()
18080:09/12/17 17:50:22 [65355] Found job 500.0 --- inserting
18081:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 499.0
18082:09/12/17 17:50:22 [65355] (499.0) SetJobLeaseTimers()
18083:09/12/17 17:50:22 [65355] Found job 499.0 --- inserting
18084:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 498.0
18085:09/12/17 17:50:22 [65355] (498.0) SetJobLeaseTimers()
18086:09/12/17 17:50:22 [65355] Found job 498.0 --- inserting
18087:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 497.0
18088:09/12/17 17:50:22 [65355] (497.0) SetJobLeaseTimers()
18089:09/12/17 17:50:22 [65355] Found job 497.0 --- inserting
18090:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 496.0
18091:09/12/17 17:50:22 [65355] (496.0) SetJobLeaseTimers()
18092:09/12/17 17:50:22 [65355] Found job 496.0 --- inserting
18093:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 495.0
18094:09/12/17 17:50:22 [65355] (495.0) SetJobLeaseTimers()
18095:09/12/17 17:50:22 [65355] Found job 495.0 --- inserting
18096:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 494.0
18097:09/12/17 17:50:22 [65355] (494.0) SetJobLeaseTimers()
18098:09/12/17 17:50:22 [65355] Found job 494.0 --- inserting
18099:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 493.0
18100:09/12/17 17:50:22 [65355] (493.0) SetJobLeaseTimers()
18101:09/12/17 17:50:22 [65355] Found job 493.0 --- inserting
18102:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 492.0
18103:09/12/17 17:50:22 [65355] (492.0) SetJobLeaseTimers()
18104:09/12/17 17:50:22 [65355] Found job 492.0 --- inserting
18105:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 491.0
18106:09/12/17 17:50:22 [65355] (491.0) SetJobLeaseTimers()
18107:09/12/17 17:50:22 [65355] Found job 491.0 --- inserting
18108:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 490.0
18109:09/12/17 17:50:22 [65355] (490.0) SetJobLeaseTimers()
18110:09/12/17 17:50:22 [65355] Found job 490.0 --- inserting
18111:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 489.0
18112:09/12/17 17:50:22 [65355] (489.0) SetJobLeaseTimers()
18113:09/12/17 17:50:22 [65355] Found job 489.0 --- inserting
18114:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 488.0
18115:09/12/17 17:50:22 [65355] (488.0) SetJobLeaseTimers()
18116:09/12/17 17:50:22 [65355] Found job 488.0 --- inserting
18117:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 487.0
18118:09/12/17 17:50:22 [65355] (487.0) SetJobLeaseTimers()
18119:09/12/17 17:50:22 [65355] Found job 487.0 --- inserting
18120:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 486.0
18121:09/12/17 17:50:22 [65355] (486.0) SetJobLeaseTimers()
18122:09/12/17 17:50:22 [65355] Found job 486.0 --- inserting
18123:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 485.0
18124:09/12/17 17:50:22 [65355] (485.0) SetJobLeaseTimers()
18125:09/12/17 17:50:22 [65355] Found job 485.0 --- inserting
18126:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 484.0
18127:09/12/17 17:50:22 [65355] (484.0) SetJobLeaseTimers()
18128:09/12/17 17:50:22 [65355] Found job 484.0 --- inserting
18129:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 483.0
18130:09/12/17 17:50:22 [65355] (483.0) SetJobLeaseTimers()
18131:09/12/17 17:50:22 [65355] Found job 483.0 --- inserting
18132:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 482.0
18133:09/12/17 17:50:22 [65355] (482.0) SetJobLeaseTimers()
18134:09/12/17 17:50:22 [65355] Found job 482.0 --- inserting
18135:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 481.0
18136:09/12/17 17:50:22 [65355] (481.0) SetJobLeaseTimers()
18137:09/12/17 17:50:22 [65355] Found job 481.0 --- inserting
18138:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 480.0
18139:09/12/17 17:50:22 [65355] (480.0) SetJobLeaseTimers()
18140:09/12/17 17:50:22 [65355] Found job 480.0 --- inserting
18141:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 516.0
18142:09/12/17 17:50:22 [65355] (516.0) SetJobLeaseTimers()
18143:09/12/17 17:50:22 [65355] Found job 516.0 --- inserting
18144:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 479.0
18145:09/12/17 17:50:22 [65355] (479.0) SetJobLeaseTimers()
18146:09/12/17 17:50:22 [65355] Found job 479.0 --- inserting
18147:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 515.0
18148:09/12/17 17:50:22 [65355] (515.0) SetJobLeaseTimers()
18149:09/12/17 17:50:22 [65355] Found job 515.0 --- inserting
18150:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 478.0
18151:09/12/17 17:50:22 [65355] (478.0) SetJobLeaseTimers()
18152:09/12/17 17:50:22 [65355] Found job 478.0 --- inserting
18153:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 514.0
18154:09/12/17 17:50:22 [65355] (514.0) SetJobLeaseTimers()
18155:09/12/17 17:50:22 [65355] Found job 514.0 --- inserting
18156:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 477.0
18157:09/12/17 17:50:22 [65355] (477.0) SetJobLeaseTimers()
18158:09/12/17 17:50:22 [65355] Found job 477.0 --- inserting
18159:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 513.0
18160:09/12/17 17:50:22 [65355] (513.0) SetJobLeaseTimers()
18161:09/12/17 17:50:22 [65355] Found job 513.0 --- inserting
18162:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 512.0
18163:09/12/17 17:50:22 [65355] (512.0) SetJobLeaseTimers()
18164:09/12/17 17:50:22 [65355] Found job 512.0 --- inserting
18165:09/12/17 17:50:22 [65355] Using job type INFNBatch for job 511.0
18166:09/12/17 17:50:22 [65355] (511.0) SetJobLeaseTimers()
18167:09/12/17 17:50:22 [65355] Found job 511.0 --- inserting
18168:09/12/17 17:50:22 [65355] Fetched 40 new job ads from schedd
18169:09/12/17 17:50:22 [65355] querying for removed/held jobs
18170:09/12/17 17:50:22 [65355] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
18171:09/12/17 17:50:22 [65355] Fetched 0 job ads from schedd
18172:09/12/17 17:50:22 [65355] leaving doContactSchedd()
18173:09/12/17 17:50:22 [65355] gahp server not up yet, delaying ping
18174:09/12/17 17:50:22 [65355] *** UpdateLeases called
18175:09/12/17 17:50:22 [65355]     Leases not supported, cancelling timer
18176:09/12/17 17:50:22 [65355] BaseResource::UpdateResource: 
18196:09/12/17 17:50:22 [65355] Trying to update collector <128.55.162.46:9619>
18197:09/12/17 17:50:22 [65355] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18198:09/12/17 17:50:22 [65355] File descriptor limits: max 4096, safe 3277
18199:09/12/17 17:50:22 [65355] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18200:09/12/17 17:50:22 [65355] GAHP server pid = 65358
18201:09/12/17 17:50:22 [65355] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
18202:09/12/17 17:50:22 [65355] GAHP[65358] <- 'COMMANDS'
18203:09/12/17 17:50:22 [65355] GAHP[65358] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
18204:09/12/17 17:50:22 [65355] GAHP[65358] <- 'ASYNC_MODE_ON'
18205:09/12/17 17:50:22 [65355] GAHP[65358] -> 'S' 'Async mode on'
18206:09/12/17 17:50:22 [65355] (510.0) gm state change: GM_INIT -> GM_START
18207:09/12/17 17:50:22 [65355] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18208:09/12/17 17:50:22 [65355] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18209:09/12/17 17:50:22 [65355] GAHP[65358] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
18210:09/12/17 17:50:22 [65355] GAHP[65358] -> 'S'
18211:09/12/17 17:50:22 [65355] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18212:09/12/17 17:50:22 [65355] (509.0) gm state change: GM_INIT -> GM_START
18213:09/12/17 17:50:22 [65355] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18214:09/12/17 17:50:22 [65355] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18215:09/12/17 17:50:22 [65355] GAHP[65358] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
18216:09/12/17 17:50:22 [65355] GAHP[65358] -> 'S'
18217:09/12/17 17:50:22 [65355] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18218:09/12/17 17:50:22 [65355] (508.0) gm state change: GM_INIT -> GM_START
18219:09/12/17 17:50:22 [65355] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18220:09/12/17 17:50:22 [65355] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18221:09/12/17 17:50:22 [65355] GAHP[65358] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
18222:09/12/17 17:50:22 [65355] GAHP[65358] -> 'S'
18223:09/12/17 17:50:22 [65355] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18224:09/12/17 17:50:22 [65355] (507.0) gm state change: GM_INIT -> GM_START
18225:09/12/17 17:50:22 [65355] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18226:09/12/17 17:50:22 [65355] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18227:09/12/17 17:50:22 [65355] GAHP[65358] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
18228:09/12/17 17:50:22 [65355] GAHP[65358] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
18229:09/12/17 17:50:22 [65355] GAHP[65358] -> EOF
18230:09/12/17 17:50:22 [65355] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
18231:09/12/17 17:55:19 Result of reading /etc/issue:  \S
18233:09/12/17 17:55:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
18235:09/12/17 17:55:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
18236:09/12/17 17:55:19 Enumerating interfaces: lo 127.0.0.1 up
18237:09/12/17 17:55:19 Enumerating interfaces: eth0 10.36.162.46 up
18238:09/12/17 17:55:19 Enumerating interfaces: ib0 128.55.162.46 up
18239:09/12/17 17:55:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
18240:09/12/17 17:55:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
18241:09/12/17 17:55:19 ******************************************************
18242:09/12/17 17:55:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
18243:09/12/17 17:55:19 ** /usr/sbin/condor_gridmanager
18244:09/12/17 17:55:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
18245:09/12/17 17:55:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
18246:09/12/17 17:55:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
18247:09/12/17 17:55:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
18248:09/12/17 17:55:19 ** PID = 65401
18249:09/12/17 17:55:19 ** Log last touched 9/12 17:50:22
18250:09/12/17 17:55:19 ******************************************************
18251:09/12/17 17:55:19 Using config source: /etc/condor-ce/condor_config
18252:09/12/17 17:55:19 Using local config sources: 
18253:09/12/17 17:55:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
18254:09/12/17 17:55:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
18255:09/12/17 17:55:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
18256:09/12/17 17:55:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
18257:09/12/17 17:55:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
18258:09/12/17 17:55:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
18259:09/12/17 17:55:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
18260:09/12/17 17:55:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
18261:09/12/17 17:55:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
18262:09/12/17 17:55:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
18263:09/12/17 17:55:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
18264:09/12/17 17:55:19    /etc/condor-ce/config.d/01-ce-auth.conf
18265:09/12/17 17:55:19    /etc/condor-ce/config.d/01-ce-router.conf
18266:09/12/17 17:55:19    /etc/condor-ce/config.d/01-common-auth.conf
18267:09/12/17 17:55:19    /etc/condor-ce/config.d/02-ce-slurm.conf
18268:09/12/17 17:55:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
18269:09/12/17 17:55:19    /etc/condor-ce/config.d/03-managed-fork.conf
18270:09/12/17 17:55:19    /etc/condor-ce/config.d/05-ce-health.conf
18271:09/12/17 17:55:19    /etc/condor-ce/config.d/05-ce-view.conf
18272:09/12/17 17:55:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
18273:09/12/17 17:55:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
18274:09/12/17 17:55:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
18275:09/12/17 17:55:19    /etc/condor-ce/config.d/50-osg-configure.conf
18276:09/12/17 17:55:19    /etc/condor-ce/config.d/99-local.conf
18277:09/12/17 17:55:19    /usr/share/condor-ce/condor_ce_router_defaults|
18278:09/12/17 17:55:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
18279:09/12/17 17:55:19 CLASSAD_CACHING is ENABLED
18280:09/12/17 17:55:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
18281:09/12/17 17:55:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_53
18282:09/12/17 17:55:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_53>
18283:09/12/17 17:55:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_53>
18284:09/12/17 17:55:19 Setting maximum accepts per cycle 8.
18285:09/12/17 17:55:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18286:09/12/17 17:55:19 [65401] Welcome to the all-singing, all dancing, "amazing" GridManager!
18287:09/12/17 17:55:19 [65401] DaemonCore: No more children processes to reap.
18288:09/12/17 17:55:19 [65401] DaemonCore: in SendAliveToParent()
18289:09/12/17 17:55:19 [65401] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
18290:09/12/17 17:55:19 [65401] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18291:09/12/17 17:55:19 [65401] IPVERIFY: ip found is 1
18292:09/12/17 17:55:19 [65401] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
18293:09/12/17 17:55:19 [65401] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18294:09/12/17 17:55:19 [65401] IPVERIFY: ip found is 1
18295:09/12/17 17:55:19 [65401] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
18296:09/12/17 17:55:19 [65401] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18297:09/12/17 17:55:19 [65401] IPVERIFY: ip found is 1
18298:09/12/17 17:55:19 [65401] IPVERIFY: checking mc0151-ib against 128.55.162.46
18299:09/12/17 17:55:19 [65401] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18300:09/12/17 17:55:19 [65401] IPVERIFY: ip found is 1
18301:09/12/17 17:55:19 [65401] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
18302:09/12/17 17:55:19 [65401] DaemonCore: Leaving SendAliveToParent() - success
18303:09/12/17 17:55:19 [65401] Checking proxies
18304:09/12/17 17:55:22 [65401] Received ADD_JOBS signal
18305:09/12/17 17:55:22 [65401] in doContactSchedd()
18306:09/12/17 17:55:22 [65401] querying for new jobs
18307:09/12/17 17:55:22 [65401] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
18308:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 510.0
18309:09/12/17 17:55:22 [65401] (510.0) SetJobLeaseTimers()
18310:09/12/17 17:55:22 [65401] Found job 510.0 --- inserting
18311:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 509.0
18312:09/12/17 17:55:22 [65401] (509.0) SetJobLeaseTimers()
18313:09/12/17 17:55:22 [65401] Found job 509.0 --- inserting
18314:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 508.0
18315:09/12/17 17:55:22 [65401] (508.0) SetJobLeaseTimers()
18316:09/12/17 17:55:22 [65401] Found job 508.0 --- inserting
18317:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 507.0
18318:09/12/17 17:55:22 [65401] (507.0) SetJobLeaseTimers()
18319:09/12/17 17:55:22 [65401] Found job 507.0 --- inserting
18320:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 506.0
18321:09/12/17 17:55:22 [65401] (506.0) SetJobLeaseTimers()
18322:09/12/17 17:55:22 [65401] Found job 506.0 --- inserting
18323:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 505.0
18324:09/12/17 17:55:22 [65401] (505.0) SetJobLeaseTimers()
18325:09/12/17 17:55:22 [65401] Found job 505.0 --- inserting
18326:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 504.0
18327:09/12/17 17:55:22 [65401] (504.0) SetJobLeaseTimers()
18328:09/12/17 17:55:22 [65401] Found job 504.0 --- inserting
18329:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 503.0
18330:09/12/17 17:55:22 [65401] (503.0) SetJobLeaseTimers()
18331:09/12/17 17:55:22 [65401] Found job 503.0 --- inserting
18332:09/12/17 17:55:22 [65401] Using job type INFNBatch for job 502.0
18333:09/12/17 17:55:22 [65401] (502.0) SetJobLeaseTimers()
18334:09/12/17 17:55:22 [65401] Found job 502.0 --- inserting
18335:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 501.0
18336:09/12/17 17:55:23 [65401] (501.0) SetJobLeaseTimers()
18337:09/12/17 17:55:23 [65401] Found job 501.0 --- inserting
18338:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 500.0
18339:09/12/17 17:55:23 [65401] (500.0) SetJobLeaseTimers()
18340:09/12/17 17:55:23 [65401] Found job 500.0 --- inserting
18341:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 499.0
18342:09/12/17 17:55:23 [65401] (499.0) SetJobLeaseTimers()
18343:09/12/17 17:55:23 [65401] Found job 499.0 --- inserting
18344:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 498.0
18345:09/12/17 17:55:23 [65401] (498.0) SetJobLeaseTimers()
18346:09/12/17 17:55:23 [65401] Found job 498.0 --- inserting
18347:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 497.0
18348:09/12/17 17:55:23 [65401] (497.0) SetJobLeaseTimers()
18349:09/12/17 17:55:23 [65401] Found job 497.0 --- inserting
18350:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 496.0
18351:09/12/17 17:55:23 [65401] (496.0) SetJobLeaseTimers()
18352:09/12/17 17:55:23 [65401] Found job 496.0 --- inserting
18353:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 495.0
18354:09/12/17 17:55:23 [65401] (495.0) SetJobLeaseTimers()
18355:09/12/17 17:55:23 [65401] Found job 495.0 --- inserting
18356:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 494.0
18357:09/12/17 17:55:23 [65401] (494.0) SetJobLeaseTimers()
18358:09/12/17 17:55:23 [65401] Found job 494.0 --- inserting
18359:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 493.0
18360:09/12/17 17:55:23 [65401] (493.0) SetJobLeaseTimers()
18361:09/12/17 17:55:23 [65401] Found job 493.0 --- inserting
18362:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 492.0
18363:09/12/17 17:55:23 [65401] (492.0) SetJobLeaseTimers()
18364:09/12/17 17:55:23 [65401] Found job 492.0 --- inserting
18365:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 491.0
18366:09/12/17 17:55:23 [65401] (491.0) SetJobLeaseTimers()
18367:09/12/17 17:55:23 [65401] Found job 491.0 --- inserting
18368:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 490.0
18369:09/12/17 17:55:23 [65401] (490.0) SetJobLeaseTimers()
18370:09/12/17 17:55:23 [65401] Found job 490.0 --- inserting
18371:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 489.0
18372:09/12/17 17:55:23 [65401] (489.0) SetJobLeaseTimers()
18373:09/12/17 17:55:23 [65401] Found job 489.0 --- inserting
18374:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 488.0
18375:09/12/17 17:55:23 [65401] (488.0) SetJobLeaseTimers()
18376:09/12/17 17:55:23 [65401] Found job 488.0 --- inserting
18377:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 487.0
18378:09/12/17 17:55:23 [65401] (487.0) SetJobLeaseTimers()
18379:09/12/17 17:55:23 [65401] Found job 487.0 --- inserting
18380:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 486.0
18381:09/12/17 17:55:23 [65401] (486.0) SetJobLeaseTimers()
18382:09/12/17 17:55:23 [65401] Found job 486.0 --- inserting
18383:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 485.0
18384:09/12/17 17:55:23 [65401] (485.0) SetJobLeaseTimers()
18385:09/12/17 17:55:23 [65401] Found job 485.0 --- inserting
18386:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 484.0
18387:09/12/17 17:55:23 [65401] (484.0) SetJobLeaseTimers()
18388:09/12/17 17:55:23 [65401] Found job 484.0 --- inserting
18389:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 483.0
18390:09/12/17 17:55:23 [65401] (483.0) SetJobLeaseTimers()
18391:09/12/17 17:55:23 [65401] Found job 483.0 --- inserting
18392:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 482.0
18393:09/12/17 17:55:23 [65401] (482.0) SetJobLeaseTimers()
18394:09/12/17 17:55:23 [65401] Found job 482.0 --- inserting
18395:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 481.0
18396:09/12/17 17:55:23 [65401] (481.0) SetJobLeaseTimers()
18397:09/12/17 17:55:23 [65401] Found job 481.0 --- inserting
18398:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 480.0
18399:09/12/17 17:55:23 [65401] (480.0) SetJobLeaseTimers()
18400:09/12/17 17:55:23 [65401] Found job 480.0 --- inserting
18401:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 516.0
18402:09/12/17 17:55:23 [65401] (516.0) SetJobLeaseTimers()
18403:09/12/17 17:55:23 [65401] Found job 516.0 --- inserting
18404:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 479.0
18405:09/12/17 17:55:23 [65401] (479.0) SetJobLeaseTimers()
18406:09/12/17 17:55:23 [65401] Found job 479.0 --- inserting
18407:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 515.0
18408:09/12/17 17:55:23 [65401] (515.0) SetJobLeaseTimers()
18409:09/12/17 17:55:23 [65401] Found job 515.0 --- inserting
18410:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 478.0
18411:09/12/17 17:55:23 [65401] (478.0) SetJobLeaseTimers()
18412:09/12/17 17:55:23 [65401] Found job 478.0 --- inserting
18413:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 514.0
18414:09/12/17 17:55:23 [65401] (514.0) SetJobLeaseTimers()
18415:09/12/17 17:55:23 [65401] Found job 514.0 --- inserting
18416:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 477.0
18417:09/12/17 17:55:23 [65401] (477.0) SetJobLeaseTimers()
18418:09/12/17 17:55:23 [65401] Found job 477.0 --- inserting
18419:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 513.0
18420:09/12/17 17:55:23 [65401] (513.0) SetJobLeaseTimers()
18421:09/12/17 17:55:23 [65401] Found job 513.0 --- inserting
18422:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 512.0
18423:09/12/17 17:55:23 [65401] (512.0) SetJobLeaseTimers()
18424:09/12/17 17:55:23 [65401] Found job 512.0 --- inserting
18425:09/12/17 17:55:23 [65401] Using job type INFNBatch for job 511.0
18426:09/12/17 17:55:23 [65401] (511.0) SetJobLeaseTimers()
18427:09/12/17 17:55:23 [65401] Found job 511.0 --- inserting
18428:09/12/17 17:55:23 [65401] Fetched 40 new job ads from schedd
18429:09/12/17 17:55:23 [65401] querying for removed/held jobs
18430:09/12/17 17:55:23 [65401] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
18431:09/12/17 17:55:23 [65401] Fetched 0 job ads from schedd
18432:09/12/17 17:55:23 [65401] leaving doContactSchedd()
18433:09/12/17 17:55:23 [65401] gahp server not up yet, delaying ping
18434:09/12/17 17:55:23 [65401] *** UpdateLeases called
18435:09/12/17 17:55:23 [65401]     Leases not supported, cancelling timer
18436:09/12/17 17:55:23 [65401] BaseResource::UpdateResource: 
18456:09/12/17 17:55:23 [65401] Trying to update collector <128.55.162.46:9619>
18457:09/12/17 17:55:23 [65401] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18458:09/12/17 17:55:23 [65401] File descriptor limits: max 4096, safe 3277
18459:09/12/17 17:55:23 [65401] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18460:09/12/17 17:55:23 [65401] GAHP server pid = 65404
18461:09/12/17 17:55:23 [65401] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
18462:09/12/17 17:55:23 [65401] GAHP[65404] <- 'COMMANDS'
18463:09/12/17 17:55:23 [65401] GAHP[65404] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
18464:09/12/17 17:55:23 [65401] GAHP[65404] <- 'ASYNC_MODE_ON'
18465:09/12/17 17:55:23 [65401] GAHP[65404] -> 'S' 'Async mode on'
18466:09/12/17 17:55:23 [65401] (510.0) gm state change: GM_INIT -> GM_START
18467:09/12/17 17:55:23 [65401] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18468:09/12/17 17:55:23 [65401] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18469:09/12/17 17:55:23 [65401] GAHP[65404] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
18470:09/12/17 17:55:23 [65401] GAHP[65404] -> 'S'
18471:09/12/17 17:55:23 [65401] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18472:09/12/17 17:55:23 [65401] (509.0) gm state change: GM_INIT -> GM_START
18473:09/12/17 17:55:23 [65401] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18474:09/12/17 17:55:23 [65401] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18475:09/12/17 17:55:23 [65401] GAHP[65404] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
18476:09/12/17 17:55:23 [65401] GAHP[65404] -> 'S'
18477:09/12/17 17:55:23 [65401] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18478:09/12/17 17:55:23 [65401] (508.0) gm state change: GM_INIT -> GM_START
18479:09/12/17 17:55:23 [65401] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18480:09/12/17 17:55:23 [65401] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18481:09/12/17 17:55:23 [65401] GAHP[65404] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
18482:09/12/17 17:55:23 [65401] GAHP[65404] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
18483:09/12/17 17:55:23 [65401] GAHP[65404] -> EOF
18484:09/12/17 17:55:23 [65401] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
18485:09/12/17 18:00:20 Result of reading /etc/issue:  \S
18487:09/12/17 18:00:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
18489:09/12/17 18:00:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
18490:09/12/17 18:00:20 Enumerating interfaces: lo 127.0.0.1 up
18491:09/12/17 18:00:20 Enumerating interfaces: eth0 10.36.162.46 up
18492:09/12/17 18:00:20 Enumerating interfaces: ib0 128.55.162.46 up
18493:09/12/17 18:00:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
18494:09/12/17 18:00:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
18495:09/12/17 18:00:20 ******************************************************
18496:09/12/17 18:00:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
18497:09/12/17 18:00:20 ** /usr/sbin/condor_gridmanager
18498:09/12/17 18:00:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
18499:09/12/17 18:00:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
18500:09/12/17 18:00:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
18501:09/12/17 18:00:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
18502:09/12/17 18:00:20 ** PID = 65469
18503:09/12/17 18:00:20 ** Log last touched 9/12 17:55:23
18504:09/12/17 18:00:20 ******************************************************
18505:09/12/17 18:00:20 Using config source: /etc/condor-ce/condor_config
18506:09/12/17 18:00:20 Using local config sources: 
18507:09/12/17 18:00:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
18508:09/12/17 18:00:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
18509:09/12/17 18:00:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
18510:09/12/17 18:00:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
18511:09/12/17 18:00:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
18512:09/12/17 18:00:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
18513:09/12/17 18:00:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
18514:09/12/17 18:00:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
18515:09/12/17 18:00:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
18516:09/12/17 18:00:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
18517:09/12/17 18:00:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
18518:09/12/17 18:00:20    /etc/condor-ce/config.d/01-ce-auth.conf
18519:09/12/17 18:00:20    /etc/condor-ce/config.d/01-ce-router.conf
18520:09/12/17 18:00:20    /etc/condor-ce/config.d/01-common-auth.conf
18521:09/12/17 18:00:20    /etc/condor-ce/config.d/02-ce-slurm.conf
18522:09/12/17 18:00:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
18523:09/12/17 18:00:20    /etc/condor-ce/config.d/03-managed-fork.conf
18524:09/12/17 18:00:20    /etc/condor-ce/config.d/05-ce-health.conf
18525:09/12/17 18:00:20    /etc/condor-ce/config.d/05-ce-view.conf
18526:09/12/17 18:00:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
18527:09/12/17 18:00:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
18528:09/12/17 18:00:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
18529:09/12/17 18:00:20    /etc/condor-ce/config.d/50-osg-configure.conf
18530:09/12/17 18:00:20    /etc/condor-ce/config.d/99-local.conf
18531:09/12/17 18:00:20    /usr/share/condor-ce/condor_ce_router_defaults|
18532:09/12/17 18:00:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
18533:09/12/17 18:00:20 CLASSAD_CACHING is ENABLED
18534:09/12/17 18:00:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
18535:09/12/17 18:00:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_56
18536:09/12/17 18:00:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_56>
18537:09/12/17 18:00:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_56>
18538:09/12/17 18:00:20 Setting maximum accepts per cycle 8.
18539:09/12/17 18:00:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18540:09/12/17 18:00:20 [65469] Welcome to the all-singing, all dancing, "amazing" GridManager!
18541:09/12/17 18:00:20 [65469] DaemonCore: No more children processes to reap.
18542:09/12/17 18:00:20 [65469] DaemonCore: in SendAliveToParent()
18543:09/12/17 18:00:20 [65469] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
18544:09/12/17 18:00:20 [65469] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18545:09/12/17 18:00:20 [65469] IPVERIFY: ip found is 1
18546:09/12/17 18:00:20 [65469] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
18547:09/12/17 18:00:20 [65469] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18548:09/12/17 18:00:20 [65469] IPVERIFY: ip found is 1
18549:09/12/17 18:00:20 [65469] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
18550:09/12/17 18:00:20 [65469] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18551:09/12/17 18:00:20 [65469] IPVERIFY: ip found is 1
18552:09/12/17 18:00:20 [65469] IPVERIFY: checking mc0151-ib against 128.55.162.46
18553:09/12/17 18:00:20 [65469] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18554:09/12/17 18:00:20 [65469] IPVERIFY: ip found is 1
18555:09/12/17 18:00:20 [65469] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
18556:09/12/17 18:00:20 [65469] DaemonCore: Leaving SendAliveToParent() - success
18557:09/12/17 18:00:20 [65469] Checking proxies
18558:09/12/17 18:00:23 [65469] Received ADD_JOBS signal
18559:09/12/17 18:00:23 [65469] in doContactSchedd()
18560:09/12/17 18:00:23 [65469] querying for new jobs
18561:09/12/17 18:00:23 [65469] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
18562:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 510.0
18563:09/12/17 18:00:23 [65469] (510.0) SetJobLeaseTimers()
18564:09/12/17 18:00:23 [65469] Found job 510.0 --- inserting
18565:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 509.0
18566:09/12/17 18:00:23 [65469] (509.0) SetJobLeaseTimers()
18567:09/12/17 18:00:23 [65469] Found job 509.0 --- inserting
18568:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 508.0
18569:09/12/17 18:00:23 [65469] (508.0) SetJobLeaseTimers()
18570:09/12/17 18:00:23 [65469] Found job 508.0 --- inserting
18571:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 507.0
18572:09/12/17 18:00:23 [65469] (507.0) SetJobLeaseTimers()
18573:09/12/17 18:00:23 [65469] Found job 507.0 --- inserting
18574:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 506.0
18575:09/12/17 18:00:23 [65469] (506.0) SetJobLeaseTimers()
18576:09/12/17 18:00:23 [65469] Found job 506.0 --- inserting
18577:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 505.0
18578:09/12/17 18:00:23 [65469] (505.0) SetJobLeaseTimers()
18579:09/12/17 18:00:23 [65469] Found job 505.0 --- inserting
18580:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 504.0
18581:09/12/17 18:00:23 [65469] (504.0) SetJobLeaseTimers()
18582:09/12/17 18:00:23 [65469] Found job 504.0 --- inserting
18583:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 503.0
18584:09/12/17 18:00:23 [65469] (503.0) SetJobLeaseTimers()
18585:09/12/17 18:00:23 [65469] Found job 503.0 --- inserting
18586:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 502.0
18587:09/12/17 18:00:23 [65469] (502.0) SetJobLeaseTimers()
18588:09/12/17 18:00:23 [65469] Found job 502.0 --- inserting
18589:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 501.0
18590:09/12/17 18:00:23 [65469] (501.0) SetJobLeaseTimers()
18591:09/12/17 18:00:23 [65469] Found job 501.0 --- inserting
18592:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 500.0
18593:09/12/17 18:00:23 [65469] (500.0) SetJobLeaseTimers()
18594:09/12/17 18:00:23 [65469] Found job 500.0 --- inserting
18595:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 499.0
18596:09/12/17 18:00:23 [65469] (499.0) SetJobLeaseTimers()
18597:09/12/17 18:00:23 [65469] Found job 499.0 --- inserting
18598:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 498.0
18599:09/12/17 18:00:23 [65469] (498.0) SetJobLeaseTimers()
18600:09/12/17 18:00:23 [65469] Found job 498.0 --- inserting
18601:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 497.0
18602:09/12/17 18:00:23 [65469] (497.0) SetJobLeaseTimers()
18603:09/12/17 18:00:23 [65469] Found job 497.0 --- inserting
18604:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 496.0
18605:09/12/17 18:00:23 [65469] (496.0) SetJobLeaseTimers()
18606:09/12/17 18:00:23 [65469] Found job 496.0 --- inserting
18607:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 495.0
18608:09/12/17 18:00:23 [65469] (495.0) SetJobLeaseTimers()
18609:09/12/17 18:00:23 [65469] Found job 495.0 --- inserting
18610:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 494.0
18611:09/12/17 18:00:23 [65469] (494.0) SetJobLeaseTimers()
18612:09/12/17 18:00:23 [65469] Found job 494.0 --- inserting
18613:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 493.0
18614:09/12/17 18:00:23 [65469] (493.0) SetJobLeaseTimers()
18615:09/12/17 18:00:23 [65469] Found job 493.0 --- inserting
18616:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 492.0
18617:09/12/17 18:00:23 [65469] (492.0) SetJobLeaseTimers()
18618:09/12/17 18:00:23 [65469] Found job 492.0 --- inserting
18619:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 491.0
18620:09/12/17 18:00:23 [65469] (491.0) SetJobLeaseTimers()
18621:09/12/17 18:00:23 [65469] Found job 491.0 --- inserting
18622:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 490.0
18623:09/12/17 18:00:23 [65469] (490.0) SetJobLeaseTimers()
18624:09/12/17 18:00:23 [65469] Found job 490.0 --- inserting
18625:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 489.0
18626:09/12/17 18:00:23 [65469] (489.0) SetJobLeaseTimers()
18627:09/12/17 18:00:23 [65469] Found job 489.0 --- inserting
18628:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 488.0
18629:09/12/17 18:00:23 [65469] (488.0) SetJobLeaseTimers()
18630:09/12/17 18:00:23 [65469] Found job 488.0 --- inserting
18631:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 487.0
18632:09/12/17 18:00:23 [65469] (487.0) SetJobLeaseTimers()
18633:09/12/17 18:00:23 [65469] Found job 487.0 --- inserting
18634:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 486.0
18635:09/12/17 18:00:23 [65469] (486.0) SetJobLeaseTimers()
18636:09/12/17 18:00:23 [65469] Found job 486.0 --- inserting
18637:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 485.0
18638:09/12/17 18:00:23 [65469] (485.0) SetJobLeaseTimers()
18639:09/12/17 18:00:23 [65469] Found job 485.0 --- inserting
18640:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 484.0
18641:09/12/17 18:00:23 [65469] (484.0) SetJobLeaseTimers()
18642:09/12/17 18:00:23 [65469] Found job 484.0 --- inserting
18643:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 483.0
18644:09/12/17 18:00:23 [65469] (483.0) SetJobLeaseTimers()
18645:09/12/17 18:00:23 [65469] Found job 483.0 --- inserting
18646:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 482.0
18647:09/12/17 18:00:23 [65469] (482.0) SetJobLeaseTimers()
18648:09/12/17 18:00:23 [65469] Found job 482.0 --- inserting
18649:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 481.0
18650:09/12/17 18:00:23 [65469] (481.0) SetJobLeaseTimers()
18651:09/12/17 18:00:23 [65469] Found job 481.0 --- inserting
18652:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 480.0
18653:09/12/17 18:00:23 [65469] (480.0) SetJobLeaseTimers()
18654:09/12/17 18:00:23 [65469] Found job 480.0 --- inserting
18655:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 516.0
18656:09/12/17 18:00:23 [65469] (516.0) SetJobLeaseTimers()
18657:09/12/17 18:00:23 [65469] Found job 516.0 --- inserting
18658:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 479.0
18659:09/12/17 18:00:23 [65469] (479.0) SetJobLeaseTimers()
18660:09/12/17 18:00:23 [65469] Found job 479.0 --- inserting
18661:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 515.0
18662:09/12/17 18:00:23 [65469] (515.0) SetJobLeaseTimers()
18663:09/12/17 18:00:23 [65469] Found job 515.0 --- inserting
18664:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 478.0
18665:09/12/17 18:00:23 [65469] (478.0) SetJobLeaseTimers()
18666:09/12/17 18:00:23 [65469] Found job 478.0 --- inserting
18667:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 514.0
18668:09/12/17 18:00:23 [65469] (514.0) SetJobLeaseTimers()
18669:09/12/17 18:00:23 [65469] Found job 514.0 --- inserting
18670:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 477.0
18671:09/12/17 18:00:23 [65469] (477.0) SetJobLeaseTimers()
18672:09/12/17 18:00:23 [65469] Found job 477.0 --- inserting
18673:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 513.0
18674:09/12/17 18:00:23 [65469] (513.0) SetJobLeaseTimers()
18675:09/12/17 18:00:23 [65469] Found job 513.0 --- inserting
18676:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 512.0
18677:09/12/17 18:00:23 [65469] (512.0) SetJobLeaseTimers()
18678:09/12/17 18:00:23 [65469] Found job 512.0 --- inserting
18679:09/12/17 18:00:23 [65469] Using job type INFNBatch for job 511.0
18680:09/12/17 18:00:23 [65469] (511.0) SetJobLeaseTimers()
18681:09/12/17 18:00:23 [65469] Found job 511.0 --- inserting
18682:09/12/17 18:00:23 [65469] Fetched 40 new job ads from schedd
18683:09/12/17 18:00:23 [65469] querying for removed/held jobs
18684:09/12/17 18:00:23 [65469] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
18685:09/12/17 18:00:23 [65469] Fetched 0 job ads from schedd
18686:09/12/17 18:00:23 [65469] leaving doContactSchedd()
18687:09/12/17 18:00:23 [65469] gahp server not up yet, delaying ping
18688:09/12/17 18:00:23 [65469] *** UpdateLeases called
18689:09/12/17 18:00:23 [65469]     Leases not supported, cancelling timer
18690:09/12/17 18:00:23 [65469] BaseResource::UpdateResource: 
18710:09/12/17 18:00:23 [65469] Trying to update collector <128.55.162.46:9619>
18711:09/12/17 18:00:23 [65469] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18712:09/12/17 18:00:23 [65469] File descriptor limits: max 4096, safe 3277
18713:09/12/17 18:00:23 [65469] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18714:09/12/17 18:00:23 [65469] GAHP server pid = 65472
18715:09/12/17 18:00:23 [65469] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
18716:09/12/17 18:00:23 [65469] GAHP[65472] <- 'COMMANDS'
18717:09/12/17 18:00:23 [65469] GAHP[65472] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
18718:09/12/17 18:00:23 [65469] GAHP[65472] <- 'ASYNC_MODE_ON'
18719:09/12/17 18:00:23 [65469] GAHP[65472] -> 'S' 'Async mode on'
18720:09/12/17 18:00:23 [65469] (510.0) gm state change: GM_INIT -> GM_START
18721:09/12/17 18:00:23 [65469] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18722:09/12/17 18:00:23 [65469] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18723:09/12/17 18:00:23 [65469] GAHP[65472] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
18724:09/12/17 18:00:23 [65469] GAHP[65472] -> 'S'
18725:09/12/17 18:00:23 [65469] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18726:09/12/17 18:00:23 [65469] (509.0) gm state change: GM_INIT -> GM_START
18727:09/12/17 18:00:23 [65469] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18728:09/12/17 18:00:23 [65469] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18729:09/12/17 18:00:23 [65469] GAHP[65472] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
18730:09/12/17 18:00:23 [65469] GAHP[65472] -> 'S'
18731:09/12/17 18:00:23 [65469] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18732:09/12/17 18:00:23 [65469] (508.0) gm state change: GM_INIT -> GM_START
18733:09/12/17 18:00:23 [65469] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18734:09/12/17 18:00:23 [65469] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18735:09/12/17 18:00:23 [65469] GAHP[65472] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
18736:09/12/17 18:00:23 [65469] GAHP[65472] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
18737:09/12/17 18:00:23 [65469] GAHP[65472] -> EOF
18738:09/12/17 18:00:23 [65469] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
18739:09/12/17 18:05:20 Result of reading /etc/issue:  \S
18741:09/12/17 18:05:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
18743:09/12/17 18:05:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
18744:09/12/17 18:05:20 Enumerating interfaces: lo 127.0.0.1 up
18745:09/12/17 18:05:20 Enumerating interfaces: eth0 10.36.162.46 up
18746:09/12/17 18:05:20 Enumerating interfaces: ib0 128.55.162.46 up
18747:09/12/17 18:05:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
18748:09/12/17 18:05:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
18749:09/12/17 18:05:20 ******************************************************
18750:09/12/17 18:05:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
18751:09/12/17 18:05:20 ** /usr/sbin/condor_gridmanager
18752:09/12/17 18:05:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
18753:09/12/17 18:05:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
18754:09/12/17 18:05:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
18755:09/12/17 18:05:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
18756:09/12/17 18:05:20 ** PID = 65516
18757:09/12/17 18:05:20 ** Log last touched 9/12 18:00:23
18758:09/12/17 18:05:20 ******************************************************
18759:09/12/17 18:05:20 Using config source: /etc/condor-ce/condor_config
18760:09/12/17 18:05:20 Using local config sources: 
18761:09/12/17 18:05:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
18762:09/12/17 18:05:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
18763:09/12/17 18:05:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
18764:09/12/17 18:05:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
18765:09/12/17 18:05:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
18766:09/12/17 18:05:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
18767:09/12/17 18:05:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
18768:09/12/17 18:05:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
18769:09/12/17 18:05:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
18770:09/12/17 18:05:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
18771:09/12/17 18:05:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
18772:09/12/17 18:05:20    /etc/condor-ce/config.d/01-ce-auth.conf
18773:09/12/17 18:05:20    /etc/condor-ce/config.d/01-ce-router.conf
18774:09/12/17 18:05:20    /etc/condor-ce/config.d/01-common-auth.conf
18775:09/12/17 18:05:20    /etc/condor-ce/config.d/02-ce-slurm.conf
18776:09/12/17 18:05:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
18777:09/12/17 18:05:20    /etc/condor-ce/config.d/03-managed-fork.conf
18778:09/12/17 18:05:20    /etc/condor-ce/config.d/05-ce-health.conf
18779:09/12/17 18:05:20    /etc/condor-ce/config.d/05-ce-view.conf
18780:09/12/17 18:05:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
18781:09/12/17 18:05:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
18782:09/12/17 18:05:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
18783:09/12/17 18:05:20    /etc/condor-ce/config.d/50-osg-configure.conf
18784:09/12/17 18:05:20    /etc/condor-ce/config.d/99-local.conf
18785:09/12/17 18:05:20    /usr/share/condor-ce/condor_ce_router_defaults|
18786:09/12/17 18:05:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
18787:09/12/17 18:05:20 CLASSAD_CACHING is ENABLED
18788:09/12/17 18:05:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
18789:09/12/17 18:05:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_58
18790:09/12/17 18:05:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_58>
18791:09/12/17 18:05:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_58>
18792:09/12/17 18:05:20 Setting maximum accepts per cycle 8.
18793:09/12/17 18:05:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18794:09/12/17 18:05:20 [65516] Welcome to the all-singing, all dancing, "amazing" GridManager!
18795:09/12/17 18:05:20 [65516] DaemonCore: No more children processes to reap.
18796:09/12/17 18:05:20 [65516] DaemonCore: in SendAliveToParent()
18797:09/12/17 18:05:20 [65516] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
18798:09/12/17 18:05:20 [65516] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18799:09/12/17 18:05:20 [65516] IPVERIFY: ip found is 1
18800:09/12/17 18:05:20 [65516] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
18801:09/12/17 18:05:20 [65516] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18802:09/12/17 18:05:20 [65516] IPVERIFY: ip found is 1
18803:09/12/17 18:05:20 [65516] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
18804:09/12/17 18:05:20 [65516] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18805:09/12/17 18:05:20 [65516] IPVERIFY: ip found is 1
18806:09/12/17 18:05:20 [65516] IPVERIFY: checking mc0151-ib against 128.55.162.46
18807:09/12/17 18:05:20 [65516] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
18808:09/12/17 18:05:20 [65516] IPVERIFY: ip found is 1
18809:09/12/17 18:05:20 [65516] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
18810:09/12/17 18:05:20 [65516] DaemonCore: Leaving SendAliveToParent() - success
18811:09/12/17 18:05:20 [65516] Checking proxies
18812:09/12/17 18:05:23 [65516] Received ADD_JOBS signal
18813:09/12/17 18:05:23 [65516] in doContactSchedd()
18814:09/12/17 18:05:23 [65516] querying for new jobs
18815:09/12/17 18:05:23 [65516] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
18816:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 510.0
18817:09/12/17 18:05:23 [65516] (510.0) SetJobLeaseTimers()
18818:09/12/17 18:05:23 [65516] Found job 510.0 --- inserting
18819:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 509.0
18820:09/12/17 18:05:23 [65516] (509.0) SetJobLeaseTimers()
18821:09/12/17 18:05:23 [65516] Found job 509.0 --- inserting
18822:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 508.0
18823:09/12/17 18:05:23 [65516] (508.0) SetJobLeaseTimers()
18824:09/12/17 18:05:23 [65516] Found job 508.0 --- inserting
18825:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 507.0
18826:09/12/17 18:05:23 [65516] (507.0) SetJobLeaseTimers()
18827:09/12/17 18:05:23 [65516] Found job 507.0 --- inserting
18828:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 506.0
18829:09/12/17 18:05:23 [65516] (506.0) SetJobLeaseTimers()
18830:09/12/17 18:05:23 [65516] Found job 506.0 --- inserting
18831:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 505.0
18832:09/12/17 18:05:23 [65516] (505.0) SetJobLeaseTimers()
18833:09/12/17 18:05:23 [65516] Found job 505.0 --- inserting
18834:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 504.0
18835:09/12/17 18:05:23 [65516] (504.0) SetJobLeaseTimers()
18836:09/12/17 18:05:23 [65516] Found job 504.0 --- inserting
18837:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 503.0
18838:09/12/17 18:05:23 [65516] (503.0) SetJobLeaseTimers()
18839:09/12/17 18:05:23 [65516] Found job 503.0 --- inserting
18840:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 502.0
18841:09/12/17 18:05:23 [65516] (502.0) SetJobLeaseTimers()
18842:09/12/17 18:05:23 [65516] Found job 502.0 --- inserting
18843:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 501.0
18844:09/12/17 18:05:23 [65516] (501.0) SetJobLeaseTimers()
18845:09/12/17 18:05:23 [65516] Found job 501.0 --- inserting
18846:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 500.0
18847:09/12/17 18:05:23 [65516] (500.0) SetJobLeaseTimers()
18848:09/12/17 18:05:23 [65516] Found job 500.0 --- inserting
18849:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 499.0
18850:09/12/17 18:05:23 [65516] (499.0) SetJobLeaseTimers()
18851:09/12/17 18:05:23 [65516] Found job 499.0 --- inserting
18852:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 498.0
18853:09/12/17 18:05:23 [65516] (498.0) SetJobLeaseTimers()
18854:09/12/17 18:05:23 [65516] Found job 498.0 --- inserting
18855:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 497.0
18856:09/12/17 18:05:23 [65516] (497.0) SetJobLeaseTimers()
18857:09/12/17 18:05:23 [65516] Found job 497.0 --- inserting
18858:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 496.0
18859:09/12/17 18:05:23 [65516] (496.0) SetJobLeaseTimers()
18860:09/12/17 18:05:23 [65516] Found job 496.0 --- inserting
18861:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 495.0
18862:09/12/17 18:05:23 [65516] (495.0) SetJobLeaseTimers()
18863:09/12/17 18:05:23 [65516] Found job 495.0 --- inserting
18864:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 494.0
18865:09/12/17 18:05:23 [65516] (494.0) SetJobLeaseTimers()
18866:09/12/17 18:05:23 [65516] Found job 494.0 --- inserting
18867:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 493.0
18868:09/12/17 18:05:23 [65516] (493.0) SetJobLeaseTimers()
18869:09/12/17 18:05:23 [65516] Found job 493.0 --- inserting
18870:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 492.0
18871:09/12/17 18:05:23 [65516] (492.0) SetJobLeaseTimers()
18872:09/12/17 18:05:23 [65516] Found job 492.0 --- inserting
18873:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 491.0
18874:09/12/17 18:05:23 [65516] (491.0) SetJobLeaseTimers()
18875:09/12/17 18:05:23 [65516] Found job 491.0 --- inserting
18876:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 490.0
18877:09/12/17 18:05:23 [65516] (490.0) SetJobLeaseTimers()
18878:09/12/17 18:05:23 [65516] Found job 490.0 --- inserting
18879:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 489.0
18880:09/12/17 18:05:23 [65516] (489.0) SetJobLeaseTimers()
18881:09/12/17 18:05:23 [65516] Found job 489.0 --- inserting
18882:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 488.0
18883:09/12/17 18:05:23 [65516] (488.0) SetJobLeaseTimers()
18884:09/12/17 18:05:23 [65516] Found job 488.0 --- inserting
18885:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 487.0
18886:09/12/17 18:05:23 [65516] (487.0) SetJobLeaseTimers()
18887:09/12/17 18:05:23 [65516] Found job 487.0 --- inserting
18888:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 486.0
18889:09/12/17 18:05:23 [65516] (486.0) SetJobLeaseTimers()
18890:09/12/17 18:05:23 [65516] Found job 486.0 --- inserting
18891:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 485.0
18892:09/12/17 18:05:23 [65516] (485.0) SetJobLeaseTimers()
18893:09/12/17 18:05:23 [65516] Found job 485.0 --- inserting
18894:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 484.0
18895:09/12/17 18:05:23 [65516] (484.0) SetJobLeaseTimers()
18896:09/12/17 18:05:23 [65516] Found job 484.0 --- inserting
18897:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 483.0
18898:09/12/17 18:05:23 [65516] (483.0) SetJobLeaseTimers()
18899:09/12/17 18:05:23 [65516] Found job 483.0 --- inserting
18900:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 482.0
18901:09/12/17 18:05:23 [65516] (482.0) SetJobLeaseTimers()
18902:09/12/17 18:05:23 [65516] Found job 482.0 --- inserting
18903:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 481.0
18904:09/12/17 18:05:23 [65516] (481.0) SetJobLeaseTimers()
18905:09/12/17 18:05:23 [65516] Found job 481.0 --- inserting
18906:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 480.0
18907:09/12/17 18:05:23 [65516] (480.0) SetJobLeaseTimers()
18908:09/12/17 18:05:23 [65516] Found job 480.0 --- inserting
18909:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 516.0
18910:09/12/17 18:05:23 [65516] (516.0) SetJobLeaseTimers()
18911:09/12/17 18:05:23 [65516] Found job 516.0 --- inserting
18912:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 479.0
18913:09/12/17 18:05:23 [65516] (479.0) SetJobLeaseTimers()
18914:09/12/17 18:05:23 [65516] Found job 479.0 --- inserting
18915:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 515.0
18916:09/12/17 18:05:23 [65516] (515.0) SetJobLeaseTimers()
18917:09/12/17 18:05:23 [65516] Found job 515.0 --- inserting
18918:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 478.0
18919:09/12/17 18:05:23 [65516] (478.0) SetJobLeaseTimers()
18920:09/12/17 18:05:23 [65516] Found job 478.0 --- inserting
18921:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 514.0
18922:09/12/17 18:05:23 [65516] (514.0) SetJobLeaseTimers()
18923:09/12/17 18:05:23 [65516] Found job 514.0 --- inserting
18924:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 477.0
18925:09/12/17 18:05:23 [65516] (477.0) SetJobLeaseTimers()
18926:09/12/17 18:05:23 [65516] Found job 477.0 --- inserting
18927:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 513.0
18928:09/12/17 18:05:23 [65516] (513.0) SetJobLeaseTimers()
18929:09/12/17 18:05:23 [65516] Found job 513.0 --- inserting
18930:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 512.0
18931:09/12/17 18:05:23 [65516] (512.0) SetJobLeaseTimers()
18932:09/12/17 18:05:23 [65516] Found job 512.0 --- inserting
18933:09/12/17 18:05:23 [65516] Using job type INFNBatch for job 511.0
18934:09/12/17 18:05:23 [65516] (511.0) SetJobLeaseTimers()
18935:09/12/17 18:05:23 [65516] Found job 511.0 --- inserting
18936:09/12/17 18:05:23 [65516] Fetched 40 new job ads from schedd
18937:09/12/17 18:05:23 [65516] querying for removed/held jobs
18938:09/12/17 18:05:23 [65516] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
18939:09/12/17 18:05:23 [65516] Fetched 0 job ads from schedd
18940:09/12/17 18:05:23 [65516] leaving doContactSchedd()
18941:09/12/17 18:05:23 [65516] gahp server not up yet, delaying ping
18942:09/12/17 18:05:23 [65516] *** UpdateLeases called
18943:09/12/17 18:05:23 [65516]     Leases not supported, cancelling timer
18944:09/12/17 18:05:23 [65516] BaseResource::UpdateResource: 
18964:09/12/17 18:05:23 [65516] Trying to update collector <128.55.162.46:9619>
18965:09/12/17 18:05:23 [65516] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
18966:09/12/17 18:05:23 [65516] File descriptor limits: max 4096, safe 3277
18967:09/12/17 18:05:23 [65516] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18968:09/12/17 18:05:23 [65516] GAHP server pid = 65520
18969:09/12/17 18:05:23 [65516] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
18970:09/12/17 18:05:23 [65516] GAHP[65520] <- 'COMMANDS'
18971:09/12/17 18:05:23 [65516] GAHP[65520] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
18972:09/12/17 18:05:23 [65516] GAHP[65520] <- 'ASYNC_MODE_ON'
18973:09/12/17 18:05:23 [65516] GAHP[65520] -> 'S' 'Async mode on'
18974:09/12/17 18:05:23 [65516] (510.0) gm state change: GM_INIT -> GM_START
18975:09/12/17 18:05:23 [65516] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18976:09/12/17 18:05:23 [65516] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18977:09/12/17 18:05:23 [65516] GAHP[65520] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
18978:09/12/17 18:05:23 [65516] GAHP[65520] -> 'S'
18979:09/12/17 18:05:23 [65516] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18980:09/12/17 18:05:23 [65516] (509.0) gm state change: GM_INIT -> GM_START
18981:09/12/17 18:05:23 [65516] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18982:09/12/17 18:05:23 [65516] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18983:09/12/17 18:05:23 [65516] GAHP[65520] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
18984:09/12/17 18:05:23 [65516] GAHP[65520] -> 'S'
18985:09/12/17 18:05:23 [65516] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
18986:09/12/17 18:05:23 [65516] (508.0) gm state change: GM_INIT -> GM_START
18987:09/12/17 18:05:23 [65516] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
18988:09/12/17 18:05:23 [65516] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
18989:09/12/17 18:05:23 [65516] GAHP[65520] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
18990:09/12/17 18:05:23 [65516] GAHP[65520] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
18991:09/12/17 18:05:23 [65516] GAHP[65520] -> EOF
18992:09/12/17 18:05:23 [65516] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
18993:09/12/17 18:10:20 Result of reading /etc/issue:  \S
18995:09/12/17 18:10:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
18997:09/12/17 18:10:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
18998:09/12/17 18:10:20 Enumerating interfaces: lo 127.0.0.1 up
18999:09/12/17 18:10:20 Enumerating interfaces: eth0 10.36.162.46 up
19000:09/12/17 18:10:20 Enumerating interfaces: ib0 128.55.162.46 up
19001:09/12/17 18:10:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
19002:09/12/17 18:10:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
19003:09/12/17 18:10:20 ******************************************************
19004:09/12/17 18:10:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
19005:09/12/17 18:10:20 ** /usr/sbin/condor_gridmanager
19006:09/12/17 18:10:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
19007:09/12/17 18:10:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
19008:09/12/17 18:10:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
19009:09/12/17 18:10:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
19010:09/12/17 18:10:20 ** PID = 65610
19011:09/12/17 18:10:20 ** Log last touched 9/12 18:05:23
19012:09/12/17 18:10:20 ******************************************************
19013:09/12/17 18:10:20 Using config source: /etc/condor-ce/condor_config
19014:09/12/17 18:10:20 Using local config sources: 
19015:09/12/17 18:10:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
19016:09/12/17 18:10:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
19017:09/12/17 18:10:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
19018:09/12/17 18:10:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
19019:09/12/17 18:10:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
19020:09/12/17 18:10:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
19021:09/12/17 18:10:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
19022:09/12/17 18:10:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
19023:09/12/17 18:10:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
19024:09/12/17 18:10:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
19025:09/12/17 18:10:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
19026:09/12/17 18:10:20    /etc/condor-ce/config.d/01-ce-auth.conf
19027:09/12/17 18:10:20    /etc/condor-ce/config.d/01-ce-router.conf
19028:09/12/17 18:10:20    /etc/condor-ce/config.d/01-common-auth.conf
19029:09/12/17 18:10:20    /etc/condor-ce/config.d/02-ce-slurm.conf
19030:09/12/17 18:10:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
19031:09/12/17 18:10:20    /etc/condor-ce/config.d/03-managed-fork.conf
19032:09/12/17 18:10:20    /etc/condor-ce/config.d/05-ce-health.conf
19033:09/12/17 18:10:20    /etc/condor-ce/config.d/05-ce-view.conf
19034:09/12/17 18:10:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
19035:09/12/17 18:10:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
19036:09/12/17 18:10:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
19037:09/12/17 18:10:20    /etc/condor-ce/config.d/50-osg-configure.conf
19038:09/12/17 18:10:20    /etc/condor-ce/config.d/99-local.conf
19039:09/12/17 18:10:20    /usr/share/condor-ce/condor_ce_router_defaults|
19040:09/12/17 18:10:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
19041:09/12/17 18:10:20 CLASSAD_CACHING is ENABLED
19042:09/12/17 18:10:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
19043:09/12/17 18:10:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_61
19044:09/12/17 18:10:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_61>
19045:09/12/17 18:10:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_61>
19046:09/12/17 18:10:20 Setting maximum accepts per cycle 8.
19047:09/12/17 18:10:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19048:09/12/17 18:10:20 [65610] Welcome to the all-singing, all dancing, "amazing" GridManager!
19049:09/12/17 18:10:20 [65610] DaemonCore: No more children processes to reap.
19050:09/12/17 18:10:20 [65610] DaemonCore: in SendAliveToParent()
19051:09/12/17 18:10:20 [65610] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
19052:09/12/17 18:10:20 [65610] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19053:09/12/17 18:10:20 [65610] IPVERIFY: ip found is 1
19054:09/12/17 18:10:20 [65610] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
19055:09/12/17 18:10:20 [65610] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19056:09/12/17 18:10:20 [65610] IPVERIFY: ip found is 1
19057:09/12/17 18:10:20 [65610] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
19058:09/12/17 18:10:20 [65610] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19059:09/12/17 18:10:20 [65610] IPVERIFY: ip found is 1
19060:09/12/17 18:10:20 [65610] IPVERIFY: checking mc0151-ib against 128.55.162.46
19061:09/12/17 18:10:20 [65610] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19062:09/12/17 18:10:20 [65610] IPVERIFY: ip found is 1
19063:09/12/17 18:10:20 [65610] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
19064:09/12/17 18:10:20 [65610] DaemonCore: Leaving SendAliveToParent() - success
19065:09/12/17 18:10:20 [65610] Checking proxies
19066:09/12/17 18:10:23 [65610] Received ADD_JOBS signal
19067:09/12/17 18:10:23 [65610] in doContactSchedd()
19068:09/12/17 18:10:23 [65610] querying for new jobs
19069:09/12/17 18:10:23 [65610] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
19070:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 510.0
19071:09/12/17 18:10:23 [65610] (510.0) SetJobLeaseTimers()
19072:09/12/17 18:10:23 [65610] Found job 510.0 --- inserting
19073:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 509.0
19074:09/12/17 18:10:23 [65610] (509.0) SetJobLeaseTimers()
19075:09/12/17 18:10:23 [65610] Found job 509.0 --- inserting
19076:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 508.0
19077:09/12/17 18:10:23 [65610] (508.0) SetJobLeaseTimers()
19078:09/12/17 18:10:23 [65610] Found job 508.0 --- inserting
19079:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 507.0
19080:09/12/17 18:10:23 [65610] (507.0) SetJobLeaseTimers()
19081:09/12/17 18:10:23 [65610] Found job 507.0 --- inserting
19082:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 506.0
19083:09/12/17 18:10:23 [65610] (506.0) SetJobLeaseTimers()
19084:09/12/17 18:10:23 [65610] Found job 506.0 --- inserting
19085:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 505.0
19086:09/12/17 18:10:23 [65610] (505.0) SetJobLeaseTimers()
19087:09/12/17 18:10:23 [65610] Found job 505.0 --- inserting
19088:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 504.0
19089:09/12/17 18:10:23 [65610] (504.0) SetJobLeaseTimers()
19090:09/12/17 18:10:23 [65610] Found job 504.0 --- inserting
19091:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 503.0
19092:09/12/17 18:10:23 [65610] (503.0) SetJobLeaseTimers()
19093:09/12/17 18:10:23 [65610] Found job 503.0 --- inserting
19094:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 502.0
19095:09/12/17 18:10:23 [65610] (502.0) SetJobLeaseTimers()
19096:09/12/17 18:10:23 [65610] Found job 502.0 --- inserting
19097:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 501.0
19098:09/12/17 18:10:23 [65610] (501.0) SetJobLeaseTimers()
19099:09/12/17 18:10:23 [65610] Found job 501.0 --- inserting
19100:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 500.0
19101:09/12/17 18:10:23 [65610] (500.0) SetJobLeaseTimers()
19102:09/12/17 18:10:23 [65610] Found job 500.0 --- inserting
19103:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 499.0
19104:09/12/17 18:10:23 [65610] (499.0) SetJobLeaseTimers()
19105:09/12/17 18:10:23 [65610] Found job 499.0 --- inserting
19106:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 498.0
19107:09/12/17 18:10:23 [65610] (498.0) SetJobLeaseTimers()
19108:09/12/17 18:10:23 [65610] Found job 498.0 --- inserting
19109:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 497.0
19110:09/12/17 18:10:23 [65610] (497.0) SetJobLeaseTimers()
19111:09/12/17 18:10:23 [65610] Found job 497.0 --- inserting
19112:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 496.0
19113:09/12/17 18:10:23 [65610] (496.0) SetJobLeaseTimers()
19114:09/12/17 18:10:23 [65610] Found job 496.0 --- inserting
19115:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 495.0
19116:09/12/17 18:10:23 [65610] (495.0) SetJobLeaseTimers()
19117:09/12/17 18:10:23 [65610] Found job 495.0 --- inserting
19118:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 494.0
19119:09/12/17 18:10:23 [65610] (494.0) SetJobLeaseTimers()
19120:09/12/17 18:10:23 [65610] Found job 494.0 --- inserting
19121:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 493.0
19122:09/12/17 18:10:23 [65610] (493.0) SetJobLeaseTimers()
19123:09/12/17 18:10:23 [65610] Found job 493.0 --- inserting
19124:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 492.0
19125:09/12/17 18:10:23 [65610] (492.0) SetJobLeaseTimers()
19126:09/12/17 18:10:23 [65610] Found job 492.0 --- inserting
19127:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 491.0
19128:09/12/17 18:10:23 [65610] (491.0) SetJobLeaseTimers()
19129:09/12/17 18:10:23 [65610] Found job 491.0 --- inserting
19130:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 490.0
19131:09/12/17 18:10:23 [65610] (490.0) SetJobLeaseTimers()
19132:09/12/17 18:10:23 [65610] Found job 490.0 --- inserting
19133:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 489.0
19134:09/12/17 18:10:23 [65610] (489.0) SetJobLeaseTimers()
19135:09/12/17 18:10:23 [65610] Found job 489.0 --- inserting
19136:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 488.0
19137:09/12/17 18:10:23 [65610] (488.0) SetJobLeaseTimers()
19138:09/12/17 18:10:23 [65610] Found job 488.0 --- inserting
19139:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 487.0
19140:09/12/17 18:10:23 [65610] (487.0) SetJobLeaseTimers()
19141:09/12/17 18:10:23 [65610] Found job 487.0 --- inserting
19142:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 486.0
19143:09/12/17 18:10:23 [65610] (486.0) SetJobLeaseTimers()
19144:09/12/17 18:10:23 [65610] Found job 486.0 --- inserting
19145:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 485.0
19146:09/12/17 18:10:23 [65610] (485.0) SetJobLeaseTimers()
19147:09/12/17 18:10:23 [65610] Found job 485.0 --- inserting
19148:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 484.0
19149:09/12/17 18:10:23 [65610] (484.0) SetJobLeaseTimers()
19150:09/12/17 18:10:23 [65610] Found job 484.0 --- inserting
19151:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 483.0
19152:09/12/17 18:10:23 [65610] (483.0) SetJobLeaseTimers()
19153:09/12/17 18:10:23 [65610] Found job 483.0 --- inserting
19154:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 482.0
19155:09/12/17 18:10:23 [65610] (482.0) SetJobLeaseTimers()
19156:09/12/17 18:10:23 [65610] Found job 482.0 --- inserting
19157:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 481.0
19158:09/12/17 18:10:23 [65610] (481.0) SetJobLeaseTimers()
19159:09/12/17 18:10:23 [65610] Found job 481.0 --- inserting
19160:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 480.0
19161:09/12/17 18:10:23 [65610] (480.0) SetJobLeaseTimers()
19162:09/12/17 18:10:23 [65610] Found job 480.0 --- inserting
19163:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 516.0
19164:09/12/17 18:10:23 [65610] (516.0) SetJobLeaseTimers()
19165:09/12/17 18:10:23 [65610] Found job 516.0 --- inserting
19166:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 479.0
19167:09/12/17 18:10:23 [65610] (479.0) SetJobLeaseTimers()
19168:09/12/17 18:10:23 [65610] Found job 479.0 --- inserting
19169:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 515.0
19170:09/12/17 18:10:23 [65610] (515.0) SetJobLeaseTimers()
19171:09/12/17 18:10:23 [65610] Found job 515.0 --- inserting
19172:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 478.0
19173:09/12/17 18:10:23 [65610] (478.0) SetJobLeaseTimers()
19174:09/12/17 18:10:23 [65610] Found job 478.0 --- inserting
19175:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 514.0
19176:09/12/17 18:10:23 [65610] (514.0) SetJobLeaseTimers()
19177:09/12/17 18:10:23 [65610] Found job 514.0 --- inserting
19178:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 477.0
19179:09/12/17 18:10:23 [65610] (477.0) SetJobLeaseTimers()
19180:09/12/17 18:10:23 [65610] Found job 477.0 --- inserting
19181:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 513.0
19182:09/12/17 18:10:23 [65610] (513.0) SetJobLeaseTimers()
19183:09/12/17 18:10:23 [65610] Found job 513.0 --- inserting
19184:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 512.0
19185:09/12/17 18:10:23 [65610] (512.0) SetJobLeaseTimers()
19186:09/12/17 18:10:23 [65610] Found job 512.0 --- inserting
19187:09/12/17 18:10:23 [65610] Using job type INFNBatch for job 511.0
19188:09/12/17 18:10:23 [65610] (511.0) SetJobLeaseTimers()
19189:09/12/17 18:10:23 [65610] Found job 511.0 --- inserting
19190:09/12/17 18:10:23 [65610] Fetched 40 new job ads from schedd
19191:09/12/17 18:10:23 [65610] querying for removed/held jobs
19192:09/12/17 18:10:23 [65610] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
19193:09/12/17 18:10:23 [65610] Fetched 0 job ads from schedd
19194:09/12/17 18:10:23 [65610] leaving doContactSchedd()
19195:09/12/17 18:10:23 [65610] gahp server not up yet, delaying ping
19196:09/12/17 18:10:23 [65610] *** UpdateLeases called
19197:09/12/17 18:10:23 [65610]     Leases not supported, cancelling timer
19198:09/12/17 18:10:23 [65610] BaseResource::UpdateResource: 
19218:09/12/17 18:10:23 [65610] Trying to update collector <128.55.162.46:9619>
19219:09/12/17 18:10:23 [65610] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19220:09/12/17 18:10:23 [65610] File descriptor limits: max 4096, safe 3277
19221:09/12/17 18:10:23 [65610] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19222:09/12/17 18:10:23 [65610] GAHP server pid = 65613
19223:09/12/17 18:10:23 [65610] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
19224:09/12/17 18:10:23 [65610] GAHP[65613] <- 'COMMANDS'
19225:09/12/17 18:10:23 [65610] GAHP[65613] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
19226:09/12/17 18:10:23 [65610] GAHP[65613] <- 'ASYNC_MODE_ON'
19227:09/12/17 18:10:23 [65610] GAHP[65613] -> 'S' 'Async mode on'
19228:09/12/17 18:10:23 [65610] (510.0) gm state change: GM_INIT -> GM_START
19229:09/12/17 18:10:23 [65610] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19230:09/12/17 18:10:23 [65610] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19231:09/12/17 18:10:23 [65610] GAHP[65613] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
19232:09/12/17 18:10:23 [65610] GAHP[65613] -> 'S'
19233:09/12/17 18:10:23 [65610] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19234:09/12/17 18:10:23 [65610] (509.0) gm state change: GM_INIT -> GM_START
19235:09/12/17 18:10:23 [65610] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19236:09/12/17 18:10:23 [65610] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19237:09/12/17 18:10:23 [65610] GAHP[65613] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
19238:09/12/17 18:10:23 [65610] GAHP[65613] -> 'S'
19239:09/12/17 18:10:23 [65610] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19240:09/12/17 18:10:23 [65610] (508.0) gm state change: GM_INIT -> GM_START
19241:09/12/17 18:10:23 [65610] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19242:09/12/17 18:10:23 [65610] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19243:09/12/17 18:10:23 [65610] GAHP[65613] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
19244:09/12/17 18:10:23 [65610] GAHP[65613] -> 'S'
19245:09/12/17 18:10:23 [65610] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19246:09/12/17 18:10:23 [65610] (507.0) gm state change: GM_INIT -> GM_START
19247:09/12/17 18:10:23 [65610] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19248:09/12/17 18:10:23 [65610] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19249:09/12/17 18:10:23 [65610] GAHP[65613] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
19250:09/12/17 18:10:23 [65610] GAHP[65613] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
19251:09/12/17 18:10:23 [65610] GAHP[65613] -> EOF
19252:09/12/17 18:10:23 [65610] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
19253:09/12/17 18:15:21 Result of reading /etc/issue:  \S
19255:09/12/17 18:15:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
19257:09/12/17 18:15:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
19258:09/12/17 18:15:21 Enumerating interfaces: lo 127.0.0.1 up
19259:09/12/17 18:15:21 Enumerating interfaces: eth0 10.36.162.46 up
19260:09/12/17 18:15:21 Enumerating interfaces: ib0 128.55.162.46 up
19261:09/12/17 18:15:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
19262:09/12/17 18:15:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
19263:09/12/17 18:15:21 ******************************************************
19264:09/12/17 18:15:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
19265:09/12/17 18:15:21 ** /usr/sbin/condor_gridmanager
19266:09/12/17 18:15:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
19267:09/12/17 18:15:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
19268:09/12/17 18:15:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
19269:09/12/17 18:15:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
19270:09/12/17 18:15:21 ** PID = 65656
19271:09/12/17 18:15:21 ** Log last touched 9/12 18:10:23
19272:09/12/17 18:15:21 ******************************************************
19273:09/12/17 18:15:21 Using config source: /etc/condor-ce/condor_config
19274:09/12/17 18:15:21 Using local config sources: 
19275:09/12/17 18:15:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
19276:09/12/17 18:15:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
19277:09/12/17 18:15:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
19278:09/12/17 18:15:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
19279:09/12/17 18:15:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
19280:09/12/17 18:15:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
19281:09/12/17 18:15:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
19282:09/12/17 18:15:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
19283:09/12/17 18:15:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
19284:09/12/17 18:15:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
19285:09/12/17 18:15:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
19286:09/12/17 18:15:21    /etc/condor-ce/config.d/01-ce-auth.conf
19287:09/12/17 18:15:21    /etc/condor-ce/config.d/01-ce-router.conf
19288:09/12/17 18:15:21    /etc/condor-ce/config.d/01-common-auth.conf
19289:09/12/17 18:15:21    /etc/condor-ce/config.d/02-ce-slurm.conf
19290:09/12/17 18:15:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
19291:09/12/17 18:15:21    /etc/condor-ce/config.d/03-managed-fork.conf
19292:09/12/17 18:15:21    /etc/condor-ce/config.d/05-ce-health.conf
19293:09/12/17 18:15:21    /etc/condor-ce/config.d/05-ce-view.conf
19294:09/12/17 18:15:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
19295:09/12/17 18:15:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
19296:09/12/17 18:15:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
19297:09/12/17 18:15:21    /etc/condor-ce/config.d/50-osg-configure.conf
19298:09/12/17 18:15:21    /etc/condor-ce/config.d/99-local.conf
19299:09/12/17 18:15:21    /usr/share/condor-ce/condor_ce_router_defaults|
19300:09/12/17 18:15:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
19301:09/12/17 18:15:21 CLASSAD_CACHING is ENABLED
19302:09/12/17 18:15:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
19303:09/12/17 18:15:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_64
19304:09/12/17 18:15:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_64>
19305:09/12/17 18:15:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_64>
19306:09/12/17 18:15:21 Setting maximum accepts per cycle 8.
19307:09/12/17 18:15:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19308:09/12/17 18:15:21 [65656] Welcome to the all-singing, all dancing, "amazing" GridManager!
19309:09/12/17 18:15:21 [65656] DaemonCore: No more children processes to reap.
19310:09/12/17 18:15:21 [65656] DaemonCore: in SendAliveToParent()
19311:09/12/17 18:15:21 [65656] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
19312:09/12/17 18:15:21 [65656] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19313:09/12/17 18:15:21 [65656] IPVERIFY: ip found is 1
19314:09/12/17 18:15:21 [65656] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
19315:09/12/17 18:15:21 [65656] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19316:09/12/17 18:15:21 [65656] IPVERIFY: ip found is 1
19317:09/12/17 18:15:21 [65656] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
19318:09/12/17 18:15:21 [65656] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19319:09/12/17 18:15:21 [65656] IPVERIFY: ip found is 1
19320:09/12/17 18:15:21 [65656] IPVERIFY: checking mc0151-ib against 128.55.162.46
19321:09/12/17 18:15:21 [65656] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19322:09/12/17 18:15:21 [65656] IPVERIFY: ip found is 1
19323:09/12/17 18:15:21 [65656] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
19324:09/12/17 18:15:21 [65656] DaemonCore: Leaving SendAliveToParent() - success
19325:09/12/17 18:15:21 [65656] Checking proxies
19326:09/12/17 18:15:24 [65656] Received ADD_JOBS signal
19327:09/12/17 18:15:24 [65656] in doContactSchedd()
19328:09/12/17 18:15:24 [65656] querying for new jobs
19329:09/12/17 18:15:24 [65656] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
19330:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 510.0
19331:09/12/17 18:15:24 [65656] (510.0) SetJobLeaseTimers()
19332:09/12/17 18:15:24 [65656] Found job 510.0 --- inserting
19333:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 509.0
19334:09/12/17 18:15:24 [65656] (509.0) SetJobLeaseTimers()
19335:09/12/17 18:15:24 [65656] Found job 509.0 --- inserting
19336:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 508.0
19337:09/12/17 18:15:24 [65656] (508.0) SetJobLeaseTimers()
19338:09/12/17 18:15:24 [65656] Found job 508.0 --- inserting
19339:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 507.0
19340:09/12/17 18:15:24 [65656] (507.0) SetJobLeaseTimers()
19341:09/12/17 18:15:24 [65656] Found job 507.0 --- inserting
19342:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 506.0
19343:09/12/17 18:15:24 [65656] (506.0) SetJobLeaseTimers()
19344:09/12/17 18:15:24 [65656] Found job 506.0 --- inserting
19345:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 505.0
19346:09/12/17 18:15:24 [65656] (505.0) SetJobLeaseTimers()
19347:09/12/17 18:15:24 [65656] Found job 505.0 --- inserting
19348:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 504.0
19349:09/12/17 18:15:24 [65656] (504.0) SetJobLeaseTimers()
19350:09/12/17 18:15:24 [65656] Found job 504.0 --- inserting
19351:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 503.0
19352:09/12/17 18:15:24 [65656] (503.0) SetJobLeaseTimers()
19353:09/12/17 18:15:24 [65656] Found job 503.0 --- inserting
19354:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 502.0
19355:09/12/17 18:15:24 [65656] (502.0) SetJobLeaseTimers()
19356:09/12/17 18:15:24 [65656] Found job 502.0 --- inserting
19357:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 501.0
19358:09/12/17 18:15:24 [65656] (501.0) SetJobLeaseTimers()
19359:09/12/17 18:15:24 [65656] Found job 501.0 --- inserting
19360:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 500.0
19361:09/12/17 18:15:24 [65656] (500.0) SetJobLeaseTimers()
19362:09/12/17 18:15:24 [65656] Found job 500.0 --- inserting
19363:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 499.0
19364:09/12/17 18:15:24 [65656] (499.0) SetJobLeaseTimers()
19365:09/12/17 18:15:24 [65656] Found job 499.0 --- inserting
19366:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 498.0
19367:09/12/17 18:15:24 [65656] (498.0) SetJobLeaseTimers()
19368:09/12/17 18:15:24 [65656] Found job 498.0 --- inserting
19369:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 497.0
19370:09/12/17 18:15:24 [65656] (497.0) SetJobLeaseTimers()
19371:09/12/17 18:15:24 [65656] Found job 497.0 --- inserting
19372:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 496.0
19373:09/12/17 18:15:24 [65656] (496.0) SetJobLeaseTimers()
19374:09/12/17 18:15:24 [65656] Found job 496.0 --- inserting
19375:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 495.0
19376:09/12/17 18:15:24 [65656] (495.0) SetJobLeaseTimers()
19377:09/12/17 18:15:24 [65656] Found job 495.0 --- inserting
19378:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 494.0
19379:09/12/17 18:15:24 [65656] (494.0) SetJobLeaseTimers()
19380:09/12/17 18:15:24 [65656] Found job 494.0 --- inserting
19381:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 493.0
19382:09/12/17 18:15:24 [65656] (493.0) SetJobLeaseTimers()
19383:09/12/17 18:15:24 [65656] Found job 493.0 --- inserting
19384:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 492.0
19385:09/12/17 18:15:24 [65656] (492.0) SetJobLeaseTimers()
19386:09/12/17 18:15:24 [65656] Found job 492.0 --- inserting
19387:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 491.0
19388:09/12/17 18:15:24 [65656] (491.0) SetJobLeaseTimers()
19389:09/12/17 18:15:24 [65656] Found job 491.0 --- inserting
19390:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 490.0
19391:09/12/17 18:15:24 [65656] (490.0) SetJobLeaseTimers()
19392:09/12/17 18:15:24 [65656] Found job 490.0 --- inserting
19393:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 489.0
19394:09/12/17 18:15:24 [65656] (489.0) SetJobLeaseTimers()
19395:09/12/17 18:15:24 [65656] Found job 489.0 --- inserting
19396:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 488.0
19397:09/12/17 18:15:24 [65656] (488.0) SetJobLeaseTimers()
19398:09/12/17 18:15:24 [65656] Found job 488.0 --- inserting
19399:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 487.0
19400:09/12/17 18:15:24 [65656] (487.0) SetJobLeaseTimers()
19401:09/12/17 18:15:24 [65656] Found job 487.0 --- inserting
19402:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 486.0
19403:09/12/17 18:15:24 [65656] (486.0) SetJobLeaseTimers()
19404:09/12/17 18:15:24 [65656] Found job 486.0 --- inserting
19405:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 485.0
19406:09/12/17 18:15:24 [65656] (485.0) SetJobLeaseTimers()
19407:09/12/17 18:15:24 [65656] Found job 485.0 --- inserting
19408:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 484.0
19409:09/12/17 18:15:24 [65656] (484.0) SetJobLeaseTimers()
19410:09/12/17 18:15:24 [65656] Found job 484.0 --- inserting
19411:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 483.0
19412:09/12/17 18:15:24 [65656] (483.0) SetJobLeaseTimers()
19413:09/12/17 18:15:24 [65656] Found job 483.0 --- inserting
19414:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 482.0
19415:09/12/17 18:15:24 [65656] (482.0) SetJobLeaseTimers()
19416:09/12/17 18:15:24 [65656] Found job 482.0 --- inserting
19417:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 481.0
19418:09/12/17 18:15:24 [65656] (481.0) SetJobLeaseTimers()
19419:09/12/17 18:15:24 [65656] Found job 481.0 --- inserting
19420:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 480.0
19421:09/12/17 18:15:24 [65656] (480.0) SetJobLeaseTimers()
19422:09/12/17 18:15:24 [65656] Found job 480.0 --- inserting
19423:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 516.0
19424:09/12/17 18:15:24 [65656] (516.0) SetJobLeaseTimers()
19425:09/12/17 18:15:24 [65656] Found job 516.0 --- inserting
19426:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 479.0
19427:09/12/17 18:15:24 [65656] (479.0) SetJobLeaseTimers()
19428:09/12/17 18:15:24 [65656] Found job 479.0 --- inserting
19429:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 515.0
19430:09/12/17 18:15:24 [65656] (515.0) SetJobLeaseTimers()
19431:09/12/17 18:15:24 [65656] Found job 515.0 --- inserting
19432:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 478.0
19433:09/12/17 18:15:24 [65656] (478.0) SetJobLeaseTimers()
19434:09/12/17 18:15:24 [65656] Found job 478.0 --- inserting
19435:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 514.0
19436:09/12/17 18:15:24 [65656] (514.0) SetJobLeaseTimers()
19437:09/12/17 18:15:24 [65656] Found job 514.0 --- inserting
19438:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 477.0
19439:09/12/17 18:15:24 [65656] (477.0) SetJobLeaseTimers()
19440:09/12/17 18:15:24 [65656] Found job 477.0 --- inserting
19441:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 513.0
19442:09/12/17 18:15:24 [65656] (513.0) SetJobLeaseTimers()
19443:09/12/17 18:15:24 [65656] Found job 513.0 --- inserting
19444:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 512.0
19445:09/12/17 18:15:24 [65656] (512.0) SetJobLeaseTimers()
19446:09/12/17 18:15:24 [65656] Found job 512.0 --- inserting
19447:09/12/17 18:15:24 [65656] Using job type INFNBatch for job 511.0
19448:09/12/17 18:15:24 [65656] (511.0) SetJobLeaseTimers()
19449:09/12/17 18:15:24 [65656] Found job 511.0 --- inserting
19450:09/12/17 18:15:24 [65656] Fetched 40 new job ads from schedd
19451:09/12/17 18:15:24 [65656] querying for removed/held jobs
19452:09/12/17 18:15:24 [65656] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
19453:09/12/17 18:15:24 [65656] Fetched 0 job ads from schedd
19454:09/12/17 18:15:24 [65656] leaving doContactSchedd()
19455:09/12/17 18:15:24 [65656] gahp server not up yet, delaying ping
19456:09/12/17 18:15:24 [65656] *** UpdateLeases called
19457:09/12/17 18:15:24 [65656]     Leases not supported, cancelling timer
19458:09/12/17 18:15:24 [65656] BaseResource::UpdateResource: 
19478:09/12/17 18:15:24 [65656] Trying to update collector <128.55.162.46:9619>
19479:09/12/17 18:15:24 [65656] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19480:09/12/17 18:15:24 [65656] File descriptor limits: max 4096, safe 3277
19481:09/12/17 18:15:24 [65656] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19482:09/12/17 18:15:24 [65656] GAHP server pid = 65659
19483:09/12/17 18:15:24 [65656] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
19484:09/12/17 18:15:24 [65656] GAHP[65659] <- 'COMMANDS'
19485:09/12/17 18:15:24 [65656] GAHP[65659] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
19486:09/12/17 18:15:24 [65656] GAHP[65659] <- 'ASYNC_MODE_ON'
19487:09/12/17 18:15:24 [65656] GAHP[65659] -> 'S' 'Async mode on'
19488:09/12/17 18:15:24 [65656] (510.0) gm state change: GM_INIT -> GM_START
19489:09/12/17 18:15:24 [65656] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19490:09/12/17 18:15:24 [65656] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19491:09/12/17 18:15:24 [65656] GAHP[65659] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
19492:09/12/17 18:15:24 [65656] GAHP[65659] -> 'S'
19493:09/12/17 18:15:24 [65656] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19494:09/12/17 18:15:24 [65656] (509.0) gm state change: GM_INIT -> GM_START
19495:09/12/17 18:15:24 [65656] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19496:09/12/17 18:15:24 [65656] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19497:09/12/17 18:15:24 [65656] GAHP[65659] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
19498:09/12/17 18:15:24 [65656] GAHP[65659] -> 'S'
19499:09/12/17 18:15:24 [65656] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19500:09/12/17 18:15:24 [65656] (508.0) gm state change: GM_INIT -> GM_START
19501:09/12/17 18:15:24 [65656] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19502:09/12/17 18:15:24 [65656] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19503:09/12/17 18:15:24 [65656] GAHP[65659] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
19504:09/12/17 18:15:24 [65656] GAHP[65659] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
19505:09/12/17 18:15:24 [65656] GAHP[65659] -> EOF
19506:09/12/17 18:15:24 [65656] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
19507:09/12/17 18:20:22 Result of reading /etc/issue:  \S
19509:09/12/17 18:20:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
19511:09/12/17 18:20:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
19512:09/12/17 18:20:22 Enumerating interfaces: lo 127.0.0.1 up
19513:09/12/17 18:20:22 Enumerating interfaces: eth0 10.36.162.46 up
19514:09/12/17 18:20:22 Enumerating interfaces: ib0 128.55.162.46 up
19515:09/12/17 18:20:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
19516:09/12/17 18:20:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
19517:09/12/17 18:20:22 ******************************************************
19518:09/12/17 18:20:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
19519:09/12/17 18:20:22 ** /usr/sbin/condor_gridmanager
19520:09/12/17 18:20:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
19521:09/12/17 18:20:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
19522:09/12/17 18:20:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
19523:09/12/17 18:20:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
19524:09/12/17 18:20:22 ** PID = 65696
19525:09/12/17 18:20:22 ** Log last touched 9/12 18:15:24
19526:09/12/17 18:20:22 ******************************************************
19527:09/12/17 18:20:22 Using config source: /etc/condor-ce/condor_config
19528:09/12/17 18:20:22 Using local config sources: 
19529:09/12/17 18:20:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
19530:09/12/17 18:20:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
19531:09/12/17 18:20:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
19532:09/12/17 18:20:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
19533:09/12/17 18:20:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
19534:09/12/17 18:20:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
19535:09/12/17 18:20:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
19536:09/12/17 18:20:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
19537:09/12/17 18:20:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
19538:09/12/17 18:20:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
19539:09/12/17 18:20:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
19540:09/12/17 18:20:22    /etc/condor-ce/config.d/01-ce-auth.conf
19541:09/12/17 18:20:22    /etc/condor-ce/config.d/01-ce-router.conf
19542:09/12/17 18:20:22    /etc/condor-ce/config.d/01-common-auth.conf
19543:09/12/17 18:20:22    /etc/condor-ce/config.d/02-ce-slurm.conf
19544:09/12/17 18:20:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
19545:09/12/17 18:20:22    /etc/condor-ce/config.d/03-managed-fork.conf
19546:09/12/17 18:20:22    /etc/condor-ce/config.d/05-ce-health.conf
19547:09/12/17 18:20:22    /etc/condor-ce/config.d/05-ce-view.conf
19548:09/12/17 18:20:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
19549:09/12/17 18:20:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
19550:09/12/17 18:20:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
19551:09/12/17 18:20:22    /etc/condor-ce/config.d/50-osg-configure.conf
19552:09/12/17 18:20:22    /etc/condor-ce/config.d/99-local.conf
19553:09/12/17 18:20:22    /usr/share/condor-ce/condor_ce_router_defaults|
19554:09/12/17 18:20:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
19555:09/12/17 18:20:22 CLASSAD_CACHING is ENABLED
19556:09/12/17 18:20:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
19557:09/12/17 18:20:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_66
19558:09/12/17 18:20:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_66>
19559:09/12/17 18:20:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_66>
19560:09/12/17 18:20:22 Setting maximum accepts per cycle 8.
19561:09/12/17 18:20:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19562:09/12/17 18:20:22 [65696] Welcome to the all-singing, all dancing, "amazing" GridManager!
19563:09/12/17 18:20:22 [65696] DaemonCore: No more children processes to reap.
19564:09/12/17 18:20:22 [65696] DaemonCore: in SendAliveToParent()
19565:09/12/17 18:20:22 [65696] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
19566:09/12/17 18:20:22 [65696] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19567:09/12/17 18:20:22 [65696] IPVERIFY: ip found is 1
19568:09/12/17 18:20:22 [65696] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
19569:09/12/17 18:20:22 [65696] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19570:09/12/17 18:20:22 [65696] IPVERIFY: ip found is 1
19571:09/12/17 18:20:22 [65696] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
19572:09/12/17 18:20:22 [65696] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19573:09/12/17 18:20:22 [65696] IPVERIFY: ip found is 1
19574:09/12/17 18:20:22 [65696] IPVERIFY: checking mc0151-ib against 128.55.162.46
19575:09/12/17 18:20:22 [65696] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19576:09/12/17 18:20:22 [65696] IPVERIFY: ip found is 1
19577:09/12/17 18:20:22 [65696] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
19578:09/12/17 18:20:22 [65696] DaemonCore: Leaving SendAliveToParent() - success
19579:09/12/17 18:20:22 [65696] Checking proxies
19580:09/12/17 18:20:25 [65696] Received ADD_JOBS signal
19581:09/12/17 18:20:25 [65696] in doContactSchedd()
19582:09/12/17 18:20:25 [65696] querying for new jobs
19583:09/12/17 18:20:25 [65696] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
19584:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 510.0
19585:09/12/17 18:20:25 [65696] (510.0) SetJobLeaseTimers()
19586:09/12/17 18:20:25 [65696] Found job 510.0 --- inserting
19587:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 509.0
19588:09/12/17 18:20:25 [65696] (509.0) SetJobLeaseTimers()
19589:09/12/17 18:20:25 [65696] Found job 509.0 --- inserting
19590:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 508.0
19591:09/12/17 18:20:25 [65696] (508.0) SetJobLeaseTimers()
19592:09/12/17 18:20:25 [65696] Found job 508.0 --- inserting
19593:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 507.0
19594:09/12/17 18:20:25 [65696] (507.0) SetJobLeaseTimers()
19595:09/12/17 18:20:25 [65696] Found job 507.0 --- inserting
19596:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 506.0
19597:09/12/17 18:20:25 [65696] (506.0) SetJobLeaseTimers()
19598:09/12/17 18:20:25 [65696] Found job 506.0 --- inserting
19599:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 505.0
19600:09/12/17 18:20:25 [65696] (505.0) SetJobLeaseTimers()
19601:09/12/17 18:20:25 [65696] Found job 505.0 --- inserting
19602:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 504.0
19603:09/12/17 18:20:25 [65696] (504.0) SetJobLeaseTimers()
19604:09/12/17 18:20:25 [65696] Found job 504.0 --- inserting
19605:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 503.0
19606:09/12/17 18:20:25 [65696] (503.0) SetJobLeaseTimers()
19607:09/12/17 18:20:25 [65696] Found job 503.0 --- inserting
19608:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 502.0
19609:09/12/17 18:20:25 [65696] (502.0) SetJobLeaseTimers()
19610:09/12/17 18:20:25 [65696] Found job 502.0 --- inserting
19611:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 501.0
19612:09/12/17 18:20:25 [65696] (501.0) SetJobLeaseTimers()
19613:09/12/17 18:20:25 [65696] Found job 501.0 --- inserting
19614:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 500.0
19615:09/12/17 18:20:25 [65696] (500.0) SetJobLeaseTimers()
19616:09/12/17 18:20:25 [65696] Found job 500.0 --- inserting
19617:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 499.0
19618:09/12/17 18:20:25 [65696] (499.0) SetJobLeaseTimers()
19619:09/12/17 18:20:25 [65696] Found job 499.0 --- inserting
19620:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 498.0
19621:09/12/17 18:20:25 [65696] (498.0) SetJobLeaseTimers()
19622:09/12/17 18:20:25 [65696] Found job 498.0 --- inserting
19623:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 497.0
19624:09/12/17 18:20:25 [65696] (497.0) SetJobLeaseTimers()
19625:09/12/17 18:20:25 [65696] Found job 497.0 --- inserting
19626:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 496.0
19627:09/12/17 18:20:25 [65696] (496.0) SetJobLeaseTimers()
19628:09/12/17 18:20:25 [65696] Found job 496.0 --- inserting
19629:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 495.0
19630:09/12/17 18:20:25 [65696] (495.0) SetJobLeaseTimers()
19631:09/12/17 18:20:25 [65696] Found job 495.0 --- inserting
19632:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 494.0
19633:09/12/17 18:20:25 [65696] (494.0) SetJobLeaseTimers()
19634:09/12/17 18:20:25 [65696] Found job 494.0 --- inserting
19635:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 493.0
19636:09/12/17 18:20:25 [65696] (493.0) SetJobLeaseTimers()
19637:09/12/17 18:20:25 [65696] Found job 493.0 --- inserting
19638:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 492.0
19639:09/12/17 18:20:25 [65696] (492.0) SetJobLeaseTimers()
19640:09/12/17 18:20:25 [65696] Found job 492.0 --- inserting
19641:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 491.0
19642:09/12/17 18:20:25 [65696] (491.0) SetJobLeaseTimers()
19643:09/12/17 18:20:25 [65696] Found job 491.0 --- inserting
19644:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 490.0
19645:09/12/17 18:20:25 [65696] (490.0) SetJobLeaseTimers()
19646:09/12/17 18:20:25 [65696] Found job 490.0 --- inserting
19647:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 489.0
19648:09/12/17 18:20:25 [65696] (489.0) SetJobLeaseTimers()
19649:09/12/17 18:20:25 [65696] Found job 489.0 --- inserting
19650:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 488.0
19651:09/12/17 18:20:25 [65696] (488.0) SetJobLeaseTimers()
19652:09/12/17 18:20:25 [65696] Found job 488.0 --- inserting
19653:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 487.0
19654:09/12/17 18:20:25 [65696] (487.0) SetJobLeaseTimers()
19655:09/12/17 18:20:25 [65696] Found job 487.0 --- inserting
19656:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 486.0
19657:09/12/17 18:20:25 [65696] (486.0) SetJobLeaseTimers()
19658:09/12/17 18:20:25 [65696] Found job 486.0 --- inserting
19659:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 485.0
19660:09/12/17 18:20:25 [65696] (485.0) SetJobLeaseTimers()
19661:09/12/17 18:20:25 [65696] Found job 485.0 --- inserting
19662:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 484.0
19663:09/12/17 18:20:25 [65696] (484.0) SetJobLeaseTimers()
19664:09/12/17 18:20:25 [65696] Found job 484.0 --- inserting
19665:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 483.0
19666:09/12/17 18:20:25 [65696] (483.0) SetJobLeaseTimers()
19667:09/12/17 18:20:25 [65696] Found job 483.0 --- inserting
19668:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 482.0
19669:09/12/17 18:20:25 [65696] (482.0) SetJobLeaseTimers()
19670:09/12/17 18:20:25 [65696] Found job 482.0 --- inserting
19671:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 481.0
19672:09/12/17 18:20:25 [65696] (481.0) SetJobLeaseTimers()
19673:09/12/17 18:20:25 [65696] Found job 481.0 --- inserting
19674:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 480.0
19675:09/12/17 18:20:25 [65696] (480.0) SetJobLeaseTimers()
19676:09/12/17 18:20:25 [65696] Found job 480.0 --- inserting
19677:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 516.0
19678:09/12/17 18:20:25 [65696] (516.0) SetJobLeaseTimers()
19679:09/12/17 18:20:25 [65696] Found job 516.0 --- inserting
19680:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 479.0
19681:09/12/17 18:20:25 [65696] (479.0) SetJobLeaseTimers()
19682:09/12/17 18:20:25 [65696] Found job 479.0 --- inserting
19683:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 515.0
19684:09/12/17 18:20:25 [65696] (515.0) SetJobLeaseTimers()
19685:09/12/17 18:20:25 [65696] Found job 515.0 --- inserting
19686:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 478.0
19687:09/12/17 18:20:25 [65696] (478.0) SetJobLeaseTimers()
19688:09/12/17 18:20:25 [65696] Found job 478.0 --- inserting
19689:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 514.0
19690:09/12/17 18:20:25 [65696] (514.0) SetJobLeaseTimers()
19691:09/12/17 18:20:25 [65696] Found job 514.0 --- inserting
19692:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 477.0
19693:09/12/17 18:20:25 [65696] (477.0) SetJobLeaseTimers()
19694:09/12/17 18:20:25 [65696] Found job 477.0 --- inserting
19695:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 513.0
19696:09/12/17 18:20:25 [65696] (513.0) SetJobLeaseTimers()
19697:09/12/17 18:20:25 [65696] Found job 513.0 --- inserting
19698:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 512.0
19699:09/12/17 18:20:25 [65696] (512.0) SetJobLeaseTimers()
19700:09/12/17 18:20:25 [65696] Found job 512.0 --- inserting
19701:09/12/17 18:20:25 [65696] Using job type INFNBatch for job 511.0
19702:09/12/17 18:20:25 [65696] (511.0) SetJobLeaseTimers()
19703:09/12/17 18:20:25 [65696] Found job 511.0 --- inserting
19704:09/12/17 18:20:25 [65696] Fetched 40 new job ads from schedd
19705:09/12/17 18:20:25 [65696] querying for removed/held jobs
19706:09/12/17 18:20:25 [65696] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
19707:09/12/17 18:20:25 [65696] Fetched 0 job ads from schedd
19708:09/12/17 18:20:25 [65696] leaving doContactSchedd()
19709:09/12/17 18:20:25 [65696] gahp server not up yet, delaying ping
19710:09/12/17 18:20:25 [65696] *** UpdateLeases called
19711:09/12/17 18:20:25 [65696]     Leases not supported, cancelling timer
19712:09/12/17 18:20:25 [65696] BaseResource::UpdateResource: 
19732:09/12/17 18:20:25 [65696] Trying to update collector <128.55.162.46:9619>
19733:09/12/17 18:20:25 [65696] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19734:09/12/17 18:20:25 [65696] File descriptor limits: max 4096, safe 3277
19735:09/12/17 18:20:25 [65696] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19736:09/12/17 18:20:25 [65696] GAHP server pid = 65699
19737:09/12/17 18:20:26 [65696] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
19738:09/12/17 18:20:26 [65696] GAHP[65699] <- 'COMMANDS'
19739:09/12/17 18:20:26 [65696] GAHP[65699] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
19740:09/12/17 18:20:26 [65696] GAHP[65699] <- 'ASYNC_MODE_ON'
19741:09/12/17 18:20:26 [65696] GAHP[65699] -> 'S' 'Async mode on'
19742:09/12/17 18:20:26 [65696] (510.0) gm state change: GM_INIT -> GM_START
19743:09/12/17 18:20:26 [65696] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19744:09/12/17 18:20:26 [65696] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19745:09/12/17 18:20:26 [65696] GAHP[65699] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
19746:09/12/17 18:20:26 [65696] GAHP[65699] -> 'S'
19747:09/12/17 18:20:26 [65696] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19748:09/12/17 18:20:26 [65696] (509.0) gm state change: GM_INIT -> GM_START
19749:09/12/17 18:20:26 [65696] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19750:09/12/17 18:20:26 [65696] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19751:09/12/17 18:20:26 [65696] GAHP[65699] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
19752:09/12/17 18:20:26 [65696] GAHP[65699] -> 'S'
19753:09/12/17 18:20:26 [65696] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19754:09/12/17 18:20:26 [65696] (508.0) gm state change: GM_INIT -> GM_START
19755:09/12/17 18:20:26 [65696] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19756:09/12/17 18:20:26 [65696] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19757:09/12/17 18:20:26 [65696] GAHP[65699] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
19758:09/12/17 18:20:26 [65696] GAHP[65699] -> 'S'
19759:09/12/17 18:20:26 [65696] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19760:09/12/17 18:20:26 [65696] (507.0) gm state change: GM_INIT -> GM_START
19761:09/12/17 18:20:26 [65696] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
19762:09/12/17 18:20:26 [65696] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
19763:09/12/17 18:20:26 [65696] GAHP[65699] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
19764:09/12/17 18:20:26 [65696] GAHP[65699] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
19765:09/12/17 18:20:26 [65696] GAHP[65699] -> EOF
19766:09/12/17 18:20:26 [65696] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
19767:09/12/17 18:25:23 Result of reading /etc/issue:  \S
19769:09/12/17 18:25:23 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
19771:09/12/17 18:25:23 Using IDs: 32 processors, 16 CPUs, 16 HTs
19772:09/12/17 18:25:23 Enumerating interfaces: lo 127.0.0.1 up
19773:09/12/17 18:25:23 Enumerating interfaces: eth0 10.36.162.46 up
19774:09/12/17 18:25:23 Enumerating interfaces: ib0 128.55.162.46 up
19775:09/12/17 18:25:23 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
19776:09/12/17 18:25:23 Initializing Directory: curr_dir = /etc/condor-ce/config.d
19777:09/12/17 18:25:23 ******************************************************
19778:09/12/17 18:25:23 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
19779:09/12/17 18:25:23 ** /usr/sbin/condor_gridmanager
19780:09/12/17 18:25:23 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
19781:09/12/17 18:25:23 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
19782:09/12/17 18:25:23 ** $CondorVersion: 8.4.12 Aug 07 2017 $
19783:09/12/17 18:25:23 ** $CondorPlatform: X86_64-CentOS_7.3 $
19784:09/12/17 18:25:23 ** PID = 65749
19785:09/12/17 18:25:23 ** Log last touched 9/12 18:20:26
19786:09/12/17 18:25:23 ******************************************************
19787:09/12/17 18:25:23 Using config source: /etc/condor-ce/condor_config
19788:09/12/17 18:25:23 Using local config sources: 
19789:09/12/17 18:25:23    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
19790:09/12/17 18:25:23    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
19791:09/12/17 18:25:23    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
19792:09/12/17 18:25:23    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
19793:09/12/17 18:25:23    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
19794:09/12/17 18:25:23    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
19795:09/12/17 18:25:23    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
19796:09/12/17 18:25:23    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
19797:09/12/17 18:25:23    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
19798:09/12/17 18:25:23    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
19799:09/12/17 18:25:23    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
19800:09/12/17 18:25:23    /etc/condor-ce/config.d/01-ce-auth.conf
19801:09/12/17 18:25:23    /etc/condor-ce/config.d/01-ce-router.conf
19802:09/12/17 18:25:23    /etc/condor-ce/config.d/01-common-auth.conf
19803:09/12/17 18:25:23    /etc/condor-ce/config.d/02-ce-slurm.conf
19804:09/12/17 18:25:23    /etc/condor-ce/config.d/03-ce-shared-port.conf
19805:09/12/17 18:25:23    /etc/condor-ce/config.d/03-managed-fork.conf
19806:09/12/17 18:25:23    /etc/condor-ce/config.d/05-ce-health.conf
19807:09/12/17 18:25:23    /etc/condor-ce/config.d/05-ce-view.conf
19808:09/12/17 18:25:23    /etc/condor-ce/config.d/10-ce-collector-generated.conf
19809:09/12/17 18:25:23    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
19810:09/12/17 18:25:23    /etc/condor-ce/config.d/50-osg-configure-present.conf
19811:09/12/17 18:25:23    /etc/condor-ce/config.d/50-osg-configure.conf
19812:09/12/17 18:25:23    /etc/condor-ce/config.d/99-local.conf
19813:09/12/17 18:25:23    /usr/share/condor-ce/condor_ce_router_defaults|
19814:09/12/17 18:25:23 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
19815:09/12/17 18:25:23 CLASSAD_CACHING is ENABLED
19816:09/12/17 18:25:23 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
19817:09/12/17 18:25:23 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_69
19818:09/12/17 18:25:23 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_69>
19819:09/12/17 18:25:23 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_69>
19820:09/12/17 18:25:23 Setting maximum accepts per cycle 8.
19821:09/12/17 18:25:23 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19822:09/12/17 18:25:23 [65749] Welcome to the all-singing, all dancing, "amazing" GridManager!
19823:09/12/17 18:25:23 [65749] DaemonCore: No more children processes to reap.
19824:09/12/17 18:25:23 [65749] DaemonCore: in SendAliveToParent()
19825:09/12/17 18:25:23 [65749] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
19826:09/12/17 18:25:23 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19827:09/12/17 18:25:23 [65749] IPVERIFY: ip found is 1
19828:09/12/17 18:25:23 [65749] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
19829:09/12/17 18:25:23 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19830:09/12/17 18:25:23 [65749] IPVERIFY: ip found is 1
19831:09/12/17 18:25:23 [65749] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
19832:09/12/17 18:25:23 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19833:09/12/17 18:25:23 [65749] IPVERIFY: ip found is 1
19834:09/12/17 18:25:23 [65749] IPVERIFY: checking mc0151-ib against 128.55.162.46
19835:09/12/17 18:25:23 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
19836:09/12/17 18:25:23 [65749] IPVERIFY: ip found is 1
19837:09/12/17 18:25:23 [65749] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
19838:09/12/17 18:25:23 [65749] DaemonCore: Leaving SendAliveToParent() - success
19839:09/12/17 18:25:23 [65749] Checking proxies
19840:09/12/17 18:25:26 [65749] Received ADD_JOBS signal
19841:09/12/17 18:25:26 [65749] in doContactSchedd()
19842:09/12/17 18:25:26 [65749] querying for new jobs
19843:09/12/17 18:25:26 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
19844:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 510.0
19845:09/12/17 18:25:26 [65749] (510.0) SetJobLeaseTimers()
19846:09/12/17 18:25:26 [65749] Found job 510.0 --- inserting
19847:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 509.0
19848:09/12/17 18:25:26 [65749] (509.0) SetJobLeaseTimers()
19849:09/12/17 18:25:26 [65749] Found job 509.0 --- inserting
19850:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 508.0
19851:09/12/17 18:25:26 [65749] (508.0) SetJobLeaseTimers()
19852:09/12/17 18:25:26 [65749] Found job 508.0 --- inserting
19853:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 507.0
19854:09/12/17 18:25:26 [65749] (507.0) SetJobLeaseTimers()
19855:09/12/17 18:25:26 [65749] Found job 507.0 --- inserting
19856:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 506.0
19857:09/12/17 18:25:26 [65749] (506.0) SetJobLeaseTimers()
19858:09/12/17 18:25:26 [65749] Found job 506.0 --- inserting
19859:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 505.0
19860:09/12/17 18:25:26 [65749] (505.0) SetJobLeaseTimers()
19861:09/12/17 18:25:26 [65749] Found job 505.0 --- inserting
19862:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 504.0
19863:09/12/17 18:25:26 [65749] (504.0) SetJobLeaseTimers()
19864:09/12/17 18:25:26 [65749] Found job 504.0 --- inserting
19865:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 503.0
19866:09/12/17 18:25:26 [65749] (503.0) SetJobLeaseTimers()
19867:09/12/17 18:25:26 [65749] Found job 503.0 --- inserting
19868:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 502.0
19869:09/12/17 18:25:26 [65749] (502.0) SetJobLeaseTimers()
19870:09/12/17 18:25:26 [65749] Found job 502.0 --- inserting
19871:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 501.0
19872:09/12/17 18:25:26 [65749] (501.0) SetJobLeaseTimers()
19873:09/12/17 18:25:26 [65749] Found job 501.0 --- inserting
19874:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 500.0
19875:09/12/17 18:25:26 [65749] (500.0) SetJobLeaseTimers()
19876:09/12/17 18:25:26 [65749] Found job 500.0 --- inserting
19877:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 499.0
19878:09/12/17 18:25:26 [65749] (499.0) SetJobLeaseTimers()
19879:09/12/17 18:25:26 [65749] Found job 499.0 --- inserting
19880:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 498.0
19881:09/12/17 18:25:26 [65749] (498.0) SetJobLeaseTimers()
19882:09/12/17 18:25:26 [65749] Found job 498.0 --- inserting
19883:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 497.0
19884:09/12/17 18:25:26 [65749] (497.0) SetJobLeaseTimers()
19885:09/12/17 18:25:26 [65749] Found job 497.0 --- inserting
19886:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 496.0
19887:09/12/17 18:25:26 [65749] (496.0) SetJobLeaseTimers()
19888:09/12/17 18:25:26 [65749] Found job 496.0 --- inserting
19889:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 495.0
19890:09/12/17 18:25:26 [65749] (495.0) SetJobLeaseTimers()
19891:09/12/17 18:25:26 [65749] Found job 495.0 --- inserting
19892:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 494.0
19893:09/12/17 18:25:26 [65749] (494.0) SetJobLeaseTimers()
19894:09/12/17 18:25:26 [65749] Found job 494.0 --- inserting
19895:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 493.0
19896:09/12/17 18:25:26 [65749] (493.0) SetJobLeaseTimers()
19897:09/12/17 18:25:26 [65749] Found job 493.0 --- inserting
19898:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 492.0
19899:09/12/17 18:25:26 [65749] (492.0) SetJobLeaseTimers()
19900:09/12/17 18:25:26 [65749] Found job 492.0 --- inserting
19901:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 491.0
19902:09/12/17 18:25:26 [65749] (491.0) SetJobLeaseTimers()
19903:09/12/17 18:25:26 [65749] Found job 491.0 --- inserting
19904:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 490.0
19905:09/12/17 18:25:26 [65749] (490.0) SetJobLeaseTimers()
19906:09/12/17 18:25:26 [65749] Found job 490.0 --- inserting
19907:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 489.0
19908:09/12/17 18:25:26 [65749] (489.0) SetJobLeaseTimers()
19909:09/12/17 18:25:26 [65749] Found job 489.0 --- inserting
19910:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 488.0
19911:09/12/17 18:25:26 [65749] (488.0) SetJobLeaseTimers()
19912:09/12/17 18:25:26 [65749] Found job 488.0 --- inserting
19913:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 487.0
19914:09/12/17 18:25:26 [65749] (487.0) SetJobLeaseTimers()
19915:09/12/17 18:25:26 [65749] Found job 487.0 --- inserting
19916:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 486.0
19917:09/12/17 18:25:26 [65749] (486.0) SetJobLeaseTimers()
19918:09/12/17 18:25:26 [65749] Found job 486.0 --- inserting
19919:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 485.0
19920:09/12/17 18:25:26 [65749] (485.0) SetJobLeaseTimers()
19921:09/12/17 18:25:26 [65749] Found job 485.0 --- inserting
19922:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 484.0
19923:09/12/17 18:25:26 [65749] (484.0) SetJobLeaseTimers()
19924:09/12/17 18:25:26 [65749] Found job 484.0 --- inserting
19925:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 483.0
19926:09/12/17 18:25:26 [65749] (483.0) SetJobLeaseTimers()
19927:09/12/17 18:25:26 [65749] Found job 483.0 --- inserting
19928:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 482.0
19929:09/12/17 18:25:26 [65749] (482.0) SetJobLeaseTimers()
19930:09/12/17 18:25:26 [65749] Found job 482.0 --- inserting
19931:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 481.0
19932:09/12/17 18:25:26 [65749] (481.0) SetJobLeaseTimers()
19933:09/12/17 18:25:26 [65749] Found job 481.0 --- inserting
19934:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 480.0
19935:09/12/17 18:25:26 [65749] (480.0) SetJobLeaseTimers()
19936:09/12/17 18:25:26 [65749] Found job 480.0 --- inserting
19937:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 516.0
19938:09/12/17 18:25:26 [65749] (516.0) SetJobLeaseTimers()
19939:09/12/17 18:25:26 [65749] Found job 516.0 --- inserting
19940:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 479.0
19941:09/12/17 18:25:26 [65749] (479.0) SetJobLeaseTimers()
19942:09/12/17 18:25:26 [65749] Found job 479.0 --- inserting
19943:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 515.0
19944:09/12/17 18:25:26 [65749] (515.0) SetJobLeaseTimers()
19945:09/12/17 18:25:26 [65749] Found job 515.0 --- inserting
19946:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 478.0
19947:09/12/17 18:25:26 [65749] (478.0) SetJobLeaseTimers()
19948:09/12/17 18:25:26 [65749] Found job 478.0 --- inserting
19949:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 514.0
19950:09/12/17 18:25:26 [65749] (514.0) SetJobLeaseTimers()
19951:09/12/17 18:25:26 [65749] Found job 514.0 --- inserting
19952:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 477.0
19953:09/12/17 18:25:26 [65749] (477.0) SetJobLeaseTimers()
19954:09/12/17 18:25:26 [65749] Found job 477.0 --- inserting
19955:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 513.0
19956:09/12/17 18:25:26 [65749] (513.0) SetJobLeaseTimers()
19957:09/12/17 18:25:26 [65749] Found job 513.0 --- inserting
19958:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 512.0
19959:09/12/17 18:25:26 [65749] (512.0) SetJobLeaseTimers()
19960:09/12/17 18:25:26 [65749] Found job 512.0 --- inserting
19961:09/12/17 18:25:26 [65749] Using job type INFNBatch for job 511.0
19962:09/12/17 18:25:26 [65749] (511.0) SetJobLeaseTimers()
19963:09/12/17 18:25:26 [65749] Found job 511.0 --- inserting
19964:09/12/17 18:25:26 [65749] Fetched 40 new job ads from schedd
19965:09/12/17 18:25:26 [65749] querying for removed/held jobs
19966:09/12/17 18:25:26 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
19967:09/12/17 18:25:26 [65749] Fetched 0 job ads from schedd
19968:09/12/17 18:25:26 [65749] leaving doContactSchedd()
19969:09/12/17 18:25:26 [65749] gahp server not up yet, delaying ping
19970:09/12/17 18:25:26 [65749] *** UpdateLeases called
19971:09/12/17 18:25:26 [65749]     Leases not supported, cancelling timer
19972:09/12/17 18:25:26 [65749] BaseResource::UpdateResource: 
19992:09/12/17 18:25:26 [65749] Trying to update collector <128.55.162.46:9619>
19993:09/12/17 18:25:26 [65749] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
19994:09/12/17 18:25:26 [65749] File descriptor limits: max 4096, safe 3277
19995:09/12/17 18:25:26 [65749] (510.0) doEvaluateState called: gmState GM_INIT, remoteState -1
19996:09/12/17 18:25:26 [65749] GAHP server pid = 65752
19997:09/12/17 18:25:26 [65749] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
19998:09/12/17 18:25:26 [65749] GAHP[65752] <- 'COMMANDS'
19999:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
20000:09/12/17 18:25:26 [65749] GAHP[65752] <- 'ASYNC_MODE_ON'
20001:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S' 'Async mode on'
20002:09/12/17 18:25:26 [65749] (510.0) gm state change: GM_INIT -> GM_START
20003:09/12/17 18:25:26 [65749] (510.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20004:09/12/17 18:25:26 [65749] (510.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20005:09/12/17 18:25:26 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/462/0/cluster462.proc0.subproc0/test.sh"\ ]'
20006:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S'
20007:09/12/17 18:25:26 [65749] (509.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20008:09/12/17 18:25:26 [65749] (509.0) gm state change: GM_INIT -> GM_START
20009:09/12/17 18:25:26 [65749] (509.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20010:09/12/17 18:25:26 [65749] (509.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20011:09/12/17 18:25:26 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/471/0/cluster471.proc0.subproc0/test.sh"\ ]'
20012:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S'
20013:09/12/17 18:25:26 [65749] (508.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20014:09/12/17 18:25:26 [65749] (508.0) gm state change: GM_INIT -> GM_START
20015:09/12/17 18:25:26 [65749] (508.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20016:09/12/17 18:25:26 [65749] (508.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20017:09/12/17 18:25:26 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/461/0/cluster461.proc0.subproc0/test.sh"\ ]'
20018:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S'
20019:09/12/17 18:25:26 [65749] (507.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20020:09/12/17 18:25:26 [65749] (507.0) gm state change: GM_INIT -> GM_START
20021:09/12/17 18:25:26 [65749] (507.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20022:09/12/17 18:25:26 [65749] (507.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20023:09/12/17 18:25:26 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/452/0/cluster452.proc0.subproc0/test.sh"\ ]'
20024:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S'
20025:09/12/17 18:25:26 [65749] (506.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20026:09/12/17 18:25:26 [65749] (506.0) gm state change: GM_INIT -> GM_START
20027:09/12/17 18:25:26 [65749] (506.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20028:09/12/17 18:25:26 [65749] (506.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20029:09/12/17 18:25:26 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/443/0/cluster443.proc0.subproc0/test.sh"\ ]'
20030:09/12/17 18:25:26 [65749] GAHP[65752] -> 'S'
20031:09/12/17 18:25:26 [65749] This process has a valid certificate & key
20032:09/12/17 18:25:27 [65749] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
20033:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20034:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20035:09/12/17 18:25:27 [65749] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
20036:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20037:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20038:09/12/17 18:25:27 [65749] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
20039:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20040:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20041:09/12/17 18:25:27 [65749] IPVERIFY: checking mc0151-ib against 128.55.162.46
20042:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20043:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20044:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20045:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20046:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20047:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20048:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20049:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
20050:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
20051:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
20052:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
20053:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
20054:09/12/17 18:25:27 [65749] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
20055:09/12/17 18:25:27 [65749] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
20056:09/12/17 18:25:27 [65749] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
20057:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20058:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20059:09/12/17 18:25:27 [65749] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
20060:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20061:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20062:09/12/17 18:25:27 [65749] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
20063:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20064:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20065:09/12/17 18:25:27 [65749] IPVERIFY: checking mc0151-ib against 128.55.162.46
20066:09/12/17 18:25:27 [65749] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
20067:09/12/17 18:25:27 [65749] IPVERIFY: ip found is 1
20068:09/12/17 18:25:27 [65749] (505.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20069:09/12/17 18:25:27 [65749] (505.0) gm state change: GM_INIT -> GM_START
20070:09/12/17 18:25:27 [65749] (505.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20071:09/12/17 18:25:27 [65749] (505.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20072:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 7 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/470/0/cluster470.proc0.subproc0/test.sh"\ ]'
20073:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20074:09/12/17 18:25:27 [65749] (504.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20075:09/12/17 18:25:27 [65749] (504.0) gm state change: GM_INIT -> GM_START
20076:09/12/17 18:25:27 [65749] (504.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20077:09/12/17 18:25:27 [65749] (504.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20078:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 8 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#504.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/460/0/cluster460.proc0.subproc0/test.sh"\ ]'
20079:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20080:09/12/17 18:25:27 [65749] (503.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20081:09/12/17 18:25:27 [65749] (503.0) gm state change: GM_INIT -> GM_START
20082:09/12/17 18:25:27 [65749] (503.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20083:09/12/17 18:25:27 [65749] (503.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20084:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 9 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#503.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/451/0/cluster451.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/451/0/cluster451.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/451/0/cluster451.proc0.subproc0/test.sh"\ ]'
20085:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20086:09/12/17 18:25:27 [65749] (502.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20087:09/12/17 18:25:27 [65749] (502.0) gm state change: GM_INIT -> GM_START
20088:09/12/17 18:25:27 [65749] (502.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20089:09/12/17 18:25:27 [65749] (502.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20090:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 10 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#502.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/442/0/cluster442.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/442/0/cluster442.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/442/0/cluster442.proc0.subproc0/test.sh"\ ]'
20091:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20092:09/12/17 18:25:27 [65749] (501.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20093:09/12/17 18:25:27 [65749] (501.0) gm state change: GM_INIT -> GM_START
20094:09/12/17 18:25:27 [65749] (501.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20095:09/12/17 18:25:27 [65749] (501.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20096:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 11 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#501.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/450/0/cluster450.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/450/0/cluster450.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/450/0/cluster450.proc0.subproc0/test.sh"\ ]'
20097:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20098:09/12/17 18:25:27 [65749] (500.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20099:09/12/17 18:25:27 [65749] (500.0) gm state change: GM_INIT -> GM_START
20100:09/12/17 18:25:27 [65749] (500.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20101:09/12/17 18:25:27 [65749] (500.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20102:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 12 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#500.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/441/0/cluster441.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/441/0/cluster441.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/441/0/cluster441.proc0.subproc0/test.sh"\ ]'
20103:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20104:09/12/17 18:25:27 [65749] (499.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20105:09/12/17 18:25:27 [65749] (499.0) gm state change: GM_INIT -> GM_START
20106:09/12/17 18:25:27 [65749] (499.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20107:09/12/17 18:25:27 [65749] (499.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20108:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 13 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#499.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/440/0/cluster440.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/440/0/cluster440.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/440/0/cluster440.proc0.subproc0/test.sh"\ ]'
20109:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20110:09/12/17 18:25:27 [65749] (498.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20111:09/12/17 18:25:27 [65749] (498.0) gm state change: GM_INIT -> GM_START
20112:09/12/17 18:25:27 [65749] (498.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20113:09/12/17 18:25:27 [65749] (498.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20114:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 14 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#498.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/469/0/cluster469.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/469/0/cluster469.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/469/0/cluster469.proc0.subproc0/test.sh"\ ]'
20115:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20116:09/12/17 18:25:27 [65749] (497.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20117:09/12/17 18:25:27 [65749] (497.0) gm state change: GM_INIT -> GM_START
20118:09/12/17 18:25:27 [65749] (497.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20119:09/12/17 18:25:27 [65749] (497.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20120:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 15 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#497.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/459/0/cluster459.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/459/0/cluster459.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/459/0/cluster459.proc0.subproc0/test.sh"\ ]'
20121:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20122:09/12/17 18:25:27 [65749] (496.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20123:09/12/17 18:25:27 [65749] (496.0) gm state change: GM_INIT -> GM_START
20124:09/12/17 18:25:27 [65749] (496.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20125:09/12/17 18:25:27 [65749] (496.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20126:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 16 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#496.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/468/0/cluster468.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/468/0/cluster468.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/468/0/cluster468.proc0.subproc0/test.sh"\ ]'
20127:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20128:09/12/17 18:25:27 [65749] (495.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20129:09/12/17 18:25:27 [65749] (495.0) gm state change: GM_INIT -> GM_START
20130:09/12/17 18:25:27 [65749] (495.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20131:09/12/17 18:25:27 [65749] (495.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20132:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 17 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#495.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/458/0/cluster458.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/458/0/cluster458.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/458/0/cluster458.proc0.subproc0/test.sh"\ ]'
20133:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20134:09/12/17 18:25:27 [65749] (494.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20135:09/12/17 18:25:27 [65749] (494.0) gm state change: GM_INIT -> GM_START
20136:09/12/17 18:25:27 [65749] (494.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20137:09/12/17 18:25:27 [65749] (494.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20138:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 18 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#494.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/449/0/cluster449.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/449/0/cluster449.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/449/0/cluster449.proc0.subproc0/test.sh"\ ]'
20139:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20140:09/12/17 18:25:27 [65749] (493.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20141:09/12/17 18:25:27 [65749] (493.0) gm state change: GM_INIT -> GM_START
20142:09/12/17 18:25:27 [65749] (493.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20143:09/12/17 18:25:27 [65749] (493.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20144:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 19 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#493.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/467/0/cluster467.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/467/0/cluster467.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/467/0/cluster467.proc0.subproc0/test.sh"\ ]'
20145:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20146:09/12/17 18:25:27 [65749] (492.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20147:09/12/17 18:25:27 [65749] (492.0) gm state change: GM_INIT -> GM_START
20148:09/12/17 18:25:27 [65749] (492.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20149:09/12/17 18:25:27 [65749] (492.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20150:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 20 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#492.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/476/0/cluster476.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/476/0/cluster476.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/476/0/cluster476.proc0.subproc0/test.sh"\ ]'
20151:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20152:09/12/17 18:25:27 [65749] (491.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20153:09/12/17 18:25:27 [65749] (491.0) gm state change: GM_INIT -> GM_START
20154:09/12/17 18:25:27 [65749] (491.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20155:09/12/17 18:25:27 [65749] (491.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20156:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 21 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#491.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/457/0/cluster457.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/457/0/cluster457.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/457/0/cluster457.proc0.subproc0/test.sh"\ ]'
20157:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20158:09/12/17 18:25:27 [65749] (490.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20159:09/12/17 18:25:27 [65749] (490.0) gm state change: GM_INIT -> GM_START
20160:09/12/17 18:25:27 [65749] (490.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20161:09/12/17 18:25:27 [65749] (490.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20162:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 22 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#490.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/448/0/cluster448.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/448/0/cluster448.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/448/0/cluster448.proc0.subproc0/test.sh"\ ]'
20163:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20164:09/12/17 18:25:27 [65749] (489.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20165:09/12/17 18:25:27 [65749] (489.0) gm state change: GM_INIT -> GM_START
20166:09/12/17 18:25:27 [65749] (489.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20167:09/12/17 18:25:27 [65749] (489.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20168:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 23 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#489.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/439/0/cluster439.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/439/0/cluster439.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/439/0/cluster439.proc0.subproc0/test.sh"\ ]'
20169:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20170:09/12/17 18:25:27 [65749] (488.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20171:09/12/17 18:25:27 [65749] (488.0) gm state change: GM_INIT -> GM_START
20172:09/12/17 18:25:27 [65749] (488.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20173:09/12/17 18:25:27 [65749] (488.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20174:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 24 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#488.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/466/0/cluster466.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/466/0/cluster466.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/466/0/cluster466.proc0.subproc0/test.sh"\ ]'
20175:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20176:09/12/17 18:25:27 [65749] (487.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20177:09/12/17 18:25:27 [65749] (487.0) gm state change: GM_INIT -> GM_START
20178:09/12/17 18:25:27 [65749] (487.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20179:09/12/17 18:25:27 [65749] (487.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20180:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 25 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#487.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/475/0/cluster475.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/475/0/cluster475.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/475/0/cluster475.proc0.subproc0/test.sh"\ ]'
20181:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20182:09/12/17 18:25:27 [65749] (486.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20183:09/12/17 18:25:27 [65749] (486.0) gm state change: GM_INIT -> GM_START
20184:09/12/17 18:25:27 [65749] (486.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20185:09/12/17 18:25:27 [65749] (486.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20186:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 26 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#486.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/456/0/cluster456.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/456/0/cluster456.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/456/0/cluster456.proc0.subproc0/test.sh"\ ]'
20187:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20188:09/12/17 18:25:27 [65749] (485.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20189:09/12/17 18:25:27 [65749] (485.0) gm state change: GM_INIT -> GM_START
20190:09/12/17 18:25:27 [65749] (485.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20191:09/12/17 18:25:27 [65749] (485.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20192:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 27 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#485.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/447/0/cluster447.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/447/0/cluster447.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/447/0/cluster447.proc0.subproc0/test.sh"\ ]'
20193:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20194:09/12/17 18:25:27 [65749] (484.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20195:09/12/17 18:25:27 [65749] (484.0) gm state change: GM_INIT -> GM_START
20196:09/12/17 18:25:27 [65749] (484.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20197:09/12/17 18:25:27 [65749] (484.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20198:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 28 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#484.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/438/0/cluster438.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/438/0/cluster438.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/438/0/cluster438.proc0.subproc0/test.sh"\ ]'
20199:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20200:09/12/17 18:25:27 [65749] (483.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20201:09/12/17 18:25:27 [65749] (483.0) gm state change: GM_INIT -> GM_START
20202:09/12/17 18:25:27 [65749] (483.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20203:09/12/17 18:25:27 [65749] (483.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20204:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 29 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#483.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/465/0/cluster465.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/465/0/cluster465.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/465/0/cluster465.proc0.subproc0/test.sh"\ ]'
20205:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20206:09/12/17 18:25:27 [65749] (482.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20207:09/12/17 18:25:27 [65749] (482.0) gm state change: GM_INIT -> GM_START
20208:09/12/17 18:25:27 [65749] (482.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20209:09/12/17 18:25:27 [65749] (482.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20210:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 30 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#482.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/474/0/cluster474.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/474/0/cluster474.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/474/0/cluster474.proc0.subproc0/test.sh"\ ]'
20211:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20212:09/12/17 18:25:27 [65749] (481.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20213:09/12/17 18:25:27 [65749] (481.0) gm state change: GM_INIT -> GM_START
20214:09/12/17 18:25:27 [65749] (481.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20215:09/12/17 18:25:27 [65749] (481.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20216:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 31 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#481.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/455/0/cluster455.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/455/0/cluster455.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/455/0/cluster455.proc0.subproc0/test.sh"\ ]'
20217:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20218:09/12/17 18:25:27 [65749] (480.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20219:09/12/17 18:25:27 [65749] (480.0) gm state change: GM_INIT -> GM_START
20220:09/12/17 18:25:27 [65749] (480.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20221:09/12/17 18:25:27 [65749] (480.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20222:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 32 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#480.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/446/0/cluster446.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/446/0/cluster446.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/446/0/cluster446.proc0.subproc0/test.sh"\ ]'
20223:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20224:09/12/17 18:25:27 [65749] (516.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20225:09/12/17 18:25:27 [65749] (516.0) gm state change: GM_INIT -> GM_START
20226:09/12/17 18:25:27 [65749] (516.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20227:09/12/17 18:25:27 [65749] (516.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20228:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 33 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#516.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/454/0/cluster454.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/454/0/cluster454.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/454/0/cluster454.proc0.subproc0/test.sh"\ ]'
20229:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20230:09/12/17 18:25:27 [65749] (479.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20231:09/12/17 18:25:27 [65749] (479.0) gm state change: GM_INIT -> GM_START
20232:09/12/17 18:25:27 [65749] (479.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20233:09/12/17 18:25:27 [65749] (479.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20234:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 34 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#479.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/437/0/cluster437.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/437/0/cluster437.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/437/0/cluster437.proc0.subproc0/test.sh"\ ]'
20235:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20236:09/12/17 18:25:27 [65749] (515.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20237:09/12/17 18:25:27 [65749] (515.0) gm state change: GM_INIT -> GM_START
20238:09/12/17 18:25:27 [65749] (515.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20239:09/12/17 18:25:27 [65749] (515.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20240:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 35 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#515.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/445/0/cluster445.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/445/0/cluster445.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/445/0/cluster445.proc0.subproc0/test.sh"\ ]'
20241:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20242:09/12/17 18:25:27 [65749] (478.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20243:09/12/17 18:25:27 [65749] (478.0) gm state change: GM_INIT -> GM_START
20244:09/12/17 18:25:27 [65749] (478.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20245:09/12/17 18:25:27 [65749] (478.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20246:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 36 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#478.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/464/0/cluster464.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/464/0/cluster464.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/464/0/cluster464.proc0.subproc0/test.sh"\ ]'
20247:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20248:09/12/17 18:25:27 [65749] (514.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20249:09/12/17 18:25:27 [65749] (514.0) gm state change: GM_INIT -> GM_START
20250:09/12/17 18:25:27 [65749] (514.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20251:09/12/17 18:25:27 [65749] (514.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20252:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 37 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#514.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/463/0/cluster463.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/463/0/cluster463.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/463/0/cluster463.proc0.subproc0/test.sh"\ ]'
20253:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20254:09/12/17 18:25:27 [65749] (477.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20255:09/12/17 18:25:27 [65749] (477.0) gm state change: GM_INIT -> GM_START
20256:09/12/17 18:25:27 [65749] (477.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20257:09/12/17 18:25:27 [65749] (477.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20258:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 38 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#477.0#1505261111";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/473/0/cluster473.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/473/0/cluster473.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/473/0/cluster473.proc0.subproc0/test.sh"\ ]'
20259:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20260:09/12/17 18:25:27 [65749] (513.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20261:09/12/17 18:25:27 [65749] (513.0) gm state change: GM_INIT -> GM_START
20262:09/12/17 18:25:27 [65749] (513.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20263:09/12/17 18:25:27 [65749] (513.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20264:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 39 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#513.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/472/0/cluster472.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/472/0/cluster472.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/472/0/cluster472.proc0.subproc0/test.sh"\ ]'
20265:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20266:09/12/17 18:25:27 [65749] (512.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20267:09/12/17 18:25:27 [65749] (512.0) gm state change: GM_INIT -> GM_START
20268:09/12/17 18:25:27 [65749] (512.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20269:09/12/17 18:25:27 [65749] (512.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20270:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 40 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#512.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/453/0/cluster453.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/453/0/cluster453.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/453/0/cluster453.proc0.subproc0/test.sh"\ ]'
20271:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20272:09/12/17 18:25:27 [65749] (511.0) doEvaluateState called: gmState GM_INIT, remoteState -1
20273:09/12/17 18:25:27 [65749] (511.0) gm state change: GM_INIT -> GM_START
20274:09/12/17 18:25:27 [65749] (511.0) gm state change: GM_START -> GM_TRANSFER_INPUT
20275:09/12/17 18:25:27 [65749] (511.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
20276:09/12/17 18:25:27 [65749] GAHP[65752] <- 'BLAH_JOB_SUBMIT 41 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#511.0#1505261112";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/444/0/cluster444.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/444/0/cluster444.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/444/0/cluster444.proc0.subproc0/test.sh"\ ]'
20277:09/12/17 18:25:27 [65749] GAHP[65752] -> 'S'
20278:09/12/17 18:25:28 [65749] Evaluating staleness of remote job statuses.
20279:09/12/17 18:25:28 [65749] (504.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20280:09/12/17 18:25:28 [65749] (505.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20281:09/12/17 18:25:28 [65749] (506.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20282:09/12/17 18:25:28 [65749] (507.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20283:09/12/17 18:25:28 [65749] (508.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20284:09/12/17 18:25:28 [65749] (509.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20285:09/12/17 18:25:28 [65749] (510.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20286:09/12/17 18:25:28 [65749] (511.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20287:09/12/17 18:25:28 [65749] (512.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20288:09/12/17 18:25:28 [65749] (513.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20289:09/12/17 18:25:28 [65749] (514.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20290:09/12/17 18:25:28 [65749] (515.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20291:09/12/17 18:25:28 [65749] (516.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20292:09/12/17 18:25:28 [65749] (477.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20293:09/12/17 18:25:28 [65749] (478.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20294:09/12/17 18:25:28 [65749] (479.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20295:09/12/17 18:25:28 [65749] (480.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20296:09/12/17 18:25:28 [65749] (481.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20297:09/12/17 18:25:28 [65749] (482.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20298:09/12/17 18:25:28 [65749] (483.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20299:09/12/17 18:25:28 [65749] (484.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20300:09/12/17 18:25:28 [65749] (485.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20301:09/12/17 18:25:28 [65749] (486.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20302:09/12/17 18:25:28 [65749] (487.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20303:09/12/17 18:25:28 [65749] (488.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20304:09/12/17 18:25:28 [65749] (489.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20305:09/12/17 18:25:28 [65749] (490.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20306:09/12/17 18:25:28 [65749] (491.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20307:09/12/17 18:25:28 [65749] (492.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20308:09/12/17 18:25:28 [65749] (493.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20309:09/12/17 18:25:28 [65749] (494.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20310:09/12/17 18:25:28 [65749] (495.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20311:09/12/17 18:25:28 [65749] (496.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20312:09/12/17 18:25:28 [65749] (497.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20313:09/12/17 18:25:28 [65749] (498.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20314:09/12/17 18:25:28 [65749] (499.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20315:09/12/17 18:25:28 [65749] (500.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20316:09/12/17 18:25:28 [65749] (501.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20317:09/12/17 18:25:28 [65749] (502.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20318:09/12/17 18:25:28 [65749] (503.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20319:09/12/17 18:25:31 [65749] resource  is now up
20320:09/12/17 18:25:31 [65749] in doContactSchedd()
20321:09/12/17 18:25:31 [65749] querying for removed/held jobs
20322:09/12/17 18:25:31 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
20323:09/12/17 18:25:31 [65749] Fetched 0 job ads from schedd
20324:09/12/17 18:25:31 [65749] Updating classad values for 504.0:
20325:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20326:09/12/17 18:25:31 [65749] Updating classad values for 505.0:
20327:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20328:09/12/17 18:25:31 [65749] Updating classad values for 506.0:
20329:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20330:09/12/17 18:25:31 [65749] Updating classad values for 507.0:
20331:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20332:09/12/17 18:25:31 [65749] Updating classad values for 508.0:
20333:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20334:09/12/17 18:25:31 [65749] Updating classad values for 509.0:
20335:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20336:09/12/17 18:25:31 [65749] Updating classad values for 510.0:
20337:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20338:09/12/17 18:25:31 [65749] Updating classad values for 511.0:
20339:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20340:09/12/17 18:25:31 [65749] Updating classad values for 512.0:
20341:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20342:09/12/17 18:25:31 [65749] Updating classad values for 513.0:
20343:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20344:09/12/17 18:25:31 [65749] Updating classad values for 514.0:
20345:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20346:09/12/17 18:25:31 [65749] Updating classad values for 515.0:
20347:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20348:09/12/17 18:25:31 [65749] Updating classad values for 516.0:
20349:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20350:09/12/17 18:25:31 [65749] Updating classad values for 477.0:
20351:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20352:09/12/17 18:25:31 [65749] Updating classad values for 478.0:
20353:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20354:09/12/17 18:25:31 [65749] Updating classad values for 479.0:
20355:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20356:09/12/17 18:25:31 [65749] Updating classad values for 480.0:
20357:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20358:09/12/17 18:25:31 [65749] Updating classad values for 481.0:
20359:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20360:09/12/17 18:25:31 [65749] Updating classad values for 482.0:
20361:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20362:09/12/17 18:25:31 [65749] Updating classad values for 483.0:
20363:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20364:09/12/17 18:25:31 [65749] Updating classad values for 484.0:
20365:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20366:09/12/17 18:25:31 [65749] Updating classad values for 485.0:
20367:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20368:09/12/17 18:25:31 [65749] Updating classad values for 486.0:
20369:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20370:09/12/17 18:25:31 [65749] Updating classad values for 487.0:
20371:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20372:09/12/17 18:25:31 [65749] Updating classad values for 488.0:
20373:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20374:09/12/17 18:25:31 [65749] Updating classad values for 489.0:
20375:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20376:09/12/17 18:25:31 [65749] Updating classad values for 490.0:
20377:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20378:09/12/17 18:25:31 [65749] Updating classad values for 491.0:
20379:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20380:09/12/17 18:25:31 [65749] Updating classad values for 492.0:
20381:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20382:09/12/17 18:25:31 [65749] Updating classad values for 493.0:
20383:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20384:09/12/17 18:25:31 [65749] Updating classad values for 494.0:
20385:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20386:09/12/17 18:25:31 [65749] Updating classad values for 495.0:
20387:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20388:09/12/17 18:25:31 [65749] Updating classad values for 496.0:
20389:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20390:09/12/17 18:25:31 [65749] Updating classad values for 497.0:
20391:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20392:09/12/17 18:25:31 [65749] Updating classad values for 498.0:
20393:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20394:09/12/17 18:25:31 [65749] Updating classad values for 499.0:
20395:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20396:09/12/17 18:25:31 [65749] Updating classad values for 500.0:
20397:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20398:09/12/17 18:25:31 [65749] Updating classad values for 501.0:
20399:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20400:09/12/17 18:25:31 [65749] Updating classad values for 502.0:
20401:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20402:09/12/17 18:25:31 [65749] Updating classad values for 503.0:
20403:09/12/17 18:25:31 [65749]    CurrentStatusUnknown = true
20404:09/12/17 18:25:31 [65749] leaving doContactSchedd()
20405:09/12/17 18:25:31 [65749] (510.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20406:09/12/17 18:25:31 [65749] (509.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20407:09/12/17 18:25:31 [65749] (508.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20408:09/12/17 18:25:31 [65749] (507.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20409:09/12/17 18:25:31 [65749] (506.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20410:09/12/17 18:25:31 [65749] (505.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20411:09/12/17 18:25:31 [65749] (504.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20412:09/12/17 18:25:31 [65749] (503.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20413:09/12/17 18:25:31 [65749] (502.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20414:09/12/17 18:25:31 [65749] (501.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20415:09/12/17 18:25:31 [65749] (500.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20416:09/12/17 18:25:31 [65749] (499.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20417:09/12/17 18:25:31 [65749] (498.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20418:09/12/17 18:25:31 [65749] (497.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20419:09/12/17 18:25:31 [65749] (496.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20420:09/12/17 18:25:31 [65749] (495.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20421:09/12/17 18:25:31 [65749] (494.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20422:09/12/17 18:25:31 [65749] (493.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20423:09/12/17 18:25:31 [65749] (492.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20424:09/12/17 18:25:31 [65749] (491.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20425:09/12/17 18:25:31 [65749] (490.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20426:09/12/17 18:25:31 [65749] (489.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20427:09/12/17 18:25:31 [65749] (488.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20428:09/12/17 18:25:31 [65749] (487.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20429:09/12/17 18:25:31 [65749] (486.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20430:09/12/17 18:25:31 [65749] (485.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20431:09/12/17 18:25:31 [65749] (484.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20432:09/12/17 18:25:31 [65749] (483.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20433:09/12/17 18:25:31 [65749] (482.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20434:09/12/17 18:25:31 [65749] (481.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20435:09/12/17 18:25:31 [65749] (480.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20436:09/12/17 18:25:31 [65749] (516.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20437:09/12/17 18:25:31 [65749] (479.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20438:09/12/17 18:25:31 [65749] (515.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20439:09/12/17 18:25:31 [65749] (478.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20440:09/12/17 18:25:31 [65749] (514.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20441:09/12/17 18:25:31 [65749] (477.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20442:09/12/17 18:25:31 [65749] (513.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20443:09/12/17 18:25:31 [65749] (512.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20444:09/12/17 18:25:31 [65749] (511.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20445:09/12/17 18:25:32 [65749] GAHP[65752] <- 'RESULTS'
20446:09/12/17 18:25:32 [65749] GAHP[65752] -> 'R'
20447:09/12/17 18:25:32 [65749] GAHP[65752] -> 'S' '1'
20448:09/12/17 18:25:32 [65749] GAHP[65752] -> '20' '0' 'No error' 'slurm/20170912/161713'
20449:09/12/17 18:25:32 [65749] (492.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20450:09/12/17 18:25:32 [65749] (492.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20451:09/12/17 18:25:33 [65749] GAHP[65752] <- 'RESULTS'
20452:09/12/17 18:25:33 [65749] GAHP[65752] -> 'R'
20453:09/12/17 18:25:33 [65749] GAHP[65752] -> 'S' '1'
20454:09/12/17 18:25:33 [65749] GAHP[65752] -> '8' '0' 'No error' 'slurm/20170912/161714'
20455:09/12/17 18:25:33 [65749] (504.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20456:09/12/17 18:25:33 [65749] (504.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20457:09/12/17 18:25:33 [65749] GAHP[65752] <- 'RESULTS'
20458:09/12/17 18:25:33 [65749] GAHP[65752] -> 'R'
20459:09/12/17 18:25:33 [65749] GAHP[65752] -> 'S' '1'
20460:09/12/17 18:25:33 [65749] GAHP[65752] -> '4' '0' 'No error' 'slurm/20170912/161715'
20461:09/12/17 18:25:33 [65749] (508.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20462:09/12/17 18:25:33 [65749] (508.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20463:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20464:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20465:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20466:09/12/17 18:25:34 [65749] GAHP[65752] -> '29' '0' 'No error' 'slurm/20170912/161719'
20467:09/12/17 18:25:34 [65749] (483.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20468:09/12/17 18:25:34 [65749] (483.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20469:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20470:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20471:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20472:09/12/17 18:25:34 [65749] GAHP[65752] -> '15' '0' 'No error' 'slurm/20170912/161721'
20473:09/12/17 18:25:34 [65749] (497.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20474:09/12/17 18:25:34 [65749] (497.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20475:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20476:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20477:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20478:09/12/17 18:25:34 [65749] GAHP[65752] -> '30' '0' 'No error' 'slurm/20170912/161722'
20479:09/12/17 18:25:34 [65749] (482.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20480:09/12/17 18:25:34 [65749] (482.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20481:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20482:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20483:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20484:09/12/17 18:25:34 [65749] GAHP[65752] -> '31' '0' 'No error' 'slurm/20170912/161725'
20485:09/12/17 18:25:34 [65749] (481.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20486:09/12/17 18:25:34 [65749] (481.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20487:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20488:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20489:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20490:09/12/17 18:25:34 [65749] GAHP[65752] -> '6' '0' 'No error' 'slurm/20170912/161726'
20491:09/12/17 18:25:34 [65749] (506.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20492:09/12/17 18:25:34 [65749] (506.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20493:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20494:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20495:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20496:09/12/17 18:25:34 [65749] GAHP[65752] -> '17' '0' 'No error' 'slurm/20170912/161727'
20497:09/12/17 18:25:34 [65749] (495.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20498:09/12/17 18:25:34 [65749] (495.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20499:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20500:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20501:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20502:09/12/17 18:25:34 [65749] GAHP[65752] -> '11' '0' 'No error' 'slurm/20170912/161728'
20503:09/12/17 18:25:34 [65749] (501.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20504:09/12/17 18:25:34 [65749] (501.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20505:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20506:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20507:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20508:09/12/17 18:25:34 [65749] GAHP[65752] -> '23' '0' 'No error' 'slurm/20170912/161729'
20509:09/12/17 18:25:34 [65749] (489.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20510:09/12/17 18:25:34 [65749] (489.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20511:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20512:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20513:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20514:09/12/17 18:25:34 [65749] GAHP[65752] -> '2' '0' 'No error' 'slurm/20170912/161731'
20515:09/12/17 18:25:34 [65749] (510.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20516:09/12/17 18:25:34 [65749] (510.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20517:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20518:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20519:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20520:09/12/17 18:25:34 [65749] GAHP[65752] -> '12' '0' 'No error' 'slurm/20170912/161732'
20521:09/12/17 18:25:34 [65749] (500.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20522:09/12/17 18:25:34 [65749] (500.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20523:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20524:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20525:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20526:09/12/17 18:25:34 [65749] GAHP[65752] -> '13' '0' 'No error' 'slurm/20170912/161733'
20527:09/12/17 18:25:34 [65749] (499.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20528:09/12/17 18:25:34 [65749] (499.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20529:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20530:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20531:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20532:09/12/17 18:25:34 [65749] GAHP[65752] -> '35' '0' 'No error' 'slurm/20170912/161734'
20533:09/12/17 18:25:34 [65749] (515.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20534:09/12/17 18:25:34 [65749] (515.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20535:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20536:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20537:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20538:09/12/17 18:25:34 [65749] GAHP[65752] -> '9' '0' 'No error' 'slurm/20170912/161738'
20539:09/12/17 18:25:34 [65749] (503.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20540:09/12/17 18:25:34 [65749] (503.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20541:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20542:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20543:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20544:09/12/17 18:25:34 [65749] GAHP[65752] -> '22' '0' 'No error' 'slurm/20170912/161739'
20545:09/12/17 18:25:34 [65749] (490.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20546:09/12/17 18:25:34 [65749] (490.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20547:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20548:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20549:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20550:09/12/17 18:25:34 [65749] GAHP[65752] -> '14' '0' 'No error' 'slurm/20170912/161740'
20551:09/12/17 18:25:34 [65749] (498.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20552:09/12/17 18:25:34 [65749] (498.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20553:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20554:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20555:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20556:09/12/17 18:25:34 [65749] GAHP[65752] -> '7' '0' 'No error' 'slurm/20170912/161742'
20557:09/12/17 18:25:34 [65749] (505.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20558:09/12/17 18:25:34 [65749] (505.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20559:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20560:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20561:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '2'
20562:09/12/17 18:25:34 [65749] GAHP[65752] -> '27' '0' 'No error' 'slurm/20170912/161744'
20563:09/12/17 18:25:34 [65749] GAHP[65752] -> '37' '0' 'No error' 'slurm/20170912/161743'
20564:09/12/17 18:25:34 [65749] (485.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20565:09/12/17 18:25:34 [65749] (485.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20566:09/12/17 18:25:34 [65749] (514.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20567:09/12/17 18:25:34 [65749] (514.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20568:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20569:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20570:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20571:09/12/17 18:25:34 [65749] GAHP[65752] -> '39' '0' 'No error' 'slurm/20170912/161745'
20572:09/12/17 18:25:34 [65749] (513.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20573:09/12/17 18:25:34 [65749] (513.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20574:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20575:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20576:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20577:09/12/17 18:25:34 [65749] GAHP[65752] -> '3' '0' 'No error' 'slurm/20170912/161746'
20578:09/12/17 18:25:34 [65749] (509.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20579:09/12/17 18:25:34 [65749] (509.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20580:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20581:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20582:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20583:09/12/17 18:25:34 [65749] GAHP[65752] -> '36' '0' 'No error' 'slurm/20170912/161747'
20584:09/12/17 18:25:34 [65749] (478.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20585:09/12/17 18:25:34 [65749] (478.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20586:09/12/17 18:25:34 [65749] GAHP[65752] <- 'RESULTS'
20587:09/12/17 18:25:34 [65749] GAHP[65752] -> 'R'
20588:09/12/17 18:25:34 [65749] GAHP[65752] -> 'S' '1'
20589:09/12/17 18:25:34 [65749] GAHP[65752] -> '18' '0' 'No error' 'slurm/20170912/161748'
20590:09/12/17 18:25:34 [65749] (494.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20591:09/12/17 18:25:34 [65749] (494.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20592:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20593:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20594:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20595:09/12/17 18:25:35 [65749] GAHP[65752] -> '19' '0' 'No error' 'slurm/20170912/161716'
20596:09/12/17 18:25:35 [65749] (493.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20597:09/12/17 18:25:35 [65749] (493.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20598:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20599:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20600:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20601:09/12/17 18:25:35 [65749] GAHP[65752] -> '28' '0' 'No error' 'slurm/20170912/161717'
20602:09/12/17 18:25:35 [65749] (484.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20603:09/12/17 18:25:35 [65749] (484.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20604:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20605:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20606:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20607:09/12/17 18:25:35 [65749] GAHP[65752] -> '24' '0' 'No error' 'slurm/20170912/161718'
20608:09/12/17 18:25:35 [65749] (488.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20609:09/12/17 18:25:35 [65749] (488.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20610:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20611:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20612:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20613:09/12/17 18:25:35 [65749] GAHP[65752] -> '10' '0' 'No error' 'slurm/20170912/161720'
20614:09/12/17 18:25:35 [65749] (502.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20615:09/12/17 18:25:35 [65749] (502.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20616:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20617:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20618:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20619:09/12/17 18:25:35 [65749] GAHP[65752] -> '21' '0' 'No error' 'slurm/20170912/161723'
20620:09/12/17 18:25:35 [65749] (491.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20621:09/12/17 18:25:35 [65749] (491.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20622:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20623:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20624:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20625:09/12/17 18:25:35 [65749] GAHP[65752] -> '25' '0' 'No error' 'slurm/20170912/161724'
20626:09/12/17 18:25:35 [65749] (487.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20627:09/12/17 18:25:35 [65749] (487.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20628:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20629:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20630:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20631:09/12/17 18:25:35 [65749] GAHP[65752] -> '40' '0' 'No error' 'slurm/20170912/161730'
20632:09/12/17 18:25:35 [65749] (512.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20633:09/12/17 18:25:35 [65749] (512.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20634:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20635:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20636:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20637:09/12/17 18:25:35 [65749] GAHP[65752] -> '32' '0' 'No error' 'slurm/20170912/161735'
20638:09/12/17 18:25:35 [65749] (480.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20639:09/12/17 18:25:35 [65749] (480.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20640:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20641:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20642:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20643:09/12/17 18:25:35 [65749] GAHP[65752] -> '34' '0' 'No error' 'slurm/20170912/161736'
20644:09/12/17 18:25:35 [65749] (479.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20645:09/12/17 18:25:35 [65749] (479.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20646:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20647:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20648:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20649:09/12/17 18:25:35 [65749] GAHP[65752] -> '41' '0' 'No error' 'slurm/20170912/161737'
20650:09/12/17 18:25:35 [65749] (511.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20651:09/12/17 18:25:35 [65749] (511.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20652:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20653:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20654:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20655:09/12/17 18:25:35 [65749] GAHP[65752] -> '38' '0' 'No error' 'slurm/20170912/161741'
20656:09/12/17 18:25:35 [65749] (477.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20657:09/12/17 18:25:35 [65749] (477.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20658:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20659:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20660:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20661:09/12/17 18:25:35 [65749] GAHP[65752] -> '26' '0' 'No error' 'slurm/20170912/161749'
20662:09/12/17 18:25:35 [65749] (486.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20663:09/12/17 18:25:35 [65749] (486.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20664:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20665:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20666:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20667:09/12/17 18:25:35 [65749] GAHP[65752] -> '5' '0' 'No error' 'slurm/20170912/161750'
20668:09/12/17 18:25:35 [65749] (507.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20669:09/12/17 18:25:35 [65749] (507.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20670:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20671:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20672:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20673:09/12/17 18:25:35 [65749] GAHP[65752] -> '16' '0' 'No error' 'slurm/20170912/161751'
20674:09/12/17 18:25:35 [65749] (496.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20675:09/12/17 18:25:35 [65749] (496.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20676:09/12/17 18:25:35 [65749] GAHP[65752] <- 'RESULTS'
20677:09/12/17 18:25:35 [65749] GAHP[65752] -> 'R'
20678:09/12/17 18:25:35 [65749] GAHP[65752] -> 'S' '1'
20679:09/12/17 18:25:35 [65749] GAHP[65752] -> '33' '0' 'No error' 'slurm/20170912/161752'
20680:09/12/17 18:25:35 [65749] (516.0) doEvaluateState called: gmState GM_SUBMIT, remoteState -1
20681:09/12/17 18:25:35 [65749] (516.0) gm state change: GM_SUBMIT -> GM_SUBMIT_SAVE
20682:09/12/17 18:25:36 [65749] in doContactSchedd()
20683:09/12/17 18:25:36 [65749] querying for removed/held jobs
20684:09/12/17 18:25:36 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
20685:09/12/17 18:25:36 [65749] Fetched 0 job ads from schedd
20686:09/12/17 18:25:36 [65749] Updating classad values for 504.0:
20687:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20688:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#504.0#1505261111 slurm/20170912/161714"
20689:09/12/17 18:25:36 [65749] Updating classad values for 505.0:
20690:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20691:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#505.0#1505261111 slurm/20170912/161742"
20692:09/12/17 18:25:36 [65749] Updating classad values for 506.0:
20693:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20694:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#506.0#1505261111 slurm/20170912/161726"
20695:09/12/17 18:25:36 [65749] Updating classad values for 507.0:
20696:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20697:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#507.0#1505261112 slurm/20170912/161750"
20698:09/12/17 18:25:36 [65749] Updating classad values for 508.0:
20699:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20700:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#508.0#1505261112 slurm/20170912/161715"
20701:09/12/17 18:25:36 [65749] Updating classad values for 509.0:
20702:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20703:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#509.0#1505261112 slurm/20170912/161746"
20704:09/12/17 18:25:36 [65749] Updating classad values for 510.0:
20705:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20706:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#510.0#1505261112 slurm/20170912/161731"
20707:09/12/17 18:25:36 [65749] Updating classad values for 511.0:
20708:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20709:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#511.0#1505261112 slurm/20170912/161737"
20710:09/12/17 18:25:36 [65749] Updating classad values for 512.0:
20711:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20712:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#512.0#1505261112 slurm/20170912/161730"
20713:09/12/17 18:25:36 [65749] Updating classad values for 513.0:
20714:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20715:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#513.0#1505261112 slurm/20170912/161745"
20716:09/12/17 18:25:36 [65749] Updating classad values for 514.0:
20717:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20718:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#514.0#1505261112 slurm/20170912/161743"
20719:09/12/17 18:25:36 [65749] Updating classad values for 515.0:
20720:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20721:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#515.0#1505261112 slurm/20170912/161734"
20722:09/12/17 18:25:36 [65749] Updating classad values for 516.0:
20723:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20724:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#516.0#1505261112 slurm/20170912/161752"
20725:09/12/17 18:25:36 [65749] Updating classad values for 477.0:
20726:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20727:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#477.0#1505261111 slurm/20170912/161741"
20728:09/12/17 18:25:36 [65749] Updating classad values for 478.0:
20729:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20730:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#478.0#1505261111 slurm/20170912/161747"
20731:09/12/17 18:25:36 [65749] Updating classad values for 479.0:
20732:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20733:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#479.0#1505261111 slurm/20170912/161736"
20734:09/12/17 18:25:36 [65749] Updating classad values for 480.0:
20735:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20736:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#480.0#1505261111 slurm/20170912/161735"
20737:09/12/17 18:25:36 [65749] Updating classad values for 481.0:
20738:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20739:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#481.0#1505261111 slurm/20170912/161725"
20740:09/12/17 18:25:36 [65749] Updating classad values for 482.0:
20741:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20742:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#482.0#1505261111 slurm/20170912/161722"
20743:09/12/17 18:25:36 [65749] Updating classad values for 483.0:
20744:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20745:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#483.0#1505261111 slurm/20170912/161719"
20746:09/12/17 18:25:36 [65749] Updating classad values for 484.0:
20747:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20748:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#484.0#1505261111 slurm/20170912/161717"
20749:09/12/17 18:25:36 [65749] Updating classad values for 485.0:
20750:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20751:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#485.0#1505261111 slurm/20170912/161744"
20752:09/12/17 18:25:36 [65749] Updating classad values for 486.0:
20753:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20754:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#486.0#1505261111 slurm/20170912/161749"
20755:09/12/17 18:25:36 [65749] Updating classad values for 487.0:
20756:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20757:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#487.0#1505261111 slurm/20170912/161724"
20758:09/12/17 18:25:36 [65749] Updating classad values for 488.0:
20759:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20760:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#488.0#1505261111 slurm/20170912/161718"
20761:09/12/17 18:25:36 [65749] Updating classad values for 489.0:
20762:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20763:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#489.0#1505261111 slurm/20170912/161729"
20764:09/12/17 18:25:36 [65749] Updating classad values for 490.0:
20765:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20766:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#490.0#1505261111 slurm/20170912/161739"
20767:09/12/17 18:25:36 [65749] Updating classad values for 491.0:
20768:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20769:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#491.0#1505261111 slurm/20170912/161723"
20770:09/12/17 18:25:36 [65749] Updating classad values for 492.0:
20771:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20772:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#492.0#1505261111 slurm/20170912/161713"
20773:09/12/17 18:25:36 [65749] Updating classad values for 493.0:
20774:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20775:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#493.0#1505261111 slurm/20170912/161716"
20776:09/12/17 18:25:36 [65749] Updating classad values for 494.0:
20777:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20778:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#494.0#1505261111 slurm/20170912/161748"
20779:09/12/17 18:25:36 [65749] Updating classad values for 495.0:
20780:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20781:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#495.0#1505261111 slurm/20170912/161727"
20782:09/12/17 18:25:36 [65749] Updating classad values for 496.0:
20783:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20784:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#496.0#1505261111 slurm/20170912/161751"
20785:09/12/17 18:25:36 [65749] Updating classad values for 497.0:
20786:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20787:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#497.0#1505261111 slurm/20170912/161721"
20788:09/12/17 18:25:36 [65749] Updating classad values for 498.0:
20789:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20790:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#498.0#1505261111 slurm/20170912/161740"
20791:09/12/17 18:25:36 [65749] Updating classad values for 499.0:
20792:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20793:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#499.0#1505261111 slurm/20170912/161733"
20794:09/12/17 18:25:36 [65749] Updating classad values for 500.0:
20795:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20796:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#500.0#1505261111 slurm/20170912/161732"
20797:09/12/17 18:25:36 [65749] Updating classad values for 501.0:
20798:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20799:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#501.0#1505261111 slurm/20170912/161728"
20800:09/12/17 18:25:36 [65749] Updating classad values for 502.0:
20801:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20802:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#502.0#1505261111 slurm/20170912/161720"
20803:09/12/17 18:25:36 [65749] Updating classad values for 503.0:
20804:09/12/17 18:25:36 [65749]    DelegatedProxyExpiration = 1505570326
20805:09/12/17 18:25:36 [65749]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#503.0#1505261111 slurm/20170912/161738"
20806:09/12/17 18:25:36 [65749] leaving doContactSchedd()
20807:09/12/17 18:25:36 [65749] (504.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20808:09/12/17 18:25:36 [65749] (504.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20809:09/12/17 18:25:36 [65749] (505.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20810:09/12/17 18:25:36 [65749] (505.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20811:09/12/17 18:25:36 [65749] (506.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20812:09/12/17 18:25:36 [65749] (506.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20813:09/12/17 18:25:36 [65749] (507.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20814:09/12/17 18:25:36 [65749] (507.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20815:09/12/17 18:25:36 [65749] (508.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20816:09/12/17 18:25:36 [65749] (508.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20817:09/12/17 18:25:36 [65749] (509.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20818:09/12/17 18:25:36 [65749] (509.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20819:09/12/17 18:25:36 [65749] (510.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20820:09/12/17 18:25:36 [65749] (510.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20821:09/12/17 18:25:36 [65749] (511.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20822:09/12/17 18:25:36 [65749] (511.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20823:09/12/17 18:25:36 [65749] (512.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20824:09/12/17 18:25:36 [65749] (512.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20825:09/12/17 18:25:36 [65749] (513.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20826:09/12/17 18:25:36 [65749] (513.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20827:09/12/17 18:25:36 [65749] (514.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20828:09/12/17 18:25:36 [65749] (514.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20829:09/12/17 18:25:36 [65749] (515.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20830:09/12/17 18:25:36 [65749] (515.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20831:09/12/17 18:25:36 [65749] (516.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20832:09/12/17 18:25:36 [65749] (516.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20833:09/12/17 18:25:36 [65749] (477.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20834:09/12/17 18:25:36 [65749] (477.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20835:09/12/17 18:25:36 [65749] (478.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20836:09/12/17 18:25:36 [65749] (478.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20837:09/12/17 18:25:36 [65749] (479.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20838:09/12/17 18:25:36 [65749] (479.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20839:09/12/17 18:25:36 [65749] (480.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20840:09/12/17 18:25:36 [65749] (480.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20841:09/12/17 18:25:36 [65749] (481.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20842:09/12/17 18:25:36 [65749] (481.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20843:09/12/17 18:25:36 [65749] (482.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20844:09/12/17 18:25:36 [65749] (482.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20845:09/12/17 18:25:36 [65749] (483.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20846:09/12/17 18:25:36 [65749] (483.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20847:09/12/17 18:25:36 [65749] (484.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20848:09/12/17 18:25:36 [65749] (484.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20849:09/12/17 18:25:36 [65749] (485.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20850:09/12/17 18:25:36 [65749] (485.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20851:09/12/17 18:25:36 [65749] (486.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20852:09/12/17 18:25:36 [65749] (486.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20853:09/12/17 18:25:36 [65749] (487.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20854:09/12/17 18:25:36 [65749] (487.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20855:09/12/17 18:25:36 [65749] (488.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20856:09/12/17 18:25:36 [65749] (488.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20857:09/12/17 18:25:36 [65749] (489.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20858:09/12/17 18:25:36 [65749] (489.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20859:09/12/17 18:25:36 [65749] (490.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20860:09/12/17 18:25:36 [65749] (490.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20861:09/12/17 18:25:36 [65749] (491.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20862:09/12/17 18:25:36 [65749] (491.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20863:09/12/17 18:25:36 [65749] (492.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20864:09/12/17 18:25:36 [65749] (492.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20865:09/12/17 18:25:36 [65749] (493.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20866:09/12/17 18:25:36 [65749] (493.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20867:09/12/17 18:25:36 [65749] (494.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20868:09/12/17 18:25:36 [65749] (494.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20869:09/12/17 18:25:36 [65749] (495.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20870:09/12/17 18:25:36 [65749] (495.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20871:09/12/17 18:25:36 [65749] (496.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20872:09/12/17 18:25:36 [65749] (496.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20873:09/12/17 18:25:36 [65749] (497.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20874:09/12/17 18:25:36 [65749] (497.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20875:09/12/17 18:25:36 [65749] (498.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20876:09/12/17 18:25:36 [65749] (498.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20877:09/12/17 18:25:36 [65749] (499.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20878:09/12/17 18:25:36 [65749] (499.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20879:09/12/17 18:25:36 [65749] (500.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20880:09/12/17 18:25:36 [65749] (500.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20881:09/12/17 18:25:36 [65749] (501.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20882:09/12/17 18:25:36 [65749] (501.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20883:09/12/17 18:25:36 [65749] (502.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20884:09/12/17 18:25:36 [65749] (502.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20885:09/12/17 18:25:36 [65749] (503.0) doEvaluateState called: gmState GM_SUBMIT_SAVE, remoteState -1
20886:09/12/17 18:25:36 [65749] (503.0) gm state change: GM_SUBMIT_SAVE -> GM_SUBMITTED
20887:09/12/17 18:26:23 [65749] Received CHECK_LEASES signal
20888:09/12/17 18:26:23 [65749] in doContactSchedd()
20889:09/12/17 18:26:23 [65749] querying for renewed leases
20890:09/12/17 18:26:23 [65749] querying for removed/held jobs
20891:09/12/17 18:26:23 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
20892:09/12/17 18:26:23 [65749] Fetched 0 job ads from schedd
20893:09/12/17 18:26:23 [65749] leaving doContactSchedd()
20894:09/12/17 18:26:26 [65749] GAHP[65752] <- 'RESULTS'
20895:09/12/17 18:26:26 [65749] GAHP[65752] -> 'S' '0'
20896:09/12/17 18:26:28 [65749] Evaluating staleness of remote job statuses.
20897:09/12/17 18:26:36 [65749] (504.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20898:09/12/17 18:26:36 [65749] (504.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20899:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 42 slurm/20170912/161714'
20900:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20901:09/12/17 18:26:36 [65749] (505.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20902:09/12/17 18:26:36 [65749] (505.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20903:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 43 slurm/20170912/161742'
20904:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20905:09/12/17 18:26:36 [65749] (506.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20906:09/12/17 18:26:36 [65749] (506.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20907:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 44 slurm/20170912/161726'
20908:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20909:09/12/17 18:26:36 [65749] (507.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20910:09/12/17 18:26:36 [65749] (507.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20911:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 45 slurm/20170912/161750'
20912:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20913:09/12/17 18:26:36 [65749] (508.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20914:09/12/17 18:26:36 [65749] (508.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20915:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 46 slurm/20170912/161715'
20916:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20917:09/12/17 18:26:36 [65749] (509.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20918:09/12/17 18:26:36 [65749] (509.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20919:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 47 slurm/20170912/161746'
20920:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20921:09/12/17 18:26:36 [65749] (510.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20922:09/12/17 18:26:36 [65749] (510.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20923:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 48 slurm/20170912/161731'
20924:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20925:09/12/17 18:26:36 [65749] (511.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20926:09/12/17 18:26:36 [65749] (511.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20927:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 49 slurm/20170912/161737'
20928:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20929:09/12/17 18:26:36 [65749] (512.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20930:09/12/17 18:26:36 [65749] (512.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20931:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 50 slurm/20170912/161730'
20932:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20933:09/12/17 18:26:36 [65749] (513.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20934:09/12/17 18:26:36 [65749] (513.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20935:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 51 slurm/20170912/161745'
20936:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20937:09/12/17 18:26:36 [65749] (514.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20938:09/12/17 18:26:36 [65749] (514.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20939:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 52 slurm/20170912/161743'
20940:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20941:09/12/17 18:26:36 [65749] (515.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20942:09/12/17 18:26:36 [65749] (515.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20943:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 53 slurm/20170912/161734'
20944:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20945:09/12/17 18:26:36 [65749] (516.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20946:09/12/17 18:26:36 [65749] (516.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20947:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 54 slurm/20170912/161752'
20948:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20949:09/12/17 18:26:36 [65749] (477.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20950:09/12/17 18:26:36 [65749] (477.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20951:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 55 slurm/20170912/161741'
20952:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20953:09/12/17 18:26:36 [65749] (478.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20954:09/12/17 18:26:36 [65749] (478.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20955:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 56 slurm/20170912/161747'
20956:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20957:09/12/17 18:26:36 [65749] (479.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20958:09/12/17 18:26:36 [65749] (479.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20959:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 57 slurm/20170912/161736'
20960:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20961:09/12/17 18:26:36 [65749] (480.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20962:09/12/17 18:26:36 [65749] (480.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20963:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 58 slurm/20170912/161735'
20964:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20965:09/12/17 18:26:36 [65749] (481.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20966:09/12/17 18:26:36 [65749] (481.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20967:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 59 slurm/20170912/161725'
20968:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20969:09/12/17 18:26:36 [65749] (482.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20970:09/12/17 18:26:36 [65749] (482.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20971:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 60 slurm/20170912/161722'
20972:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20973:09/12/17 18:26:36 [65749] (483.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20974:09/12/17 18:26:36 [65749] (483.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20975:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 61 slurm/20170912/161719'
20976:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20977:09/12/17 18:26:36 [65749] (484.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20978:09/12/17 18:26:36 [65749] (484.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20979:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 62 slurm/20170912/161717'
20980:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20981:09/12/17 18:26:36 [65749] (485.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20982:09/12/17 18:26:36 [65749] (485.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20983:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 63 slurm/20170912/161744'
20984:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20985:09/12/17 18:26:36 [65749] (486.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20986:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20987:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 64 slurm/20170912/161749'
20988:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20989:09/12/17 18:26:36 [65749] (487.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20990:09/12/17 18:26:36 [65749] (487.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20991:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 65 slurm/20170912/161724'
20992:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20993:09/12/17 18:26:36 [65749] (488.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20994:09/12/17 18:26:36 [65749] (488.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20995:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 66 slurm/20170912/161718'
20996:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
20997:09/12/17 18:26:36 [65749] (489.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
20998:09/12/17 18:26:36 [65749] (489.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
20999:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 67 slurm/20170912/161729'
21000:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21001:09/12/17 18:26:36 [65749] (490.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21002:09/12/17 18:26:36 [65749] (490.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21003:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 68 slurm/20170912/161739'
21004:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21005:09/12/17 18:26:36 [65749] (491.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21006:09/12/17 18:26:36 [65749] (491.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21007:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 69 slurm/20170912/161723'
21008:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21009:09/12/17 18:26:36 [65749] (492.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21010:09/12/17 18:26:36 [65749] (492.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21011:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 70 slurm/20170912/161713'
21012:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21013:09/12/17 18:26:36 [65749] (493.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21014:09/12/17 18:26:36 [65749] (493.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21015:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 71 slurm/20170912/161716'
21016:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21017:09/12/17 18:26:36 [65749] (494.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21018:09/12/17 18:26:36 [65749] (494.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21019:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 72 slurm/20170912/161748'
21020:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21021:09/12/17 18:26:36 [65749] (495.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21022:09/12/17 18:26:36 [65749] (495.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21023:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 73 slurm/20170912/161727'
21024:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21025:09/12/17 18:26:36 [65749] (496.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21026:09/12/17 18:26:36 [65749] (496.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21027:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 74 slurm/20170912/161751'
21028:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21029:09/12/17 18:26:36 [65749] (497.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21030:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21031:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 75 slurm/20170912/161721'
21032:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21033:09/12/17 18:26:36 [65749] (498.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21034:09/12/17 18:26:36 [65749] (498.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21035:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 76 slurm/20170912/161740'
21036:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21037:09/12/17 18:26:36 [65749] (499.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21038:09/12/17 18:26:36 [65749] (499.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21039:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 77 slurm/20170912/161733'
21040:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21041:09/12/17 18:26:36 [65749] (500.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21042:09/12/17 18:26:36 [65749] (500.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21043:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 78 slurm/20170912/161732'
21044:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21045:09/12/17 18:26:36 [65749] (501.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21046:09/12/17 18:26:36 [65749] (501.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21047:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 79 slurm/20170912/161728'
21048:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21049:09/12/17 18:26:36 [65749] (502.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21050:09/12/17 18:26:36 [65749] (502.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21051:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 80 slurm/20170912/161720'
21052:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21053:09/12/17 18:26:36 [65749] (503.0) doEvaluateState called: gmState GM_SUBMITTED, remoteState -1
21054:09/12/17 18:26:36 [65749] (503.0) gm state change: GM_SUBMITTED -> GM_POLL_ACTIVE
21055:09/12/17 18:26:36 [65749] GAHP[65752] <- 'BLAH_JOB_STATUS 81 slurm/20170912/161738'
21056:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S'
21057:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21058:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21059:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '2'
21060:09/12/17 18:26:36 [65749] GAHP[65752] -> '64' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161749"; ImageSize = 0; WorkerNode = "mc1531"; RemoteUserCpu = 0 ]'
21061:09/12/17 18:26:36 [65749] GAHP[65752] -> '75' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161721"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21062:09/12/17 18:26:36 [65749] (486.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21063:09/12/17 18:26:36 [65749] (486.0) ***ProcessRemoteAd
21064:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21065:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21066:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21067:09/12/17 18:26:36 [65749] (497.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21068:09/12/17 18:26:36 [65749] (497.0) ***ProcessRemoteAd
21069:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21070:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21071:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21072:09/12/17 18:26:36 [65749] in doContactSchedd()
21073:09/12/17 18:26:36 [65749] querying for removed/held jobs
21074:09/12/17 18:26:36 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
21075:09/12/17 18:26:36 [65749] Fetched 0 job ads from schedd
21076:09/12/17 18:26:36 [65749] Updating classad values for 486.0:
21077:09/12/17 18:26:36 [65749]    CurrentStatusUnknown = false
21078:09/12/17 18:26:36 [65749]    EnteredCurrentStatus = 1505265996
21079:09/12/17 18:26:36 [65749]    ExitCode = 0
21080:09/12/17 18:26:36 [65749]    GridJobStatus = "COMPLETED"
21081:09/12/17 18:26:36 [65749]    ImageSize = 0
21082:09/12/17 18:26:36 [65749]    JobStatus = 4
21083:09/12/17 18:26:36 [65749]    LastRemoteStatusUpdate = 1505265996
21084:09/12/17 18:26:36 [65749]    RemoteUserCpu = 0
21085:09/12/17 18:26:36 [65749]    RemoteWallClockTime = 0.0
21086:09/12/17 18:26:36 [65749] Updating classad values for 497.0:
21087:09/12/17 18:26:36 [65749]    CurrentStatusUnknown = false
21088:09/12/17 18:26:36 [65749]    EnteredCurrentStatus = 1505265996
21089:09/12/17 18:26:36 [65749]    ExitCode = 0
21090:09/12/17 18:26:36 [65749]    GridJobStatus = "COMPLETED"
21091:09/12/17 18:26:36 [65749]    ImageSize = 0
21092:09/12/17 18:26:36 [65749]    JobStatus = 4
21093:09/12/17 18:26:36 [65749]    LastRemoteStatusUpdate = 1505265996
21094:09/12/17 18:26:36 [65749]    RemoteUserCpu = 0
21095:09/12/17 18:26:36 [65749]    RemoteWallClockTime = 0.0
21096:09/12/17 18:26:36 [65749] leaving doContactSchedd()
21097:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21098:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21099:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '2'
21100:09/12/17 18:26:36 [65749] GAHP[65752] -> '68' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161739"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21101:09/12/17 18:26:36 [65749] GAHP[65752] -> '73' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161727"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21102:09/12/17 18:26:36 [65749] (486.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21103:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21104:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21105:09/12/17 18:26:36 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21106:09/12/17 18:26:36 [65749] (486.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21107:09/12/17 18:26:36 [65749] (497.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21108:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21109:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21110:09/12/17 18:26:36 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21111:09/12/17 18:26:36 [65749] (497.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21112:09/12/17 18:26:36 [65749] (490.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21113:09/12/17 18:26:36 [65749] (490.0) ***ProcessRemoteAd
21114:09/12/17 18:26:36 [65749] (490.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21115:09/12/17 18:26:36 [65749] (490.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21116:09/12/17 18:26:36 [65749] (490.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21117:09/12/17 18:26:36 [65749] (495.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21118:09/12/17 18:26:36 [65749] (495.0) ***ProcessRemoteAd
21119:09/12/17 18:26:36 [65749] (495.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21120:09/12/17 18:26:36 [65749] (495.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21121:09/12/17 18:26:36 [65749] (495.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21122:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21123:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21124:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '4'
21125:09/12/17 18:26:36 [65749] GAHP[65752] -> '78' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161732"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21126:09/12/17 18:26:36 [65749] GAHP[65752] -> '79' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161728"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21127:09/12/17 18:26:36 [65749] GAHP[65752] -> '77' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161733"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21128:09/12/17 18:26:36 [65749] GAHP[65752] -> '50' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161730"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21129:09/12/17 18:26:36 [65749] (500.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21130:09/12/17 18:26:36 [65749] (500.0) ***ProcessRemoteAd
21131:09/12/17 18:26:36 [65749] (500.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21132:09/12/17 18:26:36 [65749] (500.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21133:09/12/17 18:26:36 [65749] (500.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21134:09/12/17 18:26:36 [65749] (501.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21135:09/12/17 18:26:36 [65749] (501.0) ***ProcessRemoteAd
21136:09/12/17 18:26:36 [65749] (501.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21137:09/12/17 18:26:36 [65749] (501.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21138:09/12/17 18:26:36 [65749] (501.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21139:09/12/17 18:26:36 [65749] (499.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21140:09/12/17 18:26:36 [65749] (499.0) ***ProcessRemoteAd
21141:09/12/17 18:26:36 [65749] (499.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21142:09/12/17 18:26:36 [65749] (499.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21143:09/12/17 18:26:36 [65749] (499.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21144:09/12/17 18:26:36 [65749] (512.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21145:09/12/17 18:26:36 [65749] (512.0) ***ProcessRemoteAd
21146:09/12/17 18:26:36 [65749] (512.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21147:09/12/17 18:26:36 [65749] (512.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21148:09/12/17 18:26:36 [65749] (512.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21149:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21150:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21151:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21152:09/12/17 18:26:36 [65749] GAHP[65752] -> '65' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161724"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21153:09/12/17 18:26:36 [65749] (487.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21154:09/12/17 18:26:36 [65749] (487.0) ***ProcessRemoteAd
21155:09/12/17 18:26:36 [65749] (487.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21156:09/12/17 18:26:36 [65749] (487.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21157:09/12/17 18:26:36 [65749] (487.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21158:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21159:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21160:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21161:09/12/17 18:26:36 [65749] GAHP[65752] -> '46' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161715"; ImageSize = 0; WorkerNode = "mc1533"; RemoteUserCpu = 0 ]'
21162:09/12/17 18:26:36 [65749] (508.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21163:09/12/17 18:26:36 [65749] (508.0) ***ProcessRemoteAd
21164:09/12/17 18:26:36 [65749] (508.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21165:09/12/17 18:26:36 [65749] (508.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21166:09/12/17 18:26:36 [65749] (508.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21167:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21168:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21169:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21170:09/12/17 18:26:36 [65749] GAHP[65752] -> '60' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161722"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21171:09/12/17 18:26:36 [65749] (482.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21172:09/12/17 18:26:36 [65749] (482.0) ***ProcessRemoteAd
21173:09/12/17 18:26:36 [65749] (482.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21174:09/12/17 18:26:36 [65749] (482.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21175:09/12/17 18:26:36 [65749] (482.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21176:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21177:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21178:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21179:09/12/17 18:26:36 [65749] GAHP[65752] -> '56' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161747"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21180:09/12/17 18:26:36 [65749] (478.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21181:09/12/17 18:26:36 [65749] (478.0) ***ProcessRemoteAd
21182:09/12/17 18:26:36 [65749] (478.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21183:09/12/17 18:26:36 [65749] (478.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21184:09/12/17 18:26:36 [65749] (478.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21185:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21186:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21187:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21188:09/12/17 18:26:36 [65749] GAHP[65752] -> '61' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161719"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21189:09/12/17 18:26:36 [65749] (483.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21190:09/12/17 18:26:36 [65749] (483.0) ***ProcessRemoteAd
21191:09/12/17 18:26:36 [65749] (483.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21192:09/12/17 18:26:36 [65749] (483.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21193:09/12/17 18:26:36 [65749] (483.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21194:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21195:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21196:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21197:09/12/17 18:26:36 [65749] GAHP[65752] -> '47' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161746"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21198:09/12/17 18:26:36 [65749] (509.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21199:09/12/17 18:26:36 [65749] (509.0) ***ProcessRemoteAd
21200:09/12/17 18:26:36 [65749] (509.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21201:09/12/17 18:26:36 [65749] (509.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21202:09/12/17 18:26:36 [65749] (509.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21203:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21204:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21205:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21206:09/12/17 18:26:36 [65749] GAHP[65752] -> '58' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161735"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21207:09/12/17 18:26:36 [65749] (480.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21208:09/12/17 18:26:36 [65749] (480.0) ***ProcessRemoteAd
21209:09/12/17 18:26:36 [65749] (480.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21210:09/12/17 18:26:36 [65749] (480.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21211:09/12/17 18:26:36 [65749] (480.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21212:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21213:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21214:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21215:09/12/17 18:26:36 [65749] GAHP[65752] -> '57' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161736"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21216:09/12/17 18:26:36 [65749] (479.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21217:09/12/17 18:26:36 [65749] (479.0) ***ProcessRemoteAd
21218:09/12/17 18:26:36 [65749] (479.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21219:09/12/17 18:26:36 [65749] (479.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21220:09/12/17 18:26:36 [65749] (479.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21221:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21222:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21223:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21224:09/12/17 18:26:36 [65749] GAHP[65752] -> '42' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161714"; ImageSize = 0; WorkerNode = "mc1528"; RemoteUserCpu = 0 ]'
21225:09/12/17 18:26:36 [65749] (504.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21226:09/12/17 18:26:36 [65749] (504.0) ***ProcessRemoteAd
21227:09/12/17 18:26:36 [65749] (504.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21228:09/12/17 18:26:36 [65749] (504.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21229:09/12/17 18:26:36 [65749] (504.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21230:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21231:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21232:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21233:09/12/17 18:26:36 [65749] GAHP[65752] -> '54' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161752"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21234:09/12/17 18:26:36 [65749] (516.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21235:09/12/17 18:26:36 [65749] (516.0) ***ProcessRemoteAd
21236:09/12/17 18:26:36 [65749] (516.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21237:09/12/17 18:26:36 [65749] (516.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21238:09/12/17 18:26:36 [65749] (516.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21239:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21240:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21241:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21242:09/12/17 18:26:36 [65749] GAHP[65752] -> '72' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161748"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21243:09/12/17 18:26:36 [65749] (494.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21244:09/12/17 18:26:36 [65749] (494.0) ***ProcessRemoteAd
21245:09/12/17 18:26:36 [65749] (494.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21246:09/12/17 18:26:36 [65749] (494.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21247:09/12/17 18:26:36 [65749] (494.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21248:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21249:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21250:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21251:09/12/17 18:26:36 [65749] GAHP[65752] -> '44' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161726"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21252:09/12/17 18:26:36 [65749] (506.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21253:09/12/17 18:26:36 [65749] (506.0) ***ProcessRemoteAd
21254:09/12/17 18:26:36 [65749] (506.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21255:09/12/17 18:26:36 [65749] (506.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21256:09/12/17 18:26:36 [65749] (506.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21257:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21258:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21259:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21260:09/12/17 18:26:36 [65749] GAHP[65752] -> '49' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161737"; ImageSize = 0; WorkerNode = "mc1531"; RemoteUserCpu = 0 ]'
21261:09/12/17 18:26:36 [65749] (511.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21262:09/12/17 18:26:36 [65749] (511.0) ***ProcessRemoteAd
21263:09/12/17 18:26:36 [65749] (511.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21264:09/12/17 18:26:36 [65749] (511.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21265:09/12/17 18:26:36 [65749] (511.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21266:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21267:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21268:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21269:09/12/17 18:26:36 [65749] GAHP[65752] -> '76' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161740"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21270:09/12/17 18:26:36 [65749] (498.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21271:09/12/17 18:26:36 [65749] (498.0) ***ProcessRemoteAd
21272:09/12/17 18:26:36 [65749] (498.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21273:09/12/17 18:26:36 [65749] (498.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21274:09/12/17 18:26:36 [65749] (498.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21275:09/12/17 18:26:36 [65749] GAHP[65752] <- 'RESULTS'
21276:09/12/17 18:26:36 [65749] GAHP[65752] -> 'R'
21277:09/12/17 18:26:36 [65749] GAHP[65752] -> 'S' '1'
21278:09/12/17 18:26:36 [65749] GAHP[65752] -> '51' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161745"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21279:09/12/17 18:26:36 [65749] (513.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21280:09/12/17 18:26:36 [65749] (513.0) ***ProcessRemoteAd
21281:09/12/17 18:26:36 [65749] (513.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21282:09/12/17 18:26:36 [65749] (513.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21283:09/12/17 18:26:36 [65749] (513.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21284:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21285:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21286:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21287:09/12/17 18:26:37 [65749] GAHP[65752] -> '52' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161743"; ImageSize = 0; WorkerNode = "mc1531"; RemoteUserCpu = 0 ]'
21288:09/12/17 18:26:37 [65749] (514.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21289:09/12/17 18:26:37 [65749] (514.0) ***ProcessRemoteAd
21290:09/12/17 18:26:37 [65749] (514.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21291:09/12/17 18:26:37 [65749] (514.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21292:09/12/17 18:26:37 [65749] (514.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21293:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21294:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21295:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21296:09/12/17 18:26:37 [65749] GAHP[65752] -> '80' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161720"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21297:09/12/17 18:26:37 [65749] (502.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21298:09/12/17 18:26:37 [65749] (502.0) ***ProcessRemoteAd
21299:09/12/17 18:26:37 [65749] (502.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21300:09/12/17 18:26:37 [65749] (502.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21301:09/12/17 18:26:37 [65749] (502.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21302:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21303:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21304:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21305:09/12/17 18:26:37 [65749] GAHP[65752] -> '69' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161723"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21306:09/12/17 18:26:37 [65749] (491.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21307:09/12/17 18:26:37 [65749] (491.0) ***ProcessRemoteAd
21308:09/12/17 18:26:37 [65749] (491.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21309:09/12/17 18:26:37 [65749] (491.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21310:09/12/17 18:26:37 [65749] (491.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21311:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21312:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21313:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21314:09/12/17 18:26:37 [65749] GAHP[65752] -> '71' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161716"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21315:09/12/17 18:26:37 [65749] (493.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21316:09/12/17 18:26:37 [65749] (493.0) ***ProcessRemoteAd
21317:09/12/17 18:26:37 [65749] (493.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21318:09/12/17 18:26:37 [65749] (493.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21319:09/12/17 18:26:37 [65749] (493.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21320:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21321:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21322:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21323:09/12/17 18:26:37 [65749] GAHP[65752] -> '55' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161741"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21324:09/12/17 18:26:37 [65749] (477.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21325:09/12/17 18:26:37 [65749] (477.0) ***ProcessRemoteAd
21326:09/12/17 18:26:37 [65749] (477.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21327:09/12/17 18:26:37 [65749] (477.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21328:09/12/17 18:26:37 [65749] (477.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21329:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21330:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21331:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21332:09/12/17 18:26:37 [65749] GAHP[65752] -> '48' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161731"; ImageSize = 0; WorkerNode = "mc1531"; RemoteUserCpu = 0 ]'
21333:09/12/17 18:26:37 [65749] (510.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21334:09/12/17 18:26:37 [65749] (510.0) ***ProcessRemoteAd
21335:09/12/17 18:26:37 [65749] (510.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21336:09/12/17 18:26:37 [65749] (510.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21337:09/12/17 18:26:37 [65749] (510.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21338:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21339:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21340:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21341:09/12/17 18:26:37 [65749] GAHP[65752] -> '62' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161717"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21342:09/12/17 18:26:37 [65749] (484.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21343:09/12/17 18:26:37 [65749] (484.0) ***ProcessRemoteAd
21344:09/12/17 18:26:37 [65749] (484.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21345:09/12/17 18:26:37 [65749] (484.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21346:09/12/17 18:26:37 [65749] (484.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21347:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21348:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21349:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21350:09/12/17 18:26:37 [65749] GAHP[65752] -> '59' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161725"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21351:09/12/17 18:26:37 [65749] (481.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21352:09/12/17 18:26:37 [65749] (481.0) ***ProcessRemoteAd
21353:09/12/17 18:26:37 [65749] (481.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21354:09/12/17 18:26:37 [65749] (481.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21355:09/12/17 18:26:37 [65749] (481.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21356:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21357:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21358:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21359:09/12/17 18:26:37 [65749] GAHP[65752] -> '66' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161718"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21360:09/12/17 18:26:37 [65749] (488.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21361:09/12/17 18:26:37 [65749] (488.0) ***ProcessRemoteAd
21362:09/12/17 18:26:37 [65749] (488.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21363:09/12/17 18:26:37 [65749] (488.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21364:09/12/17 18:26:37 [65749] (488.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21365:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21366:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21367:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21368:09/12/17 18:26:37 [65749] GAHP[65752] -> '63' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161744"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21369:09/12/17 18:26:37 [65749] (485.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21370:09/12/17 18:26:37 [65749] (485.0) ***ProcessRemoteAd
21371:09/12/17 18:26:37 [65749] (485.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21372:09/12/17 18:26:37 [65749] (485.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21373:09/12/17 18:26:37 [65749] (485.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21374:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21375:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21376:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21377:09/12/17 18:26:37 [65749] GAHP[65752] -> '43' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161742"; ImageSize = 0; WorkerNode = "mc1530"; RemoteUserCpu = 0 ]'
21378:09/12/17 18:26:37 [65749] (505.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21379:09/12/17 18:26:37 [65749] (505.0) ***ProcessRemoteAd
21380:09/12/17 18:26:37 [65749] (505.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21381:09/12/17 18:26:37 [65749] (505.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21382:09/12/17 18:26:37 [65749] (505.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21383:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21384:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21385:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21386:09/12/17 18:26:37 [65749] GAHP[65752] -> '70' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161713"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21387:09/12/17 18:26:37 [65749] (492.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21388:09/12/17 18:26:37 [65749] (492.0) ***ProcessRemoteAd
21389:09/12/17 18:26:37 [65749] (492.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21390:09/12/17 18:26:37 [65749] (492.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21391:09/12/17 18:26:37 [65749] (492.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21392:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21393:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21394:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21395:09/12/17 18:26:37 [65749] GAHP[65752] -> '45' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161750"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21396:09/12/17 18:26:37 [65749] (507.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21397:09/12/17 18:26:37 [65749] (507.0) ***ProcessRemoteAd
21398:09/12/17 18:26:37 [65749] (507.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21399:09/12/17 18:26:37 [65749] (507.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21400:09/12/17 18:26:37 [65749] (507.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21401:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21402:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21403:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21404:09/12/17 18:26:37 [65749] GAHP[65752] -> '53' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161734"; ImageSize = 0; WorkerNode = "mc1504"; RemoteUserCpu = 0 ]'
21405:09/12/17 18:26:37 [65749] (515.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21406:09/12/17 18:26:37 [65749] (515.0) ***ProcessRemoteAd
21407:09/12/17 18:26:37 [65749] (515.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21408:09/12/17 18:26:37 [65749] (515.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21409:09/12/17 18:26:37 [65749] (515.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21410:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21411:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21412:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21413:09/12/17 18:26:37 [65749] GAHP[65752] -> '74' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161751"; ImageSize = 0; WorkerNode = "mc1534"; RemoteUserCpu = 0 ]'
21414:09/12/17 18:26:37 [65749] (496.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21415:09/12/17 18:26:37 [65749] (496.0) ***ProcessRemoteAd
21416:09/12/17 18:26:37 [65749] (496.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21417:09/12/17 18:26:37 [65749] (496.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21418:09/12/17 18:26:37 [65749] (496.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21419:09/12/17 18:26:37 [65749] GAHP[65752] <- 'RESULTS'
21420:09/12/17 18:26:37 [65749] GAHP[65752] -> 'R'
21421:09/12/17 18:26:37 [65749] GAHP[65752] -> 'S' '1'
21422:09/12/17 18:26:37 [65749] GAHP[65752] -> '67' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161729"; ImageSize = 0; WorkerNode = "mc1529"; RemoteUserCpu = 0 ]'
21423:09/12/17 18:26:37 [65749] (489.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21424:09/12/17 18:26:37 [65749] (489.0) ***ProcessRemoteAd
21425:09/12/17 18:26:37 [65749] (489.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21426:09/12/17 18:26:37 [65749] (489.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21427:09/12/17 18:26:37 [65749] (489.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21428:09/12/17 18:26:38 [65749] GAHP[65752] <- 'RESULTS'
21429:09/12/17 18:26:38 [65749] GAHP[65752] -> 'R'
21430:09/12/17 18:26:38 [65749] GAHP[65752] -> 'S' '1'
21431:09/12/17 18:26:38 [65749] GAHP[65752] -> '81' '0' 'No Error' '4' '[ ExitCode = 0; JobStatus = 4; BatchJobId = "161738"; ImageSize = 0; WorkerNode = "mc1532"; RemoteUserCpu = 0 ]'
21432:09/12/17 18:26:38 [65749] (503.0) doEvaluateState called: gmState GM_POLL_ACTIVE, remoteState -1
21433:09/12/17 18:26:38 [65749] (503.0) ***ProcessRemoteAd
21434:09/12/17 18:26:38 [65749] (503.0) gm state change: GM_POLL_ACTIVE -> GM_SUBMITTED
21435:09/12/17 18:26:38 [65749] (503.0) gm state change: GM_SUBMITTED -> GM_TRANSFER_OUTPUT
21436:09/12/17 18:26:38 [65749] (503.0) gm state change: GM_TRANSFER_OUTPUT -> GM_DONE_SAVE
21437:09/12/17 18:26:41 [65749] in doContactSchedd()
21438:09/12/17 18:26:41 [65749] querying for removed/held jobs
21439:09/12/17 18:26:41 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
21440:09/12/17 18:26:41 [65749] Fetched 2 job ads from schedd
21441:09/12/17 18:26:41 [65749] Updating classad values for 504.0:
21442:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21443:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21444:09/12/17 18:26:41 [65749]    ExitCode = 0
21445:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21446:09/12/17 18:26:41 [65749]    ImageSize = 0
21447:09/12/17 18:26:41 [65749]    JobStatus = 4
21448:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21449:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21450:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21451:09/12/17 18:26:41 [65749] Updating classad values for 505.0:
21452:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21453:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21454:09/12/17 18:26:41 [65749]    ExitCode = 0
21455:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21456:09/12/17 18:26:41 [65749]    ImageSize = 0
21457:09/12/17 18:26:41 [65749]    JobStatus = 4
21458:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21459:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21460:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21461:09/12/17 18:26:41 [65749] Updating classad values for 506.0:
21462:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21463:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21464:09/12/17 18:26:41 [65749]    ExitCode = 0
21465:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21466:09/12/17 18:26:41 [65749]    ImageSize = 0
21467:09/12/17 18:26:41 [65749]    JobStatus = 4
21468:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21469:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21470:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21471:09/12/17 18:26:41 [65749] Updating classad values for 507.0:
21472:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21473:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21474:09/12/17 18:26:41 [65749]    ExitCode = 0
21475:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21476:09/12/17 18:26:41 [65749]    ImageSize = 0
21477:09/12/17 18:26:41 [65749]    JobStatus = 4
21478:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21479:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21480:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21481:09/12/17 18:26:41 [65749] Updating classad values for 508.0:
21482:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21483:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21484:09/12/17 18:26:41 [65749]    ExitCode = 0
21485:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21486:09/12/17 18:26:41 [65749]    ImageSize = 0
21487:09/12/17 18:26:41 [65749]    JobStatus = 4
21488:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21489:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21490:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21491:09/12/17 18:26:41 [65749] Updating classad values for 509.0:
21492:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21493:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21494:09/12/17 18:26:41 [65749]    ExitCode = 0
21495:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21496:09/12/17 18:26:41 [65749]    ImageSize = 0
21497:09/12/17 18:26:41 [65749]    JobStatus = 4
21498:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21499:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21500:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21501:09/12/17 18:26:41 [65749] Updating classad values for 510.0:
21502:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21503:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21504:09/12/17 18:26:41 [65749]    ExitCode = 0
21505:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21506:09/12/17 18:26:41 [65749]    ImageSize = 0
21507:09/12/17 18:26:41 [65749]    JobStatus = 4
21508:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21509:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21510:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21511:09/12/17 18:26:41 [65749] Updating classad values for 511.0:
21512:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21513:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21514:09/12/17 18:26:41 [65749]    ExitCode = 0
21515:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21516:09/12/17 18:26:41 [65749]    ImageSize = 0
21517:09/12/17 18:26:41 [65749]    JobStatus = 4
21518:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21519:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21520:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21521:09/12/17 18:26:41 [65749] Updating classad values for 512.0:
21522:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21523:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21524:09/12/17 18:26:41 [65749]    ExitCode = 0
21525:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21526:09/12/17 18:26:41 [65749]    ImageSize = 0
21527:09/12/17 18:26:41 [65749]    JobStatus = 4
21528:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21529:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21530:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21531:09/12/17 18:26:41 [65749] Updating classad values for 513.0:
21532:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21533:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21534:09/12/17 18:26:41 [65749]    ExitCode = 0
21535:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21536:09/12/17 18:26:41 [65749]    ImageSize = 0
21537:09/12/17 18:26:41 [65749]    JobStatus = 4
21538:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21539:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21540:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21541:09/12/17 18:26:41 [65749] Updating classad values for 514.0:
21542:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21543:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21544:09/12/17 18:26:41 [65749]    ExitCode = 0
21545:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21546:09/12/17 18:26:41 [65749]    ImageSize = 0
21547:09/12/17 18:26:41 [65749]    JobStatus = 4
21548:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21549:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21550:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21551:09/12/17 18:26:41 [65749] Updating classad values for 515.0:
21552:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21553:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21554:09/12/17 18:26:41 [65749]    ExitCode = 0
21555:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21556:09/12/17 18:26:41 [65749]    ImageSize = 0
21557:09/12/17 18:26:41 [65749]    JobStatus = 4
21558:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21559:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21560:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21561:09/12/17 18:26:41 [65749] Updating classad values for 516.0:
21562:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21563:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21564:09/12/17 18:26:41 [65749]    ExitCode = 0
21565:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21566:09/12/17 18:26:41 [65749]    ImageSize = 0
21567:09/12/17 18:26:41 [65749]    JobStatus = 4
21568:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21569:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21570:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21571:09/12/17 18:26:41 [65749] Updating classad values for 477.0:
21572:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21573:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21574:09/12/17 18:26:41 [65749]    ExitCode = 0
21575:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21576:09/12/17 18:26:41 [65749]    ImageSize = 0
21577:09/12/17 18:26:41 [65749]    JobStatus = 4
21578:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21579:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21580:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21581:09/12/17 18:26:41 [65749] Updating classad values for 478.0:
21582:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21583:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21584:09/12/17 18:26:41 [65749]    ExitCode = 0
21585:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21586:09/12/17 18:26:41 [65749]    ImageSize = 0
21587:09/12/17 18:26:41 [65749]    JobStatus = 4
21588:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21589:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21590:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21591:09/12/17 18:26:41 [65749] Updating classad values for 479.0:
21592:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21593:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21594:09/12/17 18:26:41 [65749]    ExitCode = 0
21595:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21596:09/12/17 18:26:41 [65749]    ImageSize = 0
21597:09/12/17 18:26:41 [65749]    JobStatus = 4
21598:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21599:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21600:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21601:09/12/17 18:26:41 [65749] Updating classad values for 480.0:
21602:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21603:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21604:09/12/17 18:26:41 [65749]    ExitCode = 0
21605:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21606:09/12/17 18:26:41 [65749]    ImageSize = 0
21607:09/12/17 18:26:41 [65749]    JobStatus = 4
21608:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21609:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21610:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21611:09/12/17 18:26:41 [65749] Updating classad values for 481.0:
21612:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21613:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21614:09/12/17 18:26:41 [65749]    ExitCode = 0
21615:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21616:09/12/17 18:26:41 [65749]    ImageSize = 0
21617:09/12/17 18:26:41 [65749]    JobStatus = 4
21618:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21619:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21620:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21621:09/12/17 18:26:41 [65749] Updating classad values for 482.0:
21622:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21623:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21624:09/12/17 18:26:41 [65749]    ExitCode = 0
21625:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21626:09/12/17 18:26:41 [65749]    ImageSize = 0
21627:09/12/17 18:26:41 [65749]    JobStatus = 4
21628:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21629:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21630:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21631:09/12/17 18:26:41 [65749] Updating classad values for 483.0:
21632:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21633:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21634:09/12/17 18:26:41 [65749]    ExitCode = 0
21635:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21636:09/12/17 18:26:41 [65749]    ImageSize = 0
21637:09/12/17 18:26:41 [65749]    JobStatus = 4
21638:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21639:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21640:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21641:09/12/17 18:26:41 [65749] Updating classad values for 484.0:
21642:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21643:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21644:09/12/17 18:26:41 [65749]    ExitCode = 0
21645:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21646:09/12/17 18:26:41 [65749]    ImageSize = 0
21647:09/12/17 18:26:41 [65749]    JobStatus = 4
21648:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21649:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21650:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21651:09/12/17 18:26:41 [65749] Updating classad values for 485.0:
21652:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21653:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21654:09/12/17 18:26:41 [65749]    ExitCode = 0
21655:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21656:09/12/17 18:26:41 [65749]    ImageSize = 0
21657:09/12/17 18:26:41 [65749]    JobStatus = 4
21658:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21659:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21660:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21661:09/12/17 18:26:41 [65749] Updating classad values for 486.0:
21662:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21663:09/12/17 18:26:41 [65749]    GridJobId = undefined
21664:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 0
21665:09/12/17 18:26:41 [65749]    Managed = "ScheddDone"
21666:09/12/17 18:26:41 [65749] Updating classad values for 487.0:
21667:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21668:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21669:09/12/17 18:26:41 [65749]    ExitCode = 0
21670:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21671:09/12/17 18:26:41 [65749]    ImageSize = 0
21672:09/12/17 18:26:41 [65749]    JobStatus = 4
21673:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21674:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21675:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21676:09/12/17 18:26:41 [65749] Updating classad values for 488.0:
21677:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21678:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21679:09/12/17 18:26:41 [65749]    ExitCode = 0
21680:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21681:09/12/17 18:26:41 [65749]    ImageSize = 0
21682:09/12/17 18:26:41 [65749]    JobStatus = 4
21683:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21684:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21685:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21686:09/12/17 18:26:41 [65749] Updating classad values for 489.0:
21687:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21688:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21689:09/12/17 18:26:41 [65749]    ExitCode = 0
21690:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21691:09/12/17 18:26:41 [65749]    ImageSize = 0
21692:09/12/17 18:26:41 [65749]    JobStatus = 4
21693:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21694:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21695:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21696:09/12/17 18:26:41 [65749] Updating classad values for 490.0:
21697:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21698:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21699:09/12/17 18:26:41 [65749]    ExitCode = 0
21700:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21701:09/12/17 18:26:41 [65749]    ImageSize = 0
21702:09/12/17 18:26:41 [65749]    JobStatus = 4
21703:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21704:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21705:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21706:09/12/17 18:26:41 [65749] Updating classad values for 491.0:
21707:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21708:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21709:09/12/17 18:26:41 [65749]    ExitCode = 0
21710:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21711:09/12/17 18:26:41 [65749]    ImageSize = 0
21712:09/12/17 18:26:41 [65749]    JobStatus = 4
21713:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21714:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21715:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21716:09/12/17 18:26:41 [65749] Updating classad values for 492.0:
21717:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21718:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21719:09/12/17 18:26:41 [65749]    ExitCode = 0
21720:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21721:09/12/17 18:26:41 [65749]    ImageSize = 0
21722:09/12/17 18:26:41 [65749]    JobStatus = 4
21723:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21724:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21725:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21726:09/12/17 18:26:41 [65749] Updating classad values for 493.0:
21727:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21728:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21729:09/12/17 18:26:41 [65749]    ExitCode = 0
21730:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21731:09/12/17 18:26:41 [65749]    ImageSize = 0
21732:09/12/17 18:26:41 [65749]    JobStatus = 4
21733:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21734:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21735:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21736:09/12/17 18:26:41 [65749] Updating classad values for 494.0:
21737:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21738:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21739:09/12/17 18:26:41 [65749]    ExitCode = 0
21740:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21741:09/12/17 18:26:41 [65749]    ImageSize = 0
21742:09/12/17 18:26:41 [65749]    JobStatus = 4
21743:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21744:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21745:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21746:09/12/17 18:26:41 [65749] Updating classad values for 495.0:
21747:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21748:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21749:09/12/17 18:26:41 [65749]    ExitCode = 0
21750:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21751:09/12/17 18:26:41 [65749]    ImageSize = 0
21752:09/12/17 18:26:41 [65749]    JobStatus = 4
21753:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21754:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21755:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21756:09/12/17 18:26:41 [65749] Updating classad values for 496.0:
21757:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21758:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21759:09/12/17 18:26:41 [65749]    ExitCode = 0
21760:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21761:09/12/17 18:26:41 [65749]    ImageSize = 0
21762:09/12/17 18:26:41 [65749]    JobStatus = 4
21763:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21764:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21765:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21766:09/12/17 18:26:41 [65749] Updating classad values for 497.0:
21767:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21768:09/12/17 18:26:41 [65749]    GridJobId = undefined
21769:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 0
21770:09/12/17 18:26:41 [65749]    Managed = "ScheddDone"
21771:09/12/17 18:26:41 [65749] Updating classad values for 498.0:
21772:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21773:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21774:09/12/17 18:26:41 [65749]    ExitCode = 0
21775:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21776:09/12/17 18:26:41 [65749]    ImageSize = 0
21777:09/12/17 18:26:41 [65749]    JobStatus = 4
21778:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21779:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21780:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21781:09/12/17 18:26:41 [65749] Updating classad values for 499.0:
21782:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21783:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21784:09/12/17 18:26:41 [65749]    ExitCode = 0
21785:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21786:09/12/17 18:26:41 [65749]    ImageSize = 0
21787:09/12/17 18:26:41 [65749]    JobStatus = 4
21788:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21789:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21790:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21791:09/12/17 18:26:41 [65749] Updating classad values for 500.0:
21792:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21793:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21794:09/12/17 18:26:41 [65749]    ExitCode = 0
21795:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21796:09/12/17 18:26:41 [65749]    ImageSize = 0
21797:09/12/17 18:26:41 [65749]    JobStatus = 4
21798:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21799:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21800:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21801:09/12/17 18:26:41 [65749] Updating classad values for 501.0:
21802:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21803:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265996
21804:09/12/17 18:26:41 [65749]    ExitCode = 0
21805:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21806:09/12/17 18:26:41 [65749]    ImageSize = 0
21807:09/12/17 18:26:41 [65749]    JobStatus = 4
21808:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265996
21809:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21810:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21811:09/12/17 18:26:41 [65749] Updating classad values for 502.0:
21812:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21813:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265997
21814:09/12/17 18:26:41 [65749]    ExitCode = 0
21815:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21816:09/12/17 18:26:41 [65749]    ImageSize = 0
21817:09/12/17 18:26:41 [65749]    JobStatus = 4
21818:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265997
21819:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21820:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21821:09/12/17 18:26:41 [65749] Updating classad values for 503.0:
21822:09/12/17 18:26:41 [65749]    CurrentStatusUnknown = false
21823:09/12/17 18:26:41 [65749]    EnteredCurrentStatus = 1505265998
21824:09/12/17 18:26:41 [65749]    ExitCode = 0
21825:09/12/17 18:26:41 [65749]    GridJobStatus = "COMPLETED"
21826:09/12/17 18:26:41 [65749]    ImageSize = 0
21827:09/12/17 18:26:41 [65749]    JobStatus = 4
21828:09/12/17 18:26:41 [65749]    LastRemoteStatusUpdate = 1505265998
21829:09/12/17 18:26:41 [65749]    RemoteUserCpu = 0
21830:09/12/17 18:26:41 [65749]    RemoteWallClockTime = 0.0
21831:09/12/17 18:26:41 [65749] Deleting job 486.0 from schedd
21832:09/12/17 18:26:41 [65749] Deleting job 497.0 from schedd
21833:09/12/17 18:26:41 [65749] leaving doContactSchedd()
21834:09/12/17 18:26:41 [65749] (504.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21835:09/12/17 18:26:41 [65749] (504.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21836:09/12/17 18:26:41 [65749] (504.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21837:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21838:09/12/17 18:26:41 [65749] (504.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21839:09/12/17 18:26:41 [65749] (505.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21840:09/12/17 18:26:41 [65749] (505.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21841:09/12/17 18:26:41 [65749] (505.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21842:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21843:09/12/17 18:26:41 [65749] (505.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21844:09/12/17 18:26:41 [65749] (506.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21845:09/12/17 18:26:41 [65749] (506.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21846:09/12/17 18:26:41 [65749] (506.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21847:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21848:09/12/17 18:26:41 [65749] (506.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21849:09/12/17 18:26:41 [65749] (507.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21850:09/12/17 18:26:41 [65749] (507.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21851:09/12/17 18:26:41 [65749] (507.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21852:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21853:09/12/17 18:26:41 [65749] (507.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21854:09/12/17 18:26:41 [65749] (508.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21855:09/12/17 18:26:41 [65749] (508.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21856:09/12/17 18:26:41 [65749] (508.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21857:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21858:09/12/17 18:26:41 [65749] (508.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21859:09/12/17 18:26:41 [65749] (509.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21860:09/12/17 18:26:41 [65749] (509.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21861:09/12/17 18:26:41 [65749] (509.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21862:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21863:09/12/17 18:26:41 [65749] (509.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21864:09/12/17 18:26:41 [65749] (510.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21865:09/12/17 18:26:41 [65749] (510.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21866:09/12/17 18:26:41 [65749] (510.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21867:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21868:09/12/17 18:26:41 [65749] (510.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21869:09/12/17 18:26:41 [65749] (511.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21870:09/12/17 18:26:41 [65749] (511.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21871:09/12/17 18:26:41 [65749] (511.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21872:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21873:09/12/17 18:26:41 [65749] (511.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21874:09/12/17 18:26:41 [65749] (512.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21875:09/12/17 18:26:41 [65749] (512.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21876:09/12/17 18:26:41 [65749] (512.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21877:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21878:09/12/17 18:26:41 [65749] (512.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21879:09/12/17 18:26:41 [65749] (513.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21880:09/12/17 18:26:41 [65749] (513.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21881:09/12/17 18:26:41 [65749] (513.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21882:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21883:09/12/17 18:26:41 [65749] (513.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21884:09/12/17 18:26:41 [65749] (514.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21885:09/12/17 18:26:41 [65749] (514.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21886:09/12/17 18:26:41 [65749] (514.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21887:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21888:09/12/17 18:26:41 [65749] (514.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21889:09/12/17 18:26:41 [65749] (515.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21890:09/12/17 18:26:41 [65749] (515.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21891:09/12/17 18:26:41 [65749] (515.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21892:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21893:09/12/17 18:26:41 [65749] (515.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21894:09/12/17 18:26:41 [65749] (516.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21895:09/12/17 18:26:41 [65749] (516.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21896:09/12/17 18:26:41 [65749] (516.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21897:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21898:09/12/17 18:26:41 [65749] (516.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21899:09/12/17 18:26:41 [65749] (477.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21900:09/12/17 18:26:41 [65749] (477.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21901:09/12/17 18:26:41 [65749] (477.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21902:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21903:09/12/17 18:26:41 [65749] (477.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21904:09/12/17 18:26:41 [65749] (478.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21905:09/12/17 18:26:41 [65749] (478.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21906:09/12/17 18:26:41 [65749] (478.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21907:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21908:09/12/17 18:26:41 [65749] (478.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21909:09/12/17 18:26:41 [65749] (479.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21910:09/12/17 18:26:41 [65749] (479.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21911:09/12/17 18:26:41 [65749] (479.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21912:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21913:09/12/17 18:26:41 [65749] (479.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21914:09/12/17 18:26:41 [65749] (480.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21915:09/12/17 18:26:41 [65749] (480.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21916:09/12/17 18:26:41 [65749] (480.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21917:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21918:09/12/17 18:26:41 [65749] (480.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21919:09/12/17 18:26:41 [65749] (481.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21920:09/12/17 18:26:41 [65749] (481.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21921:09/12/17 18:26:41 [65749] (481.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21922:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21923:09/12/17 18:26:41 [65749] (481.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21924:09/12/17 18:26:41 [65749] (482.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21925:09/12/17 18:26:41 [65749] (482.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21926:09/12/17 18:26:41 [65749] (482.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21927:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21928:09/12/17 18:26:41 [65749] (482.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21929:09/12/17 18:26:41 [65749] (483.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21930:09/12/17 18:26:41 [65749] (483.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21931:09/12/17 18:26:41 [65749] (483.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21932:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21933:09/12/17 18:26:41 [65749] (483.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21934:09/12/17 18:26:41 [65749] (484.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21935:09/12/17 18:26:41 [65749] (484.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21936:09/12/17 18:26:41 [65749] (484.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21937:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21938:09/12/17 18:26:41 [65749] (484.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21939:09/12/17 18:26:41 [65749] (485.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21940:09/12/17 18:26:41 [65749] (485.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21941:09/12/17 18:26:41 [65749] (485.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21942:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21943:09/12/17 18:26:41 [65749] (485.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21944:09/12/17 18:26:41 [65749] (487.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21945:09/12/17 18:26:41 [65749] (487.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21946:09/12/17 18:26:41 [65749] (487.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21947:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21948:09/12/17 18:26:41 [65749] (487.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21949:09/12/17 18:26:41 [65749] (488.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21950:09/12/17 18:26:41 [65749] (488.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21951:09/12/17 18:26:41 [65749] (488.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21952:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21953:09/12/17 18:26:41 [65749] (488.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21954:09/12/17 18:26:41 [65749] (489.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21955:09/12/17 18:26:41 [65749] (489.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21956:09/12/17 18:26:41 [65749] (489.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21957:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21958:09/12/17 18:26:41 [65749] (489.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21959:09/12/17 18:26:41 [65749] (490.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21960:09/12/17 18:26:41 [65749] (490.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21961:09/12/17 18:26:41 [65749] (490.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21962:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21963:09/12/17 18:26:41 [65749] (490.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21964:09/12/17 18:26:41 [65749] (491.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21965:09/12/17 18:26:41 [65749] (491.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21966:09/12/17 18:26:41 [65749] (491.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21967:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21968:09/12/17 18:26:41 [65749] (491.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21969:09/12/17 18:26:41 [65749] (492.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21970:09/12/17 18:26:41 [65749] (492.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21971:09/12/17 18:26:41 [65749] (492.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21972:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21973:09/12/17 18:26:41 [65749] (492.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21974:09/12/17 18:26:41 [65749] (493.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21975:09/12/17 18:26:41 [65749] (493.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21976:09/12/17 18:26:41 [65749] (493.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21977:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21978:09/12/17 18:26:41 [65749] (493.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21979:09/12/17 18:26:41 [65749] (494.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21980:09/12/17 18:26:41 [65749] (494.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21981:09/12/17 18:26:41 [65749] (494.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21982:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21983:09/12/17 18:26:41 [65749] (494.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21984:09/12/17 18:26:41 [65749] (495.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21985:09/12/17 18:26:41 [65749] (495.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21986:09/12/17 18:26:41 [65749] (495.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21987:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21988:09/12/17 18:26:41 [65749] (495.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21989:09/12/17 18:26:41 [65749] (496.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21990:09/12/17 18:26:41 [65749] (496.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21991:09/12/17 18:26:41 [65749] (496.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21992:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21993:09/12/17 18:26:41 [65749] (496.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21994:09/12/17 18:26:41 [65749] (498.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
21995:09/12/17 18:26:41 [65749] (498.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
21996:09/12/17 18:26:41 [65749] (498.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
21997:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
21998:09/12/17 18:26:41 [65749] (498.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
21999:09/12/17 18:26:41 [65749] (499.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
22000:09/12/17 18:26:41 [65749] (499.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
22001:09/12/17 18:26:41 [65749] (499.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
22002:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
22003:09/12/17 18:26:41 [65749] (499.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
22004:09/12/17 18:26:41 [65749] (500.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
22005:09/12/17 18:26:41 [65749] (500.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
22006:09/12/17 18:26:41 [65749] (500.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
22007:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
22008:09/12/17 18:26:41 [65749] (500.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
22009:09/12/17 18:26:41 [65749] (501.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
22010:09/12/17 18:26:41 [65749] (501.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
22011:09/12/17 18:26:41 [65749] (501.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
22012:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
22013:09/12/17 18:26:41 [65749] (501.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
22014:09/12/17 18:26:41 [65749] (502.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
22015:09/12/17 18:26:41 [65749] (502.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
22016:09/12/17 18:26:41 [65749] (502.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
22017:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
22018:09/12/17 18:26:41 [65749] (502.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
22019:09/12/17 18:26:41 [65749] (503.0) doEvaluateState called: gmState GM_DONE_SAVE, remoteState 4
22020:09/12/17 18:26:41 [65749] (503.0) gm state change: GM_DONE_SAVE -> GM_DONE_COMMIT
22021:09/12/17 18:26:41 [65749] (503.0) gm state change: GM_DONE_COMMIT -> GM_DELETE_SANDBOX
22022:09/12/17 18:26:41 [65749] Initializing Directory: curr_dir = /global/homes/a/alicesgm
22023:09/12/17 18:26:42 [65749] (503.0) gm state change: GM_DELETE_SANDBOX -> GM_DELETE
22024:09/12/17 18:26:46 [65749] in doContactSchedd()
22025:09/12/17 18:26:46 [65749] querying for removed/held jobs
22026:09/12/17 18:26:46 [65749] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
22027:09/12/17 18:26:46 [65749] Fetched 38 job ads from schedd
22028:09/12/17 18:26:46 [65749] Updating classad values for 504.0:
22029:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22030:09/12/17 18:26:46 [65749]    GridJobId = undefined
22031:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22032:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22033:09/12/17 18:26:46 [65749] Updating classad values for 505.0:
22034:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22035:09/12/17 18:26:46 [65749]    GridJobId = undefined
22036:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22037:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22038:09/12/17 18:26:46 [65749] Updating classad values for 506.0:
22039:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22040:09/12/17 18:26:46 [65749]    GridJobId = undefined
22041:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22042:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22043:09/12/17 18:26:46 [65749] Updating classad values for 507.0:
22044:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22045:09/12/17 18:26:46 [65749]    GridJobId = undefined
22046:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22047:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22048:09/12/17 18:26:46 [65749] Updating classad values for 508.0:
22049:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22050:09/12/17 18:26:46 [65749]    GridJobId = undefined
22051:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22052:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22053:09/12/17 18:26:46 [65749] Updating classad values for 509.0:
22054:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22055:09/12/17 18:26:46 [65749]    GridJobId = undefined
22056:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22057:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22058:09/12/17 18:26:46 [65749] Updating classad values for 510.0:
22059:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22060:09/12/17 18:26:46 [65749]    GridJobId = undefined
22061:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22062:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22063:09/12/17 18:26:46 [65749] Updating classad values for 511.0:
22064:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22065:09/12/17 18:26:46 [65749]    GridJobId = undefined
22066:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22067:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22068:09/12/17 18:26:46 [65749] Updating classad values for 512.0:
22069:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22070:09/12/17 18:26:46 [65749]    GridJobId = undefined
22071:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22072:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22073:09/12/17 18:26:46 [65749] Updating classad values for 513.0:
22074:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22075:09/12/17 18:26:46 [65749]    GridJobId = undefined
22076:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22077:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22078:09/12/17 18:26:46 [65749] Updating classad values for 514.0:
22079:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22080:09/12/17 18:26:46 [65749]    GridJobId = undefined
22081:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22082:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22083:09/12/17 18:26:46 [65749] Updating classad values for 515.0:
22084:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22085:09/12/17 18:26:46 [65749]    GridJobId = undefined
22086:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22087:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22088:09/12/17 18:26:46 [65749] Updating classad values for 516.0:
22089:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22090:09/12/17 18:26:46 [65749]    GridJobId = undefined
22091:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22092:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22093:09/12/17 18:26:46 [65749] Updating classad values for 477.0:
22094:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22095:09/12/17 18:26:46 [65749]    GridJobId = undefined
22096:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22097:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22098:09/12/17 18:26:46 [65749] Updating classad values for 478.0:
22099:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22100:09/12/17 18:26:46 [65749]    GridJobId = undefined
22101:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22102:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22103:09/12/17 18:26:46 [65749] Updating classad values for 479.0:
22104:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22105:09/12/17 18:26:46 [65749]    GridJobId = undefined
22106:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22107:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22108:09/12/17 18:26:46 [65749] Updating classad values for 480.0:
22109:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22110:09/12/17 18:26:46 [65749]    GridJobId = undefined
22111:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22112:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22113:09/12/17 18:26:46 [65749] Updating classad values for 481.0:
22114:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22115:09/12/17 18:26:46 [65749]    GridJobId = undefined
22116:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22117:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22118:09/12/17 18:26:46 [65749] Updating classad values for 482.0:
22119:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22120:09/12/17 18:26:46 [65749]    GridJobId = undefined
22121:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22122:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22123:09/12/17 18:26:46 [65749] Updating classad values for 483.0:
22124:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22125:09/12/17 18:26:46 [65749]    GridJobId = undefined
22126:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22127:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22128:09/12/17 18:26:46 [65749] Updating classad values for 484.0:
22129:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22130:09/12/17 18:26:46 [65749]    GridJobId = undefined
22131:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22132:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22133:09/12/17 18:26:46 [65749] Updating classad values for 485.0:
22134:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22135:09/12/17 18:26:46 [65749]    GridJobId = undefined
22136:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22137:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22138:09/12/17 18:26:46 [65749] Updating classad values for 487.0:
22139:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22140:09/12/17 18:26:46 [65749]    GridJobId = undefined
22141:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22142:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22143:09/12/17 18:26:46 [65749] Updating classad values for 488.0:
22144:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22145:09/12/17 18:26:46 [65749]    GridJobId = undefined
22146:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22147:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22148:09/12/17 18:26:46 [65749] Updating classad values for 489.0:
22149:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22150:09/12/17 18:26:46 [65749]    GridJobId = undefined
22151:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22152:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22153:09/12/17 18:26:46 [65749] Updating classad values for 490.0:
22154:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22155:09/12/17 18:26:46 [65749]    GridJobId = undefined
22156:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22157:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22158:09/12/17 18:26:46 [65749] Updating classad values for 491.0:
22159:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22160:09/12/17 18:26:46 [65749]    GridJobId = undefined
22161:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22162:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22163:09/12/17 18:26:46 [65749] Updating classad values for 492.0:
22164:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22165:09/12/17 18:26:46 [65749]    GridJobId = undefined
22166:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22167:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22168:09/12/17 18:26:46 [65749] Updating classad values for 493.0:
22169:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22170:09/12/17 18:26:46 [65749]    GridJobId = undefined
22171:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22172:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22173:09/12/17 18:26:46 [65749] Updating classad values for 494.0:
22174:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22175:09/12/17 18:26:46 [65749]    GridJobId = undefined
22176:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22177:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22178:09/12/17 18:26:46 [65749] Updating classad values for 495.0:
22179:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22180:09/12/17 18:26:46 [65749]    GridJobId = undefined
22181:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22182:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22183:09/12/17 18:26:46 [65749] Updating classad values for 496.0:
22184:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22185:09/12/17 18:26:46 [65749]    GridJobId = undefined
22186:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22187:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22188:09/12/17 18:26:46 [65749] Updating classad values for 498.0:
22189:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22190:09/12/17 18:26:46 [65749]    GridJobId = undefined
22191:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22192:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22193:09/12/17 18:26:46 [65749] Updating classad values for 499.0:
22194:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22195:09/12/17 18:26:46 [65749]    GridJobId = undefined
22196:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22197:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22198:09/12/17 18:26:46 [65749] Updating classad values for 500.0:
22199:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22200:09/12/17 18:26:46 [65749]    GridJobId = undefined
22201:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22202:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22203:09/12/17 18:26:46 [65749] Updating classad values for 501.0:
22204:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22205:09/12/17 18:26:46 [65749]    GridJobId = undefined
22206:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22207:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22208:09/12/17 18:26:46 [65749] Updating classad values for 502.0:
22209:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22210:09/12/17 18:26:46 [65749]    GridJobId = undefined
22211:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22212:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22213:09/12/17 18:26:46 [65749] Updating classad values for 503.0:
22214:09/12/17 18:26:46 [65749]    CurrentStatusUnknown = false
22215:09/12/17 18:26:46 [65749]    GridJobId = undefined
22216:09/12/17 18:26:46 [65749]    LastRemoteStatusUpdate = 0
22217:09/12/17 18:26:46 [65749]    Managed = "ScheddDone"
22218:09/12/17 18:26:46 [65749] Deleting job 504.0 from schedd
22219:09/12/17 18:26:46 [65749] Deleting job 505.0 from schedd
22220:09/12/17 18:26:46 [65749] Deleting job 506.0 from schedd
22221:09/12/17 18:26:46 [65749] Deleting job 507.0 from schedd
22222:09/12/17 18:26:46 [65749] Deleting job 508.0 from schedd
22223:09/12/17 18:26:46 [65749] Deleting job 509.0 from schedd
22224:09/12/17 18:26:46 [65749] Deleting job 510.0 from schedd
22225:09/12/17 18:26:46 [65749] Deleting job 511.0 from schedd
22226:09/12/17 18:26:46 [65749] Deleting job 512.0 from schedd
22227:09/12/17 18:26:46 [65749] Deleting job 513.0 from schedd
22228:09/12/17 18:26:46 [65749] Deleting job 514.0 from schedd
22229:09/12/17 18:26:46 [65749] Deleting job 515.0 from schedd
22230:09/12/17 18:26:46 [65749] Deleting job 516.0 from schedd
22231:09/12/17 18:26:46 [65749] Deleting job 477.0 from schedd
22232:09/12/17 18:26:46 [65749] Deleting job 478.0 from schedd
22233:09/12/17 18:26:46 [65749] Deleting job 479.0 from schedd
22234:09/12/17 18:26:46 [65749] Deleting job 480.0 from schedd
22235:09/12/17 18:26:46 [65749] Deleting job 481.0 from schedd
22236:09/12/17 18:26:46 [65749] Deleting job 482.0 from schedd
22237:09/12/17 18:26:46 [65749] Deleting job 483.0 from schedd
22238:09/12/17 18:26:46 [65749] Deleting job 484.0 from schedd
22239:09/12/17 18:26:46 [65749] Deleting job 485.0 from schedd
22240:09/12/17 18:26:46 [65749] Deleting job 487.0 from schedd
22241:09/12/17 18:26:46 [65749] Deleting job 488.0 from schedd
22242:09/12/17 18:26:46 [65749] Deleting job 489.0 from schedd
22243:09/12/17 18:26:46 [65749] Deleting job 490.0 from schedd
22244:09/12/17 18:26:46 [65749] Deleting job 491.0 from schedd
22245:09/12/17 18:26:46 [65749] Deleting job 492.0 from schedd
22246:09/12/17 18:26:46 [65749] Deleting job 493.0 from schedd
22247:09/12/17 18:26:46 [65749] Deleting job 494.0 from schedd
22248:09/12/17 18:26:46 [65749] Deleting job 495.0 from schedd
22249:09/12/17 18:26:46 [65749] Deleting job 496.0 from schedd
22250:09/12/17 18:26:46 [65749] Deleting job 498.0 from schedd
22251:09/12/17 18:26:46 [65749] Deleting job 499.0 from schedd
22252:09/12/17 18:26:46 [65749] Deleting job 500.0 from schedd
22253:09/12/17 18:26:46 [65749] Deleting job 501.0 from schedd
22254:09/12/17 18:26:46 [65749] Deleting job 502.0 from schedd
22255:09/12/17 18:26:46 [65749] Deleting job 503.0 from schedd
22256:09/12/17 18:26:46 [65749] No jobs left, shutting down
22257:09/12/17 18:26:46 [65749] leaving doContactSchedd()
22258:09/12/17 18:26:46 [65749] Got SIGTERM. Performing graceful shutdown.
22259:09/12/17 18:26:46 [65749] Started timer to call main_shutdown_fast in 1800 seconds
22260:09/12/17 18:26:46 [65749] **** condor_gridmanager (condor_GRIDMANAGER) pid 65749 EXITING WITH STATUS 0
22261:09/12/17 18:33:03 Result of reading /etc/issue:  \S
22263:09/12/17 18:33:03 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
22265:09/12/17 18:33:03 Using IDs: 32 processors, 16 CPUs, 16 HTs
22266:09/12/17 18:33:03 Enumerating interfaces: lo 127.0.0.1 up
22267:09/12/17 18:33:03 Enumerating interfaces: eth0 10.36.162.46 up
22268:09/12/17 18:33:03 Enumerating interfaces: ib0 128.55.162.46 up
22269:09/12/17 18:33:03 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
22270:09/12/17 18:33:03 Initializing Directory: curr_dir = /etc/condor-ce/config.d
22271:09/12/17 18:33:03 ******************************************************
22272:09/12/17 18:33:03 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
22273:09/12/17 18:33:03 ** /usr/sbin/condor_gridmanager
22274:09/12/17 18:33:03 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
22275:09/12/17 18:33:03 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
22276:09/12/17 18:33:03 ** $CondorVersion: 8.4.12 Aug 07 2017 $
22277:09/12/17 18:33:03 ** $CondorPlatform: X86_64-CentOS_7.3 $
22278:09/12/17 18:33:03 ** PID = 68240
22279:09/12/17 18:33:03 ** Log last touched 9/12 18:26:46
22280:09/12/17 18:33:03 ******************************************************
22281:09/12/17 18:33:03 Using config source: /etc/condor-ce/condor_config
22282:09/12/17 18:33:03 Using local config sources: 
22283:09/12/17 18:33:03    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
22284:09/12/17 18:33:03    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
22285:09/12/17 18:33:03    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
22286:09/12/17 18:33:03    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
22287:09/12/17 18:33:03    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
22288:09/12/17 18:33:03    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
22289:09/12/17 18:33:03    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
22290:09/12/17 18:33:03    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
22291:09/12/17 18:33:03    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
22292:09/12/17 18:33:03    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
22293:09/12/17 18:33:03    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
22294:09/12/17 18:33:03    /etc/condor-ce/config.d/01-ce-auth.conf
22295:09/12/17 18:33:03    /etc/condor-ce/config.d/01-ce-router.conf
22296:09/12/17 18:33:03    /etc/condor-ce/config.d/01-common-auth.conf
22297:09/12/17 18:33:03    /etc/condor-ce/config.d/02-ce-slurm.conf
22298:09/12/17 18:33:03    /etc/condor-ce/config.d/03-ce-shared-port.conf
22299:09/12/17 18:33:03    /etc/condor-ce/config.d/03-managed-fork.conf
22300:09/12/17 18:33:03    /etc/condor-ce/config.d/05-ce-health.conf
22301:09/12/17 18:33:03    /etc/condor-ce/config.d/05-ce-view.conf
22302:09/12/17 18:33:03    /etc/condor-ce/config.d/10-ce-collector-generated.conf
22303:09/12/17 18:33:03    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
22304:09/12/17 18:33:03    /etc/condor-ce/config.d/50-osg-configure-present.conf
22305:09/12/17 18:33:03    /etc/condor-ce/config.d/50-osg-configure.conf
22306:09/12/17 18:33:03    /etc/condor-ce/config.d/99-local.conf
22307:09/12/17 18:33:03    /usr/share/condor-ce/condor_ce_router_defaults|
22308:09/12/17 18:33:03 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
22309:09/12/17 18:33:03 CLASSAD_CACHING is ENABLED
22310:09/12/17 18:33:03 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
22311:09/12/17 18:33:03 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_72
22312:09/12/17 18:33:03 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_72>
22313:09/12/17 18:33:03 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_72>
22314:09/12/17 18:33:03 Setting maximum accepts per cycle 8.
22315:09/12/17 18:33:03 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22316:09/12/17 18:33:03 [68240] Welcome to the all-singing, all dancing, "amazing" GridManager!
22317:09/12/17 18:33:03 [68240] DaemonCore: No more children processes to reap.
22318:09/12/17 18:33:03 [68240] DaemonCore: in SendAliveToParent()
22319:09/12/17 18:33:03 [68240] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22320:09/12/17 18:33:03 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22321:09/12/17 18:33:03 [68240] IPVERIFY: ip found is 1
22322:09/12/17 18:33:03 [68240] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22323:09/12/17 18:33:03 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22324:09/12/17 18:33:03 [68240] IPVERIFY: ip found is 1
22325:09/12/17 18:33:03 [68240] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22326:09/12/17 18:33:03 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22327:09/12/17 18:33:03 [68240] IPVERIFY: ip found is 1
22328:09/12/17 18:33:03 [68240] IPVERIFY: checking mc0151-ib against 128.55.162.46
22329:09/12/17 18:33:03 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22330:09/12/17 18:33:03 [68240] IPVERIFY: ip found is 1
22331:09/12/17 18:33:03 [68240] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
22332:09/12/17 18:33:03 [68240] DaemonCore: Leaving SendAliveToParent() - success
22333:09/12/17 18:33:03 [68240] Checking proxies
22334:09/12/17 18:33:06 [68240] Received ADD_JOBS signal
22335:09/12/17 18:33:06 [68240] in doContactSchedd()
22336:09/12/17 18:33:06 [68240] querying for new jobs
22337:09/12/17 18:33:06 [68240] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
22338:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 537.0
22339:09/12/17 18:33:06 [68240] (537.0) SetJobLeaseTimers()
22340:09/12/17 18:33:06 [68240] Found job 537.0 --- inserting
22341:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 536.0
22342:09/12/17 18:33:06 [68240] (536.0) SetJobLeaseTimers()
22343:09/12/17 18:33:06 [68240] Found job 536.0 --- inserting
22344:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 535.0
22345:09/12/17 18:33:06 [68240] (535.0) SetJobLeaseTimers()
22346:09/12/17 18:33:06 [68240] Found job 535.0 --- inserting
22347:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 534.0
22348:09/12/17 18:33:06 [68240] (534.0) SetJobLeaseTimers()
22349:09/12/17 18:33:06 [68240] Found job 534.0 --- inserting
22350:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 533.0
22351:09/12/17 18:33:06 [68240] (533.0) SetJobLeaseTimers()
22352:09/12/17 18:33:06 [68240] Found job 533.0 --- inserting
22353:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 532.0
22354:09/12/17 18:33:06 [68240] (532.0) SetJobLeaseTimers()
22355:09/12/17 18:33:06 [68240] Found job 532.0 --- inserting
22356:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 531.0
22357:09/12/17 18:33:06 [68240] (531.0) SetJobLeaseTimers()
22358:09/12/17 18:33:06 [68240] Found job 531.0 --- inserting
22359:09/12/17 18:33:06 [68240] Using job type INFNBatch for job 530.0
22360:09/12/17 18:33:06 [68240] (530.0) SetJobLeaseTimers()
22361:09/12/17 18:33:06 [68240] Found job 530.0 --- inserting
22362:09/12/17 18:33:06 [68240] Fetched 8 new job ads from schedd
22363:09/12/17 18:33:06 [68240] querying for removed/held jobs
22364:09/12/17 18:33:06 [68240] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
22365:09/12/17 18:33:06 [68240] Fetched 0 job ads from schedd
22366:09/12/17 18:33:06 [68240] leaving doContactSchedd()
22367:09/12/17 18:33:06 [68240] gahp server not up yet, delaying ping
22368:09/12/17 18:33:06 [68240] *** UpdateLeases called
22369:09/12/17 18:33:06 [68240]     Leases not supported, cancelling timer
22370:09/12/17 18:33:06 [68240] BaseResource::UpdateResource: 
22390:09/12/17 18:33:06 [68240] Trying to update collector <128.55.162.46:9619>
22391:09/12/17 18:33:06 [68240] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22392:09/12/17 18:33:06 [68240] File descriptor limits: max 4096, safe 3277
22393:09/12/17 18:33:06 [68240] (537.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22394:09/12/17 18:33:06 [68240] GAHP server pid = 68242
22395:09/12/17 18:33:06 [68240] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
22396:09/12/17 18:33:06 [68240] GAHP[68242] <- 'COMMANDS'
22397:09/12/17 18:33:06 [68240] GAHP[68242] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
22398:09/12/17 18:33:06 [68240] GAHP[68242] <- 'ASYNC_MODE_ON'
22399:09/12/17 18:33:06 [68240] GAHP[68242] -> 'S' 'Async mode on'
22400:09/12/17 18:33:06 [68240] (537.0) gm state change: GM_INIT -> GM_START
22401:09/12/17 18:33:06 [68240] (537.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22402:09/12/17 18:33:06 [68240] (537.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22403:09/12/17 18:33:06 [68240] (537.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22404:09/12/17 18:33:06 [68240] (536.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22405:09/12/17 18:33:06 [68240] (536.0) gm state change: GM_INIT -> GM_START
22406:09/12/17 18:33:06 [68240] (536.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22407:09/12/17 18:33:06 [68240] (536.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22408:09/12/17 18:33:06 [68240] (536.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22409:09/12/17 18:33:06 [68240] (535.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22410:09/12/17 18:33:06 [68240] (535.0) gm state change: GM_INIT -> GM_START
22411:09/12/17 18:33:06 [68240] (535.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22412:09/12/17 18:33:06 [68240] (535.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22413:09/12/17 18:33:06 [68240] (535.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22414:09/12/17 18:33:06 [68240] (534.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22415:09/12/17 18:33:06 [68240] (534.0) gm state change: GM_INIT -> GM_START
22416:09/12/17 18:33:06 [68240] (534.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22417:09/12/17 18:33:06 [68240] (534.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22418:09/12/17 18:33:06 [68240] (534.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22419:09/12/17 18:33:06 [68240] (533.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22420:09/12/17 18:33:06 [68240] (533.0) gm state change: GM_INIT -> GM_START
22421:09/12/17 18:33:06 [68240] (533.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22422:09/12/17 18:33:06 [68240] (533.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22423:09/12/17 18:33:06 [68240] (533.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22424:09/12/17 18:33:06 [68240] (532.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22425:09/12/17 18:33:06 [68240] (532.0) gm state change: GM_INIT -> GM_START
22426:09/12/17 18:33:06 [68240] (532.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22427:09/12/17 18:33:06 [68240] (532.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22428:09/12/17 18:33:06 [68240] (532.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22429:09/12/17 18:33:06 [68240] (531.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22430:09/12/17 18:33:06 [68240] (531.0) gm state change: GM_INIT -> GM_START
22431:09/12/17 18:33:06 [68240] (531.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22432:09/12/17 18:33:06 [68240] (531.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22433:09/12/17 18:33:06 [68240] (531.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22434:09/12/17 18:33:06 [68240] (530.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22435:09/12/17 18:33:06 [68240] (530.0) gm state change: GM_INIT -> GM_START
22436:09/12/17 18:33:06 [68240] (530.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22437:09/12/17 18:33:06 [68240] (530.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22438:09/12/17 18:33:06 [68240] (530.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22439:09/12/17 18:33:06 [68240] This process has a valid certificate & key
22440:09/12/17 18:33:06 [68240] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22441:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22442:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22443:09/12/17 18:33:06 [68240] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22444:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22445:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22446:09/12/17 18:33:06 [68240] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22447:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22448:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22449:09/12/17 18:33:06 [68240] IPVERIFY: checking mc0151-ib against 128.55.162.46
22450:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22451:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22452:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22453:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22454:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22455:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22456:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22457:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22458:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
22459:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
22460:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
22461:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
22462:09/12/17 18:33:06 [68240] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
22463:09/12/17 18:33:06 [68240] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
22464:09/12/17 18:33:06 [68240] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22465:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22466:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22467:09/12/17 18:33:06 [68240] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22468:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22469:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22470:09/12/17 18:33:06 [68240] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22471:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22472:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22473:09/12/17 18:33:06 [68240] IPVERIFY: checking mc0151-ib against 128.55.162.46
22474:09/12/17 18:33:06 [68240] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22475:09/12/17 18:33:06 [68240] IPVERIFY: ip found is 1
22476:09/12/17 18:33:08 [68240] Evaluating staleness of remote job statuses.
22477:09/12/17 18:33:11 [68240] resource  is now up
22478:09/12/17 18:33:11 [68240] in doContactSchedd()
22479:09/12/17 18:33:11 [68240] querying for removed/held jobs
22480:09/12/17 18:33:11 [68240] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
22481:09/12/17 18:33:11 [68240] Fetched 0 job ads from schedd
22482:09/12/17 18:33:11 [68240] Updating classad values for 530.0:
22483:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#530.0#1505266383"
22484:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22485:09/12/17 18:33:11 [68240] Updating classad values for 531.0:
22486:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#531.0#1505266383"
22487:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22488:09/12/17 18:33:11 [68240] Updating classad values for 532.0:
22489:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#532.0#1505266383"
22490:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22491:09/12/17 18:33:11 [68240] Updating classad values for 533.0:
22492:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#533.0#1505266383"
22493:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22494:09/12/17 18:33:11 [68240] Updating classad values for 534.0:
22495:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383"
22496:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22497:09/12/17 18:33:11 [68240] Updating classad values for 535.0:
22498:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383"
22499:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22500:09/12/17 18:33:11 [68240] Updating classad values for 536.0:
22501:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383"
22502:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22503:09/12/17 18:33:11 [68240] Updating classad values for 537.0:
22504:09/12/17 18:33:11 [68240]    GridJobId = "batch slurm mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383"
22505:09/12/17 18:33:11 [68240]    LastRemoteStatusUpdate = 1505266386
22506:09/12/17 18:33:11 [68240] leaving doContactSchedd()
22507:09/12/17 18:33:11 [68240] (530.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
22508:09/12/17 18:33:11 [68240] (530.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
22509:09/12/17 18:33:11 [68240] (530.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22510:09/12/17 18:33:11 [68240] GAHP[68242] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#530.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/518/0/cluster518.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/518/0/cluster518.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/518/0/cluster518.proc0.subproc0/test.sh"\ ]'
22511:09/12/17 18:33:11 [68240] GAHP[68242] -> 'S'
22512:09/12/17 18:33:11 [68240] (531.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
22513:09/12/17 18:33:11 [68240] (531.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
22514:09/12/17 18:33:11 [68240] (531.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22515:09/12/17 18:33:11 [68240] GAHP[68242] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#531.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/519/0/cluster519.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/519/0/cluster519.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/519/0/cluster519.proc0.subproc0/test.sh"\ ]'
22516:09/12/17 18:33:11 [68240] GAHP[68242] -> 'S'
22517:09/12/17 18:33:11 [68240] (532.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
22518:09/12/17 18:33:11 [68240] (532.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
22519:09/12/17 18:33:11 [68240] (532.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22520:09/12/17 18:33:11 [68240] GAHP[68242] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#532.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/520/0/cluster520.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/520/0/cluster520.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/520/0/cluster520.proc0.subproc0/test.sh"\ ]'
22521:09/12/17 18:33:11 [68240] GAHP[68242] -> 'S'
22522:09/12/17 18:33:11 [68240] (533.0) doEvaluateState called: gmState GM_SAVE_SANDBOX_ID, remoteState 0
22523:09/12/17 18:33:11 [68240] (533.0) gm state change: GM_SAVE_SANDBOX_ID -> GM_TRANSFER_INPUT
22524:09/12/17 18:33:11 [68240] (533.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22525:09/12/17 18:33:11 [68240] GAHP[68242] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#533.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/test.sh"\ ]'
22526:09/12/17 18:33:11 [68240] GAHP[68242] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
22527:09/12/17 18:33:11 [68240] GAHP[68242] -> EOF
22528:09/12/17 18:33:11 [68240] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
22529:09/12/17 18:33:13 Result of reading /etc/issue:  \S
22531:09/12/17 18:33:13 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
22533:09/12/17 18:33:13 Using IDs: 32 processors, 16 CPUs, 16 HTs
22534:09/12/17 18:33:13 Enumerating interfaces: lo 127.0.0.1 up
22535:09/12/17 18:33:13 Enumerating interfaces: eth0 10.36.162.46 up
22536:09/12/17 18:33:13 Enumerating interfaces: ib0 128.55.162.46 up
22537:09/12/17 18:33:13 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
22538:09/12/17 18:33:13 Initializing Directory: curr_dir = /etc/condor-ce/config.d
22539:09/12/17 18:33:13 ******************************************************
22540:09/12/17 18:33:13 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
22541:09/12/17 18:33:13 ** /usr/sbin/condor_gridmanager
22542:09/12/17 18:33:13 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
22543:09/12/17 18:33:13 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
22544:09/12/17 18:33:13 ** $CondorVersion: 8.4.12 Aug 07 2017 $
22545:09/12/17 18:33:13 ** $CondorPlatform: X86_64-CentOS_7.3 $
22546:09/12/17 18:33:13 ** PID = 68257
22547:09/12/17 18:33:13 ** Log last touched 9/12 18:33:11
22548:09/12/17 18:33:13 ******************************************************
22549:09/12/17 18:33:13 Using config source: /etc/condor-ce/condor_config
22550:09/12/17 18:33:13 Using local config sources: 
22551:09/12/17 18:33:13    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
22552:09/12/17 18:33:13    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
22553:09/12/17 18:33:13    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
22554:09/12/17 18:33:13    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
22555:09/12/17 18:33:13    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
22556:09/12/17 18:33:13    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
22557:09/12/17 18:33:13    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
22558:09/12/17 18:33:13    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
22559:09/12/17 18:33:13    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
22560:09/12/17 18:33:13    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
22561:09/12/17 18:33:13    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
22562:09/12/17 18:33:13    /etc/condor-ce/config.d/01-ce-auth.conf
22563:09/12/17 18:33:13    /etc/condor-ce/config.d/01-ce-router.conf
22564:09/12/17 18:33:13    /etc/condor-ce/config.d/01-common-auth.conf
22565:09/12/17 18:33:13    /etc/condor-ce/config.d/02-ce-slurm.conf
22566:09/12/17 18:33:13    /etc/condor-ce/config.d/03-ce-shared-port.conf
22567:09/12/17 18:33:13    /etc/condor-ce/config.d/03-managed-fork.conf
22568:09/12/17 18:33:13    /etc/condor-ce/config.d/05-ce-health.conf
22569:09/12/17 18:33:13    /etc/condor-ce/config.d/05-ce-view.conf
22570:09/12/17 18:33:13    /etc/condor-ce/config.d/10-ce-collector-generated.conf
22571:09/12/17 18:33:13    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
22572:09/12/17 18:33:13    /etc/condor-ce/config.d/50-osg-configure-present.conf
22573:09/12/17 18:33:13    /etc/condor-ce/config.d/50-osg-configure.conf
22574:09/12/17 18:33:13    /etc/condor-ce/config.d/99-local.conf
22575:09/12/17 18:33:13    /usr/share/condor-ce/condor_ce_router_defaults|
22576:09/12/17 18:33:13 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
22577:09/12/17 18:33:13 CLASSAD_CACHING is ENABLED
22578:09/12/17 18:33:13 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
22579:09/12/17 18:33:13 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_73
22580:09/12/17 18:33:13 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_73>
22581:09/12/17 18:33:13 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_73>
22582:09/12/17 18:33:13 Setting maximum accepts per cycle 8.
22583:09/12/17 18:33:13 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22584:09/12/17 18:33:13 [68257] Welcome to the all-singing, all dancing, "amazing" GridManager!
22585:09/12/17 18:33:13 [68257] DaemonCore: No more children processes to reap.
22586:09/12/17 18:33:13 [68257] DaemonCore: in SendAliveToParent()
22587:09/12/17 18:33:13 [68257] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22588:09/12/17 18:33:13 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22589:09/12/17 18:33:13 [68257] IPVERIFY: ip found is 1
22590:09/12/17 18:33:13 [68257] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22591:09/12/17 18:33:13 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22592:09/12/17 18:33:13 [68257] IPVERIFY: ip found is 1
22593:09/12/17 18:33:13 [68257] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22594:09/12/17 18:33:13 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22595:09/12/17 18:33:13 [68257] IPVERIFY: ip found is 1
22596:09/12/17 18:33:13 [68257] IPVERIFY: checking mc0151-ib against 128.55.162.46
22597:09/12/17 18:33:13 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22598:09/12/17 18:33:13 [68257] IPVERIFY: ip found is 1
22599:09/12/17 18:33:13 [68257] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
22600:09/12/17 18:33:13 [68257] DaemonCore: Leaving SendAliveToParent() - success
22601:09/12/17 18:33:13 [68257] Checking proxies
22602:09/12/17 18:33:16 [68257] Received ADD_JOBS signal
22603:09/12/17 18:33:16 [68257] in doContactSchedd()
22604:09/12/17 18:33:16 [68257] querying for new jobs
22605:09/12/17 18:33:16 [68257] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
22606:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 542.0
22607:09/12/17 18:33:16 [68257] (542.0) SetJobLeaseTimers()
22608:09/12/17 18:33:16 [68257] Found job 542.0 --- inserting
22609:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 541.0
22610:09/12/17 18:33:16 [68257] (541.0) SetJobLeaseTimers()
22611:09/12/17 18:33:16 [68257] Found job 541.0 --- inserting
22612:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 540.0
22613:09/12/17 18:33:16 [68257] (540.0) SetJobLeaseTimers()
22614:09/12/17 18:33:16 [68257] Found job 540.0 --- inserting
22615:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 539.0
22616:09/12/17 18:33:16 [68257] (539.0) SetJobLeaseTimers()
22617:09/12/17 18:33:16 [68257] Found job 539.0 --- inserting
22618:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 538.0
22619:09/12/17 18:33:16 [68257] (538.0) SetJobLeaseTimers()
22620:09/12/17 18:33:16 [68257] Found job 538.0 --- inserting
22621:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 537.0
22622:09/12/17 18:33:16 [68257] (537.0) SetJobLeaseTimers()
22623:09/12/17 18:33:16 [68257] Found job 537.0 --- inserting
22624:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 536.0
22625:09/12/17 18:33:16 [68257] (536.0) SetJobLeaseTimers()
22626:09/12/17 18:33:16 [68257] Found job 536.0 --- inserting
22627:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 535.0
22628:09/12/17 18:33:16 [68257] (535.0) SetJobLeaseTimers()
22629:09/12/17 18:33:16 [68257] Found job 535.0 --- inserting
22630:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 534.0
22631:09/12/17 18:33:16 [68257] (534.0) SetJobLeaseTimers()
22632:09/12/17 18:33:16 [68257] Found job 534.0 --- inserting
22633:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 533.0
22634:09/12/17 18:33:16 [68257] (533.0) SetJobLeaseTimers()
22635:09/12/17 18:33:16 [68257] Found job 533.0 --- inserting
22636:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 532.0
22637:09/12/17 18:33:16 [68257] (532.0) SetJobLeaseTimers()
22638:09/12/17 18:33:16 [68257] Found job 532.0 --- inserting
22639:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 531.0
22640:09/12/17 18:33:16 [68257] (531.0) SetJobLeaseTimers()
22641:09/12/17 18:33:16 [68257] Found job 531.0 --- inserting
22642:09/12/17 18:33:16 [68257] Using job type INFNBatch for job 530.0
22643:09/12/17 18:33:16 [68257] (530.0) SetJobLeaseTimers()
22644:09/12/17 18:33:16 [68257] Found job 530.0 --- inserting
22645:09/12/17 18:33:16 [68257] Fetched 13 new job ads from schedd
22646:09/12/17 18:33:16 [68257] querying for removed/held jobs
22647:09/12/17 18:33:16 [68257] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
22648:09/12/17 18:33:16 [68257] Fetched 0 job ads from schedd
22649:09/12/17 18:33:16 [68257] leaving doContactSchedd()
22650:09/12/17 18:33:16 [68257] gahp server not up yet, delaying ping
22651:09/12/17 18:33:16 [68257] *** UpdateLeases called
22652:09/12/17 18:33:16 [68257]     Leases not supported, cancelling timer
22653:09/12/17 18:33:16 [68257] BaseResource::UpdateResource: 
22673:09/12/17 18:33:16 [68257] Trying to update collector <128.55.162.46:9619>
22674:09/12/17 18:33:16 [68257] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22675:09/12/17 18:33:16 [68257] File descriptor limits: max 4096, safe 3277
22676:09/12/17 18:33:16 [68257] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22677:09/12/17 18:33:16 [68257] GAHP server pid = 68260
22678:09/12/17 18:33:16 [68257] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
22679:09/12/17 18:33:16 [68257] GAHP[68260] <- 'COMMANDS'
22680:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
22681:09/12/17 18:33:16 [68257] GAHP[68260] <- 'ASYNC_MODE_ON'
22682:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S' 'Async mode on'
22683:09/12/17 18:33:16 [68257] (542.0) gm state change: GM_INIT -> GM_START
22684:09/12/17 18:33:16 [68257] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22685:09/12/17 18:33:16 [68257] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22686:09/12/17 18:33:16 [68257] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22687:09/12/17 18:33:16 [68257] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22688:09/12/17 18:33:16 [68257] (541.0) gm state change: GM_INIT -> GM_START
22689:09/12/17 18:33:16 [68257] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22690:09/12/17 18:33:16 [68257] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22691:09/12/17 18:33:16 [68257] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22692:09/12/17 18:33:16 [68257] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22693:09/12/17 18:33:16 [68257] (540.0) gm state change: GM_INIT -> GM_START
22694:09/12/17 18:33:16 [68257] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22695:09/12/17 18:33:16 [68257] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22696:09/12/17 18:33:16 [68257] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22697:09/12/17 18:33:16 [68257] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22698:09/12/17 18:33:16 [68257] (539.0) gm state change: GM_INIT -> GM_START
22699:09/12/17 18:33:16 [68257] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22700:09/12/17 18:33:16 [68257] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22701:09/12/17 18:33:16 [68257] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22702:09/12/17 18:33:16 [68257] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22703:09/12/17 18:33:16 [68257] (538.0) gm state change: GM_INIT -> GM_START
22704:09/12/17 18:33:16 [68257] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22705:09/12/17 18:33:16 [68257] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22706:09/12/17 18:33:16 [68257] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22707:09/12/17 18:33:16 [68257] This process has a valid certificate & key
22708:09/12/17 18:33:16 [68257] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22709:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22710:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22711:09/12/17 18:33:16 [68257] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22712:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22713:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22714:09/12/17 18:33:16 [68257] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22715:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22716:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22717:09/12/17 18:33:16 [68257] IPVERIFY: checking mc0151-ib against 128.55.162.46
22718:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22719:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22720:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22721:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22722:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22723:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22724:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22725:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22726:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
22727:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
22728:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
22729:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
22730:09/12/17 18:33:16 [68257] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
22731:09/12/17 18:33:16 [68257] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
22732:09/12/17 18:33:16 [68257] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22733:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22734:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22735:09/12/17 18:33:16 [68257] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22736:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22737:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22738:09/12/17 18:33:16 [68257] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22739:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22740:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22741:09/12/17 18:33:16 [68257] IPVERIFY: checking mc0151-ib against 128.55.162.46
22742:09/12/17 18:33:16 [68257] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22743:09/12/17 18:33:16 [68257] IPVERIFY: ip found is 1
22744:09/12/17 18:33:16 [68257] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22745:09/12/17 18:33:16 [68257] (537.0) gm state change: GM_INIT -> GM_START
22746:09/12/17 18:33:16 [68257] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22747:09/12/17 18:33:16 [68257] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22748:09/12/17 18:33:16 [68257] GAHP[68260] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
22749:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S'
22750:09/12/17 18:33:16 [68257] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22751:09/12/17 18:33:16 [68257] (536.0) gm state change: GM_INIT -> GM_START
22752:09/12/17 18:33:16 [68257] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22753:09/12/17 18:33:16 [68257] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22754:09/12/17 18:33:16 [68257] GAHP[68260] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
22755:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S'
22756:09/12/17 18:33:16 [68257] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22757:09/12/17 18:33:16 [68257] (535.0) gm state change: GM_INIT -> GM_START
22758:09/12/17 18:33:16 [68257] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22759:09/12/17 18:33:16 [68257] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22760:09/12/17 18:33:16 [68257] GAHP[68260] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
22761:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S'
22762:09/12/17 18:33:16 [68257] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22763:09/12/17 18:33:16 [68257] (534.0) gm state change: GM_INIT -> GM_START
22764:09/12/17 18:33:16 [68257] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22765:09/12/17 18:33:16 [68257] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22766:09/12/17 18:33:16 [68257] GAHP[68260] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
22767:09/12/17 18:33:16 [68257] GAHP[68260] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
22768:09/12/17 18:33:16 [68257] GAHP[68260] -> 'S'
22769:09/12/17 18:33:16 [68257] (533.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22770:09/12/17 18:33:16 [68257] (533.0) gm state change: GM_INIT -> GM_START
22771:09/12/17 18:33:16 [68257] (533.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22772:09/12/17 18:33:16 [68257] (533.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22773:09/12/17 18:33:16 [68257] GAHP[68260] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#533.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/test.sh"\ ]'
22774:09/12/17 18:33:16 [68257] GAHP[68260] -> EOF
22775:09/12/17 18:33:16 [68257] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
22776:09/12/17 18:33:18 Result of reading /etc/issue:  \S
22778:09/12/17 18:33:18 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
22780:09/12/17 18:33:18 Using IDs: 32 processors, 16 CPUs, 16 HTs
22781:09/12/17 18:33:18 Enumerating interfaces: lo 127.0.0.1 up
22782:09/12/17 18:33:18 Enumerating interfaces: eth0 10.36.162.46 up
22783:09/12/17 18:33:18 Enumerating interfaces: ib0 128.55.162.46 up
22784:09/12/17 18:33:18 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
22785:09/12/17 18:33:18 Initializing Directory: curr_dir = /etc/condor-ce/config.d
22786:09/12/17 18:33:18 ******************************************************
22787:09/12/17 18:33:18 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
22788:09/12/17 18:33:18 ** /usr/sbin/condor_gridmanager
22789:09/12/17 18:33:18 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
22790:09/12/17 18:33:18 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
22791:09/12/17 18:33:18 ** $CondorVersion: 8.4.12 Aug 07 2017 $
22792:09/12/17 18:33:18 ** $CondorPlatform: X86_64-CentOS_7.3 $
22793:09/12/17 18:33:18 ** PID = 68276
22794:09/12/17 18:33:18 ** Log last touched 9/12 18:33:16
22795:09/12/17 18:33:18 ******************************************************
22796:09/12/17 18:33:18 Using config source: /etc/condor-ce/condor_config
22797:09/12/17 18:33:18 Using local config sources: 
22798:09/12/17 18:33:18    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
22799:09/12/17 18:33:18    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
22800:09/12/17 18:33:18    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
22801:09/12/17 18:33:18    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
22802:09/12/17 18:33:18    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
22803:09/12/17 18:33:18    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
22804:09/12/17 18:33:18    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
22805:09/12/17 18:33:18    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
22806:09/12/17 18:33:18    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
22807:09/12/17 18:33:18    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
22808:09/12/17 18:33:18    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
22809:09/12/17 18:33:18    /etc/condor-ce/config.d/01-ce-auth.conf
22810:09/12/17 18:33:18    /etc/condor-ce/config.d/01-ce-router.conf
22811:09/12/17 18:33:18    /etc/condor-ce/config.d/01-common-auth.conf
22812:09/12/17 18:33:18    /etc/condor-ce/config.d/02-ce-slurm.conf
22813:09/12/17 18:33:18    /etc/condor-ce/config.d/03-ce-shared-port.conf
22814:09/12/17 18:33:18    /etc/condor-ce/config.d/03-managed-fork.conf
22815:09/12/17 18:33:18    /etc/condor-ce/config.d/05-ce-health.conf
22816:09/12/17 18:33:18    /etc/condor-ce/config.d/05-ce-view.conf
22817:09/12/17 18:33:18    /etc/condor-ce/config.d/10-ce-collector-generated.conf
22818:09/12/17 18:33:18    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
22819:09/12/17 18:33:18    /etc/condor-ce/config.d/50-osg-configure-present.conf
22820:09/12/17 18:33:18    /etc/condor-ce/config.d/50-osg-configure.conf
22821:09/12/17 18:33:18    /etc/condor-ce/config.d/99-local.conf
22822:09/12/17 18:33:18    /usr/share/condor-ce/condor_ce_router_defaults|
22823:09/12/17 18:33:18 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
22824:09/12/17 18:33:18 CLASSAD_CACHING is ENABLED
22825:09/12/17 18:33:18 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
22826:09/12/17 18:33:18 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_75
22827:09/12/17 18:33:18 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_75>
22828:09/12/17 18:33:18 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_75>
22829:09/12/17 18:33:18 Setting maximum accepts per cycle 8.
22830:09/12/17 18:33:18 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22831:09/12/17 18:33:18 [68276] Welcome to the all-singing, all dancing, "amazing" GridManager!
22832:09/12/17 18:33:18 [68276] DaemonCore: No more children processes to reap.
22833:09/12/17 18:33:18 [68276] DaemonCore: in SendAliveToParent()
22834:09/12/17 18:33:18 [68276] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22835:09/12/17 18:33:18 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22836:09/12/17 18:33:18 [68276] IPVERIFY: ip found is 1
22837:09/12/17 18:33:18 [68276] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22838:09/12/17 18:33:18 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22839:09/12/17 18:33:18 [68276] IPVERIFY: ip found is 1
22840:09/12/17 18:33:18 [68276] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22841:09/12/17 18:33:18 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22842:09/12/17 18:33:18 [68276] IPVERIFY: ip found is 1
22843:09/12/17 18:33:18 [68276] IPVERIFY: checking mc0151-ib against 128.55.162.46
22844:09/12/17 18:33:18 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22845:09/12/17 18:33:18 [68276] IPVERIFY: ip found is 1
22846:09/12/17 18:33:18 [68276] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
22847:09/12/17 18:33:18 [68276] DaemonCore: Leaving SendAliveToParent() - success
22848:09/12/17 18:33:18 [68276] Checking proxies
22849:09/12/17 18:33:21 [68276] Received ADD_JOBS signal
22850:09/12/17 18:33:21 [68276] in doContactSchedd()
22851:09/12/17 18:33:21 [68276] querying for new jobs
22852:09/12/17 18:33:21 [68276] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
22853:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 542.0
22854:09/12/17 18:33:21 [68276] (542.0) SetJobLeaseTimers()
22855:09/12/17 18:33:21 [68276] Found job 542.0 --- inserting
22856:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 541.0
22857:09/12/17 18:33:21 [68276] (541.0) SetJobLeaseTimers()
22858:09/12/17 18:33:21 [68276] Found job 541.0 --- inserting
22859:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 540.0
22860:09/12/17 18:33:21 [68276] (540.0) SetJobLeaseTimers()
22861:09/12/17 18:33:21 [68276] Found job 540.0 --- inserting
22862:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 539.0
22863:09/12/17 18:33:21 [68276] (539.0) SetJobLeaseTimers()
22864:09/12/17 18:33:21 [68276] Found job 539.0 --- inserting
22865:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 538.0
22866:09/12/17 18:33:21 [68276] (538.0) SetJobLeaseTimers()
22867:09/12/17 18:33:21 [68276] Found job 538.0 --- inserting
22868:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 537.0
22869:09/12/17 18:33:21 [68276] (537.0) SetJobLeaseTimers()
22870:09/12/17 18:33:21 [68276] Found job 537.0 --- inserting
22871:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 536.0
22872:09/12/17 18:33:21 [68276] (536.0) SetJobLeaseTimers()
22873:09/12/17 18:33:21 [68276] Found job 536.0 --- inserting
22874:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 535.0
22875:09/12/17 18:33:21 [68276] (535.0) SetJobLeaseTimers()
22876:09/12/17 18:33:21 [68276] Found job 535.0 --- inserting
22877:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 534.0
22878:09/12/17 18:33:21 [68276] (534.0) SetJobLeaseTimers()
22879:09/12/17 18:33:21 [68276] Found job 534.0 --- inserting
22880:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 533.0
22881:09/12/17 18:33:21 [68276] (533.0) SetJobLeaseTimers()
22882:09/12/17 18:33:21 [68276] Found job 533.0 --- inserting
22883:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 532.0
22884:09/12/17 18:33:21 [68276] (532.0) SetJobLeaseTimers()
22885:09/12/17 18:33:21 [68276] Found job 532.0 --- inserting
22886:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 531.0
22887:09/12/17 18:33:21 [68276] (531.0) SetJobLeaseTimers()
22888:09/12/17 18:33:21 [68276] Found job 531.0 --- inserting
22889:09/12/17 18:33:21 [68276] Using job type INFNBatch for job 530.0
22890:09/12/17 18:33:21 [68276] (530.0) SetJobLeaseTimers()
22891:09/12/17 18:33:21 [68276] Found job 530.0 --- inserting
22892:09/12/17 18:33:21 [68276] Fetched 13 new job ads from schedd
22893:09/12/17 18:33:21 [68276] querying for removed/held jobs
22894:09/12/17 18:33:21 [68276] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
22895:09/12/17 18:33:21 [68276] Fetched 0 job ads from schedd
22896:09/12/17 18:33:21 [68276] leaving doContactSchedd()
22897:09/12/17 18:33:21 [68276] gahp server not up yet, delaying ping
22898:09/12/17 18:33:21 [68276] *** UpdateLeases called
22899:09/12/17 18:33:21 [68276]     Leases not supported, cancelling timer
22900:09/12/17 18:33:21 [68276] BaseResource::UpdateResource: 
22920:09/12/17 18:33:21 [68276] Trying to update collector <128.55.162.46:9619>
22921:09/12/17 18:33:21 [68276] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
22922:09/12/17 18:33:21 [68276] File descriptor limits: max 4096, safe 3277
22923:09/12/17 18:33:21 [68276] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22924:09/12/17 18:33:21 [68276] GAHP server pid = 68278
22925:09/12/17 18:33:21 [68276] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
22926:09/12/17 18:33:21 [68276] GAHP[68278] <- 'COMMANDS'
22927:09/12/17 18:33:21 [68276] GAHP[68278] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
22928:09/12/17 18:33:21 [68276] GAHP[68278] <- 'ASYNC_MODE_ON'
22929:09/12/17 18:33:21 [68276] GAHP[68278] -> 'S' 'Async mode on'
22930:09/12/17 18:33:21 [68276] (542.0) gm state change: GM_INIT -> GM_START
22931:09/12/17 18:33:21 [68276] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22932:09/12/17 18:33:21 [68276] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22933:09/12/17 18:33:21 [68276] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22934:09/12/17 18:33:21 [68276] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22935:09/12/17 18:33:21 [68276] (541.0) gm state change: GM_INIT -> GM_START
22936:09/12/17 18:33:21 [68276] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22937:09/12/17 18:33:21 [68276] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22938:09/12/17 18:33:21 [68276] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22939:09/12/17 18:33:21 [68276] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22940:09/12/17 18:33:21 [68276] (540.0) gm state change: GM_INIT -> GM_START
22941:09/12/17 18:33:21 [68276] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22942:09/12/17 18:33:21 [68276] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22943:09/12/17 18:33:21 [68276] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22944:09/12/17 18:33:21 [68276] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22945:09/12/17 18:33:21 [68276] (539.0) gm state change: GM_INIT -> GM_START
22946:09/12/17 18:33:21 [68276] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22947:09/12/17 18:33:21 [68276] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22948:09/12/17 18:33:21 [68276] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22949:09/12/17 18:33:21 [68276] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
22950:09/12/17 18:33:21 [68276] (538.0) gm state change: GM_INIT -> GM_START
22951:09/12/17 18:33:21 [68276] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
22952:09/12/17 18:33:21 [68276] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
22953:09/12/17 18:33:21 [68276] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
22954:09/12/17 18:33:21 [68276] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22955:09/12/17 18:33:21 [68276] (537.0) gm state change: GM_INIT -> GM_START
22956:09/12/17 18:33:21 [68276] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22957:09/12/17 18:33:21 [68276] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22958:09/12/17 18:33:21 [68276] GAHP[68278] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
22959:09/12/17 18:33:21 [68276] GAHP[68278] -> 'S'
22960:09/12/17 18:33:21 [68276] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22961:09/12/17 18:33:21 [68276] (536.0) gm state change: GM_INIT -> GM_START
22962:09/12/17 18:33:21 [68276] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22963:09/12/17 18:33:21 [68276] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22964:09/12/17 18:33:21 [68276] GAHP[68278] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
22965:09/12/17 18:33:21 [68276] GAHP[68278] -> 'S'
22966:09/12/17 18:33:21 [68276] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
22967:09/12/17 18:33:21 [68276] (535.0) gm state change: GM_INIT -> GM_START
22968:09/12/17 18:33:21 [68276] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
22969:09/12/17 18:33:21 [68276] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
22970:09/12/17 18:33:21 [68276] GAHP[68278] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
22971:09/12/17 18:33:21 [68276] GAHP[68278] -> 'S'
22972:09/12/17 18:33:21 [68276] This process has a valid certificate & key
22973:09/12/17 18:33:21 [68276] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22974:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22975:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
22976:09/12/17 18:33:21 [68276] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
22977:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22978:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
22979:09/12/17 18:33:21 [68276] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
22980:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22981:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
22982:09/12/17 18:33:21 [68276] IPVERIFY: checking mc0151-ib against 128.55.162.46
22983:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22984:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
22985:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22986:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22987:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22988:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22989:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22990:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
22991:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
22992:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
22993:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
22994:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
22995:09/12/17 18:33:21 [68276] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
22996:09/12/17 18:33:21 [68276] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
22997:09/12/17 18:33:21 [68276] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
22998:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
22999:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
23000:09/12/17 18:33:21 [68276] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23001:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23002:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
23003:09/12/17 18:33:21 [68276] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23004:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23005:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
23006:09/12/17 18:33:21 [68276] IPVERIFY: checking mc0151-ib against 128.55.162.46
23007:09/12/17 18:33:21 [68276] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23008:09/12/17 18:33:21 [68276] IPVERIFY: ip found is 1
23009:09/12/17 18:33:21 [68276] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23010:09/12/17 18:33:21 [68276] (534.0) gm state change: GM_INIT -> GM_START
23011:09/12/17 18:33:21 [68276] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23012:09/12/17 18:33:21 [68276] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23013:09/12/17 18:33:21 [68276] GAHP[68278] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
23014:09/12/17 18:33:21 [68276] GAHP[68278] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
23015:09/12/17 18:33:21 [68276] GAHP[68278] -> EOF
23016:09/12/17 18:33:21 [68276] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
23017:09/12/17 18:38:18 Result of reading /etc/issue:  \S
23019:09/12/17 18:38:18 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
23021:09/12/17 18:38:18 Using IDs: 32 processors, 16 CPUs, 16 HTs
23022:09/12/17 18:38:18 Enumerating interfaces: lo 127.0.0.1 up
23023:09/12/17 18:38:18 Enumerating interfaces: eth0 10.36.162.46 up
23024:09/12/17 18:38:18 Enumerating interfaces: ib0 128.55.162.46 up
23025:09/12/17 18:38:18 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
23026:09/12/17 18:38:18 Initializing Directory: curr_dir = /etc/condor-ce/config.d
23027:09/12/17 18:38:18 ******************************************************
23028:09/12/17 18:38:18 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
23029:09/12/17 18:38:18 ** /usr/sbin/condor_gridmanager
23030:09/12/17 18:38:18 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
23031:09/12/17 18:38:18 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
23032:09/12/17 18:38:18 ** $CondorVersion: 8.4.12 Aug 07 2017 $
23033:09/12/17 18:38:18 ** $CondorPlatform: X86_64-CentOS_7.3 $
23034:09/12/17 18:38:18 ** PID = 68320
23035:09/12/17 18:38:18 ** Log last touched 9/12 18:33:21
23036:09/12/17 18:38:18 ******************************************************
23037:09/12/17 18:38:18 Using config source: /etc/condor-ce/condor_config
23038:09/12/17 18:38:18 Using local config sources: 
23039:09/12/17 18:38:18    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
23040:09/12/17 18:38:18    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
23041:09/12/17 18:38:18    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
23042:09/12/17 18:38:18    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
23043:09/12/17 18:38:18    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
23044:09/12/17 18:38:18    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
23045:09/12/17 18:38:18    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
23046:09/12/17 18:38:18    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
23047:09/12/17 18:38:18    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
23048:09/12/17 18:38:18    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
23049:09/12/17 18:38:18    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
23050:09/12/17 18:38:18    /etc/condor-ce/config.d/01-ce-auth.conf
23051:09/12/17 18:38:18    /etc/condor-ce/config.d/01-ce-router.conf
23052:09/12/17 18:38:18    /etc/condor-ce/config.d/01-common-auth.conf
23053:09/12/17 18:38:18    /etc/condor-ce/config.d/02-ce-slurm.conf
23054:09/12/17 18:38:18    /etc/condor-ce/config.d/03-ce-shared-port.conf
23055:09/12/17 18:38:18    /etc/condor-ce/config.d/03-managed-fork.conf
23056:09/12/17 18:38:18    /etc/condor-ce/config.d/05-ce-health.conf
23057:09/12/17 18:38:18    /etc/condor-ce/config.d/05-ce-view.conf
23058:09/12/17 18:38:18    /etc/condor-ce/config.d/10-ce-collector-generated.conf
23059:09/12/17 18:38:18    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
23060:09/12/17 18:38:18    /etc/condor-ce/config.d/50-osg-configure-present.conf
23061:09/12/17 18:38:18    /etc/condor-ce/config.d/50-osg-configure.conf
23062:09/12/17 18:38:18    /etc/condor-ce/config.d/99-local.conf
23063:09/12/17 18:38:18    /usr/share/condor-ce/condor_ce_router_defaults|
23064:09/12/17 18:38:18 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
23065:09/12/17 18:38:18 CLASSAD_CACHING is ENABLED
23066:09/12/17 18:38:18 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
23067:09/12/17 18:38:18 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_77
23068:09/12/17 18:38:18 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_77>
23069:09/12/17 18:38:18 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_77>
23070:09/12/17 18:38:18 Setting maximum accepts per cycle 8.
23071:09/12/17 18:38:18 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23072:09/12/17 18:38:18 [68320] Welcome to the all-singing, all dancing, "amazing" GridManager!
23073:09/12/17 18:38:18 [68320] DaemonCore: No more children processes to reap.
23074:09/12/17 18:38:18 [68320] DaemonCore: in SendAliveToParent()
23075:09/12/17 18:38:18 [68320] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23076:09/12/17 18:38:18 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23077:09/12/17 18:38:18 [68320] IPVERIFY: ip found is 1
23078:09/12/17 18:38:18 [68320] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23079:09/12/17 18:38:18 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23080:09/12/17 18:38:18 [68320] IPVERIFY: ip found is 1
23081:09/12/17 18:38:18 [68320] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23082:09/12/17 18:38:18 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23083:09/12/17 18:38:18 [68320] IPVERIFY: ip found is 1
23084:09/12/17 18:38:18 [68320] IPVERIFY: checking mc0151-ib against 128.55.162.46
23085:09/12/17 18:38:18 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23086:09/12/17 18:38:18 [68320] IPVERIFY: ip found is 1
23087:09/12/17 18:38:18 [68320] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
23088:09/12/17 18:38:18 [68320] DaemonCore: Leaving SendAliveToParent() - success
23089:09/12/17 18:38:18 [68320] Checking proxies
23090:09/12/17 18:38:21 [68320] Received ADD_JOBS signal
23091:09/12/17 18:38:21 [68320] in doContactSchedd()
23092:09/12/17 18:38:21 [68320] querying for new jobs
23093:09/12/17 18:38:21 [68320] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
23094:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 542.0
23095:09/12/17 18:38:21 [68320] (542.0) SetJobLeaseTimers()
23096:09/12/17 18:38:21 [68320] Found job 542.0 --- inserting
23097:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 541.0
23098:09/12/17 18:38:21 [68320] (541.0) SetJobLeaseTimers()
23099:09/12/17 18:38:21 [68320] Found job 541.0 --- inserting
23100:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 540.0
23101:09/12/17 18:38:21 [68320] (540.0) SetJobLeaseTimers()
23102:09/12/17 18:38:21 [68320] Found job 540.0 --- inserting
23103:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 539.0
23104:09/12/17 18:38:21 [68320] (539.0) SetJobLeaseTimers()
23105:09/12/17 18:38:21 [68320] Found job 539.0 --- inserting
23106:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 538.0
23107:09/12/17 18:38:21 [68320] (538.0) SetJobLeaseTimers()
23108:09/12/17 18:38:21 [68320] Found job 538.0 --- inserting
23109:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 537.0
23110:09/12/17 18:38:21 [68320] (537.0) SetJobLeaseTimers()
23111:09/12/17 18:38:21 [68320] Found job 537.0 --- inserting
23112:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 536.0
23113:09/12/17 18:38:21 [68320] (536.0) SetJobLeaseTimers()
23114:09/12/17 18:38:21 [68320] Found job 536.0 --- inserting
23115:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 535.0
23116:09/12/17 18:38:21 [68320] (535.0) SetJobLeaseTimers()
23117:09/12/17 18:38:21 [68320] Found job 535.0 --- inserting
23118:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 534.0
23119:09/12/17 18:38:21 [68320] (534.0) SetJobLeaseTimers()
23120:09/12/17 18:38:21 [68320] Found job 534.0 --- inserting
23121:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 533.0
23122:09/12/17 18:38:21 [68320] (533.0) SetJobLeaseTimers()
23123:09/12/17 18:38:21 [68320] Found job 533.0 --- inserting
23124:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 532.0
23125:09/12/17 18:38:21 [68320] (532.0) SetJobLeaseTimers()
23126:09/12/17 18:38:21 [68320] Found job 532.0 --- inserting
23127:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 531.0
23128:09/12/17 18:38:21 [68320] (531.0) SetJobLeaseTimers()
23129:09/12/17 18:38:21 [68320] Found job 531.0 --- inserting
23130:09/12/17 18:38:21 [68320] Using job type INFNBatch for job 530.0
23131:09/12/17 18:38:21 [68320] (530.0) SetJobLeaseTimers()
23132:09/12/17 18:38:21 [68320] Found job 530.0 --- inserting
23133:09/12/17 18:38:21 [68320] Fetched 13 new job ads from schedd
23134:09/12/17 18:38:21 [68320] querying for removed/held jobs
23135:09/12/17 18:38:21 [68320] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
23136:09/12/17 18:38:21 [68320] Fetched 0 job ads from schedd
23137:09/12/17 18:38:21 [68320] leaving doContactSchedd()
23138:09/12/17 18:38:21 [68320] gahp server not up yet, delaying ping
23139:09/12/17 18:38:21 [68320] *** UpdateLeases called
23140:09/12/17 18:38:21 [68320]     Leases not supported, cancelling timer
23141:09/12/17 18:38:21 [68320] BaseResource::UpdateResource: 
23161:09/12/17 18:38:21 [68320] Trying to update collector <128.55.162.46:9619>
23162:09/12/17 18:38:21 [68320] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23163:09/12/17 18:38:21 [68320] File descriptor limits: max 4096, safe 3277
23164:09/12/17 18:38:21 [68320] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23165:09/12/17 18:38:21 [68320] GAHP server pid = 68322
23166:09/12/17 18:38:21 [68320] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
23167:09/12/17 18:38:21 [68320] GAHP[68322] <- 'COMMANDS'
23168:09/12/17 18:38:21 [68320] GAHP[68322] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
23169:09/12/17 18:38:21 [68320] GAHP[68322] <- 'ASYNC_MODE_ON'
23170:09/12/17 18:38:21 [68320] GAHP[68322] -> 'S' 'Async mode on'
23171:09/12/17 18:38:21 [68320] (542.0) gm state change: GM_INIT -> GM_START
23172:09/12/17 18:38:21 [68320] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23173:09/12/17 18:38:21 [68320] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23174:09/12/17 18:38:21 [68320] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23175:09/12/17 18:38:21 [68320] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23176:09/12/17 18:38:21 [68320] (541.0) gm state change: GM_INIT -> GM_START
23177:09/12/17 18:38:21 [68320] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23178:09/12/17 18:38:21 [68320] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23179:09/12/17 18:38:21 [68320] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23180:09/12/17 18:38:21 [68320] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23181:09/12/17 18:38:21 [68320] (540.0) gm state change: GM_INIT -> GM_START
23182:09/12/17 18:38:21 [68320] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23183:09/12/17 18:38:21 [68320] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23184:09/12/17 18:38:21 [68320] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23185:09/12/17 18:38:21 [68320] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23186:09/12/17 18:38:21 [68320] (539.0) gm state change: GM_INIT -> GM_START
23187:09/12/17 18:38:21 [68320] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23188:09/12/17 18:38:21 [68320] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23189:09/12/17 18:38:21 [68320] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23190:09/12/17 18:38:21 [68320] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23191:09/12/17 18:38:21 [68320] (538.0) gm state change: GM_INIT -> GM_START
23192:09/12/17 18:38:21 [68320] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23193:09/12/17 18:38:21 [68320] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23194:09/12/17 18:38:21 [68320] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23195:09/12/17 18:38:21 [68320] This process has a valid certificate & key
23196:09/12/17 18:38:21 [68320] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23197:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23198:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23199:09/12/17 18:38:21 [68320] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23200:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23201:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23202:09/12/17 18:38:21 [68320] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23203:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23204:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23205:09/12/17 18:38:21 [68320] IPVERIFY: checking mc0151-ib against 128.55.162.46
23206:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23207:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23208:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23209:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23210:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23211:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23212:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23213:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23214:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
23215:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
23216:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
23217:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
23218:09/12/17 18:38:21 [68320] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
23219:09/12/17 18:38:21 [68320] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
23220:09/12/17 18:38:21 [68320] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23221:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23222:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23223:09/12/17 18:38:21 [68320] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23224:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23225:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23226:09/12/17 18:38:21 [68320] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23227:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23228:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23229:09/12/17 18:38:21 [68320] IPVERIFY: checking mc0151-ib against 128.55.162.46
23230:09/12/17 18:38:21 [68320] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23231:09/12/17 18:38:21 [68320] IPVERIFY: ip found is 1
23232:09/12/17 18:38:21 [68320] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23233:09/12/17 18:38:21 [68320] (537.0) gm state change: GM_INIT -> GM_START
23234:09/12/17 18:38:21 [68320] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23235:09/12/17 18:38:21 [68320] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23236:09/12/17 18:38:21 [68320] GAHP[68322] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
23237:09/12/17 18:38:21 [68320] GAHP[68322] -> 'S'
23238:09/12/17 18:38:21 [68320] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23239:09/12/17 18:38:21 [68320] (536.0) gm state change: GM_INIT -> GM_START
23240:09/12/17 18:38:21 [68320] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23241:09/12/17 18:38:21 [68320] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23242:09/12/17 18:38:21 [68320] GAHP[68322] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
23243:09/12/17 18:38:21 [68320] GAHP[68322] -> 'S'
23244:09/12/17 18:38:21 [68320] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23245:09/12/17 18:38:21 [68320] (535.0) gm state change: GM_INIT -> GM_START
23246:09/12/17 18:38:21 [68320] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23247:09/12/17 18:38:21 [68320] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23248:09/12/17 18:38:21 [68320] GAHP[68322] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
23249:09/12/17 18:38:21 [68320] GAHP[68322] -> 'S'
23250:09/12/17 18:38:21 [68320] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23251:09/12/17 18:38:21 [68320] (534.0) gm state change: GM_INIT -> GM_START
23252:09/12/17 18:38:21 [68320] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23253:09/12/17 18:38:21 [68320] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23254:09/12/17 18:38:21 [68320] GAHP[68322] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
23255:09/12/17 18:38:21 [68320] GAHP[68322] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
23256:09/12/17 18:38:21 [68320] GAHP[68322] -> EOF
23257:09/12/17 18:38:21 [68320] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
23258:09/12/17 18:43:19 Result of reading /etc/issue:  \S
23260:09/12/17 18:43:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
23262:09/12/17 18:43:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
23263:09/12/17 18:43:19 Enumerating interfaces: lo 127.0.0.1 up
23264:09/12/17 18:43:19 Enumerating interfaces: eth0 10.36.162.46 up
23265:09/12/17 18:43:19 Enumerating interfaces: ib0 128.55.162.46 up
23266:09/12/17 18:43:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
23267:09/12/17 18:43:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
23268:09/12/17 18:43:19 ******************************************************
23269:09/12/17 18:43:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
23270:09/12/17 18:43:19 ** /usr/sbin/condor_gridmanager
23271:09/12/17 18:43:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
23272:09/12/17 18:43:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
23273:09/12/17 18:43:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
23274:09/12/17 18:43:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
23275:09/12/17 18:43:19 ** PID = 68362
23276:09/12/17 18:43:19 ** Log last touched 9/12 18:38:21
23277:09/12/17 18:43:19 ******************************************************
23278:09/12/17 18:43:19 Using config source: /etc/condor-ce/condor_config
23279:09/12/17 18:43:19 Using local config sources: 
23280:09/12/17 18:43:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
23281:09/12/17 18:43:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
23282:09/12/17 18:43:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
23283:09/12/17 18:43:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
23284:09/12/17 18:43:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
23285:09/12/17 18:43:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
23286:09/12/17 18:43:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
23287:09/12/17 18:43:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
23288:09/12/17 18:43:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
23289:09/12/17 18:43:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
23290:09/12/17 18:43:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
23291:09/12/17 18:43:19    /etc/condor-ce/config.d/01-ce-auth.conf
23292:09/12/17 18:43:19    /etc/condor-ce/config.d/01-ce-router.conf
23293:09/12/17 18:43:19    /etc/condor-ce/config.d/01-common-auth.conf
23294:09/12/17 18:43:19    /etc/condor-ce/config.d/02-ce-slurm.conf
23295:09/12/17 18:43:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
23296:09/12/17 18:43:19    /etc/condor-ce/config.d/03-managed-fork.conf
23297:09/12/17 18:43:19    /etc/condor-ce/config.d/05-ce-health.conf
23298:09/12/17 18:43:19    /etc/condor-ce/config.d/05-ce-view.conf
23299:09/12/17 18:43:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
23300:09/12/17 18:43:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
23301:09/12/17 18:43:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
23302:09/12/17 18:43:19    /etc/condor-ce/config.d/50-osg-configure.conf
23303:09/12/17 18:43:19    /etc/condor-ce/config.d/99-local.conf
23304:09/12/17 18:43:19    /usr/share/condor-ce/condor_ce_router_defaults|
23305:09/12/17 18:43:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
23306:09/12/17 18:43:19 CLASSAD_CACHING is ENABLED
23307:09/12/17 18:43:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
23308:09/12/17 18:43:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_80
23309:09/12/17 18:43:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_80>
23310:09/12/17 18:43:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_80>
23311:09/12/17 18:43:19 Setting maximum accepts per cycle 8.
23312:09/12/17 18:43:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23313:09/12/17 18:43:19 [68362] Welcome to the all-singing, all dancing, "amazing" GridManager!
23314:09/12/17 18:43:19 [68362] DaemonCore: No more children processes to reap.
23315:09/12/17 18:43:19 [68362] DaemonCore: in SendAliveToParent()
23316:09/12/17 18:43:19 [68362] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23317:09/12/17 18:43:19 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23318:09/12/17 18:43:19 [68362] IPVERIFY: ip found is 1
23319:09/12/17 18:43:19 [68362] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23320:09/12/17 18:43:19 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23321:09/12/17 18:43:19 [68362] IPVERIFY: ip found is 1
23322:09/12/17 18:43:19 [68362] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23323:09/12/17 18:43:19 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23324:09/12/17 18:43:19 [68362] IPVERIFY: ip found is 1
23325:09/12/17 18:43:19 [68362] IPVERIFY: checking mc0151-ib against 128.55.162.46
23326:09/12/17 18:43:19 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23327:09/12/17 18:43:19 [68362] IPVERIFY: ip found is 1
23328:09/12/17 18:43:19 [68362] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
23329:09/12/17 18:43:19 [68362] DaemonCore: Leaving SendAliveToParent() - success
23330:09/12/17 18:43:19 [68362] Checking proxies
23331:09/12/17 18:43:21 [68362] Received ADD_JOBS signal
23332:09/12/17 18:43:21 [68362] in doContactSchedd()
23333:09/12/17 18:43:21 [68362] querying for new jobs
23334:09/12/17 18:43:21 [68362] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
23335:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 542.0
23336:09/12/17 18:43:21 [68362] (542.0) SetJobLeaseTimers()
23337:09/12/17 18:43:21 [68362] Found job 542.0 --- inserting
23338:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 541.0
23339:09/12/17 18:43:21 [68362] (541.0) SetJobLeaseTimers()
23340:09/12/17 18:43:21 [68362] Found job 541.0 --- inserting
23341:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 540.0
23342:09/12/17 18:43:21 [68362] (540.0) SetJobLeaseTimers()
23343:09/12/17 18:43:21 [68362] Found job 540.0 --- inserting
23344:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 539.0
23345:09/12/17 18:43:21 [68362] (539.0) SetJobLeaseTimers()
23346:09/12/17 18:43:21 [68362] Found job 539.0 --- inserting
23347:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 538.0
23348:09/12/17 18:43:21 [68362] (538.0) SetJobLeaseTimers()
23349:09/12/17 18:43:21 [68362] Found job 538.0 --- inserting
23350:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 537.0
23351:09/12/17 18:43:21 [68362] (537.0) SetJobLeaseTimers()
23352:09/12/17 18:43:21 [68362] Found job 537.0 --- inserting
23353:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 536.0
23354:09/12/17 18:43:21 [68362] (536.0) SetJobLeaseTimers()
23355:09/12/17 18:43:21 [68362] Found job 536.0 --- inserting
23356:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 535.0
23357:09/12/17 18:43:21 [68362] (535.0) SetJobLeaseTimers()
23358:09/12/17 18:43:21 [68362] Found job 535.0 --- inserting
23359:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 534.0
23360:09/12/17 18:43:21 [68362] (534.0) SetJobLeaseTimers()
23361:09/12/17 18:43:21 [68362] Found job 534.0 --- inserting
23362:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 533.0
23363:09/12/17 18:43:21 [68362] (533.0) SetJobLeaseTimers()
23364:09/12/17 18:43:21 [68362] Found job 533.0 --- inserting
23365:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 532.0
23366:09/12/17 18:43:21 [68362] (532.0) SetJobLeaseTimers()
23367:09/12/17 18:43:21 [68362] Found job 532.0 --- inserting
23368:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 531.0
23369:09/12/17 18:43:21 [68362] (531.0) SetJobLeaseTimers()
23370:09/12/17 18:43:21 [68362] Found job 531.0 --- inserting
23371:09/12/17 18:43:21 [68362] Using job type INFNBatch for job 530.0
23372:09/12/17 18:43:21 [68362] (530.0) SetJobLeaseTimers()
23373:09/12/17 18:43:21 [68362] Found job 530.0 --- inserting
23374:09/12/17 18:43:21 [68362] Fetched 13 new job ads from schedd
23375:09/12/17 18:43:21 [68362] querying for removed/held jobs
23376:09/12/17 18:43:21 [68362] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
23377:09/12/17 18:43:21 [68362] Fetched 0 job ads from schedd
23378:09/12/17 18:43:21 [68362] leaving doContactSchedd()
23379:09/12/17 18:43:21 [68362] gahp server not up yet, delaying ping
23380:09/12/17 18:43:21 [68362] *** UpdateLeases called
23381:09/12/17 18:43:21 [68362]     Leases not supported, cancelling timer
23382:09/12/17 18:43:21 [68362] BaseResource::UpdateResource: 
23402:09/12/17 18:43:21 [68362] Trying to update collector <128.55.162.46:9619>
23403:09/12/17 18:43:21 [68362] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23404:09/12/17 18:43:21 [68362] File descriptor limits: max 4096, safe 3277
23405:09/12/17 18:43:21 [68362] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23406:09/12/17 18:43:21 [68362] GAHP server pid = 68364
23407:09/12/17 18:43:21 [68362] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
23408:09/12/17 18:43:21 [68362] GAHP[68364] <- 'COMMANDS'
23409:09/12/17 18:43:21 [68362] GAHP[68364] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
23410:09/12/17 18:43:21 [68362] GAHP[68364] <- 'ASYNC_MODE_ON'
23411:09/12/17 18:43:21 [68362] GAHP[68364] -> 'S' 'Async mode on'
23412:09/12/17 18:43:21 [68362] (542.0) gm state change: GM_INIT -> GM_START
23413:09/12/17 18:43:21 [68362] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23414:09/12/17 18:43:21 [68362] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23415:09/12/17 18:43:21 [68362] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23416:09/12/17 18:43:21 [68362] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23417:09/12/17 18:43:21 [68362] (541.0) gm state change: GM_INIT -> GM_START
23418:09/12/17 18:43:21 [68362] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23419:09/12/17 18:43:21 [68362] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23420:09/12/17 18:43:21 [68362] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23421:09/12/17 18:43:21 [68362] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23422:09/12/17 18:43:21 [68362] (540.0) gm state change: GM_INIT -> GM_START
23423:09/12/17 18:43:21 [68362] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23424:09/12/17 18:43:21 [68362] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23425:09/12/17 18:43:21 [68362] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23426:09/12/17 18:43:21 [68362] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23427:09/12/17 18:43:21 [68362] (539.0) gm state change: GM_INIT -> GM_START
23428:09/12/17 18:43:21 [68362] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23429:09/12/17 18:43:21 [68362] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23430:09/12/17 18:43:21 [68362] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23431:09/12/17 18:43:21 [68362] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23432:09/12/17 18:43:21 [68362] (538.0) gm state change: GM_INIT -> GM_START
23433:09/12/17 18:43:21 [68362] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23434:09/12/17 18:43:21 [68362] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23435:09/12/17 18:43:21 [68362] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23436:09/12/17 18:43:21 [68362] This process has a valid certificate & key
23437:09/12/17 18:43:21 [68362] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23438:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23439:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23440:09/12/17 18:43:21 [68362] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23441:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23442:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23443:09/12/17 18:43:21 [68362] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23444:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23445:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23446:09/12/17 18:43:21 [68362] IPVERIFY: checking mc0151-ib against 128.55.162.46
23447:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23448:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23449:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23450:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23451:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23452:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23453:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23454:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23455:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
23456:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
23457:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
23458:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
23459:09/12/17 18:43:21 [68362] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
23460:09/12/17 18:43:21 [68362] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
23461:09/12/17 18:43:21 [68362] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23462:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23463:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23464:09/12/17 18:43:21 [68362] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23465:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23466:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23467:09/12/17 18:43:21 [68362] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23468:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23469:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23470:09/12/17 18:43:21 [68362] IPVERIFY: checking mc0151-ib against 128.55.162.46
23471:09/12/17 18:43:21 [68362] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23472:09/12/17 18:43:21 [68362] IPVERIFY: ip found is 1
23473:09/12/17 18:43:21 [68362] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23474:09/12/17 18:43:21 [68362] (537.0) gm state change: GM_INIT -> GM_START
23475:09/12/17 18:43:21 [68362] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23476:09/12/17 18:43:21 [68362] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23477:09/12/17 18:43:21 [68362] GAHP[68364] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
23478:09/12/17 18:43:21 [68362] GAHP[68364] -> 'S'
23479:09/12/17 18:43:21 [68362] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23480:09/12/17 18:43:21 [68362] (536.0) gm state change: GM_INIT -> GM_START
23481:09/12/17 18:43:21 [68362] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23482:09/12/17 18:43:21 [68362] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23483:09/12/17 18:43:21 [68362] GAHP[68364] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
23484:09/12/17 18:43:21 [68362] GAHP[68364] -> 'S'
23485:09/12/17 18:43:21 [68362] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23486:09/12/17 18:43:21 [68362] (535.0) gm state change: GM_INIT -> GM_START
23487:09/12/17 18:43:21 [68362] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23488:09/12/17 18:43:21 [68362] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23489:09/12/17 18:43:21 [68362] GAHP[68364] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
23490:09/12/17 18:43:21 [68362] GAHP[68364] -> 'S'
23491:09/12/17 18:43:21 [68362] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23492:09/12/17 18:43:21 [68362] (534.0) gm state change: GM_INIT -> GM_START
23493:09/12/17 18:43:21 [68362] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23494:09/12/17 18:43:21 [68362] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23495:09/12/17 18:43:21 [68362] GAHP[68364] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
23496:09/12/17 18:43:21 [68362] GAHP[68364] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
23497:09/12/17 18:43:21 [68362] GAHP[68364] -> EOF
23498:09/12/17 18:43:21 [68362] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
23499:09/12/17 18:48:19 Result of reading /etc/issue:  \S
23501:09/12/17 18:48:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
23503:09/12/17 18:48:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
23504:09/12/17 18:48:19 Enumerating interfaces: lo 127.0.0.1 up
23505:09/12/17 18:48:19 Enumerating interfaces: eth0 10.36.162.46 up
23506:09/12/17 18:48:19 Enumerating interfaces: ib0 128.55.162.46 up
23507:09/12/17 18:48:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
23508:09/12/17 18:48:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
23509:09/12/17 18:48:19 ******************************************************
23510:09/12/17 18:48:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
23511:09/12/17 18:48:19 ** /usr/sbin/condor_gridmanager
23512:09/12/17 18:48:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
23513:09/12/17 18:48:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
23514:09/12/17 18:48:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
23515:09/12/17 18:48:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
23516:09/12/17 18:48:19 ** PID = 68418
23517:09/12/17 18:48:19 ** Log last touched 9/12 18:43:21
23518:09/12/17 18:48:19 ******************************************************
23519:09/12/17 18:48:19 Using config source: /etc/condor-ce/condor_config
23520:09/12/17 18:48:19 Using local config sources: 
23521:09/12/17 18:48:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
23522:09/12/17 18:48:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
23523:09/12/17 18:48:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
23524:09/12/17 18:48:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
23525:09/12/17 18:48:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
23526:09/12/17 18:48:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
23527:09/12/17 18:48:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
23528:09/12/17 18:48:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
23529:09/12/17 18:48:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
23530:09/12/17 18:48:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
23531:09/12/17 18:48:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
23532:09/12/17 18:48:19    /etc/condor-ce/config.d/01-ce-auth.conf
23533:09/12/17 18:48:19    /etc/condor-ce/config.d/01-ce-router.conf
23534:09/12/17 18:48:19    /etc/condor-ce/config.d/01-common-auth.conf
23535:09/12/17 18:48:19    /etc/condor-ce/config.d/02-ce-slurm.conf
23536:09/12/17 18:48:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
23537:09/12/17 18:48:19    /etc/condor-ce/config.d/03-managed-fork.conf
23538:09/12/17 18:48:19    /etc/condor-ce/config.d/05-ce-health.conf
23539:09/12/17 18:48:19    /etc/condor-ce/config.d/05-ce-view.conf
23540:09/12/17 18:48:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
23541:09/12/17 18:48:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
23542:09/12/17 18:48:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
23543:09/12/17 18:48:19    /etc/condor-ce/config.d/50-osg-configure.conf
23544:09/12/17 18:48:19    /etc/condor-ce/config.d/99-local.conf
23545:09/12/17 18:48:19    /usr/share/condor-ce/condor_ce_router_defaults|
23546:09/12/17 18:48:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
23547:09/12/17 18:48:19 CLASSAD_CACHING is ENABLED
23548:09/12/17 18:48:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
23549:09/12/17 18:48:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_83
23550:09/12/17 18:48:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_83>
23551:09/12/17 18:48:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_83>
23552:09/12/17 18:48:19 Setting maximum accepts per cycle 8.
23553:09/12/17 18:48:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23554:09/12/17 18:48:19 [68418] Welcome to the all-singing, all dancing, "amazing" GridManager!
23555:09/12/17 18:48:19 [68418] DaemonCore: No more children processes to reap.
23556:09/12/17 18:48:19 [68418] DaemonCore: in SendAliveToParent()
23557:09/12/17 18:48:19 [68418] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23558:09/12/17 18:48:19 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23559:09/12/17 18:48:19 [68418] IPVERIFY: ip found is 1
23560:09/12/17 18:48:19 [68418] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23561:09/12/17 18:48:19 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23562:09/12/17 18:48:19 [68418] IPVERIFY: ip found is 1
23563:09/12/17 18:48:19 [68418] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23564:09/12/17 18:48:19 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23565:09/12/17 18:48:19 [68418] IPVERIFY: ip found is 1
23566:09/12/17 18:48:19 [68418] IPVERIFY: checking mc0151-ib against 128.55.162.46
23567:09/12/17 18:48:19 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23568:09/12/17 18:48:19 [68418] IPVERIFY: ip found is 1
23569:09/12/17 18:48:19 [68418] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
23570:09/12/17 18:48:19 [68418] DaemonCore: Leaving SendAliveToParent() - success
23571:09/12/17 18:48:19 [68418] Checking proxies
23572:09/12/17 18:48:22 [68418] Received ADD_JOBS signal
23573:09/12/17 18:48:22 [68418] in doContactSchedd()
23574:09/12/17 18:48:22 [68418] querying for new jobs
23575:09/12/17 18:48:22 [68418] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
23576:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 542.0
23577:09/12/17 18:48:22 [68418] (542.0) SetJobLeaseTimers()
23578:09/12/17 18:48:22 [68418] Found job 542.0 --- inserting
23579:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 541.0
23580:09/12/17 18:48:22 [68418] (541.0) SetJobLeaseTimers()
23581:09/12/17 18:48:22 [68418] Found job 541.0 --- inserting
23582:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 540.0
23583:09/12/17 18:48:22 [68418] (540.0) SetJobLeaseTimers()
23584:09/12/17 18:48:22 [68418] Found job 540.0 --- inserting
23585:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 539.0
23586:09/12/17 18:48:22 [68418] (539.0) SetJobLeaseTimers()
23587:09/12/17 18:48:22 [68418] Found job 539.0 --- inserting
23588:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 538.0
23589:09/12/17 18:48:22 [68418] (538.0) SetJobLeaseTimers()
23590:09/12/17 18:48:22 [68418] Found job 538.0 --- inserting
23591:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 537.0
23592:09/12/17 18:48:22 [68418] (537.0) SetJobLeaseTimers()
23593:09/12/17 18:48:22 [68418] Found job 537.0 --- inserting
23594:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 536.0
23595:09/12/17 18:48:22 [68418] (536.0) SetJobLeaseTimers()
23596:09/12/17 18:48:22 [68418] Found job 536.0 --- inserting
23597:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 535.0
23598:09/12/17 18:48:22 [68418] (535.0) SetJobLeaseTimers()
23599:09/12/17 18:48:22 [68418] Found job 535.0 --- inserting
23600:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 534.0
23601:09/12/17 18:48:22 [68418] (534.0) SetJobLeaseTimers()
23602:09/12/17 18:48:22 [68418] Found job 534.0 --- inserting
23603:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 533.0
23604:09/12/17 18:48:22 [68418] (533.0) SetJobLeaseTimers()
23605:09/12/17 18:48:22 [68418] Found job 533.0 --- inserting
23606:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 532.0
23607:09/12/17 18:48:22 [68418] (532.0) SetJobLeaseTimers()
23608:09/12/17 18:48:22 [68418] Found job 532.0 --- inserting
23609:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 531.0
23610:09/12/17 18:48:22 [68418] (531.0) SetJobLeaseTimers()
23611:09/12/17 18:48:22 [68418] Found job 531.0 --- inserting
23612:09/12/17 18:48:22 [68418] Using job type INFNBatch for job 530.0
23613:09/12/17 18:48:22 [68418] (530.0) SetJobLeaseTimers()
23614:09/12/17 18:48:22 [68418] Found job 530.0 --- inserting
23615:09/12/17 18:48:22 [68418] Fetched 13 new job ads from schedd
23616:09/12/17 18:48:22 [68418] querying for removed/held jobs
23617:09/12/17 18:48:22 [68418] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
23618:09/12/17 18:48:22 [68418] Fetched 0 job ads from schedd
23619:09/12/17 18:48:22 [68418] leaving doContactSchedd()
23620:09/12/17 18:48:22 [68418] gahp server not up yet, delaying ping
23621:09/12/17 18:48:22 [68418] *** UpdateLeases called
23622:09/12/17 18:48:22 [68418]     Leases not supported, cancelling timer
23623:09/12/17 18:48:22 [68418] BaseResource::UpdateResource: 
23643:09/12/17 18:48:22 [68418] Trying to update collector <128.55.162.46:9619>
23644:09/12/17 18:48:22 [68418] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23645:09/12/17 18:48:22 [68418] File descriptor limits: max 4096, safe 3277
23646:09/12/17 18:48:22 [68418] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23647:09/12/17 18:48:22 [68418] GAHP server pid = 68421
23648:09/12/17 18:48:22 [68418] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
23649:09/12/17 18:48:22 [68418] GAHP[68421] <- 'COMMANDS'
23650:09/12/17 18:48:22 [68418] GAHP[68421] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
23651:09/12/17 18:48:22 [68418] GAHP[68421] <- 'ASYNC_MODE_ON'
23652:09/12/17 18:48:22 [68418] GAHP[68421] -> 'S' 'Async mode on'
23653:09/12/17 18:48:22 [68418] (542.0) gm state change: GM_INIT -> GM_START
23654:09/12/17 18:48:22 [68418] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23655:09/12/17 18:48:22 [68418] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23656:09/12/17 18:48:22 [68418] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23657:09/12/17 18:48:22 [68418] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23658:09/12/17 18:48:22 [68418] (541.0) gm state change: GM_INIT -> GM_START
23659:09/12/17 18:48:22 [68418] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23660:09/12/17 18:48:22 [68418] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23661:09/12/17 18:48:22 [68418] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23662:09/12/17 18:48:22 [68418] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23663:09/12/17 18:48:22 [68418] (540.0) gm state change: GM_INIT -> GM_START
23664:09/12/17 18:48:22 [68418] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23665:09/12/17 18:48:22 [68418] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23666:09/12/17 18:48:22 [68418] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23667:09/12/17 18:48:22 [68418] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23668:09/12/17 18:48:22 [68418] (539.0) gm state change: GM_INIT -> GM_START
23669:09/12/17 18:48:22 [68418] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23670:09/12/17 18:48:22 [68418] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23671:09/12/17 18:48:22 [68418] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23672:09/12/17 18:48:22 [68418] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23673:09/12/17 18:48:22 [68418] (538.0) gm state change: GM_INIT -> GM_START
23674:09/12/17 18:48:22 [68418] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23675:09/12/17 18:48:22 [68418] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23676:09/12/17 18:48:22 [68418] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23677:09/12/17 18:48:22 [68418] This process has a valid certificate & key
23678:09/12/17 18:48:22 [68418] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23679:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23680:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23681:09/12/17 18:48:22 [68418] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23682:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23683:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23684:09/12/17 18:48:22 [68418] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23685:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23686:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23687:09/12/17 18:48:22 [68418] IPVERIFY: checking mc0151-ib against 128.55.162.46
23688:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23689:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23690:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23691:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23692:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23693:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23694:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23695:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23696:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
23697:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
23698:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
23699:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
23700:09/12/17 18:48:22 [68418] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
23701:09/12/17 18:48:22 [68418] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
23702:09/12/17 18:48:22 [68418] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23703:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23704:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23705:09/12/17 18:48:22 [68418] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23706:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23707:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23708:09/12/17 18:48:22 [68418] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23709:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23710:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23711:09/12/17 18:48:22 [68418] IPVERIFY: checking mc0151-ib against 128.55.162.46
23712:09/12/17 18:48:22 [68418] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23713:09/12/17 18:48:22 [68418] IPVERIFY: ip found is 1
23714:09/12/17 18:48:22 [68418] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23715:09/12/17 18:48:22 [68418] (537.0) gm state change: GM_INIT -> GM_START
23716:09/12/17 18:48:22 [68418] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23717:09/12/17 18:48:22 [68418] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23718:09/12/17 18:48:22 [68418] GAHP[68421] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
23719:09/12/17 18:48:22 [68418] GAHP[68421] -> 'S'
23720:09/12/17 18:48:22 [68418] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23721:09/12/17 18:48:22 [68418] (536.0) gm state change: GM_INIT -> GM_START
23722:09/12/17 18:48:22 [68418] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23723:09/12/17 18:48:22 [68418] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23724:09/12/17 18:48:22 [68418] GAHP[68421] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
23725:09/12/17 18:48:22 [68418] GAHP[68421] -> 'S'
23726:09/12/17 18:48:22 [68418] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23727:09/12/17 18:48:22 [68418] (535.0) gm state change: GM_INIT -> GM_START
23728:09/12/17 18:48:22 [68418] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23729:09/12/17 18:48:22 [68418] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23730:09/12/17 18:48:22 [68418] GAHP[68421] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
23731:09/12/17 18:48:22 [68418] GAHP[68421] -> 'S'
23732:09/12/17 18:48:22 [68418] GAHP[68421] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
23733:09/12/17 18:48:22 [68418] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23734:09/12/17 18:48:22 [68418] (534.0) gm state change: GM_INIT -> GM_START
23735:09/12/17 18:48:22 [68418] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23736:09/12/17 18:48:22 [68418] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23737:09/12/17 18:48:22 [68418] GAHP[68421] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
23738:09/12/17 18:48:22 [68418] GAHP[68421] -> EOF
23739:09/12/17 18:48:22 [68418] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
23740:09/12/17 18:53:19 Result of reading /etc/issue:  \S
23742:09/12/17 18:53:19 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
23744:09/12/17 18:53:19 Using IDs: 32 processors, 16 CPUs, 16 HTs
23745:09/12/17 18:53:19 Enumerating interfaces: lo 127.0.0.1 up
23746:09/12/17 18:53:19 Enumerating interfaces: eth0 10.36.162.46 up
23747:09/12/17 18:53:19 Enumerating interfaces: ib0 128.55.162.46 up
23748:09/12/17 18:53:19 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
23749:09/12/17 18:53:19 Initializing Directory: curr_dir = /etc/condor-ce/config.d
23750:09/12/17 18:53:19 ******************************************************
23751:09/12/17 18:53:19 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
23752:09/12/17 18:53:19 ** /usr/sbin/condor_gridmanager
23753:09/12/17 18:53:19 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
23754:09/12/17 18:53:19 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
23755:09/12/17 18:53:19 ** $CondorVersion: 8.4.12 Aug 07 2017 $
23756:09/12/17 18:53:19 ** $CondorPlatform: X86_64-CentOS_7.3 $
23757:09/12/17 18:53:19 ** PID = 68462
23758:09/12/17 18:53:19 ** Log last touched 9/12 18:48:22
23759:09/12/17 18:53:19 ******************************************************
23760:09/12/17 18:53:19 Using config source: /etc/condor-ce/condor_config
23761:09/12/17 18:53:19 Using local config sources: 
23762:09/12/17 18:53:19    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
23763:09/12/17 18:53:19    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
23764:09/12/17 18:53:19    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
23765:09/12/17 18:53:19    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
23766:09/12/17 18:53:19    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
23767:09/12/17 18:53:19    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
23768:09/12/17 18:53:19    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
23769:09/12/17 18:53:19    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
23770:09/12/17 18:53:19    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
23771:09/12/17 18:53:19    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
23772:09/12/17 18:53:19    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
23773:09/12/17 18:53:19    /etc/condor-ce/config.d/01-ce-auth.conf
23774:09/12/17 18:53:19    /etc/condor-ce/config.d/01-ce-router.conf
23775:09/12/17 18:53:19    /etc/condor-ce/config.d/01-common-auth.conf
23776:09/12/17 18:53:19    /etc/condor-ce/config.d/02-ce-slurm.conf
23777:09/12/17 18:53:19    /etc/condor-ce/config.d/03-ce-shared-port.conf
23778:09/12/17 18:53:19    /etc/condor-ce/config.d/03-managed-fork.conf
23779:09/12/17 18:53:19    /etc/condor-ce/config.d/05-ce-health.conf
23780:09/12/17 18:53:19    /etc/condor-ce/config.d/05-ce-view.conf
23781:09/12/17 18:53:19    /etc/condor-ce/config.d/10-ce-collector-generated.conf
23782:09/12/17 18:53:19    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
23783:09/12/17 18:53:19    /etc/condor-ce/config.d/50-osg-configure-present.conf
23784:09/12/17 18:53:19    /etc/condor-ce/config.d/50-osg-configure.conf
23785:09/12/17 18:53:19    /etc/condor-ce/config.d/99-local.conf
23786:09/12/17 18:53:19    /usr/share/condor-ce/condor_ce_router_defaults|
23787:09/12/17 18:53:19 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
23788:09/12/17 18:53:19 CLASSAD_CACHING is ENABLED
23789:09/12/17 18:53:19 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
23790:09/12/17 18:53:19 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_85
23791:09/12/17 18:53:19 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_85>
23792:09/12/17 18:53:19 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_85>
23793:09/12/17 18:53:19 Setting maximum accepts per cycle 8.
23794:09/12/17 18:53:19 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23795:09/12/17 18:53:19 [68462] Welcome to the all-singing, all dancing, "amazing" GridManager!
23796:09/12/17 18:53:19 [68462] DaemonCore: No more children processes to reap.
23797:09/12/17 18:53:19 [68462] DaemonCore: in SendAliveToParent()
23798:09/12/17 18:53:19 [68462] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23799:09/12/17 18:53:19 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23800:09/12/17 18:53:19 [68462] IPVERIFY: ip found is 1
23801:09/12/17 18:53:19 [68462] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23802:09/12/17 18:53:19 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23803:09/12/17 18:53:19 [68462] IPVERIFY: ip found is 1
23804:09/12/17 18:53:19 [68462] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23805:09/12/17 18:53:19 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23806:09/12/17 18:53:19 [68462] IPVERIFY: ip found is 1
23807:09/12/17 18:53:19 [68462] IPVERIFY: checking mc0151-ib against 128.55.162.46
23808:09/12/17 18:53:19 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23809:09/12/17 18:53:19 [68462] IPVERIFY: ip found is 1
23810:09/12/17 18:53:19 [68462] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
23811:09/12/17 18:53:19 [68462] DaemonCore: Leaving SendAliveToParent() - success
23812:09/12/17 18:53:19 [68462] Checking proxies
23813:09/12/17 18:53:22 [68462] Received ADD_JOBS signal
23814:09/12/17 18:53:22 [68462] in doContactSchedd()
23815:09/12/17 18:53:22 [68462] querying for new jobs
23816:09/12/17 18:53:22 [68462] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
23817:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 542.0
23818:09/12/17 18:53:22 [68462] (542.0) SetJobLeaseTimers()
23819:09/12/17 18:53:22 [68462] Found job 542.0 --- inserting
23820:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 541.0
23821:09/12/17 18:53:22 [68462] (541.0) SetJobLeaseTimers()
23822:09/12/17 18:53:22 [68462] Found job 541.0 --- inserting
23823:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 540.0
23824:09/12/17 18:53:22 [68462] (540.0) SetJobLeaseTimers()
23825:09/12/17 18:53:22 [68462] Found job 540.0 --- inserting
23826:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 539.0
23827:09/12/17 18:53:22 [68462] (539.0) SetJobLeaseTimers()
23828:09/12/17 18:53:22 [68462] Found job 539.0 --- inserting
23829:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 538.0
23830:09/12/17 18:53:22 [68462] (538.0) SetJobLeaseTimers()
23831:09/12/17 18:53:22 [68462] Found job 538.0 --- inserting
23832:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 537.0
23833:09/12/17 18:53:22 [68462] (537.0) SetJobLeaseTimers()
23834:09/12/17 18:53:22 [68462] Found job 537.0 --- inserting
23835:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 536.0
23836:09/12/17 18:53:22 [68462] (536.0) SetJobLeaseTimers()
23837:09/12/17 18:53:22 [68462] Found job 536.0 --- inserting
23838:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 535.0
23839:09/12/17 18:53:22 [68462] (535.0) SetJobLeaseTimers()
23840:09/12/17 18:53:22 [68462] Found job 535.0 --- inserting
23841:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 534.0
23842:09/12/17 18:53:22 [68462] (534.0) SetJobLeaseTimers()
23843:09/12/17 18:53:22 [68462] Found job 534.0 --- inserting
23844:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 533.0
23845:09/12/17 18:53:22 [68462] (533.0) SetJobLeaseTimers()
23846:09/12/17 18:53:22 [68462] Found job 533.0 --- inserting
23847:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 532.0
23848:09/12/17 18:53:22 [68462] (532.0) SetJobLeaseTimers()
23849:09/12/17 18:53:22 [68462] Found job 532.0 --- inserting
23850:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 531.0
23851:09/12/17 18:53:22 [68462] (531.0) SetJobLeaseTimers()
23852:09/12/17 18:53:22 [68462] Found job 531.0 --- inserting
23853:09/12/17 18:53:22 [68462] Using job type INFNBatch for job 530.0
23854:09/12/17 18:53:22 [68462] (530.0) SetJobLeaseTimers()
23855:09/12/17 18:53:22 [68462] Found job 530.0 --- inserting
23856:09/12/17 18:53:22 [68462] Fetched 13 new job ads from schedd
23857:09/12/17 18:53:22 [68462] querying for removed/held jobs
23858:09/12/17 18:53:22 [68462] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
23859:09/12/17 18:53:22 [68462] Fetched 0 job ads from schedd
23860:09/12/17 18:53:22 [68462] leaving doContactSchedd()
23861:09/12/17 18:53:22 [68462] gahp server not up yet, delaying ping
23862:09/12/17 18:53:22 [68462] *** UpdateLeases called
23863:09/12/17 18:53:22 [68462]     Leases not supported, cancelling timer
23864:09/12/17 18:53:22 [68462] BaseResource::UpdateResource: 
23884:09/12/17 18:53:22 [68462] Trying to update collector <128.55.162.46:9619>
23885:09/12/17 18:53:22 [68462] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
23886:09/12/17 18:53:22 [68462] File descriptor limits: max 4096, safe 3277
23887:09/12/17 18:53:22 [68462] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23888:09/12/17 18:53:22 [68462] GAHP server pid = 68465
23889:09/12/17 18:53:22 [68462] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
23890:09/12/17 18:53:22 [68462] GAHP[68465] <- 'COMMANDS'
23891:09/12/17 18:53:22 [68462] GAHP[68465] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
23892:09/12/17 18:53:22 [68462] GAHP[68465] <- 'ASYNC_MODE_ON'
23893:09/12/17 18:53:22 [68462] GAHP[68465] -> 'S' 'Async mode on'
23894:09/12/17 18:53:22 [68462] (542.0) gm state change: GM_INIT -> GM_START
23895:09/12/17 18:53:22 [68462] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23896:09/12/17 18:53:22 [68462] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23897:09/12/17 18:53:22 [68462] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23898:09/12/17 18:53:22 [68462] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23899:09/12/17 18:53:22 [68462] (541.0) gm state change: GM_INIT -> GM_START
23900:09/12/17 18:53:22 [68462] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23901:09/12/17 18:53:22 [68462] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23902:09/12/17 18:53:22 [68462] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23903:09/12/17 18:53:22 [68462] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23904:09/12/17 18:53:22 [68462] (540.0) gm state change: GM_INIT -> GM_START
23905:09/12/17 18:53:22 [68462] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23906:09/12/17 18:53:22 [68462] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23907:09/12/17 18:53:22 [68462] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23908:09/12/17 18:53:22 [68462] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23909:09/12/17 18:53:22 [68462] (539.0) gm state change: GM_INIT -> GM_START
23910:09/12/17 18:53:22 [68462] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23911:09/12/17 18:53:22 [68462] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23912:09/12/17 18:53:22 [68462] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23913:09/12/17 18:53:22 [68462] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
23914:09/12/17 18:53:22 [68462] (538.0) gm state change: GM_INIT -> GM_START
23915:09/12/17 18:53:22 [68462] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
23916:09/12/17 18:53:22 [68462] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
23917:09/12/17 18:53:22 [68462] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
23918:09/12/17 18:53:22 [68462] This process has a valid certificate & key
23919:09/12/17 18:53:22 [68462] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23920:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23921:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23922:09/12/17 18:53:22 [68462] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23923:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23924:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23925:09/12/17 18:53:22 [68462] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23926:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23927:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23928:09/12/17 18:53:22 [68462] IPVERIFY: checking mc0151-ib against 128.55.162.46
23929:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23930:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23931:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23932:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23933:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23934:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23935:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23936:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
23937:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
23938:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
23939:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
23940:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
23941:09/12/17 18:53:22 [68462] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
23942:09/12/17 18:53:22 [68462] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
23943:09/12/17 18:53:22 [68462] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
23944:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23945:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23946:09/12/17 18:53:22 [68462] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
23947:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23948:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23949:09/12/17 18:53:22 [68462] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
23950:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23951:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23952:09/12/17 18:53:22 [68462] IPVERIFY: checking mc0151-ib against 128.55.162.46
23953:09/12/17 18:53:22 [68462] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
23954:09/12/17 18:53:22 [68462] IPVERIFY: ip found is 1
23955:09/12/17 18:53:22 [68462] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23956:09/12/17 18:53:22 [68462] (537.0) gm state change: GM_INIT -> GM_START
23957:09/12/17 18:53:22 [68462] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23958:09/12/17 18:53:22 [68462] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23959:09/12/17 18:53:22 [68462] GAHP[68465] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
23960:09/12/17 18:53:22 [68462] GAHP[68465] -> 'S'
23961:09/12/17 18:53:22 [68462] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23962:09/12/17 18:53:22 [68462] (536.0) gm state change: GM_INIT -> GM_START
23963:09/12/17 18:53:22 [68462] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23964:09/12/17 18:53:22 [68462] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23965:09/12/17 18:53:22 [68462] GAHP[68465] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
23966:09/12/17 18:53:22 [68462] GAHP[68465] -> 'S'
23967:09/12/17 18:53:22 [68462] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23968:09/12/17 18:53:22 [68462] (535.0) gm state change: GM_INIT -> GM_START
23969:09/12/17 18:53:22 [68462] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23970:09/12/17 18:53:22 [68462] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23971:09/12/17 18:53:22 [68462] GAHP[68465] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
23972:09/12/17 18:53:22 [68462] GAHP[68465] -> 'S'
23973:09/12/17 18:53:22 [68462] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
23974:09/12/17 18:53:22 [68462] (534.0) gm state change: GM_INIT -> GM_START
23975:09/12/17 18:53:22 [68462] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
23976:09/12/17 18:53:22 [68462] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
23977:09/12/17 18:53:22 [68462] GAHP[68465] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
23978:09/12/17 18:53:22 [68462] GAHP[68465] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
23979:09/12/17 18:53:22 [68462] GAHP[68465] -> EOF
23980:09/12/17 18:53:22 [68462] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
23981:09/12/17 18:58:20 Result of reading /etc/issue:  \S
23983:09/12/17 18:58:20 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
23985:09/12/17 18:58:20 Using IDs: 32 processors, 16 CPUs, 16 HTs
23986:09/12/17 18:58:20 Enumerating interfaces: lo 127.0.0.1 up
23987:09/12/17 18:58:20 Enumerating interfaces: eth0 10.36.162.46 up
23988:09/12/17 18:58:20 Enumerating interfaces: ib0 128.55.162.46 up
23989:09/12/17 18:58:20 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
23990:09/12/17 18:58:20 Initializing Directory: curr_dir = /etc/condor-ce/config.d
23991:09/12/17 18:58:20 ******************************************************
23992:09/12/17 18:58:20 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
23993:09/12/17 18:58:20 ** /usr/sbin/condor_gridmanager
23994:09/12/17 18:58:20 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
23995:09/12/17 18:58:20 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
23996:09/12/17 18:58:20 ** $CondorVersion: 8.4.12 Aug 07 2017 $
23997:09/12/17 18:58:20 ** $CondorPlatform: X86_64-CentOS_7.3 $
23998:09/12/17 18:58:20 ** PID = 68504
23999:09/12/17 18:58:20 ** Log last touched 9/12 18:53:22
24000:09/12/17 18:58:20 ******************************************************
24001:09/12/17 18:58:20 Using config source: /etc/condor-ce/condor_config
24002:09/12/17 18:58:20 Using local config sources: 
24003:09/12/17 18:58:20    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
24004:09/12/17 18:58:20    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
24005:09/12/17 18:58:20    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
24006:09/12/17 18:58:20    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
24007:09/12/17 18:58:20    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
24008:09/12/17 18:58:20    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
24009:09/12/17 18:58:20    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
24010:09/12/17 18:58:20    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
24011:09/12/17 18:58:20    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
24012:09/12/17 18:58:20    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
24013:09/12/17 18:58:20    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
24014:09/12/17 18:58:20    /etc/condor-ce/config.d/01-ce-auth.conf
24015:09/12/17 18:58:20    /etc/condor-ce/config.d/01-ce-router.conf
24016:09/12/17 18:58:20    /etc/condor-ce/config.d/01-common-auth.conf
24017:09/12/17 18:58:20    /etc/condor-ce/config.d/02-ce-slurm.conf
24018:09/12/17 18:58:20    /etc/condor-ce/config.d/03-ce-shared-port.conf
24019:09/12/17 18:58:20    /etc/condor-ce/config.d/03-managed-fork.conf
24020:09/12/17 18:58:20    /etc/condor-ce/config.d/05-ce-health.conf
24021:09/12/17 18:58:20    /etc/condor-ce/config.d/05-ce-view.conf
24022:09/12/17 18:58:20    /etc/condor-ce/config.d/10-ce-collector-generated.conf
24023:09/12/17 18:58:20    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
24024:09/12/17 18:58:20    /etc/condor-ce/config.d/50-osg-configure-present.conf
24025:09/12/17 18:58:20    /etc/condor-ce/config.d/50-osg-configure.conf
24026:09/12/17 18:58:20    /etc/condor-ce/config.d/99-local.conf
24027:09/12/17 18:58:20    /usr/share/condor-ce/condor_ce_router_defaults|
24028:09/12/17 18:58:20 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
24029:09/12/17 18:58:20 CLASSAD_CACHING is ENABLED
24030:09/12/17 18:58:20 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
24031:09/12/17 18:58:20 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_88
24032:09/12/17 18:58:20 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_88>
24033:09/12/17 18:58:20 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_88>
24034:09/12/17 18:58:20 Setting maximum accepts per cycle 8.
24035:09/12/17 18:58:20 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24036:09/12/17 18:58:20 [68504] Welcome to the all-singing, all dancing, "amazing" GridManager!
24037:09/12/17 18:58:20 [68504] DaemonCore: No more children processes to reap.
24038:09/12/17 18:58:20 [68504] DaemonCore: in SendAliveToParent()
24039:09/12/17 18:58:20 [68504] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24040:09/12/17 18:58:20 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24041:09/12/17 18:58:20 [68504] IPVERIFY: ip found is 1
24042:09/12/17 18:58:20 [68504] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24043:09/12/17 18:58:20 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24044:09/12/17 18:58:20 [68504] IPVERIFY: ip found is 1
24045:09/12/17 18:58:20 [68504] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24046:09/12/17 18:58:20 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24047:09/12/17 18:58:20 [68504] IPVERIFY: ip found is 1
24048:09/12/17 18:58:20 [68504] IPVERIFY: checking mc0151-ib against 128.55.162.46
24049:09/12/17 18:58:20 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24050:09/12/17 18:58:20 [68504] IPVERIFY: ip found is 1
24051:09/12/17 18:58:20 [68504] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
24052:09/12/17 18:58:20 [68504] DaemonCore: Leaving SendAliveToParent() - success
24053:09/12/17 18:58:20 [68504] Checking proxies
24054:09/12/17 18:58:23 [68504] Received ADD_JOBS signal
24055:09/12/17 18:58:23 [68504] in doContactSchedd()
24056:09/12/17 18:58:23 [68504] querying for new jobs
24057:09/12/17 18:58:23 [68504] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
24058:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 542.0
24059:09/12/17 18:58:23 [68504] (542.0) SetJobLeaseTimers()
24060:09/12/17 18:58:23 [68504] Found job 542.0 --- inserting
24061:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 541.0
24062:09/12/17 18:58:23 [68504] (541.0) SetJobLeaseTimers()
24063:09/12/17 18:58:23 [68504] Found job 541.0 --- inserting
24064:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 540.0
24065:09/12/17 18:58:23 [68504] (540.0) SetJobLeaseTimers()
24066:09/12/17 18:58:23 [68504] Found job 540.0 --- inserting
24067:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 539.0
24068:09/12/17 18:58:23 [68504] (539.0) SetJobLeaseTimers()
24069:09/12/17 18:58:23 [68504] Found job 539.0 --- inserting
24070:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 538.0
24071:09/12/17 18:58:23 [68504] (538.0) SetJobLeaseTimers()
24072:09/12/17 18:58:23 [68504] Found job 538.0 --- inserting
24073:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 537.0
24074:09/12/17 18:58:23 [68504] (537.0) SetJobLeaseTimers()
24075:09/12/17 18:58:23 [68504] Found job 537.0 --- inserting
24076:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 536.0
24077:09/12/17 18:58:23 [68504] (536.0) SetJobLeaseTimers()
24078:09/12/17 18:58:23 [68504] Found job 536.0 --- inserting
24079:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 535.0
24080:09/12/17 18:58:23 [68504] (535.0) SetJobLeaseTimers()
24081:09/12/17 18:58:23 [68504] Found job 535.0 --- inserting
24082:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 534.0
24083:09/12/17 18:58:23 [68504] (534.0) SetJobLeaseTimers()
24084:09/12/17 18:58:23 [68504] Found job 534.0 --- inserting
24085:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 533.0
24086:09/12/17 18:58:23 [68504] (533.0) SetJobLeaseTimers()
24087:09/12/17 18:58:23 [68504] Found job 533.0 --- inserting
24088:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 532.0
24089:09/12/17 18:58:23 [68504] (532.0) SetJobLeaseTimers()
24090:09/12/17 18:58:23 [68504] Found job 532.0 --- inserting
24091:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 531.0
24092:09/12/17 18:58:23 [68504] (531.0) SetJobLeaseTimers()
24093:09/12/17 18:58:23 [68504] Found job 531.0 --- inserting
24094:09/12/17 18:58:23 [68504] Using job type INFNBatch for job 530.0
24095:09/12/17 18:58:23 [68504] (530.0) SetJobLeaseTimers()
24096:09/12/17 18:58:23 [68504] Found job 530.0 --- inserting
24097:09/12/17 18:58:23 [68504] Fetched 13 new job ads from schedd
24098:09/12/17 18:58:23 [68504] querying for removed/held jobs
24099:09/12/17 18:58:23 [68504] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
24100:09/12/17 18:58:23 [68504] Fetched 0 job ads from schedd
24101:09/12/17 18:58:23 [68504] leaving doContactSchedd()
24102:09/12/17 18:58:23 [68504] gahp server not up yet, delaying ping
24103:09/12/17 18:58:23 [68504] *** UpdateLeases called
24104:09/12/17 18:58:23 [68504]     Leases not supported, cancelling timer
24105:09/12/17 18:58:23 [68504] BaseResource::UpdateResource: 
24125:09/12/17 18:58:23 [68504] Trying to update collector <128.55.162.46:9619>
24126:09/12/17 18:58:23 [68504] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24127:09/12/17 18:58:23 [68504] File descriptor limits: max 4096, safe 3277
24128:09/12/17 18:58:23 [68504] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24129:09/12/17 18:58:23 [68504] GAHP server pid = 68507
24130:09/12/17 18:58:23 [68504] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
24131:09/12/17 18:58:23 [68504] GAHP[68507] <- 'COMMANDS'
24132:09/12/17 18:58:23 [68504] GAHP[68507] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
24133:09/12/17 18:58:23 [68504] GAHP[68507] <- 'ASYNC_MODE_ON'
24134:09/12/17 18:58:23 [68504] GAHP[68507] -> 'S' 'Async mode on'
24135:09/12/17 18:58:23 [68504] (542.0) gm state change: GM_INIT -> GM_START
24136:09/12/17 18:58:23 [68504] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24137:09/12/17 18:58:23 [68504] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24138:09/12/17 18:58:23 [68504] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24139:09/12/17 18:58:23 [68504] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24140:09/12/17 18:58:23 [68504] (541.0) gm state change: GM_INIT -> GM_START
24141:09/12/17 18:58:23 [68504] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24142:09/12/17 18:58:23 [68504] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24143:09/12/17 18:58:23 [68504] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24144:09/12/17 18:58:23 [68504] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24145:09/12/17 18:58:23 [68504] (540.0) gm state change: GM_INIT -> GM_START
24146:09/12/17 18:58:23 [68504] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24147:09/12/17 18:58:23 [68504] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24148:09/12/17 18:58:23 [68504] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24149:09/12/17 18:58:23 [68504] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24150:09/12/17 18:58:23 [68504] (539.0) gm state change: GM_INIT -> GM_START
24151:09/12/17 18:58:23 [68504] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24152:09/12/17 18:58:23 [68504] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24153:09/12/17 18:58:23 [68504] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24154:09/12/17 18:58:23 [68504] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24155:09/12/17 18:58:23 [68504] (538.0) gm state change: GM_INIT -> GM_START
24156:09/12/17 18:58:23 [68504] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24157:09/12/17 18:58:23 [68504] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24158:09/12/17 18:58:23 [68504] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24159:09/12/17 18:58:23 [68504] This process has a valid certificate & key
24160:09/12/17 18:58:24 [68504] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24161:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24162:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24163:09/12/17 18:58:24 [68504] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24164:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24165:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24166:09/12/17 18:58:24 [68504] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24167:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24168:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24169:09/12/17 18:58:24 [68504] IPVERIFY: checking mc0151-ib against 128.55.162.46
24170:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24171:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24172:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24173:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24174:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24175:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24176:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24177:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24178:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
24179:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
24180:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
24181:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
24182:09/12/17 18:58:24 [68504] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
24183:09/12/17 18:58:24 [68504] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
24184:09/12/17 18:58:24 [68504] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24185:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24186:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24187:09/12/17 18:58:24 [68504] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24188:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24189:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24190:09/12/17 18:58:24 [68504] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24191:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24192:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24193:09/12/17 18:58:24 [68504] IPVERIFY: checking mc0151-ib against 128.55.162.46
24194:09/12/17 18:58:24 [68504] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24195:09/12/17 18:58:24 [68504] IPVERIFY: ip found is 1
24196:09/12/17 18:58:24 [68504] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24197:09/12/17 18:58:24 [68504] (537.0) gm state change: GM_INIT -> GM_START
24198:09/12/17 18:58:24 [68504] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24199:09/12/17 18:58:24 [68504] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24200:09/12/17 18:58:24 [68504] GAHP[68507] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
24201:09/12/17 18:58:24 [68504] GAHP[68507] -> 'S'
24202:09/12/17 18:58:24 [68504] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24203:09/12/17 18:58:24 [68504] (536.0) gm state change: GM_INIT -> GM_START
24204:09/12/17 18:58:24 [68504] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24205:09/12/17 18:58:24 [68504] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24206:09/12/17 18:58:24 [68504] GAHP[68507] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
24207:09/12/17 18:58:24 [68504] GAHP[68507] -> 'S'
24208:09/12/17 18:58:24 [68504] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24209:09/12/17 18:58:24 [68504] (535.0) gm state change: GM_INIT -> GM_START
24210:09/12/17 18:58:24 [68504] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24211:09/12/17 18:58:24 [68504] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24212:09/12/17 18:58:24 [68504] GAHP[68507] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
24213:09/12/17 18:58:24 [68504] GAHP[68507] -> 'S'
24214:09/12/17 18:58:24 [68504] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24215:09/12/17 18:58:24 [68504] (534.0) gm state change: GM_INIT -> GM_START
24216:09/12/17 18:58:24 [68504] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24217:09/12/17 18:58:24 [68504] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24218:09/12/17 18:58:24 [68504] GAHP[68507] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
24219:09/12/17 18:58:24 [68504] GAHP[68507] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
24220:09/12/17 18:58:24 [68504] GAHP[68507] -> EOF
24221:09/12/17 18:58:24 [68504] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
24222:09/12/17 19:03:21 Result of reading /etc/issue:  \S
24224:09/12/17 19:03:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
24226:09/12/17 19:03:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
24227:09/12/17 19:03:21 Enumerating interfaces: lo 127.0.0.1 up
24228:09/12/17 19:03:21 Enumerating interfaces: eth0 10.36.162.46 up
24229:09/12/17 19:03:21 Enumerating interfaces: ib0 128.55.162.46 up
24230:09/12/17 19:03:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
24231:09/12/17 19:03:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
24232:09/12/17 19:03:21 ******************************************************
24233:09/12/17 19:03:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
24234:09/12/17 19:03:21 ** /usr/sbin/condor_gridmanager
24235:09/12/17 19:03:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
24236:09/12/17 19:03:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
24237:09/12/17 19:03:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
24238:09/12/17 19:03:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
24239:09/12/17 19:03:21 ** PID = 68564
24240:09/12/17 19:03:21 ** Log last touched 9/12 18:58:24
24241:09/12/17 19:03:21 ******************************************************
24242:09/12/17 19:03:21 Using config source: /etc/condor-ce/condor_config
24243:09/12/17 19:03:21 Using local config sources: 
24244:09/12/17 19:03:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
24245:09/12/17 19:03:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
24246:09/12/17 19:03:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
24247:09/12/17 19:03:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
24248:09/12/17 19:03:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
24249:09/12/17 19:03:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
24250:09/12/17 19:03:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
24251:09/12/17 19:03:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
24252:09/12/17 19:03:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
24253:09/12/17 19:03:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
24254:09/12/17 19:03:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
24255:09/12/17 19:03:21    /etc/condor-ce/config.d/01-ce-auth.conf
24256:09/12/17 19:03:21    /etc/condor-ce/config.d/01-ce-router.conf
24257:09/12/17 19:03:21    /etc/condor-ce/config.d/01-common-auth.conf
24258:09/12/17 19:03:21    /etc/condor-ce/config.d/02-ce-slurm.conf
24259:09/12/17 19:03:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
24260:09/12/17 19:03:21    /etc/condor-ce/config.d/03-managed-fork.conf
24261:09/12/17 19:03:21    /etc/condor-ce/config.d/05-ce-health.conf
24262:09/12/17 19:03:21    /etc/condor-ce/config.d/05-ce-view.conf
24263:09/12/17 19:03:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
24264:09/12/17 19:03:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
24265:09/12/17 19:03:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
24266:09/12/17 19:03:21    /etc/condor-ce/config.d/50-osg-configure.conf
24267:09/12/17 19:03:21    /etc/condor-ce/config.d/99-local.conf
24268:09/12/17 19:03:21    /usr/share/condor-ce/condor_ce_router_defaults|
24269:09/12/17 19:03:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
24270:09/12/17 19:03:21 CLASSAD_CACHING is ENABLED
24271:09/12/17 19:03:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
24272:09/12/17 19:03:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_91
24273:09/12/17 19:03:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_91>
24274:09/12/17 19:03:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_91>
24275:09/12/17 19:03:21 Setting maximum accepts per cycle 8.
24276:09/12/17 19:03:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24277:09/12/17 19:03:21 [68564] Welcome to the all-singing, all dancing, "amazing" GridManager!
24278:09/12/17 19:03:21 [68564] DaemonCore: No more children processes to reap.
24279:09/12/17 19:03:21 [68564] DaemonCore: in SendAliveToParent()
24280:09/12/17 19:03:21 [68564] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24281:09/12/17 19:03:21 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24282:09/12/17 19:03:21 [68564] IPVERIFY: ip found is 1
24283:09/12/17 19:03:21 [68564] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24284:09/12/17 19:03:21 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24285:09/12/17 19:03:21 [68564] IPVERIFY: ip found is 1
24286:09/12/17 19:03:21 [68564] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24287:09/12/17 19:03:21 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24288:09/12/17 19:03:21 [68564] IPVERIFY: ip found is 1
24289:09/12/17 19:03:21 [68564] IPVERIFY: checking mc0151-ib against 128.55.162.46
24290:09/12/17 19:03:21 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24291:09/12/17 19:03:21 [68564] IPVERIFY: ip found is 1
24292:09/12/17 19:03:21 [68564] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
24293:09/12/17 19:03:21 [68564] DaemonCore: Leaving SendAliveToParent() - success
24294:09/12/17 19:03:21 [68564] Checking proxies
24295:09/12/17 19:03:24 [68564] Received ADD_JOBS signal
24296:09/12/17 19:03:24 [68564] in doContactSchedd()
24297:09/12/17 19:03:24 [68564] querying for new jobs
24298:09/12/17 19:03:24 [68564] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
24299:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 542.0
24300:09/12/17 19:03:24 [68564] (542.0) SetJobLeaseTimers()
24301:09/12/17 19:03:24 [68564] Found job 542.0 --- inserting
24302:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 541.0
24303:09/12/17 19:03:24 [68564] (541.0) SetJobLeaseTimers()
24304:09/12/17 19:03:24 [68564] Found job 541.0 --- inserting
24305:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 540.0
24306:09/12/17 19:03:24 [68564] (540.0) SetJobLeaseTimers()
24307:09/12/17 19:03:24 [68564] Found job 540.0 --- inserting
24308:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 539.0
24309:09/12/17 19:03:24 [68564] (539.0) SetJobLeaseTimers()
24310:09/12/17 19:03:24 [68564] Found job 539.0 --- inserting
24311:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 538.0
24312:09/12/17 19:03:24 [68564] (538.0) SetJobLeaseTimers()
24313:09/12/17 19:03:24 [68564] Found job 538.0 --- inserting
24314:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 537.0
24315:09/12/17 19:03:24 [68564] (537.0) SetJobLeaseTimers()
24316:09/12/17 19:03:24 [68564] Found job 537.0 --- inserting
24317:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 536.0
24318:09/12/17 19:03:24 [68564] (536.0) SetJobLeaseTimers()
24319:09/12/17 19:03:24 [68564] Found job 536.0 --- inserting
24320:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 535.0
24321:09/12/17 19:03:24 [68564] (535.0) SetJobLeaseTimers()
24322:09/12/17 19:03:24 [68564] Found job 535.0 --- inserting
24323:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 534.0
24324:09/12/17 19:03:24 [68564] (534.0) SetJobLeaseTimers()
24325:09/12/17 19:03:24 [68564] Found job 534.0 --- inserting
24326:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 533.0
24327:09/12/17 19:03:24 [68564] (533.0) SetJobLeaseTimers()
24328:09/12/17 19:03:24 [68564] Found job 533.0 --- inserting
24329:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 532.0
24330:09/12/17 19:03:24 [68564] (532.0) SetJobLeaseTimers()
24331:09/12/17 19:03:24 [68564] Found job 532.0 --- inserting
24332:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 531.0
24333:09/12/17 19:03:24 [68564] (531.0) SetJobLeaseTimers()
24334:09/12/17 19:03:24 [68564] Found job 531.0 --- inserting
24335:09/12/17 19:03:24 [68564] Using job type INFNBatch for job 530.0
24336:09/12/17 19:03:24 [68564] (530.0) SetJobLeaseTimers()
24337:09/12/17 19:03:24 [68564] Found job 530.0 --- inserting
24338:09/12/17 19:03:24 [68564] Fetched 13 new job ads from schedd
24339:09/12/17 19:03:24 [68564] querying for removed/held jobs
24340:09/12/17 19:03:24 [68564] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
24341:09/12/17 19:03:24 [68564] Fetched 0 job ads from schedd
24342:09/12/17 19:03:24 [68564] leaving doContactSchedd()
24343:09/12/17 19:03:24 [68564] gahp server not up yet, delaying ping
24344:09/12/17 19:03:24 [68564] *** UpdateLeases called
24345:09/12/17 19:03:24 [68564]     Leases not supported, cancelling timer
24346:09/12/17 19:03:24 [68564] BaseResource::UpdateResource: 
24366:09/12/17 19:03:24 [68564] Trying to update collector <128.55.162.46:9619>
24367:09/12/17 19:03:24 [68564] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24368:09/12/17 19:03:24 [68564] File descriptor limits: max 4096, safe 3277
24369:09/12/17 19:03:24 [68564] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24370:09/12/17 19:03:24 [68564] GAHP server pid = 68567
24371:09/12/17 19:03:24 [68564] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
24372:09/12/17 19:03:24 [68564] GAHP[68567] <- 'COMMANDS'
24373:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
24374:09/12/17 19:03:24 [68564] GAHP[68567] <- 'ASYNC_MODE_ON'
24375:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S' 'Async mode on'
24376:09/12/17 19:03:24 [68564] (542.0) gm state change: GM_INIT -> GM_START
24377:09/12/17 19:03:24 [68564] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24378:09/12/17 19:03:24 [68564] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24379:09/12/17 19:03:24 [68564] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24380:09/12/17 19:03:24 [68564] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24381:09/12/17 19:03:24 [68564] (541.0) gm state change: GM_INIT -> GM_START
24382:09/12/17 19:03:24 [68564] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24383:09/12/17 19:03:24 [68564] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24384:09/12/17 19:03:24 [68564] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24385:09/12/17 19:03:24 [68564] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24386:09/12/17 19:03:24 [68564] (540.0) gm state change: GM_INIT -> GM_START
24387:09/12/17 19:03:24 [68564] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24388:09/12/17 19:03:24 [68564] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24389:09/12/17 19:03:24 [68564] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24390:09/12/17 19:03:24 [68564] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24391:09/12/17 19:03:24 [68564] (539.0) gm state change: GM_INIT -> GM_START
24392:09/12/17 19:03:24 [68564] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24393:09/12/17 19:03:24 [68564] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24394:09/12/17 19:03:24 [68564] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24395:09/12/17 19:03:24 [68564] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24396:09/12/17 19:03:24 [68564] (538.0) gm state change: GM_INIT -> GM_START
24397:09/12/17 19:03:24 [68564] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24398:09/12/17 19:03:24 [68564] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24399:09/12/17 19:03:24 [68564] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24400:09/12/17 19:03:24 [68564] This process has a valid certificate & key
24401:09/12/17 19:03:24 [68564] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24402:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24403:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24404:09/12/17 19:03:24 [68564] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24405:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24406:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24407:09/12/17 19:03:24 [68564] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24408:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24409:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24410:09/12/17 19:03:24 [68564] IPVERIFY: checking mc0151-ib against 128.55.162.46
24411:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24412:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24413:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24414:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24415:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24416:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24417:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24418:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24419:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
24420:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
24421:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
24422:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
24423:09/12/17 19:03:24 [68564] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
24424:09/12/17 19:03:24 [68564] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
24425:09/12/17 19:03:24 [68564] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24426:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24427:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24428:09/12/17 19:03:24 [68564] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24429:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24430:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24431:09/12/17 19:03:24 [68564] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24432:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24433:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24434:09/12/17 19:03:24 [68564] IPVERIFY: checking mc0151-ib against 128.55.162.46
24435:09/12/17 19:03:24 [68564] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24436:09/12/17 19:03:24 [68564] IPVERIFY: ip found is 1
24437:09/12/17 19:03:24 [68564] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24438:09/12/17 19:03:24 [68564] (537.0) gm state change: GM_INIT -> GM_START
24439:09/12/17 19:03:24 [68564] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24440:09/12/17 19:03:24 [68564] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24441:09/12/17 19:03:24 [68564] GAHP[68567] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
24442:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S'
24443:09/12/17 19:03:24 [68564] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24444:09/12/17 19:03:24 [68564] (536.0) gm state change: GM_INIT -> GM_START
24445:09/12/17 19:03:24 [68564] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24446:09/12/17 19:03:24 [68564] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24447:09/12/17 19:03:24 [68564] GAHP[68567] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
24448:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S'
24449:09/12/17 19:03:24 [68564] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24450:09/12/17 19:03:24 [68564] (535.0) gm state change: GM_INIT -> GM_START
24451:09/12/17 19:03:24 [68564] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24452:09/12/17 19:03:24 [68564] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24453:09/12/17 19:03:24 [68564] GAHP[68567] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
24454:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S'
24455:09/12/17 19:03:24 [68564] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24456:09/12/17 19:03:24 [68564] (534.0) gm state change: GM_INIT -> GM_START
24457:09/12/17 19:03:24 [68564] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24458:09/12/17 19:03:24 [68564] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24459:09/12/17 19:03:24 [68564] GAHP[68567] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
24460:09/12/17 19:03:24 [68564] GAHP[68567] -> 'S'
24461:09/12/17 19:03:24 [68564] (533.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24462:09/12/17 19:03:24 [68564] (533.0) gm state change: GM_INIT -> GM_START
24463:09/12/17 19:03:24 [68564] (533.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24464:09/12/17 19:03:24 [68564] (533.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24465:09/12/17 19:03:24 [68564] GAHP[68567] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#533.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/test.sh"\ ]'
24466:09/12/17 19:03:24 [68564] GAHP[68567] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
24467:09/12/17 19:03:24 [68564] GAHP[68567] -> EOF
24468:09/12/17 19:03:24 [68564] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
24469:09/12/17 19:08:21 Result of reading /etc/issue:  \S
24471:09/12/17 19:08:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
24473:09/12/17 19:08:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
24474:09/12/17 19:08:21 Enumerating interfaces: lo 127.0.0.1 up
24475:09/12/17 19:08:21 Enumerating interfaces: eth0 10.36.162.46 up
24476:09/12/17 19:08:21 Enumerating interfaces: ib0 128.55.162.46 up
24477:09/12/17 19:08:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
24478:09/12/17 19:08:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
24479:09/12/17 19:08:21 ******************************************************
24480:09/12/17 19:08:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
24481:09/12/17 19:08:21 ** /usr/sbin/condor_gridmanager
24482:09/12/17 19:08:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
24483:09/12/17 19:08:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
24484:09/12/17 19:08:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
24485:09/12/17 19:08:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
24486:09/12/17 19:08:21 ** PID = 68626
24487:09/12/17 19:08:21 ** Log last touched 9/12 19:03:24
24488:09/12/17 19:08:21 ******************************************************
24489:09/12/17 19:08:21 Using config source: /etc/condor-ce/condor_config
24490:09/12/17 19:08:21 Using local config sources: 
24491:09/12/17 19:08:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
24492:09/12/17 19:08:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
24493:09/12/17 19:08:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
24494:09/12/17 19:08:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
24495:09/12/17 19:08:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
24496:09/12/17 19:08:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
24497:09/12/17 19:08:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
24498:09/12/17 19:08:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
24499:09/12/17 19:08:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
24500:09/12/17 19:08:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
24501:09/12/17 19:08:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
24502:09/12/17 19:08:21    /etc/condor-ce/config.d/01-ce-auth.conf
24503:09/12/17 19:08:21    /etc/condor-ce/config.d/01-ce-router.conf
24504:09/12/17 19:08:21    /etc/condor-ce/config.d/01-common-auth.conf
24505:09/12/17 19:08:21    /etc/condor-ce/config.d/02-ce-slurm.conf
24506:09/12/17 19:08:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
24507:09/12/17 19:08:21    /etc/condor-ce/config.d/03-managed-fork.conf
24508:09/12/17 19:08:21    /etc/condor-ce/config.d/05-ce-health.conf
24509:09/12/17 19:08:21    /etc/condor-ce/config.d/05-ce-view.conf
24510:09/12/17 19:08:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
24511:09/12/17 19:08:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
24512:09/12/17 19:08:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
24513:09/12/17 19:08:21    /etc/condor-ce/config.d/50-osg-configure.conf
24514:09/12/17 19:08:21    /etc/condor-ce/config.d/99-local.conf
24515:09/12/17 19:08:21    /usr/share/condor-ce/condor_ce_router_defaults|
24516:09/12/17 19:08:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
24517:09/12/17 19:08:21 CLASSAD_CACHING is ENABLED
24518:09/12/17 19:08:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
24519:09/12/17 19:08:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_93
24520:09/12/17 19:08:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_93>
24521:09/12/17 19:08:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_93>
24522:09/12/17 19:08:21 Setting maximum accepts per cycle 8.
24523:09/12/17 19:08:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24524:09/12/17 19:08:21 [68626] Welcome to the all-singing, all dancing, "amazing" GridManager!
24525:09/12/17 19:08:21 [68626] DaemonCore: No more children processes to reap.
24526:09/12/17 19:08:21 [68626] DaemonCore: in SendAliveToParent()
24527:09/12/17 19:08:21 [68626] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24528:09/12/17 19:08:21 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24529:09/12/17 19:08:21 [68626] IPVERIFY: ip found is 1
24530:09/12/17 19:08:21 [68626] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24531:09/12/17 19:08:21 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24532:09/12/17 19:08:21 [68626] IPVERIFY: ip found is 1
24533:09/12/17 19:08:21 [68626] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24534:09/12/17 19:08:21 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24535:09/12/17 19:08:21 [68626] IPVERIFY: ip found is 1
24536:09/12/17 19:08:21 [68626] IPVERIFY: checking mc0151-ib against 128.55.162.46
24537:09/12/17 19:08:21 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24538:09/12/17 19:08:21 [68626] IPVERIFY: ip found is 1
24539:09/12/17 19:08:21 [68626] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
24540:09/12/17 19:08:21 [68626] DaemonCore: Leaving SendAliveToParent() - success
24541:09/12/17 19:08:21 [68626] Checking proxies
24542:09/12/17 19:08:24 [68626] Received ADD_JOBS signal
24543:09/12/17 19:08:24 [68626] in doContactSchedd()
24544:09/12/17 19:08:24 [68626] querying for new jobs
24545:09/12/17 19:08:24 [68626] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
24546:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 542.0
24547:09/12/17 19:08:24 [68626] (542.0) SetJobLeaseTimers()
24548:09/12/17 19:08:24 [68626] Found job 542.0 --- inserting
24549:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 541.0
24550:09/12/17 19:08:24 [68626] (541.0) SetJobLeaseTimers()
24551:09/12/17 19:08:24 [68626] Found job 541.0 --- inserting
24552:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 540.0
24553:09/12/17 19:08:24 [68626] (540.0) SetJobLeaseTimers()
24554:09/12/17 19:08:24 [68626] Found job 540.0 --- inserting
24555:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 539.0
24556:09/12/17 19:08:24 [68626] (539.0) SetJobLeaseTimers()
24557:09/12/17 19:08:24 [68626] Found job 539.0 --- inserting
24558:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 538.0
24559:09/12/17 19:08:24 [68626] (538.0) SetJobLeaseTimers()
24560:09/12/17 19:08:24 [68626] Found job 538.0 --- inserting
24561:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 537.0
24562:09/12/17 19:08:24 [68626] (537.0) SetJobLeaseTimers()
24563:09/12/17 19:08:24 [68626] Found job 537.0 --- inserting
24564:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 536.0
24565:09/12/17 19:08:24 [68626] (536.0) SetJobLeaseTimers()
24566:09/12/17 19:08:24 [68626] Found job 536.0 --- inserting
24567:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 535.0
24568:09/12/17 19:08:24 [68626] (535.0) SetJobLeaseTimers()
24569:09/12/17 19:08:24 [68626] Found job 535.0 --- inserting
24570:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 534.0
24571:09/12/17 19:08:24 [68626] (534.0) SetJobLeaseTimers()
24572:09/12/17 19:08:24 [68626] Found job 534.0 --- inserting
24573:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 533.0
24574:09/12/17 19:08:24 [68626] (533.0) SetJobLeaseTimers()
24575:09/12/17 19:08:24 [68626] Found job 533.0 --- inserting
24576:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 532.0
24577:09/12/17 19:08:24 [68626] (532.0) SetJobLeaseTimers()
24578:09/12/17 19:08:24 [68626] Found job 532.0 --- inserting
24579:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 531.0
24580:09/12/17 19:08:24 [68626] (531.0) SetJobLeaseTimers()
24581:09/12/17 19:08:24 [68626] Found job 531.0 --- inserting
24582:09/12/17 19:08:24 [68626] Using job type INFNBatch for job 530.0
24583:09/12/17 19:08:24 [68626] (530.0) SetJobLeaseTimers()
24584:09/12/17 19:08:24 [68626] Found job 530.0 --- inserting
24585:09/12/17 19:08:24 [68626] Fetched 13 new job ads from schedd
24586:09/12/17 19:08:24 [68626] querying for removed/held jobs
24587:09/12/17 19:08:24 [68626] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
24588:09/12/17 19:08:24 [68626] Fetched 0 job ads from schedd
24589:09/12/17 19:08:24 [68626] leaving doContactSchedd()
24590:09/12/17 19:08:24 [68626] gahp server not up yet, delaying ping
24591:09/12/17 19:08:24 [68626] *** UpdateLeases called
24592:09/12/17 19:08:24 [68626]     Leases not supported, cancelling timer
24593:09/12/17 19:08:24 [68626] BaseResource::UpdateResource: 
24613:09/12/17 19:08:24 [68626] Trying to update collector <128.55.162.46:9619>
24614:09/12/17 19:08:24 [68626] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24615:09/12/17 19:08:24 [68626] File descriptor limits: max 4096, safe 3277
24616:09/12/17 19:08:24 [68626] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24617:09/12/17 19:08:24 [68626] GAHP server pid = 68633
24618:09/12/17 19:08:25 [68626] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
24619:09/12/17 19:08:25 [68626] GAHP[68633] <- 'COMMANDS'
24620:09/12/17 19:08:25 [68626] GAHP[68633] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
24621:09/12/17 19:08:25 [68626] GAHP[68633] <- 'ASYNC_MODE_ON'
24622:09/12/17 19:08:25 [68626] GAHP[68633] -> 'S' 'Async mode on'
24623:09/12/17 19:08:25 [68626] (542.0) gm state change: GM_INIT -> GM_START
24624:09/12/17 19:08:25 [68626] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24625:09/12/17 19:08:25 [68626] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24626:09/12/17 19:08:25 [68626] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24627:09/12/17 19:08:25 [68626] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24628:09/12/17 19:08:25 [68626] (541.0) gm state change: GM_INIT -> GM_START
24629:09/12/17 19:08:25 [68626] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24630:09/12/17 19:08:25 [68626] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24631:09/12/17 19:08:25 [68626] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24632:09/12/17 19:08:25 [68626] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24633:09/12/17 19:08:25 [68626] (540.0) gm state change: GM_INIT -> GM_START
24634:09/12/17 19:08:25 [68626] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24635:09/12/17 19:08:25 [68626] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24636:09/12/17 19:08:25 [68626] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24637:09/12/17 19:08:25 [68626] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24638:09/12/17 19:08:25 [68626] (539.0) gm state change: GM_INIT -> GM_START
24639:09/12/17 19:08:25 [68626] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24640:09/12/17 19:08:25 [68626] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24641:09/12/17 19:08:25 [68626] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24642:09/12/17 19:08:25 [68626] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24643:09/12/17 19:08:25 [68626] (538.0) gm state change: GM_INIT -> GM_START
24644:09/12/17 19:08:25 [68626] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24645:09/12/17 19:08:25 [68626] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24646:09/12/17 19:08:25 [68626] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24647:09/12/17 19:08:25 [68626] This process has a valid certificate & key
24648:09/12/17 19:08:25 [68626] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24649:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24650:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24651:09/12/17 19:08:25 [68626] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24652:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24653:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24654:09/12/17 19:08:25 [68626] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24655:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24656:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24657:09/12/17 19:08:25 [68626] IPVERIFY: checking mc0151-ib against 128.55.162.46
24658:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24659:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24660:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24661:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24662:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24663:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24664:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24665:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24666:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
24667:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
24668:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
24669:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
24670:09/12/17 19:08:25 [68626] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
24671:09/12/17 19:08:25 [68626] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
24672:09/12/17 19:08:25 [68626] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24673:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24674:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24675:09/12/17 19:08:25 [68626] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24676:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24677:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24678:09/12/17 19:08:25 [68626] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24679:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24680:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24681:09/12/17 19:08:25 [68626] IPVERIFY: checking mc0151-ib against 128.55.162.46
24682:09/12/17 19:08:25 [68626] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24683:09/12/17 19:08:25 [68626] IPVERIFY: ip found is 1
24684:09/12/17 19:08:25 [68626] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24685:09/12/17 19:08:25 [68626] (537.0) gm state change: GM_INIT -> GM_START
24686:09/12/17 19:08:25 [68626] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24687:09/12/17 19:08:25 [68626] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24688:09/12/17 19:08:25 [68626] GAHP[68633] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
24689:09/12/17 19:08:25 [68626] GAHP[68633] -> 'S'
24690:09/12/17 19:08:25 [68626] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24691:09/12/17 19:08:25 [68626] (536.0) gm state change: GM_INIT -> GM_START
24692:09/12/17 19:08:25 [68626] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24693:09/12/17 19:08:25 [68626] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24694:09/12/17 19:08:25 [68626] GAHP[68633] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
24695:09/12/17 19:08:25 [68626] GAHP[68633] -> 'S'
24696:09/12/17 19:08:25 [68626] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24697:09/12/17 19:08:25 [68626] (535.0) gm state change: GM_INIT -> GM_START
24698:09/12/17 19:08:25 [68626] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24699:09/12/17 19:08:25 [68626] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24700:09/12/17 19:08:25 [68626] GAHP[68633] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
24701:09/12/17 19:08:25 [68626] GAHP[68633] -> 'S'
24702:09/12/17 19:08:25 [68626] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24703:09/12/17 19:08:25 [68626] (534.0) gm state change: GM_INIT -> GM_START
24704:09/12/17 19:08:25 [68626] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24705:09/12/17 19:08:25 [68626] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24706:09/12/17 19:08:25 [68626] GAHP[68633] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
24707:09/12/17 19:08:25 [68626] GAHP[68633] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
24708:09/12/17 19:08:25 [68626] GAHP[68633] -> EOF
24709:09/12/17 19:08:25 [68626] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
24710:09/12/17 19:13:21 Result of reading /etc/issue:  \S
24712:09/12/17 19:13:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
24714:09/12/17 19:13:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
24715:09/12/17 19:13:21 Enumerating interfaces: lo 127.0.0.1 up
24716:09/12/17 19:13:21 Enumerating interfaces: eth0 10.36.162.46 up
24717:09/12/17 19:13:21 Enumerating interfaces: ib0 128.55.162.46 up
24718:09/12/17 19:13:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
24719:09/12/17 19:13:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
24720:09/12/17 19:13:21 ******************************************************
24721:09/12/17 19:13:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
24722:09/12/17 19:13:21 ** /usr/sbin/condor_gridmanager
24723:09/12/17 19:13:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
24724:09/12/17 19:13:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
24725:09/12/17 19:13:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
24726:09/12/17 19:13:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
24727:09/12/17 19:13:21 ** PID = 68729
24728:09/12/17 19:13:21 ** Log last touched 9/12 19:08:25
24729:09/12/17 19:13:21 ******************************************************
24730:09/12/17 19:13:21 Using config source: /etc/condor-ce/condor_config
24731:09/12/17 19:13:21 Using local config sources: 
24732:09/12/17 19:13:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
24733:09/12/17 19:13:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
24734:09/12/17 19:13:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
24735:09/12/17 19:13:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
24736:09/12/17 19:13:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
24737:09/12/17 19:13:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
24738:09/12/17 19:13:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
24739:09/12/17 19:13:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
24740:09/12/17 19:13:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
24741:09/12/17 19:13:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
24742:09/12/17 19:13:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
24743:09/12/17 19:13:21    /etc/condor-ce/config.d/01-ce-auth.conf
24744:09/12/17 19:13:21    /etc/condor-ce/config.d/01-ce-router.conf
24745:09/12/17 19:13:21    /etc/condor-ce/config.d/01-common-auth.conf
24746:09/12/17 19:13:21    /etc/condor-ce/config.d/02-ce-slurm.conf
24747:09/12/17 19:13:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
24748:09/12/17 19:13:21    /etc/condor-ce/config.d/03-managed-fork.conf
24749:09/12/17 19:13:21    /etc/condor-ce/config.d/05-ce-health.conf
24750:09/12/17 19:13:21    /etc/condor-ce/config.d/05-ce-view.conf
24751:09/12/17 19:13:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
24752:09/12/17 19:13:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
24753:09/12/17 19:13:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
24754:09/12/17 19:13:21    /etc/condor-ce/config.d/50-osg-configure.conf
24755:09/12/17 19:13:21    /etc/condor-ce/config.d/99-local.conf
24756:09/12/17 19:13:21    /usr/share/condor-ce/condor_ce_router_defaults|
24757:09/12/17 19:13:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
24758:09/12/17 19:13:21 CLASSAD_CACHING is ENABLED
24759:09/12/17 19:13:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
24760:09/12/17 19:13:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_96
24761:09/12/17 19:13:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_96>
24762:09/12/17 19:13:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_96>
24763:09/12/17 19:13:21 Setting maximum accepts per cycle 8.
24764:09/12/17 19:13:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24765:09/12/17 19:13:21 [68729] Welcome to the all-singing, all dancing, "amazing" GridManager!
24766:09/12/17 19:13:21 [68729] DaemonCore: No more children processes to reap.
24767:09/12/17 19:13:21 [68729] DaemonCore: in SendAliveToParent()
24768:09/12/17 19:13:21 [68729] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24769:09/12/17 19:13:21 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24770:09/12/17 19:13:21 [68729] IPVERIFY: ip found is 1
24771:09/12/17 19:13:21 [68729] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24772:09/12/17 19:13:21 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24773:09/12/17 19:13:21 [68729] IPVERIFY: ip found is 1
24774:09/12/17 19:13:21 [68729] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24775:09/12/17 19:13:21 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24776:09/12/17 19:13:21 [68729] IPVERIFY: ip found is 1
24777:09/12/17 19:13:21 [68729] IPVERIFY: checking mc0151-ib against 128.55.162.46
24778:09/12/17 19:13:21 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24779:09/12/17 19:13:21 [68729] IPVERIFY: ip found is 1
24780:09/12/17 19:13:21 [68729] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
24781:09/12/17 19:13:21 [68729] DaemonCore: Leaving SendAliveToParent() - success
24782:09/12/17 19:13:21 [68729] Checking proxies
24783:09/12/17 19:13:24 [68729] Received ADD_JOBS signal
24784:09/12/17 19:13:24 [68729] in doContactSchedd()
24785:09/12/17 19:13:24 [68729] querying for new jobs
24786:09/12/17 19:13:24 [68729] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
24787:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 542.0
24788:09/12/17 19:13:24 [68729] (542.0) SetJobLeaseTimers()
24789:09/12/17 19:13:24 [68729] Found job 542.0 --- inserting
24790:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 541.0
24791:09/12/17 19:13:24 [68729] (541.0) SetJobLeaseTimers()
24792:09/12/17 19:13:24 [68729] Found job 541.0 --- inserting
24793:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 540.0
24794:09/12/17 19:13:24 [68729] (540.0) SetJobLeaseTimers()
24795:09/12/17 19:13:24 [68729] Found job 540.0 --- inserting
24796:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 539.0
24797:09/12/17 19:13:24 [68729] (539.0) SetJobLeaseTimers()
24798:09/12/17 19:13:24 [68729] Found job 539.0 --- inserting
24799:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 538.0
24800:09/12/17 19:13:24 [68729] (538.0) SetJobLeaseTimers()
24801:09/12/17 19:13:24 [68729] Found job 538.0 --- inserting
24802:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 537.0
24803:09/12/17 19:13:24 [68729] (537.0) SetJobLeaseTimers()
24804:09/12/17 19:13:24 [68729] Found job 537.0 --- inserting
24805:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 536.0
24806:09/12/17 19:13:24 [68729] (536.0) SetJobLeaseTimers()
24807:09/12/17 19:13:24 [68729] Found job 536.0 --- inserting
24808:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 535.0
24809:09/12/17 19:13:24 [68729] (535.0) SetJobLeaseTimers()
24810:09/12/17 19:13:24 [68729] Found job 535.0 --- inserting
24811:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 534.0
24812:09/12/17 19:13:24 [68729] (534.0) SetJobLeaseTimers()
24813:09/12/17 19:13:24 [68729] Found job 534.0 --- inserting
24814:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 533.0
24815:09/12/17 19:13:24 [68729] (533.0) SetJobLeaseTimers()
24816:09/12/17 19:13:24 [68729] Found job 533.0 --- inserting
24817:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 532.0
24818:09/12/17 19:13:24 [68729] (532.0) SetJobLeaseTimers()
24819:09/12/17 19:13:24 [68729] Found job 532.0 --- inserting
24820:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 531.0
24821:09/12/17 19:13:24 [68729] (531.0) SetJobLeaseTimers()
24822:09/12/17 19:13:24 [68729] Found job 531.0 --- inserting
24823:09/12/17 19:13:24 [68729] Using job type INFNBatch for job 530.0
24824:09/12/17 19:13:24 [68729] (530.0) SetJobLeaseTimers()
24825:09/12/17 19:13:24 [68729] Found job 530.0 --- inserting
24826:09/12/17 19:13:24 [68729] Fetched 13 new job ads from schedd
24827:09/12/17 19:13:24 [68729] querying for removed/held jobs
24828:09/12/17 19:13:24 [68729] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
24829:09/12/17 19:13:24 [68729] Fetched 0 job ads from schedd
24830:09/12/17 19:13:24 [68729] leaving doContactSchedd()
24831:09/12/17 19:13:24 [68729] gahp server not up yet, delaying ping
24832:09/12/17 19:13:24 [68729] *** UpdateLeases called
24833:09/12/17 19:13:24 [68729]     Leases not supported, cancelling timer
24834:09/12/17 19:13:24 [68729] BaseResource::UpdateResource: 
24854:09/12/17 19:13:24 [68729] Trying to update collector <128.55.162.46:9619>
24855:09/12/17 19:13:24 [68729] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
24856:09/12/17 19:13:24 [68729] File descriptor limits: max 4096, safe 3277
24857:09/12/17 19:13:24 [68729] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24858:09/12/17 19:13:24 [68729] GAHP server pid = 68732
24859:09/12/17 19:13:24 [68729] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
24860:09/12/17 19:13:24 [68729] GAHP[68732] <- 'COMMANDS'
24861:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
24862:09/12/17 19:13:24 [68729] GAHP[68732] <- 'ASYNC_MODE_ON'
24863:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S' 'Async mode on'
24864:09/12/17 19:13:24 [68729] (542.0) gm state change: GM_INIT -> GM_START
24865:09/12/17 19:13:24 [68729] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24866:09/12/17 19:13:24 [68729] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24867:09/12/17 19:13:24 [68729] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24868:09/12/17 19:13:24 [68729] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24869:09/12/17 19:13:24 [68729] (541.0) gm state change: GM_INIT -> GM_START
24870:09/12/17 19:13:24 [68729] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24871:09/12/17 19:13:24 [68729] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24872:09/12/17 19:13:24 [68729] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24873:09/12/17 19:13:24 [68729] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24874:09/12/17 19:13:24 [68729] (540.0) gm state change: GM_INIT -> GM_START
24875:09/12/17 19:13:24 [68729] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24876:09/12/17 19:13:24 [68729] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24877:09/12/17 19:13:24 [68729] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24878:09/12/17 19:13:24 [68729] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24879:09/12/17 19:13:24 [68729] (539.0) gm state change: GM_INIT -> GM_START
24880:09/12/17 19:13:24 [68729] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24881:09/12/17 19:13:24 [68729] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24882:09/12/17 19:13:24 [68729] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24883:09/12/17 19:13:24 [68729] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
24884:09/12/17 19:13:24 [68729] (538.0) gm state change: GM_INIT -> GM_START
24885:09/12/17 19:13:24 [68729] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
24886:09/12/17 19:13:24 [68729] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
24887:09/12/17 19:13:24 [68729] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
24888:09/12/17 19:13:24 [68729] This process has a valid certificate & key
24889:09/12/17 19:13:24 [68729] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24890:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24891:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24892:09/12/17 19:13:24 [68729] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24893:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24894:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24895:09/12/17 19:13:24 [68729] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24896:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24897:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24898:09/12/17 19:13:24 [68729] IPVERIFY: checking mc0151-ib against 128.55.162.46
24899:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24900:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24901:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24902:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24903:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24904:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24905:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24906:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
24907:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
24908:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
24909:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
24910:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
24911:09/12/17 19:13:24 [68729] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
24912:09/12/17 19:13:24 [68729] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
24913:09/12/17 19:13:24 [68729] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
24914:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24915:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24916:09/12/17 19:13:24 [68729] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
24917:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24918:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24919:09/12/17 19:13:24 [68729] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
24920:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24921:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24922:09/12/17 19:13:24 [68729] IPVERIFY: checking mc0151-ib against 128.55.162.46
24923:09/12/17 19:13:24 [68729] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
24924:09/12/17 19:13:24 [68729] IPVERIFY: ip found is 1
24925:09/12/17 19:13:24 [68729] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24926:09/12/17 19:13:24 [68729] (537.0) gm state change: GM_INIT -> GM_START
24927:09/12/17 19:13:24 [68729] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24928:09/12/17 19:13:24 [68729] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24929:09/12/17 19:13:24 [68729] GAHP[68732] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
24930:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S'
24931:09/12/17 19:13:24 [68729] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24932:09/12/17 19:13:24 [68729] (536.0) gm state change: GM_INIT -> GM_START
24933:09/12/17 19:13:24 [68729] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24934:09/12/17 19:13:24 [68729] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24935:09/12/17 19:13:24 [68729] GAHP[68732] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
24936:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S'
24937:09/12/17 19:13:24 [68729] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24938:09/12/17 19:13:24 [68729] (535.0) gm state change: GM_INIT -> GM_START
24939:09/12/17 19:13:24 [68729] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24940:09/12/17 19:13:24 [68729] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24941:09/12/17 19:13:24 [68729] GAHP[68732] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
24942:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S'
24943:09/12/17 19:13:24 [68729] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24944:09/12/17 19:13:24 [68729] (534.0) gm state change: GM_INIT -> GM_START
24945:09/12/17 19:13:24 [68729] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24946:09/12/17 19:13:24 [68729] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24947:09/12/17 19:13:24 [68729] GAHP[68732] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
24948:09/12/17 19:13:24 [68729] GAHP[68732] -> 'S'
24949:09/12/17 19:13:24 [68729] (533.0) doEvaluateState called: gmState GM_INIT, remoteState -1
24950:09/12/17 19:13:24 [68729] (533.0) gm state change: GM_INIT -> GM_START
24951:09/12/17 19:13:24 [68729] (533.0) gm state change: GM_START -> GM_TRANSFER_INPUT
24952:09/12/17 19:13:24 [68729] (533.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
24953:09/12/17 19:13:24 [68729] GAHP[68732] <- 'BLAH_JOB_SUBMIT 6 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#533.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/521/0/cluster521.proc0.subproc0/test.sh"\ ]'
24954:09/12/17 19:13:24 [68729] GAHP[68732] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
24955:09/12/17 19:13:24 [68729] GAHP[68732] -> EOF
24956:09/12/17 19:13:24 [68729] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
24957:09/12/17 19:18:21 Result of reading /etc/issue:  \S
24959:09/12/17 19:18:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
24961:09/12/17 19:18:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
24962:09/12/17 19:18:21 Enumerating interfaces: lo 127.0.0.1 up
24963:09/12/17 19:18:21 Enumerating interfaces: eth0 10.36.162.46 up
24964:09/12/17 19:18:21 Enumerating interfaces: ib0 128.55.162.46 up
24965:09/12/17 19:18:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
24966:09/12/17 19:18:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
24967:09/12/17 19:18:21 ******************************************************
24968:09/12/17 19:18:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
24969:09/12/17 19:18:21 ** /usr/sbin/condor_gridmanager
24970:09/12/17 19:18:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
24971:09/12/17 19:18:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
24972:09/12/17 19:18:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
24973:09/12/17 19:18:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
24974:09/12/17 19:18:21 ** PID = 68776
24975:09/12/17 19:18:21 ** Log last touched 9/12 19:13:24
24976:09/12/17 19:18:21 ******************************************************
24977:09/12/17 19:18:21 Using config source: /etc/condor-ce/condor_config
24978:09/12/17 19:18:21 Using local config sources: 
24979:09/12/17 19:18:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
24980:09/12/17 19:18:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
24981:09/12/17 19:18:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
24982:09/12/17 19:18:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
24983:09/12/17 19:18:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
24984:09/12/17 19:18:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
24985:09/12/17 19:18:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
24986:09/12/17 19:18:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
24987:09/12/17 19:18:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
24988:09/12/17 19:18:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
24989:09/12/17 19:18:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
24990:09/12/17 19:18:21    /etc/condor-ce/config.d/01-ce-auth.conf
24991:09/12/17 19:18:21    /etc/condor-ce/config.d/01-ce-router.conf
24992:09/12/17 19:18:21    /etc/condor-ce/config.d/01-common-auth.conf
24993:09/12/17 19:18:21    /etc/condor-ce/config.d/02-ce-slurm.conf
24994:09/12/17 19:18:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
24995:09/12/17 19:18:21    /etc/condor-ce/config.d/03-managed-fork.conf
24996:09/12/17 19:18:21    /etc/condor-ce/config.d/05-ce-health.conf
24997:09/12/17 19:18:21    /etc/condor-ce/config.d/05-ce-view.conf
24998:09/12/17 19:18:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
24999:09/12/17 19:18:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
25000:09/12/17 19:18:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
25001:09/12/17 19:18:21    /etc/condor-ce/config.d/50-osg-configure.conf
25002:09/12/17 19:18:21    /etc/condor-ce/config.d/99-local.conf
25003:09/12/17 19:18:21    /usr/share/condor-ce/condor_ce_router_defaults|
25004:09/12/17 19:18:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
25005:09/12/17 19:18:21 CLASSAD_CACHING is ENABLED
25006:09/12/17 19:18:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
25007:09/12/17 19:18:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_99
25008:09/12/17 19:18:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_99>
25009:09/12/17 19:18:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_99>
25010:09/12/17 19:18:21 Setting maximum accepts per cycle 8.
25011:09/12/17 19:18:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25012:09/12/17 19:18:21 [68776] Welcome to the all-singing, all dancing, "amazing" GridManager!
25013:09/12/17 19:18:21 [68776] DaemonCore: No more children processes to reap.
25014:09/12/17 19:18:21 [68776] DaemonCore: in SendAliveToParent()
25015:09/12/17 19:18:21 [68776] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25016:09/12/17 19:18:21 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25017:09/12/17 19:18:21 [68776] IPVERIFY: ip found is 1
25018:09/12/17 19:18:21 [68776] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25019:09/12/17 19:18:21 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25020:09/12/17 19:18:21 [68776] IPVERIFY: ip found is 1
25021:09/12/17 19:18:21 [68776] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25022:09/12/17 19:18:21 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25023:09/12/17 19:18:21 [68776] IPVERIFY: ip found is 1
25024:09/12/17 19:18:21 [68776] IPVERIFY: checking mc0151-ib against 128.55.162.46
25025:09/12/17 19:18:21 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25026:09/12/17 19:18:21 [68776] IPVERIFY: ip found is 1
25027:09/12/17 19:18:21 [68776] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
25028:09/12/17 19:18:21 [68776] DaemonCore: Leaving SendAliveToParent() - success
25029:09/12/17 19:18:21 [68776] Checking proxies
25030:09/12/17 19:18:24 [68776] Received ADD_JOBS signal
25031:09/12/17 19:18:24 [68776] in doContactSchedd()
25032:09/12/17 19:18:24 [68776] querying for new jobs
25033:09/12/17 19:18:24 [68776] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
25034:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 542.0
25035:09/12/17 19:18:24 [68776] (542.0) SetJobLeaseTimers()
25036:09/12/17 19:18:24 [68776] Found job 542.0 --- inserting
25037:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 541.0
25038:09/12/17 19:18:24 [68776] (541.0) SetJobLeaseTimers()
25039:09/12/17 19:18:24 [68776] Found job 541.0 --- inserting
25040:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 540.0
25041:09/12/17 19:18:24 [68776] (540.0) SetJobLeaseTimers()
25042:09/12/17 19:18:24 [68776] Found job 540.0 --- inserting
25043:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 539.0
25044:09/12/17 19:18:24 [68776] (539.0) SetJobLeaseTimers()
25045:09/12/17 19:18:24 [68776] Found job 539.0 --- inserting
25046:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 538.0
25047:09/12/17 19:18:24 [68776] (538.0) SetJobLeaseTimers()
25048:09/12/17 19:18:24 [68776] Found job 538.0 --- inserting
25049:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 537.0
25050:09/12/17 19:18:24 [68776] (537.0) SetJobLeaseTimers()
25051:09/12/17 19:18:24 [68776] Found job 537.0 --- inserting
25052:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 536.0
25053:09/12/17 19:18:24 [68776] (536.0) SetJobLeaseTimers()
25054:09/12/17 19:18:24 [68776] Found job 536.0 --- inserting
25055:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 535.0
25056:09/12/17 19:18:24 [68776] (535.0) SetJobLeaseTimers()
25057:09/12/17 19:18:24 [68776] Found job 535.0 --- inserting
25058:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 534.0
25059:09/12/17 19:18:24 [68776] (534.0) SetJobLeaseTimers()
25060:09/12/17 19:18:24 [68776] Found job 534.0 --- inserting
25061:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 533.0
25062:09/12/17 19:18:24 [68776] (533.0) SetJobLeaseTimers()
25063:09/12/17 19:18:24 [68776] Found job 533.0 --- inserting
25064:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 532.0
25065:09/12/17 19:18:24 [68776] (532.0) SetJobLeaseTimers()
25066:09/12/17 19:18:24 [68776] Found job 532.0 --- inserting
25067:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 531.0
25068:09/12/17 19:18:24 [68776] (531.0) SetJobLeaseTimers()
25069:09/12/17 19:18:24 [68776] Found job 531.0 --- inserting
25070:09/12/17 19:18:24 [68776] Using job type INFNBatch for job 530.0
25071:09/12/17 19:18:24 [68776] (530.0) SetJobLeaseTimers()
25072:09/12/17 19:18:24 [68776] Found job 530.0 --- inserting
25073:09/12/17 19:18:24 [68776] Fetched 13 new job ads from schedd
25074:09/12/17 19:18:24 [68776] querying for removed/held jobs
25075:09/12/17 19:18:24 [68776] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
25076:09/12/17 19:18:24 [68776] Fetched 0 job ads from schedd
25077:09/12/17 19:18:24 [68776] leaving doContactSchedd()
25078:09/12/17 19:18:24 [68776] gahp server not up yet, delaying ping
25079:09/12/17 19:18:24 [68776] *** UpdateLeases called
25080:09/12/17 19:18:24 [68776]     Leases not supported, cancelling timer
25081:09/12/17 19:18:24 [68776] BaseResource::UpdateResource: 
25101:09/12/17 19:18:24 [68776] Trying to update collector <128.55.162.46:9619>
25102:09/12/17 19:18:24 [68776] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25103:09/12/17 19:18:24 [68776] File descriptor limits: max 4096, safe 3277
25104:09/12/17 19:18:24 [68776] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25105:09/12/17 19:18:24 [68776] GAHP server pid = 68779
25106:09/12/17 19:18:24 [68776] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
25107:09/12/17 19:18:24 [68776] GAHP[68779] <- 'COMMANDS'
25108:09/12/17 19:18:24 [68776] GAHP[68779] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
25109:09/12/17 19:18:24 [68776] GAHP[68779] <- 'ASYNC_MODE_ON'
25110:09/12/17 19:18:24 [68776] GAHP[68779] -> 'S' 'Async mode on'
25111:09/12/17 19:18:24 [68776] (542.0) gm state change: GM_INIT -> GM_START
25112:09/12/17 19:18:24 [68776] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25113:09/12/17 19:18:24 [68776] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25114:09/12/17 19:18:24 [68776] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25115:09/12/17 19:18:24 [68776] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25116:09/12/17 19:18:24 [68776] (541.0) gm state change: GM_INIT -> GM_START
25117:09/12/17 19:18:24 [68776] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25118:09/12/17 19:18:24 [68776] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25119:09/12/17 19:18:24 [68776] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25120:09/12/17 19:18:24 [68776] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25121:09/12/17 19:18:24 [68776] (540.0) gm state change: GM_INIT -> GM_START
25122:09/12/17 19:18:24 [68776] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25123:09/12/17 19:18:24 [68776] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25124:09/12/17 19:18:24 [68776] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25125:09/12/17 19:18:24 [68776] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25126:09/12/17 19:18:24 [68776] (539.0) gm state change: GM_INIT -> GM_START
25127:09/12/17 19:18:24 [68776] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25128:09/12/17 19:18:24 [68776] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25129:09/12/17 19:18:24 [68776] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25130:09/12/17 19:18:24 [68776] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25131:09/12/17 19:18:24 [68776] (538.0) gm state change: GM_INIT -> GM_START
25132:09/12/17 19:18:24 [68776] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25133:09/12/17 19:18:24 [68776] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25134:09/12/17 19:18:24 [68776] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25135:09/12/17 19:18:24 [68776] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25136:09/12/17 19:18:24 [68776] (537.0) gm state change: GM_INIT -> GM_START
25137:09/12/17 19:18:24 [68776] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25138:09/12/17 19:18:24 [68776] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25139:09/12/17 19:18:24 [68776] GAHP[68779] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
25140:09/12/17 19:18:24 [68776] GAHP[68779] -> 'S'
25141:09/12/17 19:18:24 [68776] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25142:09/12/17 19:18:24 [68776] (536.0) gm state change: GM_INIT -> GM_START
25143:09/12/17 19:18:24 [68776] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25144:09/12/17 19:18:24 [68776] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25145:09/12/17 19:18:24 [68776] GAHP[68779] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
25146:09/12/17 19:18:24 [68776] GAHP[68779] -> 'S'
25147:09/12/17 19:18:24 [68776] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25148:09/12/17 19:18:24 [68776] (535.0) gm state change: GM_INIT -> GM_START
25149:09/12/17 19:18:24 [68776] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25150:09/12/17 19:18:24 [68776] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25151:09/12/17 19:18:24 [68776] GAHP[68779] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
25152:09/12/17 19:18:24 [68776] GAHP[68779] -> 'S'
25153:09/12/17 19:18:24 [68776] This process has a valid certificate & key
25154:09/12/17 19:18:24 [68776] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25155:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25156:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25157:09/12/17 19:18:24 [68776] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25158:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25159:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25160:09/12/17 19:18:24 [68776] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25161:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25162:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25163:09/12/17 19:18:24 [68776] IPVERIFY: checking mc0151-ib against 128.55.162.46
25164:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25165:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25166:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25167:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25168:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25169:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25170:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25171:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25172:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
25173:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
25174:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
25175:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
25176:09/12/17 19:18:24 [68776] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
25177:09/12/17 19:18:24 [68776] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
25178:09/12/17 19:18:24 [68776] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25179:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25180:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25181:09/12/17 19:18:24 [68776] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25182:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25183:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25184:09/12/17 19:18:24 [68776] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25185:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25186:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25187:09/12/17 19:18:24 [68776] IPVERIFY: checking mc0151-ib against 128.55.162.46
25188:09/12/17 19:18:24 [68776] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25189:09/12/17 19:18:24 [68776] IPVERIFY: ip found is 1
25190:09/12/17 19:18:24 [68776] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25191:09/12/17 19:18:24 [68776] (534.0) gm state change: GM_INIT -> GM_START
25192:09/12/17 19:18:24 [68776] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25193:09/12/17 19:18:24 [68776] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25194:09/12/17 19:18:24 [68776] GAHP[68779] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
25195:09/12/17 19:18:24 [68776] GAHP[68779] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
25196:09/12/17 19:18:24 [68776] GAHP[68779] -> EOF
25197:09/12/17 19:18:24 [68776] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
25198:09/12/17 19:23:21 Result of reading /etc/issue:  \S
25200:09/12/17 19:23:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
25202:09/12/17 19:23:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
25203:09/12/17 19:23:21 Enumerating interfaces: lo 127.0.0.1 up
25204:09/12/17 19:23:21 Enumerating interfaces: eth0 10.36.162.46 up
25205:09/12/17 19:23:21 Enumerating interfaces: ib0 128.55.162.46 up
25206:09/12/17 19:23:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
25207:09/12/17 19:23:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
25208:09/12/17 19:23:21 ******************************************************
25209:09/12/17 19:23:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
25210:09/12/17 19:23:21 ** /usr/sbin/condor_gridmanager
25211:09/12/17 19:23:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
25212:09/12/17 19:23:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
25213:09/12/17 19:23:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
25214:09/12/17 19:23:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
25215:09/12/17 19:23:21 ** PID = 68833
25216:09/12/17 19:23:21 ** Log last touched 9/12 19:18:24
25217:09/12/17 19:23:21 ******************************************************
25218:09/12/17 19:23:21 Using config source: /etc/condor-ce/condor_config
25219:09/12/17 19:23:21 Using local config sources: 
25220:09/12/17 19:23:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
25221:09/12/17 19:23:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
25222:09/12/17 19:23:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
25223:09/12/17 19:23:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
25224:09/12/17 19:23:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
25225:09/12/17 19:23:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
25226:09/12/17 19:23:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
25227:09/12/17 19:23:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
25228:09/12/17 19:23:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
25229:09/12/17 19:23:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
25230:09/12/17 19:23:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
25231:09/12/17 19:23:21    /etc/condor-ce/config.d/01-ce-auth.conf
25232:09/12/17 19:23:21    /etc/condor-ce/config.d/01-ce-router.conf
25233:09/12/17 19:23:21    /etc/condor-ce/config.d/01-common-auth.conf
25234:09/12/17 19:23:21    /etc/condor-ce/config.d/02-ce-slurm.conf
25235:09/12/17 19:23:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
25236:09/12/17 19:23:21    /etc/condor-ce/config.d/03-managed-fork.conf
25237:09/12/17 19:23:21    /etc/condor-ce/config.d/05-ce-health.conf
25238:09/12/17 19:23:21    /etc/condor-ce/config.d/05-ce-view.conf
25239:09/12/17 19:23:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
25240:09/12/17 19:23:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
25241:09/12/17 19:23:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
25242:09/12/17 19:23:21    /etc/condor-ce/config.d/50-osg-configure.conf
25243:09/12/17 19:23:21    /etc/condor-ce/config.d/99-local.conf
25244:09/12/17 19:23:21    /usr/share/condor-ce/condor_ce_router_defaults|
25245:09/12/17 19:23:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
25246:09/12/17 19:23:21 CLASSAD_CACHING is ENABLED
25247:09/12/17 19:23:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
25248:09/12/17 19:23:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_101
25249:09/12/17 19:23:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_101>
25250:09/12/17 19:23:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_101>
25251:09/12/17 19:23:21 Setting maximum accepts per cycle 8.
25252:09/12/17 19:23:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25253:09/12/17 19:23:21 [68833] Welcome to the all-singing, all dancing, "amazing" GridManager!
25254:09/12/17 19:23:21 [68833] DaemonCore: No more children processes to reap.
25255:09/12/17 19:23:21 [68833] DaemonCore: in SendAliveToParent()
25256:09/12/17 19:23:21 [68833] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25257:09/12/17 19:23:21 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25258:09/12/17 19:23:21 [68833] IPVERIFY: ip found is 1
25259:09/12/17 19:23:21 [68833] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25260:09/12/17 19:23:21 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25261:09/12/17 19:23:21 [68833] IPVERIFY: ip found is 1
25262:09/12/17 19:23:21 [68833] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25263:09/12/17 19:23:21 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25264:09/12/17 19:23:21 [68833] IPVERIFY: ip found is 1
25265:09/12/17 19:23:21 [68833] IPVERIFY: checking mc0151-ib against 128.55.162.46
25266:09/12/17 19:23:21 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25267:09/12/17 19:23:21 [68833] IPVERIFY: ip found is 1
25268:09/12/17 19:23:21 [68833] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
25269:09/12/17 19:23:21 [68833] DaemonCore: Leaving SendAliveToParent() - success
25270:09/12/17 19:23:21 [68833] Checking proxies
25271:09/12/17 19:23:24 [68833] Received ADD_JOBS signal
25272:09/12/17 19:23:24 [68833] in doContactSchedd()
25273:09/12/17 19:23:24 [68833] querying for new jobs
25274:09/12/17 19:23:24 [68833] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
25275:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 542.0
25276:09/12/17 19:23:24 [68833] (542.0) SetJobLeaseTimers()
25277:09/12/17 19:23:24 [68833] Found job 542.0 --- inserting
25278:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 541.0
25279:09/12/17 19:23:24 [68833] (541.0) SetJobLeaseTimers()
25280:09/12/17 19:23:24 [68833] Found job 541.0 --- inserting
25281:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 540.0
25282:09/12/17 19:23:24 [68833] (540.0) SetJobLeaseTimers()
25283:09/12/17 19:23:24 [68833] Found job 540.0 --- inserting
25284:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 539.0
25285:09/12/17 19:23:24 [68833] (539.0) SetJobLeaseTimers()
25286:09/12/17 19:23:24 [68833] Found job 539.0 --- inserting
25287:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 538.0
25288:09/12/17 19:23:24 [68833] (538.0) SetJobLeaseTimers()
25289:09/12/17 19:23:24 [68833] Found job 538.0 --- inserting
25290:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 537.0
25291:09/12/17 19:23:24 [68833] (537.0) SetJobLeaseTimers()
25292:09/12/17 19:23:24 [68833] Found job 537.0 --- inserting
25293:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 536.0
25294:09/12/17 19:23:24 [68833] (536.0) SetJobLeaseTimers()
25295:09/12/17 19:23:24 [68833] Found job 536.0 --- inserting
25296:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 535.0
25297:09/12/17 19:23:24 [68833] (535.0) SetJobLeaseTimers()
25298:09/12/17 19:23:24 [68833] Found job 535.0 --- inserting
25299:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 534.0
25300:09/12/17 19:23:24 [68833] (534.0) SetJobLeaseTimers()
25301:09/12/17 19:23:24 [68833] Found job 534.0 --- inserting
25302:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 533.0
25303:09/12/17 19:23:24 [68833] (533.0) SetJobLeaseTimers()
25304:09/12/17 19:23:24 [68833] Found job 533.0 --- inserting
25305:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 532.0
25306:09/12/17 19:23:24 [68833] (532.0) SetJobLeaseTimers()
25307:09/12/17 19:23:24 [68833] Found job 532.0 --- inserting
25308:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 531.0
25309:09/12/17 19:23:24 [68833] (531.0) SetJobLeaseTimers()
25310:09/12/17 19:23:24 [68833] Found job 531.0 --- inserting
25311:09/12/17 19:23:24 [68833] Using job type INFNBatch for job 530.0
25312:09/12/17 19:23:24 [68833] (530.0) SetJobLeaseTimers()
25313:09/12/17 19:23:24 [68833] Found job 530.0 --- inserting
25314:09/12/17 19:23:24 [68833] Fetched 13 new job ads from schedd
25315:09/12/17 19:23:24 [68833] querying for removed/held jobs
25316:09/12/17 19:23:24 [68833] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
25317:09/12/17 19:23:24 [68833] Fetched 0 job ads from schedd
25318:09/12/17 19:23:24 [68833] leaving doContactSchedd()
25319:09/12/17 19:23:24 [68833] gahp server not up yet, delaying ping
25320:09/12/17 19:23:24 [68833] *** UpdateLeases called
25321:09/12/17 19:23:24 [68833]     Leases not supported, cancelling timer
25322:09/12/17 19:23:24 [68833] BaseResource::UpdateResource: 
25342:09/12/17 19:23:24 [68833] Trying to update collector <128.55.162.46:9619>
25343:09/12/17 19:23:24 [68833] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25344:09/12/17 19:23:24 [68833] File descriptor limits: max 4096, safe 3277
25345:09/12/17 19:23:24 [68833] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25346:09/12/17 19:23:24 [68833] GAHP server pid = 68836
25347:09/12/17 19:23:24 [68833] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
25348:09/12/17 19:23:24 [68833] GAHP[68836] <- 'COMMANDS'
25349:09/12/17 19:23:24 [68833] GAHP[68836] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
25350:09/12/17 19:23:24 [68833] GAHP[68836] <- 'ASYNC_MODE_ON'
25351:09/12/17 19:23:24 [68833] GAHP[68836] -> 'S' 'Async mode on'
25352:09/12/17 19:23:24 [68833] (542.0) gm state change: GM_INIT -> GM_START
25353:09/12/17 19:23:24 [68833] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25354:09/12/17 19:23:24 [68833] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25355:09/12/17 19:23:24 [68833] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25356:09/12/17 19:23:24 [68833] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25357:09/12/17 19:23:24 [68833] (541.0) gm state change: GM_INIT -> GM_START
25358:09/12/17 19:23:24 [68833] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25359:09/12/17 19:23:24 [68833] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25360:09/12/17 19:23:24 [68833] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25361:09/12/17 19:23:24 [68833] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25362:09/12/17 19:23:24 [68833] (540.0) gm state change: GM_INIT -> GM_START
25363:09/12/17 19:23:24 [68833] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25364:09/12/17 19:23:24 [68833] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25365:09/12/17 19:23:24 [68833] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25366:09/12/17 19:23:24 [68833] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25367:09/12/17 19:23:24 [68833] (539.0) gm state change: GM_INIT -> GM_START
25368:09/12/17 19:23:24 [68833] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25369:09/12/17 19:23:24 [68833] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25370:09/12/17 19:23:24 [68833] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25371:09/12/17 19:23:24 [68833] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25372:09/12/17 19:23:24 [68833] (538.0) gm state change: GM_INIT -> GM_START
25373:09/12/17 19:23:24 [68833] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25374:09/12/17 19:23:24 [68833] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25375:09/12/17 19:23:24 [68833] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25376:09/12/17 19:23:24 [68833] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25377:09/12/17 19:23:24 [68833] (537.0) gm state change: GM_INIT -> GM_START
25378:09/12/17 19:23:24 [68833] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25379:09/12/17 19:23:24 [68833] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25380:09/12/17 19:23:24 [68833] GAHP[68836] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
25381:09/12/17 19:23:24 [68833] GAHP[68836] -> 'S'
25382:09/12/17 19:23:24 [68833] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25383:09/12/17 19:23:24 [68833] (536.0) gm state change: GM_INIT -> GM_START
25384:09/12/17 19:23:24 [68833] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25385:09/12/17 19:23:24 [68833] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25386:09/12/17 19:23:24 [68833] GAHP[68836] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
25387:09/12/17 19:23:24 [68833] GAHP[68836] -> 'S'
25388:09/12/17 19:23:24 [68833] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25389:09/12/17 19:23:24 [68833] (535.0) gm state change: GM_INIT -> GM_START
25390:09/12/17 19:23:24 [68833] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25391:09/12/17 19:23:24 [68833] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25392:09/12/17 19:23:24 [68833] GAHP[68836] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
25393:09/12/17 19:23:24 [68833] GAHP[68836] -> 'S'
25394:09/12/17 19:23:24 [68833] This process has a valid certificate & key
25395:09/12/17 19:23:24 [68833] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25396:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25397:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25398:09/12/17 19:23:24 [68833] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25399:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25400:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25401:09/12/17 19:23:24 [68833] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25402:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25403:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25404:09/12/17 19:23:24 [68833] IPVERIFY: checking mc0151-ib against 128.55.162.46
25405:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25406:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25407:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25408:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25409:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25410:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25411:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25412:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25413:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
25414:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
25415:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
25416:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
25417:09/12/17 19:23:24 [68833] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
25418:09/12/17 19:23:24 [68833] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
25419:09/12/17 19:23:24 [68833] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25420:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25421:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25422:09/12/17 19:23:24 [68833] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25423:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25424:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25425:09/12/17 19:23:24 [68833] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25426:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25427:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25428:09/12/17 19:23:24 [68833] IPVERIFY: checking mc0151-ib against 128.55.162.46
25429:09/12/17 19:23:24 [68833] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25430:09/12/17 19:23:24 [68833] IPVERIFY: ip found is 1
25431:09/12/17 19:23:24 [68833] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25432:09/12/17 19:23:24 [68833] (534.0) gm state change: GM_INIT -> GM_START
25433:09/12/17 19:23:24 [68833] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25434:09/12/17 19:23:24 [68833] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25435:09/12/17 19:23:24 [68833] GAHP[68836] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
25436:09/12/17 19:23:24 [68833] GAHP[68836] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
25437:09/12/17 19:23:24 [68833] GAHP[68836] -> EOF
25438:09/12/17 19:23:24 [68833] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
25439:09/12/17 19:28:21 Result of reading /etc/issue:  \S
25441:09/12/17 19:28:21 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
25443:09/12/17 19:28:21 Using IDs: 32 processors, 16 CPUs, 16 HTs
25444:09/12/17 19:28:21 Enumerating interfaces: lo 127.0.0.1 up
25445:09/12/17 19:28:21 Enumerating interfaces: eth0 10.36.162.46 up
25446:09/12/17 19:28:21 Enumerating interfaces: ib0 128.55.162.46 up
25447:09/12/17 19:28:21 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
25448:09/12/17 19:28:21 Initializing Directory: curr_dir = /etc/condor-ce/config.d
25449:09/12/17 19:28:21 ******************************************************
25450:09/12/17 19:28:21 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
25451:09/12/17 19:28:21 ** /usr/sbin/condor_gridmanager
25452:09/12/17 19:28:21 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
25453:09/12/17 19:28:21 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
25454:09/12/17 19:28:21 ** $CondorVersion: 8.4.12 Aug 07 2017 $
25455:09/12/17 19:28:21 ** $CondorPlatform: X86_64-CentOS_7.3 $
25456:09/12/17 19:28:21 ** PID = 68885
25457:09/12/17 19:28:21 ** Log last touched 9/12 19:23:24
25458:09/12/17 19:28:21 ******************************************************
25459:09/12/17 19:28:21 Using config source: /etc/condor-ce/condor_config
25460:09/12/17 19:28:21 Using local config sources: 
25461:09/12/17 19:28:21    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
25462:09/12/17 19:28:21    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
25463:09/12/17 19:28:21    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
25464:09/12/17 19:28:21    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
25465:09/12/17 19:28:21    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
25466:09/12/17 19:28:21    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
25467:09/12/17 19:28:21    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
25468:09/12/17 19:28:21    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
25469:09/12/17 19:28:21    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
25470:09/12/17 19:28:21    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
25471:09/12/17 19:28:21    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
25472:09/12/17 19:28:21    /etc/condor-ce/config.d/01-ce-auth.conf
25473:09/12/17 19:28:21    /etc/condor-ce/config.d/01-ce-router.conf
25474:09/12/17 19:28:21    /etc/condor-ce/config.d/01-common-auth.conf
25475:09/12/17 19:28:21    /etc/condor-ce/config.d/02-ce-slurm.conf
25476:09/12/17 19:28:21    /etc/condor-ce/config.d/03-ce-shared-port.conf
25477:09/12/17 19:28:21    /etc/condor-ce/config.d/03-managed-fork.conf
25478:09/12/17 19:28:21    /etc/condor-ce/config.d/05-ce-health.conf
25479:09/12/17 19:28:21    /etc/condor-ce/config.d/05-ce-view.conf
25480:09/12/17 19:28:21    /etc/condor-ce/config.d/10-ce-collector-generated.conf
25481:09/12/17 19:28:21    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
25482:09/12/17 19:28:21    /etc/condor-ce/config.d/50-osg-configure-present.conf
25483:09/12/17 19:28:21    /etc/condor-ce/config.d/50-osg-configure.conf
25484:09/12/17 19:28:21    /etc/condor-ce/config.d/99-local.conf
25485:09/12/17 19:28:21    /usr/share/condor-ce/condor_ce_router_defaults|
25486:09/12/17 19:28:21 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
25487:09/12/17 19:28:21 CLASSAD_CACHING is ENABLED
25488:09/12/17 19:28:21 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
25489:09/12/17 19:28:21 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_104
25490:09/12/17 19:28:21 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_104>
25491:09/12/17 19:28:21 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_104>
25492:09/12/17 19:28:21 Setting maximum accepts per cycle 8.
25493:09/12/17 19:28:21 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25494:09/12/17 19:28:21 [68885] Welcome to the all-singing, all dancing, "amazing" GridManager!
25495:09/12/17 19:28:21 [68885] DaemonCore: No more children processes to reap.
25496:09/12/17 19:28:21 [68885] DaemonCore: in SendAliveToParent()
25497:09/12/17 19:28:21 [68885] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25498:09/12/17 19:28:21 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25499:09/12/17 19:28:21 [68885] IPVERIFY: ip found is 1
25500:09/12/17 19:28:21 [68885] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25501:09/12/17 19:28:21 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25502:09/12/17 19:28:21 [68885] IPVERIFY: ip found is 1
25503:09/12/17 19:28:21 [68885] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25504:09/12/17 19:28:21 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25505:09/12/17 19:28:21 [68885] IPVERIFY: ip found is 1
25506:09/12/17 19:28:21 [68885] IPVERIFY: checking mc0151-ib against 128.55.162.46
25507:09/12/17 19:28:21 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25508:09/12/17 19:28:21 [68885] IPVERIFY: ip found is 1
25509:09/12/17 19:28:21 [68885] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
25510:09/12/17 19:28:21 [68885] DaemonCore: Leaving SendAliveToParent() - success
25511:09/12/17 19:28:21 [68885] Checking proxies
25512:09/12/17 19:28:24 [68885] Received ADD_JOBS signal
25513:09/12/17 19:28:24 [68885] in doContactSchedd()
25514:09/12/17 19:28:24 [68885] querying for new jobs
25515:09/12/17 19:28:24 [68885] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
25516:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 542.0
25517:09/12/17 19:28:24 [68885] (542.0) SetJobLeaseTimers()
25518:09/12/17 19:28:24 [68885] Found job 542.0 --- inserting
25519:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 541.0
25520:09/12/17 19:28:24 [68885] (541.0) SetJobLeaseTimers()
25521:09/12/17 19:28:24 [68885] Found job 541.0 --- inserting
25522:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 540.0
25523:09/12/17 19:28:24 [68885] (540.0) SetJobLeaseTimers()
25524:09/12/17 19:28:24 [68885] Found job 540.0 --- inserting
25525:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 539.0
25526:09/12/17 19:28:24 [68885] (539.0) SetJobLeaseTimers()
25527:09/12/17 19:28:24 [68885] Found job 539.0 --- inserting
25528:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 538.0
25529:09/12/17 19:28:24 [68885] (538.0) SetJobLeaseTimers()
25530:09/12/17 19:28:24 [68885] Found job 538.0 --- inserting
25531:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 537.0
25532:09/12/17 19:28:24 [68885] (537.0) SetJobLeaseTimers()
25533:09/12/17 19:28:24 [68885] Found job 537.0 --- inserting
25534:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 536.0
25535:09/12/17 19:28:24 [68885] (536.0) SetJobLeaseTimers()
25536:09/12/17 19:28:24 [68885] Found job 536.0 --- inserting
25537:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 535.0
25538:09/12/17 19:28:24 [68885] (535.0) SetJobLeaseTimers()
25539:09/12/17 19:28:24 [68885] Found job 535.0 --- inserting
25540:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 534.0
25541:09/12/17 19:28:24 [68885] (534.0) SetJobLeaseTimers()
25542:09/12/17 19:28:24 [68885] Found job 534.0 --- inserting
25543:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 533.0
25544:09/12/17 19:28:24 [68885] (533.0) SetJobLeaseTimers()
25545:09/12/17 19:28:24 [68885] Found job 533.0 --- inserting
25546:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 532.0
25547:09/12/17 19:28:24 [68885] (532.0) SetJobLeaseTimers()
25548:09/12/17 19:28:24 [68885] Found job 532.0 --- inserting
25549:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 531.0
25550:09/12/17 19:28:24 [68885] (531.0) SetJobLeaseTimers()
25551:09/12/17 19:28:24 [68885] Found job 531.0 --- inserting
25552:09/12/17 19:28:24 [68885] Using job type INFNBatch for job 530.0
25553:09/12/17 19:28:24 [68885] (530.0) SetJobLeaseTimers()
25554:09/12/17 19:28:24 [68885] Found job 530.0 --- inserting
25555:09/12/17 19:28:24 [68885] Fetched 13 new job ads from schedd
25556:09/12/17 19:28:24 [68885] querying for removed/held jobs
25557:09/12/17 19:28:24 [68885] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
25558:09/12/17 19:28:24 [68885] Fetched 0 job ads from schedd
25559:09/12/17 19:28:24 [68885] leaving doContactSchedd()
25560:09/12/17 19:28:24 [68885] gahp server not up yet, delaying ping
25561:09/12/17 19:28:24 [68885] *** UpdateLeases called
25562:09/12/17 19:28:24 [68885]     Leases not supported, cancelling timer
25563:09/12/17 19:28:24 [68885] BaseResource::UpdateResource: 
25583:09/12/17 19:28:24 [68885] Trying to update collector <128.55.162.46:9619>
25584:09/12/17 19:28:24 [68885] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25585:09/12/17 19:28:24 [68885] File descriptor limits: max 4096, safe 3277
25586:09/12/17 19:28:24 [68885] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25587:09/12/17 19:28:24 [68885] GAHP server pid = 68888
25588:09/12/17 19:28:24 [68885] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
25589:09/12/17 19:28:24 [68885] GAHP[68888] <- 'COMMANDS'
25590:09/12/17 19:28:24 [68885] GAHP[68888] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
25591:09/12/17 19:28:24 [68885] GAHP[68888] <- 'ASYNC_MODE_ON'
25592:09/12/17 19:28:24 [68885] GAHP[68888] -> 'S' 'Async mode on'
25593:09/12/17 19:28:24 [68885] (542.0) gm state change: GM_INIT -> GM_START
25594:09/12/17 19:28:24 [68885] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25595:09/12/17 19:28:24 [68885] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25596:09/12/17 19:28:24 [68885] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25597:09/12/17 19:28:24 [68885] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25598:09/12/17 19:28:24 [68885] (541.0) gm state change: GM_INIT -> GM_START
25599:09/12/17 19:28:24 [68885] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25600:09/12/17 19:28:24 [68885] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25601:09/12/17 19:28:24 [68885] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25602:09/12/17 19:28:24 [68885] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25603:09/12/17 19:28:24 [68885] (540.0) gm state change: GM_INIT -> GM_START
25604:09/12/17 19:28:24 [68885] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25605:09/12/17 19:28:24 [68885] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25606:09/12/17 19:28:24 [68885] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25607:09/12/17 19:28:24 [68885] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25608:09/12/17 19:28:24 [68885] (539.0) gm state change: GM_INIT -> GM_START
25609:09/12/17 19:28:24 [68885] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25610:09/12/17 19:28:24 [68885] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25611:09/12/17 19:28:24 [68885] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25612:09/12/17 19:28:24 [68885] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25613:09/12/17 19:28:24 [68885] (538.0) gm state change: GM_INIT -> GM_START
25614:09/12/17 19:28:24 [68885] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25615:09/12/17 19:28:24 [68885] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25616:09/12/17 19:28:24 [68885] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25617:09/12/17 19:28:24 [68885] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25618:09/12/17 19:28:24 [68885] (537.0) gm state change: GM_INIT -> GM_START
25619:09/12/17 19:28:24 [68885] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25620:09/12/17 19:28:24 [68885] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25621:09/12/17 19:28:24 [68885] GAHP[68888] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
25622:09/12/17 19:28:24 [68885] GAHP[68888] -> 'S'
25623:09/12/17 19:28:24 [68885] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25624:09/12/17 19:28:24 [68885] (536.0) gm state change: GM_INIT -> GM_START
25625:09/12/17 19:28:24 [68885] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25626:09/12/17 19:28:24 [68885] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25627:09/12/17 19:28:24 [68885] GAHP[68888] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
25628:09/12/17 19:28:24 [68885] GAHP[68888] -> 'S'
25629:09/12/17 19:28:24 [68885] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25630:09/12/17 19:28:24 [68885] (535.0) gm state change: GM_INIT -> GM_START
25631:09/12/17 19:28:24 [68885] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25632:09/12/17 19:28:24 [68885] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25633:09/12/17 19:28:24 [68885] GAHP[68888] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
25634:09/12/17 19:28:24 [68885] GAHP[68888] -> 'S'
25635:09/12/17 19:28:24 [68885] This process has a valid certificate & key
25636:09/12/17 19:28:24 [68885] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25637:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25638:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25639:09/12/17 19:28:24 [68885] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25640:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25641:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25642:09/12/17 19:28:24 [68885] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25643:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25644:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25645:09/12/17 19:28:24 [68885] IPVERIFY: checking mc0151-ib against 128.55.162.46
25646:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25647:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25648:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25649:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25650:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25651:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25652:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25653:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25654:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
25655:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
25656:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
25657:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
25658:09/12/17 19:28:24 [68885] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
25659:09/12/17 19:28:24 [68885] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
25660:09/12/17 19:28:24 [68885] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25661:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25662:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25663:09/12/17 19:28:24 [68885] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25664:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25665:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25666:09/12/17 19:28:24 [68885] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25667:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25668:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25669:09/12/17 19:28:24 [68885] IPVERIFY: checking mc0151-ib against 128.55.162.46
25670:09/12/17 19:28:24 [68885] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25671:09/12/17 19:28:24 [68885] IPVERIFY: ip found is 1
25672:09/12/17 19:28:24 [68885] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25673:09/12/17 19:28:24 [68885] (534.0) gm state change: GM_INIT -> GM_START
25674:09/12/17 19:28:24 [68885] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25675:09/12/17 19:28:24 [68885] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25676:09/12/17 19:28:24 [68885] GAHP[68888] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
25677:09/12/17 19:28:24 [68885] GAHP[68888] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
25678:09/12/17 19:28:24 [68885] GAHP[68888] -> EOF
25679:09/12/17 19:28:24 [68885] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
25680:09/12/17 19:33:22 Result of reading /etc/issue:  \S
25682:09/12/17 19:33:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
25684:09/12/17 19:33:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
25685:09/12/17 19:33:22 Enumerating interfaces: lo 127.0.0.1 up
25686:09/12/17 19:33:22 Enumerating interfaces: eth0 10.36.162.46 up
25687:09/12/17 19:33:22 Enumerating interfaces: ib0 128.55.162.46 up
25688:09/12/17 19:33:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
25689:09/12/17 19:33:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
25690:09/12/17 19:33:22 ******************************************************
25691:09/12/17 19:33:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
25692:09/12/17 19:33:22 ** /usr/sbin/condor_gridmanager
25693:09/12/17 19:33:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
25694:09/12/17 19:33:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
25695:09/12/17 19:33:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
25696:09/12/17 19:33:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
25697:09/12/17 19:33:22 ** PID = 68938
25698:09/12/17 19:33:22 ** Log last touched 9/12 19:28:24
25699:09/12/17 19:33:22 ******************************************************
25700:09/12/17 19:33:22 Using config source: /etc/condor-ce/condor_config
25701:09/12/17 19:33:22 Using local config sources: 
25702:09/12/17 19:33:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
25703:09/12/17 19:33:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
25704:09/12/17 19:33:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
25705:09/12/17 19:33:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
25706:09/12/17 19:33:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
25707:09/12/17 19:33:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
25708:09/12/17 19:33:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
25709:09/12/17 19:33:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
25710:09/12/17 19:33:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
25711:09/12/17 19:33:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
25712:09/12/17 19:33:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
25713:09/12/17 19:33:22    /etc/condor-ce/config.d/01-ce-auth.conf
25714:09/12/17 19:33:22    /etc/condor-ce/config.d/01-ce-router.conf
25715:09/12/17 19:33:22    /etc/condor-ce/config.d/01-common-auth.conf
25716:09/12/17 19:33:22    /etc/condor-ce/config.d/02-ce-slurm.conf
25717:09/12/17 19:33:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
25718:09/12/17 19:33:22    /etc/condor-ce/config.d/03-managed-fork.conf
25719:09/12/17 19:33:22    /etc/condor-ce/config.d/05-ce-health.conf
25720:09/12/17 19:33:22    /etc/condor-ce/config.d/05-ce-view.conf
25721:09/12/17 19:33:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
25722:09/12/17 19:33:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
25723:09/12/17 19:33:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
25724:09/12/17 19:33:22    /etc/condor-ce/config.d/50-osg-configure.conf
25725:09/12/17 19:33:22    /etc/condor-ce/config.d/99-local.conf
25726:09/12/17 19:33:22    /usr/share/condor-ce/condor_ce_router_defaults|
25727:09/12/17 19:33:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
25728:09/12/17 19:33:22 CLASSAD_CACHING is ENABLED
25729:09/12/17 19:33:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
25730:09/12/17 19:33:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_107
25731:09/12/17 19:33:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_107>
25732:09/12/17 19:33:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_107>
25733:09/12/17 19:33:22 Setting maximum accepts per cycle 8.
25734:09/12/17 19:33:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25735:09/12/17 19:33:22 [68938] Welcome to the all-singing, all dancing, "amazing" GridManager!
25736:09/12/17 19:33:22 [68938] DaemonCore: No more children processes to reap.
25737:09/12/17 19:33:22 [68938] DaemonCore: in SendAliveToParent()
25738:09/12/17 19:33:22 [68938] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25739:09/12/17 19:33:22 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25740:09/12/17 19:33:22 [68938] IPVERIFY: ip found is 1
25741:09/12/17 19:33:22 [68938] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25742:09/12/17 19:33:22 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25743:09/12/17 19:33:22 [68938] IPVERIFY: ip found is 1
25744:09/12/17 19:33:22 [68938] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25745:09/12/17 19:33:22 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25746:09/12/17 19:33:22 [68938] IPVERIFY: ip found is 1
25747:09/12/17 19:33:22 [68938] IPVERIFY: checking mc0151-ib against 128.55.162.46
25748:09/12/17 19:33:22 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25749:09/12/17 19:33:22 [68938] IPVERIFY: ip found is 1
25750:09/12/17 19:33:22 [68938] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
25751:09/12/17 19:33:22 [68938] DaemonCore: Leaving SendAliveToParent() - success
25752:09/12/17 19:33:22 [68938] Checking proxies
25753:09/12/17 19:33:25 [68938] Received ADD_JOBS signal
25754:09/12/17 19:33:25 [68938] in doContactSchedd()
25755:09/12/17 19:33:25 [68938] querying for new jobs
25756:09/12/17 19:33:25 [68938] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
25757:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 542.0
25758:09/12/17 19:33:25 [68938] (542.0) SetJobLeaseTimers()
25759:09/12/17 19:33:25 [68938] Found job 542.0 --- inserting
25760:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 541.0
25761:09/12/17 19:33:25 [68938] (541.0) SetJobLeaseTimers()
25762:09/12/17 19:33:25 [68938] Found job 541.0 --- inserting
25763:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 540.0
25764:09/12/17 19:33:25 [68938] (540.0) SetJobLeaseTimers()
25765:09/12/17 19:33:25 [68938] Found job 540.0 --- inserting
25766:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 539.0
25767:09/12/17 19:33:25 [68938] (539.0) SetJobLeaseTimers()
25768:09/12/17 19:33:25 [68938] Found job 539.0 --- inserting
25769:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 538.0
25770:09/12/17 19:33:25 [68938] (538.0) SetJobLeaseTimers()
25771:09/12/17 19:33:25 [68938] Found job 538.0 --- inserting
25772:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 537.0
25773:09/12/17 19:33:25 [68938] (537.0) SetJobLeaseTimers()
25774:09/12/17 19:33:25 [68938] Found job 537.0 --- inserting
25775:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 536.0
25776:09/12/17 19:33:25 [68938] (536.0) SetJobLeaseTimers()
25777:09/12/17 19:33:25 [68938] Found job 536.0 --- inserting
25778:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 535.0
25779:09/12/17 19:33:25 [68938] (535.0) SetJobLeaseTimers()
25780:09/12/17 19:33:25 [68938] Found job 535.0 --- inserting
25781:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 534.0
25782:09/12/17 19:33:25 [68938] (534.0) SetJobLeaseTimers()
25783:09/12/17 19:33:25 [68938] Found job 534.0 --- inserting
25784:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 533.0
25785:09/12/17 19:33:25 [68938] (533.0) SetJobLeaseTimers()
25786:09/12/17 19:33:25 [68938] Found job 533.0 --- inserting
25787:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 532.0
25788:09/12/17 19:33:25 [68938] (532.0) SetJobLeaseTimers()
25789:09/12/17 19:33:25 [68938] Found job 532.0 --- inserting
25790:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 531.0
25791:09/12/17 19:33:25 [68938] (531.0) SetJobLeaseTimers()
25792:09/12/17 19:33:25 [68938] Found job 531.0 --- inserting
25793:09/12/17 19:33:25 [68938] Using job type INFNBatch for job 530.0
25794:09/12/17 19:33:25 [68938] (530.0) SetJobLeaseTimers()
25795:09/12/17 19:33:25 [68938] Found job 530.0 --- inserting
25796:09/12/17 19:33:25 [68938] Fetched 13 new job ads from schedd
25797:09/12/17 19:33:25 [68938] querying for removed/held jobs
25798:09/12/17 19:33:25 [68938] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
25799:09/12/17 19:33:25 [68938] Fetched 0 job ads from schedd
25800:09/12/17 19:33:25 [68938] leaving doContactSchedd()
25801:09/12/17 19:33:25 [68938] gahp server not up yet, delaying ping
25802:09/12/17 19:33:25 [68938] *** UpdateLeases called
25803:09/12/17 19:33:25 [68938]     Leases not supported, cancelling timer
25804:09/12/17 19:33:25 [68938] BaseResource::UpdateResource: 
25824:09/12/17 19:33:25 [68938] Trying to update collector <128.55.162.46:9619>
25825:09/12/17 19:33:25 [68938] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25826:09/12/17 19:33:25 [68938] File descriptor limits: max 4096, safe 3277
25827:09/12/17 19:33:25 [68938] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25828:09/12/17 19:33:25 [68938] GAHP server pid = 68942
25829:09/12/17 19:33:25 [68938] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
25830:09/12/17 19:33:25 [68938] GAHP[68942] <- 'COMMANDS'
25831:09/12/17 19:33:25 [68938] GAHP[68942] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
25832:09/12/17 19:33:25 [68938] GAHP[68942] <- 'ASYNC_MODE_ON'
25833:09/12/17 19:33:25 [68938] GAHP[68942] -> 'S' 'Async mode on'
25834:09/12/17 19:33:25 [68938] (542.0) gm state change: GM_INIT -> GM_START
25835:09/12/17 19:33:25 [68938] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25836:09/12/17 19:33:25 [68938] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25837:09/12/17 19:33:25 [68938] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25838:09/12/17 19:33:25 [68938] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25839:09/12/17 19:33:25 [68938] (541.0) gm state change: GM_INIT -> GM_START
25840:09/12/17 19:33:25 [68938] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25841:09/12/17 19:33:25 [68938] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25842:09/12/17 19:33:25 [68938] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25843:09/12/17 19:33:25 [68938] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25844:09/12/17 19:33:25 [68938] (540.0) gm state change: GM_INIT -> GM_START
25845:09/12/17 19:33:25 [68938] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25846:09/12/17 19:33:25 [68938] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25847:09/12/17 19:33:25 [68938] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25848:09/12/17 19:33:25 [68938] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25849:09/12/17 19:33:25 [68938] (539.0) gm state change: GM_INIT -> GM_START
25850:09/12/17 19:33:25 [68938] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25851:09/12/17 19:33:25 [68938] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25852:09/12/17 19:33:25 [68938] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25853:09/12/17 19:33:25 [68938] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
25854:09/12/17 19:33:25 [68938] (538.0) gm state change: GM_INIT -> GM_START
25855:09/12/17 19:33:25 [68938] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
25856:09/12/17 19:33:25 [68938] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
25857:09/12/17 19:33:25 [68938] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
25858:09/12/17 19:33:25 [68938] This process has a valid certificate & key
25859:09/12/17 19:33:25 [68938] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25860:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25861:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25862:09/12/17 19:33:25 [68938] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25863:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25864:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25865:09/12/17 19:33:25 [68938] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25866:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25867:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25868:09/12/17 19:33:25 [68938] IPVERIFY: checking mc0151-ib against 128.55.162.46
25869:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25870:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25871:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25872:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25873:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25874:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25875:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25876:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
25877:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
25878:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
25879:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
25880:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
25881:09/12/17 19:33:25 [68938] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
25882:09/12/17 19:33:25 [68938] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
25883:09/12/17 19:33:25 [68938] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25884:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25885:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25886:09/12/17 19:33:25 [68938] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25887:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25888:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25889:09/12/17 19:33:25 [68938] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25890:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25891:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25892:09/12/17 19:33:25 [68938] IPVERIFY: checking mc0151-ib against 128.55.162.46
25893:09/12/17 19:33:25 [68938] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25894:09/12/17 19:33:25 [68938] IPVERIFY: ip found is 1
25895:09/12/17 19:33:25 [68938] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25896:09/12/17 19:33:25 [68938] (537.0) gm state change: GM_INIT -> GM_START
25897:09/12/17 19:33:25 [68938] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25898:09/12/17 19:33:25 [68938] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25899:09/12/17 19:33:25 [68938] GAHP[68942] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
25900:09/12/17 19:33:25 [68938] GAHP[68942] -> 'S'
25901:09/12/17 19:33:25 [68938] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25902:09/12/17 19:33:25 [68938] (536.0) gm state change: GM_INIT -> GM_START
25903:09/12/17 19:33:25 [68938] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25904:09/12/17 19:33:25 [68938] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25905:09/12/17 19:33:25 [68938] GAHP[68942] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
25906:09/12/17 19:33:25 [68938] GAHP[68942] -> 'S'
25907:09/12/17 19:33:25 [68938] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25908:09/12/17 19:33:25 [68938] (535.0) gm state change: GM_INIT -> GM_START
25909:09/12/17 19:33:25 [68938] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25910:09/12/17 19:33:25 [68938] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25911:09/12/17 19:33:25 [68938] GAHP[68942] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
25912:09/12/17 19:33:25 [68938] GAHP[68942] -> 'S'
25913:09/12/17 19:33:25 [68938] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
25914:09/12/17 19:33:25 [68938] (534.0) gm state change: GM_INIT -> GM_START
25915:09/12/17 19:33:25 [68938] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
25916:09/12/17 19:33:25 [68938] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
25917:09/12/17 19:33:25 [68938] GAHP[68942] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
25918:09/12/17 19:33:25 [68938] GAHP[68942] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
25919:09/12/17 19:33:25 [68938] GAHP[68942] -> EOF
25920:09/12/17 19:33:25 [68938] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
25921:09/12/17 19:38:22 Result of reading /etc/issue:  \S
25923:09/12/17 19:38:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
25925:09/12/17 19:38:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
25926:09/12/17 19:38:22 Enumerating interfaces: lo 127.0.0.1 up
25927:09/12/17 19:38:22 Enumerating interfaces: eth0 10.36.162.46 up
25928:09/12/17 19:38:22 Enumerating interfaces: ib0 128.55.162.46 up
25929:09/12/17 19:38:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
25930:09/12/17 19:38:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
25931:09/12/17 19:38:22 ******************************************************
25932:09/12/17 19:38:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
25933:09/12/17 19:38:22 ** /usr/sbin/condor_gridmanager
25934:09/12/17 19:38:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
25935:09/12/17 19:38:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
25936:09/12/17 19:38:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
25937:09/12/17 19:38:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
25938:09/12/17 19:38:22 ** PID = 68991
25939:09/12/17 19:38:22 ** Log last touched 9/12 19:33:25
25940:09/12/17 19:38:22 ******************************************************
25941:09/12/17 19:38:22 Using config source: /etc/condor-ce/condor_config
25942:09/12/17 19:38:22 Using local config sources: 
25943:09/12/17 19:38:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
25944:09/12/17 19:38:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
25945:09/12/17 19:38:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
25946:09/12/17 19:38:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
25947:09/12/17 19:38:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
25948:09/12/17 19:38:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
25949:09/12/17 19:38:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
25950:09/12/17 19:38:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
25951:09/12/17 19:38:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
25952:09/12/17 19:38:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
25953:09/12/17 19:38:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
25954:09/12/17 19:38:22    /etc/condor-ce/config.d/01-ce-auth.conf
25955:09/12/17 19:38:22    /etc/condor-ce/config.d/01-ce-router.conf
25956:09/12/17 19:38:22    /etc/condor-ce/config.d/01-common-auth.conf
25957:09/12/17 19:38:22    /etc/condor-ce/config.d/02-ce-slurm.conf
25958:09/12/17 19:38:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
25959:09/12/17 19:38:22    /etc/condor-ce/config.d/03-managed-fork.conf
25960:09/12/17 19:38:22    /etc/condor-ce/config.d/05-ce-health.conf
25961:09/12/17 19:38:22    /etc/condor-ce/config.d/05-ce-view.conf
25962:09/12/17 19:38:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
25963:09/12/17 19:38:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
25964:09/12/17 19:38:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
25965:09/12/17 19:38:22    /etc/condor-ce/config.d/50-osg-configure.conf
25966:09/12/17 19:38:22    /etc/condor-ce/config.d/99-local.conf
25967:09/12/17 19:38:22    /usr/share/condor-ce/condor_ce_router_defaults|
25968:09/12/17 19:38:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
25969:09/12/17 19:38:22 CLASSAD_CACHING is ENABLED
25970:09/12/17 19:38:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
25971:09/12/17 19:38:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_109
25972:09/12/17 19:38:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_109>
25973:09/12/17 19:38:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_109>
25974:09/12/17 19:38:22 Setting maximum accepts per cycle 8.
25975:09/12/17 19:38:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
25976:09/12/17 19:38:22 [68991] Welcome to the all-singing, all dancing, "amazing" GridManager!
25977:09/12/17 19:38:22 [68991] DaemonCore: No more children processes to reap.
25978:09/12/17 19:38:22 [68991] DaemonCore: in SendAliveToParent()
25979:09/12/17 19:38:22 [68991] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
25980:09/12/17 19:38:22 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25981:09/12/17 19:38:22 [68991] IPVERIFY: ip found is 1
25982:09/12/17 19:38:22 [68991] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
25983:09/12/17 19:38:22 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25984:09/12/17 19:38:22 [68991] IPVERIFY: ip found is 1
25985:09/12/17 19:38:22 [68991] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
25986:09/12/17 19:38:22 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25987:09/12/17 19:38:22 [68991] IPVERIFY: ip found is 1
25988:09/12/17 19:38:22 [68991] IPVERIFY: checking mc0151-ib against 128.55.162.46
25989:09/12/17 19:38:22 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
25990:09/12/17 19:38:22 [68991] IPVERIFY: ip found is 1
25991:09/12/17 19:38:22 [68991] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
25992:09/12/17 19:38:22 [68991] DaemonCore: Leaving SendAliveToParent() - success
25993:09/12/17 19:38:22 [68991] Checking proxies
25994:09/12/17 19:38:25 [68991] Received ADD_JOBS signal
25995:09/12/17 19:38:25 [68991] in doContactSchedd()
25996:09/12/17 19:38:25 [68991] querying for new jobs
25997:09/12/17 19:38:25 [68991] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
25998:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 542.0
25999:09/12/17 19:38:25 [68991] (542.0) SetJobLeaseTimers()
26000:09/12/17 19:38:25 [68991] Found job 542.0 --- inserting
26001:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 541.0
26002:09/12/17 19:38:25 [68991] (541.0) SetJobLeaseTimers()
26003:09/12/17 19:38:25 [68991] Found job 541.0 --- inserting
26004:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 540.0
26005:09/12/17 19:38:25 [68991] (540.0) SetJobLeaseTimers()
26006:09/12/17 19:38:25 [68991] Found job 540.0 --- inserting
26007:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 539.0
26008:09/12/17 19:38:25 [68991] (539.0) SetJobLeaseTimers()
26009:09/12/17 19:38:25 [68991] Found job 539.0 --- inserting
26010:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 538.0
26011:09/12/17 19:38:25 [68991] (538.0) SetJobLeaseTimers()
26012:09/12/17 19:38:25 [68991] Found job 538.0 --- inserting
26013:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 537.0
26014:09/12/17 19:38:25 [68991] (537.0) SetJobLeaseTimers()
26015:09/12/17 19:38:25 [68991] Found job 537.0 --- inserting
26016:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 536.0
26017:09/12/17 19:38:25 [68991] (536.0) SetJobLeaseTimers()
26018:09/12/17 19:38:25 [68991] Found job 536.0 --- inserting
26019:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 535.0
26020:09/12/17 19:38:25 [68991] (535.0) SetJobLeaseTimers()
26021:09/12/17 19:38:25 [68991] Found job 535.0 --- inserting
26022:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 534.0
26023:09/12/17 19:38:25 [68991] (534.0) SetJobLeaseTimers()
26024:09/12/17 19:38:25 [68991] Found job 534.0 --- inserting
26025:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 533.0
26026:09/12/17 19:38:25 [68991] (533.0) SetJobLeaseTimers()
26027:09/12/17 19:38:25 [68991] Found job 533.0 --- inserting
26028:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 532.0
26029:09/12/17 19:38:25 [68991] (532.0) SetJobLeaseTimers()
26030:09/12/17 19:38:25 [68991] Found job 532.0 --- inserting
26031:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 531.0
26032:09/12/17 19:38:25 [68991] (531.0) SetJobLeaseTimers()
26033:09/12/17 19:38:25 [68991] Found job 531.0 --- inserting
26034:09/12/17 19:38:25 [68991] Using job type INFNBatch for job 530.0
26035:09/12/17 19:38:25 [68991] (530.0) SetJobLeaseTimers()
26036:09/12/17 19:38:25 [68991] Found job 530.0 --- inserting
26037:09/12/17 19:38:25 [68991] Fetched 13 new job ads from schedd
26038:09/12/17 19:38:25 [68991] querying for removed/held jobs
26039:09/12/17 19:38:25 [68991] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
26040:09/12/17 19:38:25 [68991] Fetched 0 job ads from schedd
26041:09/12/17 19:38:25 [68991] leaving doContactSchedd()
26042:09/12/17 19:38:25 [68991] gahp server not up yet, delaying ping
26043:09/12/17 19:38:25 [68991] *** UpdateLeases called
26044:09/12/17 19:38:25 [68991]     Leases not supported, cancelling timer
26045:09/12/17 19:38:25 [68991] BaseResource::UpdateResource: 
26065:09/12/17 19:38:25 [68991] Trying to update collector <128.55.162.46:9619>
26066:09/12/17 19:38:25 [68991] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26067:09/12/17 19:38:25 [68991] File descriptor limits: max 4096, safe 3277
26068:09/12/17 19:38:25 [68991] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26069:09/12/17 19:38:25 [68991] GAHP server pid = 68994
26070:09/12/17 19:38:25 [68991] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
26071:09/12/17 19:38:25 [68991] GAHP[68994] <- 'COMMANDS'
26072:09/12/17 19:38:25 [68991] GAHP[68994] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
26073:09/12/17 19:38:25 [68991] GAHP[68994] <- 'ASYNC_MODE_ON'
26074:09/12/17 19:38:25 [68991] GAHP[68994] -> 'S' 'Async mode on'
26075:09/12/17 19:38:25 [68991] (542.0) gm state change: GM_INIT -> GM_START
26076:09/12/17 19:38:25 [68991] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26077:09/12/17 19:38:25 [68991] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26078:09/12/17 19:38:25 [68991] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26079:09/12/17 19:38:25 [68991] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26080:09/12/17 19:38:25 [68991] (541.0) gm state change: GM_INIT -> GM_START
26081:09/12/17 19:38:25 [68991] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26082:09/12/17 19:38:25 [68991] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26083:09/12/17 19:38:25 [68991] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26084:09/12/17 19:38:25 [68991] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26085:09/12/17 19:38:25 [68991] (540.0) gm state change: GM_INIT -> GM_START
26086:09/12/17 19:38:25 [68991] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26087:09/12/17 19:38:25 [68991] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26088:09/12/17 19:38:25 [68991] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26089:09/12/17 19:38:25 [68991] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26090:09/12/17 19:38:25 [68991] (539.0) gm state change: GM_INIT -> GM_START
26091:09/12/17 19:38:25 [68991] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26092:09/12/17 19:38:25 [68991] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26093:09/12/17 19:38:25 [68991] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26094:09/12/17 19:38:25 [68991] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26095:09/12/17 19:38:25 [68991] (538.0) gm state change: GM_INIT -> GM_START
26096:09/12/17 19:38:25 [68991] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26097:09/12/17 19:38:25 [68991] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26098:09/12/17 19:38:25 [68991] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26099:09/12/17 19:38:25 [68991] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26100:09/12/17 19:38:25 [68991] (537.0) gm state change: GM_INIT -> GM_START
26101:09/12/17 19:38:25 [68991] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26102:09/12/17 19:38:25 [68991] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26103:09/12/17 19:38:25 [68991] GAHP[68994] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
26104:09/12/17 19:38:25 [68991] GAHP[68994] -> 'S'
26105:09/12/17 19:38:25 [68991] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26106:09/12/17 19:38:25 [68991] (536.0) gm state change: GM_INIT -> GM_START
26107:09/12/17 19:38:25 [68991] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26108:09/12/17 19:38:25 [68991] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26109:09/12/17 19:38:25 [68991] GAHP[68994] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
26110:09/12/17 19:38:25 [68991] GAHP[68994] -> 'S'
26111:09/12/17 19:38:25 [68991] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26112:09/12/17 19:38:25 [68991] (535.0) gm state change: GM_INIT -> GM_START
26113:09/12/17 19:38:25 [68991] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26114:09/12/17 19:38:25 [68991] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26115:09/12/17 19:38:25 [68991] GAHP[68994] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
26116:09/12/17 19:38:25 [68991] GAHP[68994] -> 'S'
26117:09/12/17 19:38:25 [68991] This process has a valid certificate & key
26118:09/12/17 19:38:25 [68991] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26119:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26120:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26121:09/12/17 19:38:25 [68991] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26122:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26123:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26124:09/12/17 19:38:25 [68991] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26125:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26126:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26127:09/12/17 19:38:25 [68991] IPVERIFY: checking mc0151-ib against 128.55.162.46
26128:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26129:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26130:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26131:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26132:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26133:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26134:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26135:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26136:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
26137:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
26138:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
26139:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
26140:09/12/17 19:38:25 [68991] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
26141:09/12/17 19:38:25 [68991] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
26142:09/12/17 19:38:25 [68991] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26143:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26144:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26145:09/12/17 19:38:25 [68991] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26146:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26147:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26148:09/12/17 19:38:25 [68991] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26149:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26150:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26151:09/12/17 19:38:25 [68991] IPVERIFY: checking mc0151-ib against 128.55.162.46
26152:09/12/17 19:38:25 [68991] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26153:09/12/17 19:38:25 [68991] IPVERIFY: ip found is 1
26154:09/12/17 19:38:25 [68991] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26155:09/12/17 19:38:25 [68991] (534.0) gm state change: GM_INIT -> GM_START
26156:09/12/17 19:38:25 [68991] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26157:09/12/17 19:38:25 [68991] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26158:09/12/17 19:38:25 [68991] GAHP[68994] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
26159:09/12/17 19:38:25 [68991] GAHP[68994] (stderr) -> Assertion globus_thread_equal( mutex->thread_id, globus_thread_self() ) failed in file globus_module.c at line 1148
26160:09/12/17 19:38:25 [68991] GAHP[68994] -> EOF
26161:09/12/17 19:38:25 [68991] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
26162:09/12/17 19:43:22 Result of reading /etc/issue:  \S
26164:09/12/17 19:43:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
26166:09/12/17 19:43:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
26167:09/12/17 19:43:22 Enumerating interfaces: lo 127.0.0.1 up
26168:09/12/17 19:43:22 Enumerating interfaces: eth0 10.36.162.46 up
26169:09/12/17 19:43:22 Enumerating interfaces: ib0 128.55.162.46 up
26170:09/12/17 19:43:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
26171:09/12/17 19:43:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
26172:09/12/17 19:43:22 ******************************************************
26173:09/12/17 19:43:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
26174:09/12/17 19:43:22 ** /usr/sbin/condor_gridmanager
26175:09/12/17 19:43:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
26176:09/12/17 19:43:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
26177:09/12/17 19:43:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
26178:09/12/17 19:43:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
26179:09/12/17 19:43:22 ** PID = 69037
26180:09/12/17 19:43:22 ** Log last touched 9/12 19:38:25
26181:09/12/17 19:43:22 ******************************************************
26182:09/12/17 19:43:22 Using config source: /etc/condor-ce/condor_config
26183:09/12/17 19:43:22 Using local config sources: 
26184:09/12/17 19:43:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
26185:09/12/17 19:43:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
26186:09/12/17 19:43:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
26187:09/12/17 19:43:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
26188:09/12/17 19:43:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
26189:09/12/17 19:43:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
26190:09/12/17 19:43:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
26191:09/12/17 19:43:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
26192:09/12/17 19:43:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
26193:09/12/17 19:43:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
26194:09/12/17 19:43:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
26195:09/12/17 19:43:22    /etc/condor-ce/config.d/01-ce-auth.conf
26196:09/12/17 19:43:22    /etc/condor-ce/config.d/01-ce-router.conf
26197:09/12/17 19:43:22    /etc/condor-ce/config.d/01-common-auth.conf
26198:09/12/17 19:43:22    /etc/condor-ce/config.d/02-ce-slurm.conf
26199:09/12/17 19:43:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
26200:09/12/17 19:43:22    /etc/condor-ce/config.d/03-managed-fork.conf
26201:09/12/17 19:43:22    /etc/condor-ce/config.d/05-ce-health.conf
26202:09/12/17 19:43:22    /etc/condor-ce/config.d/05-ce-view.conf
26203:09/12/17 19:43:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
26204:09/12/17 19:43:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
26205:09/12/17 19:43:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
26206:09/12/17 19:43:22    /etc/condor-ce/config.d/50-osg-configure.conf
26207:09/12/17 19:43:22    /etc/condor-ce/config.d/99-local.conf
26208:09/12/17 19:43:22    /usr/share/condor-ce/condor_ce_router_defaults|
26209:09/12/17 19:43:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
26210:09/12/17 19:43:22 CLASSAD_CACHING is ENABLED
26211:09/12/17 19:43:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
26212:09/12/17 19:43:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_112
26213:09/12/17 19:43:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_112>
26214:09/12/17 19:43:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_112>
26215:09/12/17 19:43:22 Setting maximum accepts per cycle 8.
26216:09/12/17 19:43:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26217:09/12/17 19:43:22 [69037] Welcome to the all-singing, all dancing, "amazing" GridManager!
26218:09/12/17 19:43:22 [69037] DaemonCore: No more children processes to reap.
26219:09/12/17 19:43:22 [69037] DaemonCore: in SendAliveToParent()
26220:09/12/17 19:43:22 [69037] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26221:09/12/17 19:43:22 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26222:09/12/17 19:43:22 [69037] IPVERIFY: ip found is 1
26223:09/12/17 19:43:22 [69037] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26224:09/12/17 19:43:22 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26225:09/12/17 19:43:22 [69037] IPVERIFY: ip found is 1
26226:09/12/17 19:43:22 [69037] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26227:09/12/17 19:43:22 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26228:09/12/17 19:43:22 [69037] IPVERIFY: ip found is 1
26229:09/12/17 19:43:22 [69037] IPVERIFY: checking mc0151-ib against 128.55.162.46
26230:09/12/17 19:43:22 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26231:09/12/17 19:43:22 [69037] IPVERIFY: ip found is 1
26232:09/12/17 19:43:22 [69037] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
26233:09/12/17 19:43:22 [69037] DaemonCore: Leaving SendAliveToParent() - success
26234:09/12/17 19:43:22 [69037] Checking proxies
26235:09/12/17 19:43:25 [69037] Received ADD_JOBS signal
26236:09/12/17 19:43:25 [69037] in doContactSchedd()
26237:09/12/17 19:43:25 [69037] querying for new jobs
26238:09/12/17 19:43:25 [69037] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
26239:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 542.0
26240:09/12/17 19:43:25 [69037] (542.0) SetJobLeaseTimers()
26241:09/12/17 19:43:25 [69037] Found job 542.0 --- inserting
26242:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 541.0
26243:09/12/17 19:43:25 [69037] (541.0) SetJobLeaseTimers()
26244:09/12/17 19:43:25 [69037] Found job 541.0 --- inserting
26245:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 540.0
26246:09/12/17 19:43:25 [69037] (540.0) SetJobLeaseTimers()
26247:09/12/17 19:43:25 [69037] Found job 540.0 --- inserting
26248:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 539.0
26249:09/12/17 19:43:25 [69037] (539.0) SetJobLeaseTimers()
26250:09/12/17 19:43:25 [69037] Found job 539.0 --- inserting
26251:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 538.0
26252:09/12/17 19:43:25 [69037] (538.0) SetJobLeaseTimers()
26253:09/12/17 19:43:25 [69037] Found job 538.0 --- inserting
26254:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 537.0
26255:09/12/17 19:43:25 [69037] (537.0) SetJobLeaseTimers()
26256:09/12/17 19:43:25 [69037] Found job 537.0 --- inserting
26257:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 536.0
26258:09/12/17 19:43:25 [69037] (536.0) SetJobLeaseTimers()
26259:09/12/17 19:43:25 [69037] Found job 536.0 --- inserting
26260:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 535.0
26261:09/12/17 19:43:25 [69037] (535.0) SetJobLeaseTimers()
26262:09/12/17 19:43:25 [69037] Found job 535.0 --- inserting
26263:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 534.0
26264:09/12/17 19:43:25 [69037] (534.0) SetJobLeaseTimers()
26265:09/12/17 19:43:25 [69037] Found job 534.0 --- inserting
26266:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 533.0
26267:09/12/17 19:43:25 [69037] (533.0) SetJobLeaseTimers()
26268:09/12/17 19:43:25 [69037] Found job 533.0 --- inserting
26269:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 532.0
26270:09/12/17 19:43:25 [69037] (532.0) SetJobLeaseTimers()
26271:09/12/17 19:43:25 [69037] Found job 532.0 --- inserting
26272:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 531.0
26273:09/12/17 19:43:25 [69037] (531.0) SetJobLeaseTimers()
26274:09/12/17 19:43:25 [69037] Found job 531.0 --- inserting
26275:09/12/17 19:43:25 [69037] Using job type INFNBatch for job 530.0
26276:09/12/17 19:43:25 [69037] (530.0) SetJobLeaseTimers()
26277:09/12/17 19:43:25 [69037] Found job 530.0 --- inserting
26278:09/12/17 19:43:25 [69037] Fetched 13 new job ads from schedd
26279:09/12/17 19:43:25 [69037] querying for removed/held jobs
26280:09/12/17 19:43:25 [69037] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
26281:09/12/17 19:43:25 [69037] Fetched 0 job ads from schedd
26282:09/12/17 19:43:25 [69037] leaving doContactSchedd()
26283:09/12/17 19:43:25 [69037] gahp server not up yet, delaying ping
26284:09/12/17 19:43:25 [69037] *** UpdateLeases called
26285:09/12/17 19:43:25 [69037]     Leases not supported, cancelling timer
26286:09/12/17 19:43:25 [69037] BaseResource::UpdateResource: 
26306:09/12/17 19:43:25 [69037] Trying to update collector <128.55.162.46:9619>
26307:09/12/17 19:43:25 [69037] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26308:09/12/17 19:43:25 [69037] File descriptor limits: max 4096, safe 3277
26309:09/12/17 19:43:25 [69037] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26310:09/12/17 19:43:25 [69037] GAHP server pid = 69040
26311:09/12/17 19:43:25 [69037] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
26312:09/12/17 19:43:25 [69037] GAHP[69040] <- 'COMMANDS'
26313:09/12/17 19:43:25 [69037] GAHP[69040] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
26314:09/12/17 19:43:25 [69037] GAHP[69040] <- 'ASYNC_MODE_ON'
26315:09/12/17 19:43:25 [69037] GAHP[69040] -> 'S' 'Async mode on'
26316:09/12/17 19:43:25 [69037] (542.0) gm state change: GM_INIT -> GM_START
26317:09/12/17 19:43:25 [69037] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26318:09/12/17 19:43:25 [69037] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26319:09/12/17 19:43:25 [69037] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26320:09/12/17 19:43:25 [69037] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26321:09/12/17 19:43:25 [69037] (541.0) gm state change: GM_INIT -> GM_START
26322:09/12/17 19:43:25 [69037] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26323:09/12/17 19:43:25 [69037] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26324:09/12/17 19:43:25 [69037] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26325:09/12/17 19:43:25 [69037] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26326:09/12/17 19:43:25 [69037] (540.0) gm state change: GM_INIT -> GM_START
26327:09/12/17 19:43:25 [69037] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26328:09/12/17 19:43:25 [69037] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26329:09/12/17 19:43:25 [69037] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26330:09/12/17 19:43:25 [69037] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26331:09/12/17 19:43:25 [69037] (539.0) gm state change: GM_INIT -> GM_START
26332:09/12/17 19:43:25 [69037] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26333:09/12/17 19:43:25 [69037] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26334:09/12/17 19:43:25 [69037] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26335:09/12/17 19:43:25 [69037] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26336:09/12/17 19:43:25 [69037] (538.0) gm state change: GM_INIT -> GM_START
26337:09/12/17 19:43:25 [69037] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26338:09/12/17 19:43:25 [69037] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26339:09/12/17 19:43:25 [69037] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26340:09/12/17 19:43:25 [69037] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26341:09/12/17 19:43:25 [69037] (537.0) gm state change: GM_INIT -> GM_START
26342:09/12/17 19:43:25 [69037] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26343:09/12/17 19:43:25 [69037] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26344:09/12/17 19:43:25 [69037] GAHP[69040] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
26345:09/12/17 19:43:25 [69037] GAHP[69040] -> 'S'
26346:09/12/17 19:43:25 [69037] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26347:09/12/17 19:43:25 [69037] (536.0) gm state change: GM_INIT -> GM_START
26348:09/12/17 19:43:25 [69037] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26349:09/12/17 19:43:25 [69037] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26350:09/12/17 19:43:25 [69037] GAHP[69040] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
26351:09/12/17 19:43:25 [69037] GAHP[69040] -> 'S'
26352:09/12/17 19:43:25 [69037] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26353:09/12/17 19:43:25 [69037] (535.0) gm state change: GM_INIT -> GM_START
26354:09/12/17 19:43:25 [69037] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26355:09/12/17 19:43:25 [69037] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26356:09/12/17 19:43:25 [69037] GAHP[69040] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
26357:09/12/17 19:43:25 [69037] GAHP[69040] -> 'S'
26358:09/12/17 19:43:25 [69037] This process has a valid certificate & key
26359:09/12/17 19:43:25 [69037] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26360:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26361:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26362:09/12/17 19:43:25 [69037] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26363:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26364:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26365:09/12/17 19:43:25 [69037] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26366:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26367:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26368:09/12/17 19:43:25 [69037] IPVERIFY: checking mc0151-ib against 128.55.162.46
26369:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26370:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26371:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26372:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26373:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26374:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26375:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26376:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26377:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
26378:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
26379:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
26380:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
26381:09/12/17 19:43:25 [69037] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
26382:09/12/17 19:43:25 [69037] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
26383:09/12/17 19:43:25 [69037] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26384:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26385:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26386:09/12/17 19:43:25 [69037] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26387:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26388:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26389:09/12/17 19:43:25 [69037] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26390:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26391:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26392:09/12/17 19:43:25 [69037] IPVERIFY: checking mc0151-ib against 128.55.162.46
26393:09/12/17 19:43:25 [69037] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26394:09/12/17 19:43:25 [69037] IPVERIFY: ip found is 1
26395:09/12/17 19:43:25 [69037] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26396:09/12/17 19:43:25 [69037] (534.0) gm state change: GM_INIT -> GM_START
26397:09/12/17 19:43:25 [69037] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26398:09/12/17 19:43:25 [69037] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26399:09/12/17 19:43:25 [69037] GAHP[69040] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
26400:09/12/17 19:43:25 [69037] GAHP[69040] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
26401:09/12/17 19:43:25 [69037] GAHP[69040] -> EOF
26402:09/12/17 19:43:25 [69037] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
26403:09/12/17 19:48:22 Result of reading /etc/issue:  \S
26405:09/12/17 19:48:22 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
26407:09/12/17 19:48:22 Using IDs: 32 processors, 16 CPUs, 16 HTs
26408:09/12/17 19:48:22 Enumerating interfaces: lo 127.0.0.1 up
26409:09/12/17 19:48:22 Enumerating interfaces: eth0 10.36.162.46 up
26410:09/12/17 19:48:22 Enumerating interfaces: ib0 128.55.162.46 up
26411:09/12/17 19:48:22 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
26412:09/12/17 19:48:22 Initializing Directory: curr_dir = /etc/condor-ce/config.d
26413:09/12/17 19:48:22 ******************************************************
26414:09/12/17 19:48:22 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
26415:09/12/17 19:48:22 ** /usr/sbin/condor_gridmanager
26416:09/12/17 19:48:22 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
26417:09/12/17 19:48:22 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
26418:09/12/17 19:48:22 ** $CondorVersion: 8.4.12 Aug 07 2017 $
26419:09/12/17 19:48:22 ** $CondorPlatform: X86_64-CentOS_7.3 $
26420:09/12/17 19:48:22 ** PID = 69083
26421:09/12/17 19:48:22 ** Log last touched 9/12 19:43:25
26422:09/12/17 19:48:22 ******************************************************
26423:09/12/17 19:48:22 Using config source: /etc/condor-ce/condor_config
26424:09/12/17 19:48:22 Using local config sources: 
26425:09/12/17 19:48:22    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
26426:09/12/17 19:48:22    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
26427:09/12/17 19:48:22    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
26428:09/12/17 19:48:22    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
26429:09/12/17 19:48:22    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
26430:09/12/17 19:48:22    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
26431:09/12/17 19:48:22    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
26432:09/12/17 19:48:22    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
26433:09/12/17 19:48:22    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
26434:09/12/17 19:48:22    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
26435:09/12/17 19:48:22    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
26436:09/12/17 19:48:22    /etc/condor-ce/config.d/01-ce-auth.conf
26437:09/12/17 19:48:22    /etc/condor-ce/config.d/01-ce-router.conf
26438:09/12/17 19:48:22    /etc/condor-ce/config.d/01-common-auth.conf
26439:09/12/17 19:48:22    /etc/condor-ce/config.d/02-ce-slurm.conf
26440:09/12/17 19:48:22    /etc/condor-ce/config.d/03-ce-shared-port.conf
26441:09/12/17 19:48:22    /etc/condor-ce/config.d/03-managed-fork.conf
26442:09/12/17 19:48:22    /etc/condor-ce/config.d/05-ce-health.conf
26443:09/12/17 19:48:22    /etc/condor-ce/config.d/05-ce-view.conf
26444:09/12/17 19:48:22    /etc/condor-ce/config.d/10-ce-collector-generated.conf
26445:09/12/17 19:48:22    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
26446:09/12/17 19:48:22    /etc/condor-ce/config.d/50-osg-configure-present.conf
26447:09/12/17 19:48:22    /etc/condor-ce/config.d/50-osg-configure.conf
26448:09/12/17 19:48:22    /etc/condor-ce/config.d/99-local.conf
26449:09/12/17 19:48:22    /usr/share/condor-ce/condor_ce_router_defaults|
26450:09/12/17 19:48:22 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
26451:09/12/17 19:48:22 CLASSAD_CACHING is ENABLED
26452:09/12/17 19:48:22 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
26453:09/12/17 19:48:22 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_115
26454:09/12/17 19:48:22 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_115>
26455:09/12/17 19:48:22 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_115>
26456:09/12/17 19:48:22 Setting maximum accepts per cycle 8.
26457:09/12/17 19:48:22 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26458:09/12/17 19:48:22 [69083] Welcome to the all-singing, all dancing, "amazing" GridManager!
26459:09/12/17 19:48:22 [69083] DaemonCore: No more children processes to reap.
26460:09/12/17 19:48:22 [69083] DaemonCore: in SendAliveToParent()
26461:09/12/17 19:48:22 [69083] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26462:09/12/17 19:48:22 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26463:09/12/17 19:48:22 [69083] IPVERIFY: ip found is 1
26464:09/12/17 19:48:22 [69083] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26465:09/12/17 19:48:22 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26466:09/12/17 19:48:22 [69083] IPVERIFY: ip found is 1
26467:09/12/17 19:48:22 [69083] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26468:09/12/17 19:48:22 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26469:09/12/17 19:48:22 [69083] IPVERIFY: ip found is 1
26470:09/12/17 19:48:22 [69083] IPVERIFY: checking mc0151-ib against 128.55.162.46
26471:09/12/17 19:48:22 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26472:09/12/17 19:48:22 [69083] IPVERIFY: ip found is 1
26473:09/12/17 19:48:22 [69083] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
26474:09/12/17 19:48:22 [69083] DaemonCore: Leaving SendAliveToParent() - success
26475:09/12/17 19:48:22 [69083] Checking proxies
26476:09/12/17 19:48:25 [69083] Received ADD_JOBS signal
26477:09/12/17 19:48:25 [69083] in doContactSchedd()
26478:09/12/17 19:48:25 [69083] querying for new jobs
26479:09/12/17 19:48:25 [69083] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
26480:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 542.0
26481:09/12/17 19:48:25 [69083] (542.0) SetJobLeaseTimers()
26482:09/12/17 19:48:25 [69083] Found job 542.0 --- inserting
26483:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 541.0
26484:09/12/17 19:48:25 [69083] (541.0) SetJobLeaseTimers()
26485:09/12/17 19:48:25 [69083] Found job 541.0 --- inserting
26486:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 540.0
26487:09/12/17 19:48:25 [69083] (540.0) SetJobLeaseTimers()
26488:09/12/17 19:48:25 [69083] Found job 540.0 --- inserting
26489:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 539.0
26490:09/12/17 19:48:25 [69083] (539.0) SetJobLeaseTimers()
26491:09/12/17 19:48:25 [69083] Found job 539.0 --- inserting
26492:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 538.0
26493:09/12/17 19:48:25 [69083] (538.0) SetJobLeaseTimers()
26494:09/12/17 19:48:25 [69083] Found job 538.0 --- inserting
26495:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 537.0
26496:09/12/17 19:48:25 [69083] (537.0) SetJobLeaseTimers()
26497:09/12/17 19:48:25 [69083] Found job 537.0 --- inserting
26498:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 536.0
26499:09/12/17 19:48:25 [69083] (536.0) SetJobLeaseTimers()
26500:09/12/17 19:48:25 [69083] Found job 536.0 --- inserting
26501:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 535.0
26502:09/12/17 19:48:25 [69083] (535.0) SetJobLeaseTimers()
26503:09/12/17 19:48:25 [69083] Found job 535.0 --- inserting
26504:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 534.0
26505:09/12/17 19:48:25 [69083] (534.0) SetJobLeaseTimers()
26506:09/12/17 19:48:25 [69083] Found job 534.0 --- inserting
26507:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 533.0
26508:09/12/17 19:48:25 [69083] (533.0) SetJobLeaseTimers()
26509:09/12/17 19:48:25 [69083] Found job 533.0 --- inserting
26510:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 532.0
26511:09/12/17 19:48:25 [69083] (532.0) SetJobLeaseTimers()
26512:09/12/17 19:48:25 [69083] Found job 532.0 --- inserting
26513:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 531.0
26514:09/12/17 19:48:25 [69083] (531.0) SetJobLeaseTimers()
26515:09/12/17 19:48:25 [69083] Found job 531.0 --- inserting
26516:09/12/17 19:48:25 [69083] Using job type INFNBatch for job 530.0
26517:09/12/17 19:48:25 [69083] (530.0) SetJobLeaseTimers()
26518:09/12/17 19:48:25 [69083] Found job 530.0 --- inserting
26519:09/12/17 19:48:25 [69083] Fetched 13 new job ads from schedd
26520:09/12/17 19:48:25 [69083] querying for removed/held jobs
26521:09/12/17 19:48:25 [69083] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
26522:09/12/17 19:48:25 [69083] Fetched 0 job ads from schedd
26523:09/12/17 19:48:25 [69083] leaving doContactSchedd()
26524:09/12/17 19:48:25 [69083] gahp server not up yet, delaying ping
26525:09/12/17 19:48:25 [69083] *** UpdateLeases called
26526:09/12/17 19:48:25 [69083]     Leases not supported, cancelling timer
26527:09/12/17 19:48:25 [69083] BaseResource::UpdateResource: 
26547:09/12/17 19:48:25 [69083] Trying to update collector <128.55.162.46:9619>
26548:09/12/17 19:48:25 [69083] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26549:09/12/17 19:48:25 [69083] File descriptor limits: max 4096, safe 3277
26550:09/12/17 19:48:25 [69083] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26551:09/12/17 19:48:25 [69083] GAHP server pid = 69086
26552:09/12/17 19:48:25 [69083] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
26553:09/12/17 19:48:25 [69083] GAHP[69086] <- 'COMMANDS'
26554:09/12/17 19:48:25 [69083] GAHP[69086] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
26555:09/12/17 19:48:25 [69083] GAHP[69086] <- 'ASYNC_MODE_ON'
26556:09/12/17 19:48:25 [69083] GAHP[69086] -> 'S' 'Async mode on'
26557:09/12/17 19:48:25 [69083] (542.0) gm state change: GM_INIT -> GM_START
26558:09/12/17 19:48:25 [69083] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26559:09/12/17 19:48:25 [69083] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26560:09/12/17 19:48:25 [69083] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26561:09/12/17 19:48:25 [69083] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26562:09/12/17 19:48:25 [69083] (541.0) gm state change: GM_INIT -> GM_START
26563:09/12/17 19:48:25 [69083] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26564:09/12/17 19:48:25 [69083] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26565:09/12/17 19:48:25 [69083] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26566:09/12/17 19:48:25 [69083] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26567:09/12/17 19:48:25 [69083] (540.0) gm state change: GM_INIT -> GM_START
26568:09/12/17 19:48:25 [69083] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26569:09/12/17 19:48:25 [69083] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26570:09/12/17 19:48:25 [69083] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26571:09/12/17 19:48:25 [69083] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26572:09/12/17 19:48:25 [69083] (539.0) gm state change: GM_INIT -> GM_START
26573:09/12/17 19:48:25 [69083] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26574:09/12/17 19:48:25 [69083] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26575:09/12/17 19:48:25 [69083] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26576:09/12/17 19:48:25 [69083] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26577:09/12/17 19:48:25 [69083] (538.0) gm state change: GM_INIT -> GM_START
26578:09/12/17 19:48:25 [69083] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26579:09/12/17 19:48:25 [69083] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26580:09/12/17 19:48:25 [69083] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26581:09/12/17 19:48:25 [69083] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26582:09/12/17 19:48:25 [69083] (537.0) gm state change: GM_INIT -> GM_START
26583:09/12/17 19:48:25 [69083] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26584:09/12/17 19:48:25 [69083] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26585:09/12/17 19:48:25 [69083] GAHP[69086] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
26586:09/12/17 19:48:25 [69083] GAHP[69086] -> 'S'
26587:09/12/17 19:48:25 [69083] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26588:09/12/17 19:48:25 [69083] (536.0) gm state change: GM_INIT -> GM_START
26589:09/12/17 19:48:25 [69083] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26590:09/12/17 19:48:25 [69083] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26591:09/12/17 19:48:25 [69083] GAHP[69086] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
26592:09/12/17 19:48:25 [69083] GAHP[69086] -> 'S'
26593:09/12/17 19:48:25 [69083] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26594:09/12/17 19:48:25 [69083] (535.0) gm state change: GM_INIT -> GM_START
26595:09/12/17 19:48:25 [69083] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26596:09/12/17 19:48:25 [69083] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26597:09/12/17 19:48:25 [69083] GAHP[69086] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
26598:09/12/17 19:48:25 [69083] GAHP[69086] -> 'S'
26599:09/12/17 19:48:25 [69083] This process has a valid certificate & key
26600:09/12/17 19:48:26 [69083] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26601:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26602:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26603:09/12/17 19:48:26 [69083] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26604:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26605:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26606:09/12/17 19:48:26 [69083] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26607:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26608:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26609:09/12/17 19:48:26 [69083] IPVERIFY: checking mc0151-ib against 128.55.162.46
26610:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26611:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26612:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26613:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26614:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26615:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26616:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26617:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26618:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
26619:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
26620:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
26621:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
26622:09/12/17 19:48:26 [69083] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
26623:09/12/17 19:48:26 [69083] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
26624:09/12/17 19:48:26 [69083] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26625:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26626:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26627:09/12/17 19:48:26 [69083] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26628:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26629:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26630:09/12/17 19:48:26 [69083] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26631:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26632:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26633:09/12/17 19:48:26 [69083] IPVERIFY: checking mc0151-ib against 128.55.162.46
26634:09/12/17 19:48:26 [69083] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26635:09/12/17 19:48:26 [69083] IPVERIFY: ip found is 1
26636:09/12/17 19:48:26 [69083] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26637:09/12/17 19:48:26 [69083] (534.0) gm state change: GM_INIT -> GM_START
26638:09/12/17 19:48:26 [69083] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26639:09/12/17 19:48:26 [69083] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26640:09/12/17 19:48:26 [69083] GAHP[69086] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
26641:09/12/17 19:48:26 [69083] GAHP[69086] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
26642:09/12/17 19:48:26 [69083] GAHP[69086] -> EOF
26643:09/12/17 19:48:26 [69083] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
26644:09/12/17 19:53:24 Result of reading /etc/issue:  \S
26646:09/12/17 19:53:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
26648:09/12/17 19:53:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
26649:09/12/17 19:53:24 Enumerating interfaces: lo 127.0.0.1 up
26650:09/12/17 19:53:24 Enumerating interfaces: eth0 10.36.162.46 up
26651:09/12/17 19:53:24 Enumerating interfaces: ib0 128.55.162.46 up
26652:09/12/17 19:53:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
26653:09/12/17 19:53:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
26654:09/12/17 19:53:24 ******************************************************
26655:09/12/17 19:53:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
26656:09/12/17 19:53:24 ** /usr/sbin/condor_gridmanager
26657:09/12/17 19:53:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
26658:09/12/17 19:53:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
26659:09/12/17 19:53:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
26660:09/12/17 19:53:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
26661:09/12/17 19:53:24 ** PID = 69136
26662:09/12/17 19:53:24 ** Log last touched 9/12 19:48:26
26663:09/12/17 19:53:24 ******************************************************
26664:09/12/17 19:53:24 Using config source: /etc/condor-ce/condor_config
26665:09/12/17 19:53:24 Using local config sources: 
26666:09/12/17 19:53:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
26667:09/12/17 19:53:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
26668:09/12/17 19:53:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
26669:09/12/17 19:53:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
26670:09/12/17 19:53:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
26671:09/12/17 19:53:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
26672:09/12/17 19:53:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
26673:09/12/17 19:53:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
26674:09/12/17 19:53:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
26675:09/12/17 19:53:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
26676:09/12/17 19:53:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
26677:09/12/17 19:53:24    /etc/condor-ce/config.d/01-ce-auth.conf
26678:09/12/17 19:53:24    /etc/condor-ce/config.d/01-ce-router.conf
26679:09/12/17 19:53:24    /etc/condor-ce/config.d/01-common-auth.conf
26680:09/12/17 19:53:24    /etc/condor-ce/config.d/02-ce-slurm.conf
26681:09/12/17 19:53:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
26682:09/12/17 19:53:24    /etc/condor-ce/config.d/03-managed-fork.conf
26683:09/12/17 19:53:24    /etc/condor-ce/config.d/05-ce-health.conf
26684:09/12/17 19:53:24    /etc/condor-ce/config.d/05-ce-view.conf
26685:09/12/17 19:53:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
26686:09/12/17 19:53:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
26687:09/12/17 19:53:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
26688:09/12/17 19:53:24    /etc/condor-ce/config.d/50-osg-configure.conf
26689:09/12/17 19:53:24    /etc/condor-ce/config.d/99-local.conf
26690:09/12/17 19:53:24    /usr/share/condor-ce/condor_ce_router_defaults|
26691:09/12/17 19:53:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
26692:09/12/17 19:53:24 CLASSAD_CACHING is ENABLED
26693:09/12/17 19:53:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
26694:09/12/17 19:53:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_117
26695:09/12/17 19:53:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_117>
26696:09/12/17 19:53:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_117>
26697:09/12/17 19:53:24 Setting maximum accepts per cycle 8.
26698:09/12/17 19:53:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26699:09/12/17 19:53:24 [69136] Welcome to the all-singing, all dancing, "amazing" GridManager!
26700:09/12/17 19:53:24 [69136] DaemonCore: No more children processes to reap.
26701:09/12/17 19:53:24 [69136] DaemonCore: in SendAliveToParent()
26702:09/12/17 19:53:24 [69136] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26703:09/12/17 19:53:24 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26704:09/12/17 19:53:24 [69136] IPVERIFY: ip found is 1
26705:09/12/17 19:53:24 [69136] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26706:09/12/17 19:53:24 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26707:09/12/17 19:53:24 [69136] IPVERIFY: ip found is 1
26708:09/12/17 19:53:24 [69136] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26709:09/12/17 19:53:24 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26710:09/12/17 19:53:24 [69136] IPVERIFY: ip found is 1
26711:09/12/17 19:53:24 [69136] IPVERIFY: checking mc0151-ib against 128.55.162.46
26712:09/12/17 19:53:24 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26713:09/12/17 19:53:24 [69136] IPVERIFY: ip found is 1
26714:09/12/17 19:53:24 [69136] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
26715:09/12/17 19:53:24 [69136] DaemonCore: Leaving SendAliveToParent() - success
26716:09/12/17 19:53:24 [69136] Checking proxies
26717:09/12/17 19:53:27 [69136] Received ADD_JOBS signal
26718:09/12/17 19:53:27 [69136] in doContactSchedd()
26719:09/12/17 19:53:27 [69136] querying for new jobs
26720:09/12/17 19:53:27 [69136] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
26721:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 542.0
26722:09/12/17 19:53:27 [69136] (542.0) SetJobLeaseTimers()
26723:09/12/17 19:53:27 [69136] Found job 542.0 --- inserting
26724:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 541.0
26725:09/12/17 19:53:27 [69136] (541.0) SetJobLeaseTimers()
26726:09/12/17 19:53:27 [69136] Found job 541.0 --- inserting
26727:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 540.0
26728:09/12/17 19:53:27 [69136] (540.0) SetJobLeaseTimers()
26729:09/12/17 19:53:27 [69136] Found job 540.0 --- inserting
26730:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 539.0
26731:09/12/17 19:53:27 [69136] (539.0) SetJobLeaseTimers()
26732:09/12/17 19:53:27 [69136] Found job 539.0 --- inserting
26733:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 538.0
26734:09/12/17 19:53:27 [69136] (538.0) SetJobLeaseTimers()
26735:09/12/17 19:53:27 [69136] Found job 538.0 --- inserting
26736:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 537.0
26737:09/12/17 19:53:27 [69136] (537.0) SetJobLeaseTimers()
26738:09/12/17 19:53:27 [69136] Found job 537.0 --- inserting
26739:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 536.0
26740:09/12/17 19:53:27 [69136] (536.0) SetJobLeaseTimers()
26741:09/12/17 19:53:27 [69136] Found job 536.0 --- inserting
26742:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 535.0
26743:09/12/17 19:53:27 [69136] (535.0) SetJobLeaseTimers()
26744:09/12/17 19:53:27 [69136] Found job 535.0 --- inserting
26745:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 534.0
26746:09/12/17 19:53:27 [69136] (534.0) SetJobLeaseTimers()
26747:09/12/17 19:53:27 [69136] Found job 534.0 --- inserting
26748:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 533.0
26749:09/12/17 19:53:27 [69136] (533.0) SetJobLeaseTimers()
26750:09/12/17 19:53:27 [69136] Found job 533.0 --- inserting
26751:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 532.0
26752:09/12/17 19:53:27 [69136] (532.0) SetJobLeaseTimers()
26753:09/12/17 19:53:27 [69136] Found job 532.0 --- inserting
26754:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 531.0
26755:09/12/17 19:53:27 [69136] (531.0) SetJobLeaseTimers()
26756:09/12/17 19:53:27 [69136] Found job 531.0 --- inserting
26757:09/12/17 19:53:27 [69136] Using job type INFNBatch for job 530.0
26758:09/12/17 19:53:27 [69136] (530.0) SetJobLeaseTimers()
26759:09/12/17 19:53:27 [69136] Found job 530.0 --- inserting
26760:09/12/17 19:53:27 [69136] Fetched 13 new job ads from schedd
26761:09/12/17 19:53:27 [69136] querying for removed/held jobs
26762:09/12/17 19:53:27 [69136] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
26763:09/12/17 19:53:27 [69136] Fetched 0 job ads from schedd
26764:09/12/17 19:53:27 [69136] leaving doContactSchedd()
26765:09/12/17 19:53:27 [69136] gahp server not up yet, delaying ping
26766:09/12/17 19:53:27 [69136] *** UpdateLeases called
26767:09/12/17 19:53:27 [69136]     Leases not supported, cancelling timer
26768:09/12/17 19:53:27 [69136] BaseResource::UpdateResource: 
26788:09/12/17 19:53:27 [69136] Trying to update collector <128.55.162.46:9619>
26789:09/12/17 19:53:27 [69136] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26790:09/12/17 19:53:27 [69136] File descriptor limits: max 4096, safe 3277
26791:09/12/17 19:53:27 [69136] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26792:09/12/17 19:53:27 [69136] GAHP server pid = 69139
26793:09/12/17 19:53:27 [69136] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
26794:09/12/17 19:53:27 [69136] GAHP[69139] <- 'COMMANDS'
26795:09/12/17 19:53:27 [69136] GAHP[69139] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
26796:09/12/17 19:53:27 [69136] GAHP[69139] <- 'ASYNC_MODE_ON'
26797:09/12/17 19:53:27 [69136] GAHP[69139] -> 'S' 'Async mode on'
26798:09/12/17 19:53:27 [69136] (542.0) gm state change: GM_INIT -> GM_START
26799:09/12/17 19:53:27 [69136] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26800:09/12/17 19:53:27 [69136] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26801:09/12/17 19:53:27 [69136] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26802:09/12/17 19:53:27 [69136] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26803:09/12/17 19:53:27 [69136] (541.0) gm state change: GM_INIT -> GM_START
26804:09/12/17 19:53:27 [69136] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26805:09/12/17 19:53:27 [69136] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26806:09/12/17 19:53:27 [69136] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26807:09/12/17 19:53:27 [69136] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26808:09/12/17 19:53:27 [69136] (540.0) gm state change: GM_INIT -> GM_START
26809:09/12/17 19:53:27 [69136] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26810:09/12/17 19:53:27 [69136] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26811:09/12/17 19:53:27 [69136] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26812:09/12/17 19:53:27 [69136] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26813:09/12/17 19:53:27 [69136] (539.0) gm state change: GM_INIT -> GM_START
26814:09/12/17 19:53:27 [69136] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26815:09/12/17 19:53:27 [69136] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26816:09/12/17 19:53:27 [69136] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26817:09/12/17 19:53:27 [69136] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
26818:09/12/17 19:53:27 [69136] (538.0) gm state change: GM_INIT -> GM_START
26819:09/12/17 19:53:27 [69136] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
26820:09/12/17 19:53:27 [69136] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
26821:09/12/17 19:53:27 [69136] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
26822:09/12/17 19:53:27 [69136] This process has a valid certificate & key
26823:09/12/17 19:53:27 [69136] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26824:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26825:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26826:09/12/17 19:53:27 [69136] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26827:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26828:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26829:09/12/17 19:53:27 [69136] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26830:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26831:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26832:09/12/17 19:53:27 [69136] IPVERIFY: checking mc0151-ib against 128.55.162.46
26833:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26834:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26835:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26836:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26837:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26838:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26839:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26840:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
26841:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
26842:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
26843:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
26844:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
26845:09/12/17 19:53:27 [69136] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
26846:09/12/17 19:53:27 [69136] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
26847:09/12/17 19:53:27 [69136] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26848:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26849:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26850:09/12/17 19:53:27 [69136] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26851:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26852:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26853:09/12/17 19:53:27 [69136] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26854:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26855:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26856:09/12/17 19:53:27 [69136] IPVERIFY: checking mc0151-ib against 128.55.162.46
26857:09/12/17 19:53:27 [69136] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26858:09/12/17 19:53:27 [69136] IPVERIFY: ip found is 1
26859:09/12/17 19:53:27 [69136] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26860:09/12/17 19:53:27 [69136] (537.0) gm state change: GM_INIT -> GM_START
26861:09/12/17 19:53:27 [69136] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26862:09/12/17 19:53:27 [69136] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26863:09/12/17 19:53:27 [69136] GAHP[69139] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
26864:09/12/17 19:53:27 [69136] GAHP[69139] -> 'S'
26865:09/12/17 19:53:27 [69136] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26866:09/12/17 19:53:27 [69136] (536.0) gm state change: GM_INIT -> GM_START
26867:09/12/17 19:53:27 [69136] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26868:09/12/17 19:53:27 [69136] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26869:09/12/17 19:53:27 [69136] GAHP[69139] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
26870:09/12/17 19:53:27 [69136] GAHP[69139] -> 'S'
26871:09/12/17 19:53:27 [69136] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26872:09/12/17 19:53:27 [69136] (535.0) gm state change: GM_INIT -> GM_START
26873:09/12/17 19:53:27 [69136] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26874:09/12/17 19:53:27 [69136] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26875:09/12/17 19:53:27 [69136] GAHP[69139] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
26876:09/12/17 19:53:27 [69136] GAHP[69139] -> 'S'
26877:09/12/17 19:53:27 [69136] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
26878:09/12/17 19:53:27 [69136] (534.0) gm state change: GM_INIT -> GM_START
26879:09/12/17 19:53:27 [69136] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
26880:09/12/17 19:53:27 [69136] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
26881:09/12/17 19:53:27 [69136] GAHP[69139] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
26882:09/12/17 19:53:27 [69136] GAHP[69139] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
26883:09/12/17 19:53:27 [69136] GAHP[69139] -> EOF
26884:09/12/17 19:53:27 [69136] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
26885:09/12/17 19:58:24 Result of reading /etc/issue:  \S
26887:09/12/17 19:58:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
26889:09/12/17 19:58:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
26890:09/12/17 19:58:24 Enumerating interfaces: lo 127.0.0.1 up
26891:09/12/17 19:58:24 Enumerating interfaces: eth0 10.36.162.46 up
26892:09/12/17 19:58:24 Enumerating interfaces: ib0 128.55.162.46 up
26893:09/12/17 19:58:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
26894:09/12/17 19:58:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
26895:09/12/17 19:58:24 ******************************************************
26896:09/12/17 19:58:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
26897:09/12/17 19:58:24 ** /usr/sbin/condor_gridmanager
26898:09/12/17 19:58:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
26899:09/12/17 19:58:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
26900:09/12/17 19:58:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
26901:09/12/17 19:58:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
26902:09/12/17 19:58:24 ** PID = 69188
26903:09/12/17 19:58:24 ** Log last touched 9/12 19:53:27
26904:09/12/17 19:58:24 ******************************************************
26905:09/12/17 19:58:24 Using config source: /etc/condor-ce/condor_config
26906:09/12/17 19:58:24 Using local config sources: 
26907:09/12/17 19:58:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
26908:09/12/17 19:58:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
26909:09/12/17 19:58:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
26910:09/12/17 19:58:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
26911:09/12/17 19:58:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
26912:09/12/17 19:58:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
26913:09/12/17 19:58:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
26914:09/12/17 19:58:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
26915:09/12/17 19:58:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
26916:09/12/17 19:58:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
26917:09/12/17 19:58:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
26918:09/12/17 19:58:24    /etc/condor-ce/config.d/01-ce-auth.conf
26919:09/12/17 19:58:24    /etc/condor-ce/config.d/01-ce-router.conf
26920:09/12/17 19:58:24    /etc/condor-ce/config.d/01-common-auth.conf
26921:09/12/17 19:58:24    /etc/condor-ce/config.d/02-ce-slurm.conf
26922:09/12/17 19:58:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
26923:09/12/17 19:58:24    /etc/condor-ce/config.d/03-managed-fork.conf
26924:09/12/17 19:58:24    /etc/condor-ce/config.d/05-ce-health.conf
26925:09/12/17 19:58:24    /etc/condor-ce/config.d/05-ce-view.conf
26926:09/12/17 19:58:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
26927:09/12/17 19:58:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
26928:09/12/17 19:58:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
26929:09/12/17 19:58:24    /etc/condor-ce/config.d/50-osg-configure.conf
26930:09/12/17 19:58:24    /etc/condor-ce/config.d/99-local.conf
26931:09/12/17 19:58:24    /usr/share/condor-ce/condor_ce_router_defaults|
26932:09/12/17 19:58:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
26933:09/12/17 19:58:24 CLASSAD_CACHING is ENABLED
26934:09/12/17 19:58:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
26935:09/12/17 19:58:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_120
26936:09/12/17 19:58:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_120>
26937:09/12/17 19:58:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_120>
26938:09/12/17 19:58:24 Setting maximum accepts per cycle 8.
26939:09/12/17 19:58:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
26940:09/12/17 19:58:24 [69188] Welcome to the all-singing, all dancing, "amazing" GridManager!
26941:09/12/17 19:58:24 [69188] DaemonCore: No more children processes to reap.
26942:09/12/17 19:58:24 [69188] DaemonCore: in SendAliveToParent()
26943:09/12/17 19:58:24 [69188] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
26944:09/12/17 19:58:24 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26945:09/12/17 19:58:24 [69188] IPVERIFY: ip found is 1
26946:09/12/17 19:58:24 [69188] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
26947:09/12/17 19:58:24 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26948:09/12/17 19:58:24 [69188] IPVERIFY: ip found is 1
26949:09/12/17 19:58:24 [69188] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
26950:09/12/17 19:58:24 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26951:09/12/17 19:58:24 [69188] IPVERIFY: ip found is 1
26952:09/12/17 19:58:24 [69188] IPVERIFY: checking mc0151-ib against 128.55.162.46
26953:09/12/17 19:58:24 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
26954:09/12/17 19:58:24 [69188] IPVERIFY: ip found is 1
26955:09/12/17 19:58:24 [69188] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
26956:09/12/17 19:58:24 [69188] DaemonCore: Leaving SendAliveToParent() - success
26957:09/12/17 19:58:24 [69188] Checking proxies
26958:09/12/17 19:58:27 [69188] Received ADD_JOBS signal
26959:09/12/17 19:58:27 [69188] in doContactSchedd()
26960:09/12/17 19:58:27 [69188] querying for new jobs
26961:09/12/17 19:58:27 [69188] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
26962:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 542.0
26963:09/12/17 19:58:27 [69188] (542.0) SetJobLeaseTimers()
26964:09/12/17 19:58:27 [69188] Found job 542.0 --- inserting
26965:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 541.0
26966:09/12/17 19:58:27 [69188] (541.0) SetJobLeaseTimers()
26967:09/12/17 19:58:27 [69188] Found job 541.0 --- inserting
26968:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 540.0
26969:09/12/17 19:58:27 [69188] (540.0) SetJobLeaseTimers()
26970:09/12/17 19:58:27 [69188] Found job 540.0 --- inserting
26971:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 539.0
26972:09/12/17 19:58:27 [69188] (539.0) SetJobLeaseTimers()
26973:09/12/17 19:58:27 [69188] Found job 539.0 --- inserting
26974:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 538.0
26975:09/12/17 19:58:27 [69188] (538.0) SetJobLeaseTimers()
26976:09/12/17 19:58:27 [69188] Found job 538.0 --- inserting
26977:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 537.0
26978:09/12/17 19:58:27 [69188] (537.0) SetJobLeaseTimers()
26979:09/12/17 19:58:27 [69188] Found job 537.0 --- inserting
26980:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 536.0
26981:09/12/17 19:58:27 [69188] (536.0) SetJobLeaseTimers()
26982:09/12/17 19:58:27 [69188] Found job 536.0 --- inserting
26983:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 535.0
26984:09/12/17 19:58:27 [69188] (535.0) SetJobLeaseTimers()
26985:09/12/17 19:58:27 [69188] Found job 535.0 --- inserting
26986:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 534.0
26987:09/12/17 19:58:27 [69188] (534.0) SetJobLeaseTimers()
26988:09/12/17 19:58:27 [69188] Found job 534.0 --- inserting
26989:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 533.0
26990:09/12/17 19:58:27 [69188] (533.0) SetJobLeaseTimers()
26991:09/12/17 19:58:27 [69188] Found job 533.0 --- inserting
26992:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 532.0
26993:09/12/17 19:58:27 [69188] (532.0) SetJobLeaseTimers()
26994:09/12/17 19:58:27 [69188] Found job 532.0 --- inserting
26995:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 531.0
26996:09/12/17 19:58:27 [69188] (531.0) SetJobLeaseTimers()
26997:09/12/17 19:58:27 [69188] Found job 531.0 --- inserting
26998:09/12/17 19:58:27 [69188] Using job type INFNBatch for job 530.0
26999:09/12/17 19:58:27 [69188] (530.0) SetJobLeaseTimers()
27000:09/12/17 19:58:27 [69188] Found job 530.0 --- inserting
27001:09/12/17 19:58:27 [69188] Fetched 13 new job ads from schedd
27002:09/12/17 19:58:27 [69188] querying for removed/held jobs
27003:09/12/17 19:58:27 [69188] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
27004:09/12/17 19:58:27 [69188] Fetched 0 job ads from schedd
27005:09/12/17 19:58:27 [69188] leaving doContactSchedd()
27006:09/12/17 19:58:27 [69188] gahp server not up yet, delaying ping
27007:09/12/17 19:58:27 [69188] *** UpdateLeases called
27008:09/12/17 19:58:27 [69188]     Leases not supported, cancelling timer
27009:09/12/17 19:58:27 [69188] BaseResource::UpdateResource: 
27029:09/12/17 19:58:27 [69188] Trying to update collector <128.55.162.46:9619>
27030:09/12/17 19:58:27 [69188] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27031:09/12/17 19:58:27 [69188] File descriptor limits: max 4096, safe 3277
27032:09/12/17 19:58:27 [69188] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27033:09/12/17 19:58:27 [69188] GAHP server pid = 69191
27034:09/12/17 19:58:27 [69188] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
27035:09/12/17 19:58:27 [69188] GAHP[69191] <- 'COMMANDS'
27036:09/12/17 19:58:27 [69188] GAHP[69191] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
27037:09/12/17 19:58:27 [69188] GAHP[69191] <- 'ASYNC_MODE_ON'
27038:09/12/17 19:58:27 [69188] GAHP[69191] -> 'S' 'Async mode on'
27039:09/12/17 19:58:27 [69188] (542.0) gm state change: GM_INIT -> GM_START
27040:09/12/17 19:58:27 [69188] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27041:09/12/17 19:58:27 [69188] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27042:09/12/17 19:58:27 [69188] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27043:09/12/17 19:58:27 [69188] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27044:09/12/17 19:58:27 [69188] (541.0) gm state change: GM_INIT -> GM_START
27045:09/12/17 19:58:27 [69188] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27046:09/12/17 19:58:27 [69188] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27047:09/12/17 19:58:27 [69188] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27048:09/12/17 19:58:27 [69188] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27049:09/12/17 19:58:27 [69188] (540.0) gm state change: GM_INIT -> GM_START
27050:09/12/17 19:58:27 [69188] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27051:09/12/17 19:58:27 [69188] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27052:09/12/17 19:58:27 [69188] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27053:09/12/17 19:58:27 [69188] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27054:09/12/17 19:58:27 [69188] (539.0) gm state change: GM_INIT -> GM_START
27055:09/12/17 19:58:27 [69188] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27056:09/12/17 19:58:27 [69188] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27057:09/12/17 19:58:27 [69188] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27058:09/12/17 19:58:27 [69188] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27059:09/12/17 19:58:27 [69188] (538.0) gm state change: GM_INIT -> GM_START
27060:09/12/17 19:58:27 [69188] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27061:09/12/17 19:58:27 [69188] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27062:09/12/17 19:58:27 [69188] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27063:09/12/17 19:58:27 [69188] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27064:09/12/17 19:58:27 [69188] (537.0) gm state change: GM_INIT -> GM_START
27065:09/12/17 19:58:27 [69188] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27066:09/12/17 19:58:27 [69188] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27067:09/12/17 19:58:27 [69188] GAHP[69191] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
27068:09/12/17 19:58:27 [69188] GAHP[69191] -> 'S'
27069:09/12/17 19:58:27 [69188] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27070:09/12/17 19:58:27 [69188] (536.0) gm state change: GM_INIT -> GM_START
27071:09/12/17 19:58:27 [69188] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27072:09/12/17 19:58:27 [69188] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27073:09/12/17 19:58:27 [69188] GAHP[69191] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
27074:09/12/17 19:58:27 [69188] GAHP[69191] -> 'S'
27075:09/12/17 19:58:27 [69188] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27076:09/12/17 19:58:27 [69188] (535.0) gm state change: GM_INIT -> GM_START
27077:09/12/17 19:58:27 [69188] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27078:09/12/17 19:58:27 [69188] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27079:09/12/17 19:58:27 [69188] GAHP[69191] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
27080:09/12/17 19:58:27 [69188] GAHP[69191] -> 'S'
27081:09/12/17 19:58:27 [69188] This process has a valid certificate & key
27082:09/12/17 19:58:27 [69188] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27083:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27084:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27085:09/12/17 19:58:27 [69188] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27086:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27087:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27088:09/12/17 19:58:27 [69188] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27089:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27090:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27091:09/12/17 19:58:27 [69188] IPVERIFY: checking mc0151-ib against 128.55.162.46
27092:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27093:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27094:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27095:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27096:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27097:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27098:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27099:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27100:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
27101:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
27102:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
27103:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
27104:09/12/17 19:58:27 [69188] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
27105:09/12/17 19:58:27 [69188] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
27106:09/12/17 19:58:27 [69188] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27107:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27108:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27109:09/12/17 19:58:27 [69188] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27110:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27111:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27112:09/12/17 19:58:27 [69188] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27113:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27114:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27115:09/12/17 19:58:27 [69188] IPVERIFY: checking mc0151-ib against 128.55.162.46
27116:09/12/17 19:58:27 [69188] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27117:09/12/17 19:58:27 [69188] IPVERIFY: ip found is 1
27118:09/12/17 19:58:27 [69188] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27119:09/12/17 19:58:27 [69188] (534.0) gm state change: GM_INIT -> GM_START
27120:09/12/17 19:58:27 [69188] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27121:09/12/17 19:58:27 [69188] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27122:09/12/17 19:58:27 [69188] GAHP[69191] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
27123:09/12/17 19:58:27 [69188] GAHP[69191] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
27124:09/12/17 19:58:27 [69188] GAHP[69191] -> EOF
27125:09/12/17 19:58:27 [69188] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
27126:09/12/17 20:03:24 Result of reading /etc/issue:  \S
27128:09/12/17 20:03:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
27130:09/12/17 20:03:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
27131:09/12/17 20:03:24 Enumerating interfaces: lo 127.0.0.1 up
27132:09/12/17 20:03:24 Enumerating interfaces: eth0 10.36.162.46 up
27133:09/12/17 20:03:24 Enumerating interfaces: ib0 128.55.162.46 up
27134:09/12/17 20:03:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
27135:09/12/17 20:03:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
27136:09/12/17 20:03:24 ******************************************************
27137:09/12/17 20:03:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
27138:09/12/17 20:03:24 ** /usr/sbin/condor_gridmanager
27139:09/12/17 20:03:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
27140:09/12/17 20:03:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
27141:09/12/17 20:03:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
27142:09/12/17 20:03:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
27143:09/12/17 20:03:24 ** PID = 69315
27144:09/12/17 20:03:24 ** Log last touched 9/12 19:58:27
27145:09/12/17 20:03:24 ******************************************************
27146:09/12/17 20:03:24 Using config source: /etc/condor-ce/condor_config
27147:09/12/17 20:03:24 Using local config sources: 
27148:09/12/17 20:03:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
27149:09/12/17 20:03:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
27150:09/12/17 20:03:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
27151:09/12/17 20:03:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
27152:09/12/17 20:03:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
27153:09/12/17 20:03:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
27154:09/12/17 20:03:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
27155:09/12/17 20:03:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
27156:09/12/17 20:03:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
27157:09/12/17 20:03:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
27158:09/12/17 20:03:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
27159:09/12/17 20:03:24    /etc/condor-ce/config.d/01-ce-auth.conf
27160:09/12/17 20:03:24    /etc/condor-ce/config.d/01-ce-router.conf
27161:09/12/17 20:03:24    /etc/condor-ce/config.d/01-common-auth.conf
27162:09/12/17 20:03:24    /etc/condor-ce/config.d/02-ce-slurm.conf
27163:09/12/17 20:03:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
27164:09/12/17 20:03:24    /etc/condor-ce/config.d/03-managed-fork.conf
27165:09/12/17 20:03:24    /etc/condor-ce/config.d/05-ce-health.conf
27166:09/12/17 20:03:24    /etc/condor-ce/config.d/05-ce-view.conf
27167:09/12/17 20:03:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
27168:09/12/17 20:03:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
27169:09/12/17 20:03:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
27170:09/12/17 20:03:24    /etc/condor-ce/config.d/50-osg-configure.conf
27171:09/12/17 20:03:24    /etc/condor-ce/config.d/99-local.conf
27172:09/12/17 20:03:24    /usr/share/condor-ce/condor_ce_router_defaults|
27173:09/12/17 20:03:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
27174:09/12/17 20:03:24 CLASSAD_CACHING is ENABLED
27175:09/12/17 20:03:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
27176:09/12/17 20:03:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_123
27177:09/12/17 20:03:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_123>
27178:09/12/17 20:03:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_123>
27179:09/12/17 20:03:24 Setting maximum accepts per cycle 8.
27180:09/12/17 20:03:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27181:09/12/17 20:03:24 [69315] Welcome to the all-singing, all dancing, "amazing" GridManager!
27182:09/12/17 20:03:24 [69315] DaemonCore: No more children processes to reap.
27183:09/12/17 20:03:24 [69315] DaemonCore: in SendAliveToParent()
27184:09/12/17 20:03:24 [69315] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27185:09/12/17 20:03:24 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27186:09/12/17 20:03:24 [69315] IPVERIFY: ip found is 1
27187:09/12/17 20:03:24 [69315] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27188:09/12/17 20:03:24 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27189:09/12/17 20:03:24 [69315] IPVERIFY: ip found is 1
27190:09/12/17 20:03:24 [69315] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27191:09/12/17 20:03:24 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27192:09/12/17 20:03:24 [69315] IPVERIFY: ip found is 1
27193:09/12/17 20:03:24 [69315] IPVERIFY: checking mc0151-ib against 128.55.162.46
27194:09/12/17 20:03:24 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27195:09/12/17 20:03:24 [69315] IPVERIFY: ip found is 1
27196:09/12/17 20:03:24 [69315] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
27197:09/12/17 20:03:24 [69315] DaemonCore: Leaving SendAliveToParent() - success
27198:09/12/17 20:03:24 [69315] Checking proxies
27199:09/12/17 20:03:27 [69315] Received ADD_JOBS signal
27200:09/12/17 20:03:27 [69315] in doContactSchedd()
27201:09/12/17 20:03:27 [69315] querying for new jobs
27202:09/12/17 20:03:27 [69315] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
27203:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 542.0
27204:09/12/17 20:03:27 [69315] (542.0) SetJobLeaseTimers()
27205:09/12/17 20:03:27 [69315] Found job 542.0 --- inserting
27206:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 541.0
27207:09/12/17 20:03:27 [69315] (541.0) SetJobLeaseTimers()
27208:09/12/17 20:03:27 [69315] Found job 541.0 --- inserting
27209:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 540.0
27210:09/12/17 20:03:27 [69315] (540.0) SetJobLeaseTimers()
27211:09/12/17 20:03:27 [69315] Found job 540.0 --- inserting
27212:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 539.0
27213:09/12/17 20:03:27 [69315] (539.0) SetJobLeaseTimers()
27214:09/12/17 20:03:27 [69315] Found job 539.0 --- inserting
27215:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 538.0
27216:09/12/17 20:03:27 [69315] (538.0) SetJobLeaseTimers()
27217:09/12/17 20:03:27 [69315] Found job 538.0 --- inserting
27218:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 537.0
27219:09/12/17 20:03:27 [69315] (537.0) SetJobLeaseTimers()
27220:09/12/17 20:03:27 [69315] Found job 537.0 --- inserting
27221:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 536.0
27222:09/12/17 20:03:27 [69315] (536.0) SetJobLeaseTimers()
27223:09/12/17 20:03:27 [69315] Found job 536.0 --- inserting
27224:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 535.0
27225:09/12/17 20:03:27 [69315] (535.0) SetJobLeaseTimers()
27226:09/12/17 20:03:27 [69315] Found job 535.0 --- inserting
27227:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 534.0
27228:09/12/17 20:03:27 [69315] (534.0) SetJobLeaseTimers()
27229:09/12/17 20:03:27 [69315] Found job 534.0 --- inserting
27230:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 533.0
27231:09/12/17 20:03:27 [69315] (533.0) SetJobLeaseTimers()
27232:09/12/17 20:03:27 [69315] Found job 533.0 --- inserting
27233:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 532.0
27234:09/12/17 20:03:27 [69315] (532.0) SetJobLeaseTimers()
27235:09/12/17 20:03:27 [69315] Found job 532.0 --- inserting
27236:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 531.0
27237:09/12/17 20:03:27 [69315] (531.0) SetJobLeaseTimers()
27238:09/12/17 20:03:27 [69315] Found job 531.0 --- inserting
27239:09/12/17 20:03:27 [69315] Using job type INFNBatch for job 530.0
27240:09/12/17 20:03:27 [69315] (530.0) SetJobLeaseTimers()
27241:09/12/17 20:03:27 [69315] Found job 530.0 --- inserting
27242:09/12/17 20:03:27 [69315] Fetched 13 new job ads from schedd
27243:09/12/17 20:03:27 [69315] querying for removed/held jobs
27244:09/12/17 20:03:27 [69315] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
27245:09/12/17 20:03:27 [69315] Fetched 0 job ads from schedd
27246:09/12/17 20:03:27 [69315] leaving doContactSchedd()
27247:09/12/17 20:03:27 [69315] gahp server not up yet, delaying ping
27248:09/12/17 20:03:27 [69315] *** UpdateLeases called
27249:09/12/17 20:03:27 [69315]     Leases not supported, cancelling timer
27250:09/12/17 20:03:27 [69315] BaseResource::UpdateResource: 
27270:09/12/17 20:03:27 [69315] Trying to update collector <128.55.162.46:9619>
27271:09/12/17 20:03:27 [69315] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27272:09/12/17 20:03:27 [69315] File descriptor limits: max 4096, safe 3277
27273:09/12/17 20:03:27 [69315] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27274:09/12/17 20:03:27 [69315] GAHP server pid = 69318
27275:09/12/17 20:03:27 [69315] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
27276:09/12/17 20:03:27 [69315] GAHP[69318] <- 'COMMANDS'
27277:09/12/17 20:03:27 [69315] GAHP[69318] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
27278:09/12/17 20:03:27 [69315] GAHP[69318] <- 'ASYNC_MODE_ON'
27279:09/12/17 20:03:27 [69315] GAHP[69318] -> 'S' 'Async mode on'
27280:09/12/17 20:03:27 [69315] (542.0) gm state change: GM_INIT -> GM_START
27281:09/12/17 20:03:27 [69315] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27282:09/12/17 20:03:27 [69315] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27283:09/12/17 20:03:27 [69315] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27284:09/12/17 20:03:27 [69315] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27285:09/12/17 20:03:27 [69315] (541.0) gm state change: GM_INIT -> GM_START
27286:09/12/17 20:03:27 [69315] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27287:09/12/17 20:03:27 [69315] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27288:09/12/17 20:03:27 [69315] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27289:09/12/17 20:03:27 [69315] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27290:09/12/17 20:03:27 [69315] (540.0) gm state change: GM_INIT -> GM_START
27291:09/12/17 20:03:27 [69315] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27292:09/12/17 20:03:27 [69315] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27293:09/12/17 20:03:27 [69315] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27294:09/12/17 20:03:27 [69315] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27295:09/12/17 20:03:27 [69315] (539.0) gm state change: GM_INIT -> GM_START
27296:09/12/17 20:03:27 [69315] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27297:09/12/17 20:03:27 [69315] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27298:09/12/17 20:03:27 [69315] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27299:09/12/17 20:03:27 [69315] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27300:09/12/17 20:03:27 [69315] (538.0) gm state change: GM_INIT -> GM_START
27301:09/12/17 20:03:27 [69315] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27302:09/12/17 20:03:27 [69315] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27303:09/12/17 20:03:27 [69315] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27304:09/12/17 20:03:27 [69315] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27305:09/12/17 20:03:27 [69315] (537.0) gm state change: GM_INIT -> GM_START
27306:09/12/17 20:03:27 [69315] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27307:09/12/17 20:03:27 [69315] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27308:09/12/17 20:03:27 [69315] GAHP[69318] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
27309:09/12/17 20:03:27 [69315] GAHP[69318] -> 'S'
27310:09/12/17 20:03:27 [69315] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27311:09/12/17 20:03:27 [69315] (536.0) gm state change: GM_INIT -> GM_START
27312:09/12/17 20:03:27 [69315] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27313:09/12/17 20:03:27 [69315] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27314:09/12/17 20:03:27 [69315] GAHP[69318] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
27315:09/12/17 20:03:27 [69315] GAHP[69318] -> 'S'
27316:09/12/17 20:03:27 [69315] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27317:09/12/17 20:03:27 [69315] (535.0) gm state change: GM_INIT -> GM_START
27318:09/12/17 20:03:27 [69315] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27319:09/12/17 20:03:27 [69315] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27320:09/12/17 20:03:27 [69315] GAHP[69318] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
27321:09/12/17 20:03:27 [69315] GAHP[69318] -> 'S'
27322:09/12/17 20:03:27 [69315] This process has a valid certificate & key
27323:09/12/17 20:03:27 [69315] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27324:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27325:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27326:09/12/17 20:03:27 [69315] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27327:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27328:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27329:09/12/17 20:03:27 [69315] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27330:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27331:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27332:09/12/17 20:03:27 [69315] IPVERIFY: checking mc0151-ib against 128.55.162.46
27333:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27334:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27335:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27336:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27337:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27338:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27339:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27340:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27341:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
27342:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
27343:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
27344:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
27345:09/12/17 20:03:27 [69315] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
27346:09/12/17 20:03:27 [69315] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
27347:09/12/17 20:03:27 [69315] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27348:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27349:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27350:09/12/17 20:03:27 [69315] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27351:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27352:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27353:09/12/17 20:03:27 [69315] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27354:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27355:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27356:09/12/17 20:03:27 [69315] IPVERIFY: checking mc0151-ib against 128.55.162.46
27357:09/12/17 20:03:27 [69315] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27358:09/12/17 20:03:27 [69315] IPVERIFY: ip found is 1
27359:09/12/17 20:03:27 [69315] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27360:09/12/17 20:03:27 [69315] (534.0) gm state change: GM_INIT -> GM_START
27361:09/12/17 20:03:27 [69315] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27362:09/12/17 20:03:27 [69315] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27363:09/12/17 20:03:27 [69315] GAHP[69318] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
27364:09/12/17 20:03:27 [69315] GAHP[69318] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
27365:09/12/17 20:03:27 [69315] GAHP[69318] -> EOF
27366:09/12/17 20:03:27 [69315] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
27367:09/12/17 20:08:24 Result of reading /etc/issue:  \S
27369:09/12/17 20:08:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
27371:09/12/17 20:08:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
27372:09/12/17 20:08:24 Enumerating interfaces: lo 127.0.0.1 up
27373:09/12/17 20:08:24 Enumerating interfaces: eth0 10.36.162.46 up
27374:09/12/17 20:08:24 Enumerating interfaces: ib0 128.55.162.46 up
27375:09/12/17 20:08:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
27376:09/12/17 20:08:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
27377:09/12/17 20:08:24 ******************************************************
27378:09/12/17 20:08:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
27379:09/12/17 20:08:24 ** /usr/sbin/condor_gridmanager
27380:09/12/17 20:08:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
27381:09/12/17 20:08:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
27382:09/12/17 20:08:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
27383:09/12/17 20:08:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
27384:09/12/17 20:08:24 ** PID = 69359
27385:09/12/17 20:08:24 ** Log last touched 9/12 20:03:27
27386:09/12/17 20:08:24 ******************************************************
27387:09/12/17 20:08:24 Using config source: /etc/condor-ce/condor_config
27388:09/12/17 20:08:24 Using local config sources: 
27389:09/12/17 20:08:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
27390:09/12/17 20:08:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
27391:09/12/17 20:08:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
27392:09/12/17 20:08:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
27393:09/12/17 20:08:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
27394:09/12/17 20:08:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
27395:09/12/17 20:08:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
27396:09/12/17 20:08:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
27397:09/12/17 20:08:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
27398:09/12/17 20:08:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
27399:09/12/17 20:08:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
27400:09/12/17 20:08:24    /etc/condor-ce/config.d/01-ce-auth.conf
27401:09/12/17 20:08:24    /etc/condor-ce/config.d/01-ce-router.conf
27402:09/12/17 20:08:24    /etc/condor-ce/config.d/01-common-auth.conf
27403:09/12/17 20:08:24    /etc/condor-ce/config.d/02-ce-slurm.conf
27404:09/12/17 20:08:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
27405:09/12/17 20:08:24    /etc/condor-ce/config.d/03-managed-fork.conf
27406:09/12/17 20:08:24    /etc/condor-ce/config.d/05-ce-health.conf
27407:09/12/17 20:08:24    /etc/condor-ce/config.d/05-ce-view.conf
27408:09/12/17 20:08:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
27409:09/12/17 20:08:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
27410:09/12/17 20:08:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
27411:09/12/17 20:08:24    /etc/condor-ce/config.d/50-osg-configure.conf
27412:09/12/17 20:08:24    /etc/condor-ce/config.d/99-local.conf
27413:09/12/17 20:08:24    /usr/share/condor-ce/condor_ce_router_defaults|
27414:09/12/17 20:08:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
27415:09/12/17 20:08:24 CLASSAD_CACHING is ENABLED
27416:09/12/17 20:08:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
27417:09/12/17 20:08:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_125
27418:09/12/17 20:08:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_125>
27419:09/12/17 20:08:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_125>
27420:09/12/17 20:08:24 Setting maximum accepts per cycle 8.
27421:09/12/17 20:08:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27422:09/12/17 20:08:24 [69359] Welcome to the all-singing, all dancing, "amazing" GridManager!
27423:09/12/17 20:08:24 [69359] DaemonCore: No more children processes to reap.
27424:09/12/17 20:08:24 [69359] DaemonCore: in SendAliveToParent()
27425:09/12/17 20:08:24 [69359] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27426:09/12/17 20:08:24 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27427:09/12/17 20:08:24 [69359] IPVERIFY: ip found is 1
27428:09/12/17 20:08:24 [69359] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27429:09/12/17 20:08:24 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27430:09/12/17 20:08:24 [69359] IPVERIFY: ip found is 1
27431:09/12/17 20:08:24 [69359] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27432:09/12/17 20:08:24 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27433:09/12/17 20:08:24 [69359] IPVERIFY: ip found is 1
27434:09/12/17 20:08:24 [69359] IPVERIFY: checking mc0151-ib against 128.55.162.46
27435:09/12/17 20:08:24 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27436:09/12/17 20:08:24 [69359] IPVERIFY: ip found is 1
27437:09/12/17 20:08:24 [69359] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
27438:09/12/17 20:08:24 [69359] DaemonCore: Leaving SendAliveToParent() - success
27439:09/12/17 20:08:24 [69359] Checking proxies
27440:09/12/17 20:08:27 [69359] Received ADD_JOBS signal
27441:09/12/17 20:08:27 [69359] in doContactSchedd()
27442:09/12/17 20:08:27 [69359] querying for new jobs
27443:09/12/17 20:08:27 [69359] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
27444:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 542.0
27445:09/12/17 20:08:27 [69359] (542.0) SetJobLeaseTimers()
27446:09/12/17 20:08:27 [69359] Found job 542.0 --- inserting
27447:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 541.0
27448:09/12/17 20:08:27 [69359] (541.0) SetJobLeaseTimers()
27449:09/12/17 20:08:27 [69359] Found job 541.0 --- inserting
27450:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 540.0
27451:09/12/17 20:08:27 [69359] (540.0) SetJobLeaseTimers()
27452:09/12/17 20:08:27 [69359] Found job 540.0 --- inserting
27453:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 539.0
27454:09/12/17 20:08:27 [69359] (539.0) SetJobLeaseTimers()
27455:09/12/17 20:08:27 [69359] Found job 539.0 --- inserting
27456:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 538.0
27457:09/12/17 20:08:27 [69359] (538.0) SetJobLeaseTimers()
27458:09/12/17 20:08:27 [69359] Found job 538.0 --- inserting
27459:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 537.0
27460:09/12/17 20:08:27 [69359] (537.0) SetJobLeaseTimers()
27461:09/12/17 20:08:27 [69359] Found job 537.0 --- inserting
27462:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 536.0
27463:09/12/17 20:08:27 [69359] (536.0) SetJobLeaseTimers()
27464:09/12/17 20:08:27 [69359] Found job 536.0 --- inserting
27465:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 535.0
27466:09/12/17 20:08:27 [69359] (535.0) SetJobLeaseTimers()
27467:09/12/17 20:08:27 [69359] Found job 535.0 --- inserting
27468:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 534.0
27469:09/12/17 20:08:27 [69359] (534.0) SetJobLeaseTimers()
27470:09/12/17 20:08:27 [69359] Found job 534.0 --- inserting
27471:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 533.0
27472:09/12/17 20:08:27 [69359] (533.0) SetJobLeaseTimers()
27473:09/12/17 20:08:27 [69359] Found job 533.0 --- inserting
27474:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 532.0
27475:09/12/17 20:08:27 [69359] (532.0) SetJobLeaseTimers()
27476:09/12/17 20:08:27 [69359] Found job 532.0 --- inserting
27477:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 531.0
27478:09/12/17 20:08:27 [69359] (531.0) SetJobLeaseTimers()
27479:09/12/17 20:08:27 [69359] Found job 531.0 --- inserting
27480:09/12/17 20:08:27 [69359] Using job type INFNBatch for job 530.0
27481:09/12/17 20:08:27 [69359] (530.0) SetJobLeaseTimers()
27482:09/12/17 20:08:27 [69359] Found job 530.0 --- inserting
27483:09/12/17 20:08:27 [69359] Fetched 13 new job ads from schedd
27484:09/12/17 20:08:27 [69359] querying for removed/held jobs
27485:09/12/17 20:08:27 [69359] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
27486:09/12/17 20:08:27 [69359] Fetched 0 job ads from schedd
27487:09/12/17 20:08:27 [69359] leaving doContactSchedd()
27488:09/12/17 20:08:27 [69359] gahp server not up yet, delaying ping
27489:09/12/17 20:08:27 [69359] *** UpdateLeases called
27490:09/12/17 20:08:27 [69359]     Leases not supported, cancelling timer
27491:09/12/17 20:08:27 [69359] BaseResource::UpdateResource: 
27511:09/12/17 20:08:27 [69359] Trying to update collector <128.55.162.46:9619>
27512:09/12/17 20:08:27 [69359] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27513:09/12/17 20:08:27 [69359] File descriptor limits: max 4096, safe 3277
27514:09/12/17 20:08:27 [69359] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27515:09/12/17 20:08:27 [69359] GAHP server pid = 69362
27516:09/12/17 20:08:27 [69359] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
27517:09/12/17 20:08:27 [69359] GAHP[69362] <- 'COMMANDS'
27518:09/12/17 20:08:27 [69359] GAHP[69362] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
27519:09/12/17 20:08:27 [69359] GAHP[69362] <- 'ASYNC_MODE_ON'
27520:09/12/17 20:08:27 [69359] GAHP[69362] -> 'S' 'Async mode on'
27521:09/12/17 20:08:27 [69359] (542.0) gm state change: GM_INIT -> GM_START
27522:09/12/17 20:08:27 [69359] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27523:09/12/17 20:08:27 [69359] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27524:09/12/17 20:08:27 [69359] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27525:09/12/17 20:08:27 [69359] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27526:09/12/17 20:08:27 [69359] (541.0) gm state change: GM_INIT -> GM_START
27527:09/12/17 20:08:27 [69359] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27528:09/12/17 20:08:27 [69359] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27529:09/12/17 20:08:27 [69359] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27530:09/12/17 20:08:27 [69359] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27531:09/12/17 20:08:27 [69359] (540.0) gm state change: GM_INIT -> GM_START
27532:09/12/17 20:08:27 [69359] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27533:09/12/17 20:08:27 [69359] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27534:09/12/17 20:08:27 [69359] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27535:09/12/17 20:08:27 [69359] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27536:09/12/17 20:08:27 [69359] (539.0) gm state change: GM_INIT -> GM_START
27537:09/12/17 20:08:27 [69359] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27538:09/12/17 20:08:27 [69359] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27539:09/12/17 20:08:27 [69359] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27540:09/12/17 20:08:27 [69359] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27541:09/12/17 20:08:27 [69359] (538.0) gm state change: GM_INIT -> GM_START
27542:09/12/17 20:08:27 [69359] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27543:09/12/17 20:08:27 [69359] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27544:09/12/17 20:08:27 [69359] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27545:09/12/17 20:08:27 [69359] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27546:09/12/17 20:08:27 [69359] (537.0) gm state change: GM_INIT -> GM_START
27547:09/12/17 20:08:27 [69359] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27548:09/12/17 20:08:27 [69359] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27549:09/12/17 20:08:27 [69359] GAHP[69362] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
27550:09/12/17 20:08:27 [69359] GAHP[69362] -> 'S'
27551:09/12/17 20:08:27 [69359] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27552:09/12/17 20:08:27 [69359] (536.0) gm state change: GM_INIT -> GM_START
27553:09/12/17 20:08:27 [69359] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27554:09/12/17 20:08:27 [69359] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27555:09/12/17 20:08:27 [69359] GAHP[69362] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
27556:09/12/17 20:08:27 [69359] GAHP[69362] -> 'S'
27557:09/12/17 20:08:27 [69359] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27558:09/12/17 20:08:27 [69359] (535.0) gm state change: GM_INIT -> GM_START
27559:09/12/17 20:08:27 [69359] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27560:09/12/17 20:08:27 [69359] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27561:09/12/17 20:08:27 [69359] GAHP[69362] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
27562:09/12/17 20:08:27 [69359] GAHP[69362] -> 'S'
27563:09/12/17 20:08:27 [69359] This process has a valid certificate & key
27564:09/12/17 20:08:27 [69359] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27565:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27566:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27567:09/12/17 20:08:27 [69359] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27568:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27569:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27570:09/12/17 20:08:27 [69359] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27571:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27572:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27573:09/12/17 20:08:27 [69359] IPVERIFY: checking mc0151-ib against 128.55.162.46
27574:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27575:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27576:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27577:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27578:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27579:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27580:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27581:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27582:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
27583:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
27584:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
27585:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
27586:09/12/17 20:08:27 [69359] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
27587:09/12/17 20:08:27 [69359] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
27588:09/12/17 20:08:27 [69359] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27589:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27590:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27591:09/12/17 20:08:27 [69359] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27592:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27593:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27594:09/12/17 20:08:27 [69359] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27595:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27596:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27597:09/12/17 20:08:27 [69359] IPVERIFY: checking mc0151-ib against 128.55.162.46
27598:09/12/17 20:08:27 [69359] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27599:09/12/17 20:08:27 [69359] IPVERIFY: ip found is 1
27600:09/12/17 20:08:27 [69359] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27601:09/12/17 20:08:27 [69359] (534.0) gm state change: GM_INIT -> GM_START
27602:09/12/17 20:08:27 [69359] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27603:09/12/17 20:08:27 [69359] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27604:09/12/17 20:08:27 [69359] GAHP[69362] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
27605:09/12/17 20:08:27 [69359] GAHP[69362] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
27606:09/12/17 20:08:27 [69359] GAHP[69362] -> EOF
27607:09/12/17 20:08:27 [69359] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
27608:09/12/17 20:13:24 Result of reading /etc/issue:  \S
27610:09/12/17 20:13:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
27612:09/12/17 20:13:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
27613:09/12/17 20:13:24 Enumerating interfaces: lo 127.0.0.1 up
27614:09/12/17 20:13:24 Enumerating interfaces: eth0 10.36.162.46 up
27615:09/12/17 20:13:24 Enumerating interfaces: ib0 128.55.162.46 up
27616:09/12/17 20:13:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
27617:09/12/17 20:13:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
27618:09/12/17 20:13:24 ******************************************************
27619:09/12/17 20:13:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
27620:09/12/17 20:13:24 ** /usr/sbin/condor_gridmanager
27621:09/12/17 20:13:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
27622:09/12/17 20:13:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
27623:09/12/17 20:13:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
27624:09/12/17 20:13:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
27625:09/12/17 20:13:24 ** PID = 69406
27626:09/12/17 20:13:24 ** Log last touched 9/12 20:08:27
27627:09/12/17 20:13:24 ******************************************************
27628:09/12/17 20:13:24 Using config source: /etc/condor-ce/condor_config
27629:09/12/17 20:13:24 Using local config sources: 
27630:09/12/17 20:13:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
27631:09/12/17 20:13:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
27632:09/12/17 20:13:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
27633:09/12/17 20:13:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
27634:09/12/17 20:13:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
27635:09/12/17 20:13:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
27636:09/12/17 20:13:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
27637:09/12/17 20:13:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
27638:09/12/17 20:13:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
27639:09/12/17 20:13:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
27640:09/12/17 20:13:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
27641:09/12/17 20:13:24    /etc/condor-ce/config.d/01-ce-auth.conf
27642:09/12/17 20:13:24    /etc/condor-ce/config.d/01-ce-router.conf
27643:09/12/17 20:13:24    /etc/condor-ce/config.d/01-common-auth.conf
27644:09/12/17 20:13:24    /etc/condor-ce/config.d/02-ce-slurm.conf
27645:09/12/17 20:13:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
27646:09/12/17 20:13:24    /etc/condor-ce/config.d/03-managed-fork.conf
27647:09/12/17 20:13:24    /etc/condor-ce/config.d/05-ce-health.conf
27648:09/12/17 20:13:24    /etc/condor-ce/config.d/05-ce-view.conf
27649:09/12/17 20:13:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
27650:09/12/17 20:13:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
27651:09/12/17 20:13:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
27652:09/12/17 20:13:24    /etc/condor-ce/config.d/50-osg-configure.conf
27653:09/12/17 20:13:24    /etc/condor-ce/config.d/99-local.conf
27654:09/12/17 20:13:24    /usr/share/condor-ce/condor_ce_router_defaults|
27655:09/12/17 20:13:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
27656:09/12/17 20:13:24 CLASSAD_CACHING is ENABLED
27657:09/12/17 20:13:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
27658:09/12/17 20:13:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_128
27659:09/12/17 20:13:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_128>
27660:09/12/17 20:13:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_128>
27661:09/12/17 20:13:24 Setting maximum accepts per cycle 8.
27662:09/12/17 20:13:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27663:09/12/17 20:13:24 [69406] Welcome to the all-singing, all dancing, "amazing" GridManager!
27664:09/12/17 20:13:24 [69406] DaemonCore: No more children processes to reap.
27665:09/12/17 20:13:24 [69406] DaemonCore: in SendAliveToParent()
27666:09/12/17 20:13:24 [69406] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27667:09/12/17 20:13:24 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27668:09/12/17 20:13:24 [69406] IPVERIFY: ip found is 1
27669:09/12/17 20:13:24 [69406] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27670:09/12/17 20:13:24 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27671:09/12/17 20:13:24 [69406] IPVERIFY: ip found is 1
27672:09/12/17 20:13:24 [69406] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27673:09/12/17 20:13:24 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27674:09/12/17 20:13:24 [69406] IPVERIFY: ip found is 1
27675:09/12/17 20:13:24 [69406] IPVERIFY: checking mc0151-ib against 128.55.162.46
27676:09/12/17 20:13:24 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27677:09/12/17 20:13:24 [69406] IPVERIFY: ip found is 1
27678:09/12/17 20:13:24 [69406] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
27679:09/12/17 20:13:24 [69406] DaemonCore: Leaving SendAliveToParent() - success
27680:09/12/17 20:13:24 [69406] Checking proxies
27681:09/12/17 20:13:27 [69406] Received ADD_JOBS signal
27682:09/12/17 20:13:27 [69406] in doContactSchedd()
27683:09/12/17 20:13:27 [69406] querying for new jobs
27684:09/12/17 20:13:27 [69406] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
27685:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 542.0
27686:09/12/17 20:13:27 [69406] (542.0) SetJobLeaseTimers()
27687:09/12/17 20:13:27 [69406] Found job 542.0 --- inserting
27688:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 541.0
27689:09/12/17 20:13:27 [69406] (541.0) SetJobLeaseTimers()
27690:09/12/17 20:13:27 [69406] Found job 541.0 --- inserting
27691:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 540.0
27692:09/12/17 20:13:27 [69406] (540.0) SetJobLeaseTimers()
27693:09/12/17 20:13:27 [69406] Found job 540.0 --- inserting
27694:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 539.0
27695:09/12/17 20:13:27 [69406] (539.0) SetJobLeaseTimers()
27696:09/12/17 20:13:27 [69406] Found job 539.0 --- inserting
27697:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 538.0
27698:09/12/17 20:13:27 [69406] (538.0) SetJobLeaseTimers()
27699:09/12/17 20:13:27 [69406] Found job 538.0 --- inserting
27700:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 537.0
27701:09/12/17 20:13:27 [69406] (537.0) SetJobLeaseTimers()
27702:09/12/17 20:13:27 [69406] Found job 537.0 --- inserting
27703:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 536.0
27704:09/12/17 20:13:27 [69406] (536.0) SetJobLeaseTimers()
27705:09/12/17 20:13:27 [69406] Found job 536.0 --- inserting
27706:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 535.0
27707:09/12/17 20:13:27 [69406] (535.0) SetJobLeaseTimers()
27708:09/12/17 20:13:27 [69406] Found job 535.0 --- inserting
27709:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 534.0
27710:09/12/17 20:13:27 [69406] (534.0) SetJobLeaseTimers()
27711:09/12/17 20:13:27 [69406] Found job 534.0 --- inserting
27712:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 533.0
27713:09/12/17 20:13:27 [69406] (533.0) SetJobLeaseTimers()
27714:09/12/17 20:13:27 [69406] Found job 533.0 --- inserting
27715:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 532.0
27716:09/12/17 20:13:27 [69406] (532.0) SetJobLeaseTimers()
27717:09/12/17 20:13:27 [69406] Found job 532.0 --- inserting
27718:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 531.0
27719:09/12/17 20:13:27 [69406] (531.0) SetJobLeaseTimers()
27720:09/12/17 20:13:27 [69406] Found job 531.0 --- inserting
27721:09/12/17 20:13:27 [69406] Using job type INFNBatch for job 530.0
27722:09/12/17 20:13:27 [69406] (530.0) SetJobLeaseTimers()
27723:09/12/17 20:13:27 [69406] Found job 530.0 --- inserting
27724:09/12/17 20:13:27 [69406] Fetched 13 new job ads from schedd
27725:09/12/17 20:13:27 [69406] querying for removed/held jobs
27726:09/12/17 20:13:27 [69406] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
27727:09/12/17 20:13:27 [69406] Fetched 0 job ads from schedd
27728:09/12/17 20:13:27 [69406] leaving doContactSchedd()
27729:09/12/17 20:13:27 [69406] gahp server not up yet, delaying ping
27730:09/12/17 20:13:27 [69406] *** UpdateLeases called
27731:09/12/17 20:13:27 [69406]     Leases not supported, cancelling timer
27732:09/12/17 20:13:27 [69406] BaseResource::UpdateResource: 
27752:09/12/17 20:13:27 [69406] Trying to update collector <128.55.162.46:9619>
27753:09/12/17 20:13:27 [69406] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27754:09/12/17 20:13:27 [69406] File descriptor limits: max 4096, safe 3277
27755:09/12/17 20:13:27 [69406] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27756:09/12/17 20:13:27 [69406] GAHP server pid = 69409
27757:09/12/17 20:13:27 [69406] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
27758:09/12/17 20:13:27 [69406] GAHP[69409] <- 'COMMANDS'
27759:09/12/17 20:13:27 [69406] GAHP[69409] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
27760:09/12/17 20:13:27 [69406] GAHP[69409] <- 'ASYNC_MODE_ON'
27761:09/12/17 20:13:27 [69406] GAHP[69409] -> 'S' 'Async mode on'
27762:09/12/17 20:13:27 [69406] (542.0) gm state change: GM_INIT -> GM_START
27763:09/12/17 20:13:27 [69406] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27764:09/12/17 20:13:27 [69406] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27765:09/12/17 20:13:27 [69406] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27766:09/12/17 20:13:27 [69406] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27767:09/12/17 20:13:27 [69406] (541.0) gm state change: GM_INIT -> GM_START
27768:09/12/17 20:13:27 [69406] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27769:09/12/17 20:13:27 [69406] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27770:09/12/17 20:13:27 [69406] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27771:09/12/17 20:13:27 [69406] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27772:09/12/17 20:13:27 [69406] (540.0) gm state change: GM_INIT -> GM_START
27773:09/12/17 20:13:27 [69406] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27774:09/12/17 20:13:27 [69406] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27775:09/12/17 20:13:27 [69406] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27776:09/12/17 20:13:27 [69406] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27777:09/12/17 20:13:27 [69406] (539.0) gm state change: GM_INIT -> GM_START
27778:09/12/17 20:13:27 [69406] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27779:09/12/17 20:13:27 [69406] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27780:09/12/17 20:13:27 [69406] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27781:09/12/17 20:13:27 [69406] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27782:09/12/17 20:13:27 [69406] (538.0) gm state change: GM_INIT -> GM_START
27783:09/12/17 20:13:27 [69406] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
27784:09/12/17 20:13:27 [69406] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
27785:09/12/17 20:13:27 [69406] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
27786:09/12/17 20:13:27 [69406] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27787:09/12/17 20:13:27 [69406] (537.0) gm state change: GM_INIT -> GM_START
27788:09/12/17 20:13:27 [69406] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27789:09/12/17 20:13:27 [69406] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27790:09/12/17 20:13:27 [69406] GAHP[69409] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
27791:09/12/17 20:13:27 [69406] GAHP[69409] -> 'S'
27792:09/12/17 20:13:27 [69406] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27793:09/12/17 20:13:27 [69406] (536.0) gm state change: GM_INIT -> GM_START
27794:09/12/17 20:13:27 [69406] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27795:09/12/17 20:13:27 [69406] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27796:09/12/17 20:13:27 [69406] GAHP[69409] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
27797:09/12/17 20:13:27 [69406] GAHP[69409] -> 'S'
27798:09/12/17 20:13:27 [69406] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27799:09/12/17 20:13:27 [69406] (535.0) gm state change: GM_INIT -> GM_START
27800:09/12/17 20:13:27 [69406] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27801:09/12/17 20:13:27 [69406] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27802:09/12/17 20:13:27 [69406] GAHP[69409] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
27803:09/12/17 20:13:27 [69406] GAHP[69409] -> 'S'
27804:09/12/17 20:13:27 [69406] This process has a valid certificate & key
27805:09/12/17 20:13:27 [69406] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27806:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27807:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27808:09/12/17 20:13:27 [69406] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27809:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27810:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27811:09/12/17 20:13:27 [69406] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27812:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27813:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27814:09/12/17 20:13:27 [69406] IPVERIFY: checking mc0151-ib against 128.55.162.46
27815:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27816:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27817:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27818:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27819:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27820:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27821:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27822:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
27823:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
27824:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
27825:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
27826:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
27827:09/12/17 20:13:27 [69406] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
27828:09/12/17 20:13:27 [69406] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
27829:09/12/17 20:13:27 [69406] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27830:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27831:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27832:09/12/17 20:13:27 [69406] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27833:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27834:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27835:09/12/17 20:13:27 [69406] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27836:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27837:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27838:09/12/17 20:13:27 [69406] IPVERIFY: checking mc0151-ib against 128.55.162.46
27839:09/12/17 20:13:27 [69406] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27840:09/12/17 20:13:27 [69406] IPVERIFY: ip found is 1
27841:09/12/17 20:13:27 [69406] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
27842:09/12/17 20:13:27 [69406] (534.0) gm state change: GM_INIT -> GM_START
27843:09/12/17 20:13:27 [69406] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
27844:09/12/17 20:13:27 [69406] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
27845:09/12/17 20:13:27 [69406] GAHP[69409] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
27846:09/12/17 20:13:27 [69406] GAHP[69409] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
27847:09/12/17 20:13:27 [69406] GAHP[69409] -> EOF
27848:09/12/17 20:13:27 [69406] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
27849:09/12/17 20:18:24 Result of reading /etc/issue:  \S
27851:09/12/17 20:18:24 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
27853:09/12/17 20:18:24 Using IDs: 32 processors, 16 CPUs, 16 HTs
27854:09/12/17 20:18:24 Enumerating interfaces: lo 127.0.0.1 up
27855:09/12/17 20:18:24 Enumerating interfaces: eth0 10.36.162.46 up
27856:09/12/17 20:18:24 Enumerating interfaces: ib0 128.55.162.46 up
27857:09/12/17 20:18:24 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
27858:09/12/17 20:18:24 Initializing Directory: curr_dir = /etc/condor-ce/config.d
27859:09/12/17 20:18:24 ******************************************************
27860:09/12/17 20:18:24 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
27861:09/12/17 20:18:24 ** /usr/sbin/condor_gridmanager
27862:09/12/17 20:18:24 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
27863:09/12/17 20:18:24 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
27864:09/12/17 20:18:24 ** $CondorVersion: 8.4.12 Aug 07 2017 $
27865:09/12/17 20:18:24 ** $CondorPlatform: X86_64-CentOS_7.3 $
27866:09/12/17 20:18:24 ** PID = 69458
27867:09/12/17 20:18:24 ** Log last touched 9/12 20:13:27
27868:09/12/17 20:18:24 ******************************************************
27869:09/12/17 20:18:24 Using config source: /etc/condor-ce/condor_config
27870:09/12/17 20:18:24 Using local config sources: 
27871:09/12/17 20:18:24    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
27872:09/12/17 20:18:24    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
27873:09/12/17 20:18:24    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
27874:09/12/17 20:18:24    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
27875:09/12/17 20:18:24    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
27876:09/12/17 20:18:24    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
27877:09/12/17 20:18:24    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
27878:09/12/17 20:18:24    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
27879:09/12/17 20:18:24    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
27880:09/12/17 20:18:24    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
27881:09/12/17 20:18:24    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
27882:09/12/17 20:18:24    /etc/condor-ce/config.d/01-ce-auth.conf
27883:09/12/17 20:18:24    /etc/condor-ce/config.d/01-ce-router.conf
27884:09/12/17 20:18:24    /etc/condor-ce/config.d/01-common-auth.conf
27885:09/12/17 20:18:24    /etc/condor-ce/config.d/02-ce-slurm.conf
27886:09/12/17 20:18:24    /etc/condor-ce/config.d/03-ce-shared-port.conf
27887:09/12/17 20:18:24    /etc/condor-ce/config.d/03-managed-fork.conf
27888:09/12/17 20:18:24    /etc/condor-ce/config.d/05-ce-health.conf
27889:09/12/17 20:18:24    /etc/condor-ce/config.d/05-ce-view.conf
27890:09/12/17 20:18:24    /etc/condor-ce/config.d/10-ce-collector-generated.conf
27891:09/12/17 20:18:24    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
27892:09/12/17 20:18:24    /etc/condor-ce/config.d/50-osg-configure-present.conf
27893:09/12/17 20:18:24    /etc/condor-ce/config.d/50-osg-configure.conf
27894:09/12/17 20:18:24    /etc/condor-ce/config.d/99-local.conf
27895:09/12/17 20:18:24    /usr/share/condor-ce/condor_ce_router_defaults|
27896:09/12/17 20:18:24 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
27897:09/12/17 20:18:24 CLASSAD_CACHING is ENABLED
27898:09/12/17 20:18:24 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
27899:09/12/17 20:18:24 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_131
27900:09/12/17 20:18:24 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_131>
27901:09/12/17 20:18:24 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_131>
27902:09/12/17 20:18:24 Setting maximum accepts per cycle 8.
27903:09/12/17 20:18:24 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27904:09/12/17 20:18:24 [69458] Welcome to the all-singing, all dancing, "amazing" GridManager!
27905:09/12/17 20:18:24 [69458] DaemonCore: No more children processes to reap.
27906:09/12/17 20:18:24 [69458] DaemonCore: in SendAliveToParent()
27907:09/12/17 20:18:24 [69458] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
27908:09/12/17 20:18:24 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27909:09/12/17 20:18:24 [69458] IPVERIFY: ip found is 1
27910:09/12/17 20:18:24 [69458] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
27911:09/12/17 20:18:24 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27912:09/12/17 20:18:24 [69458] IPVERIFY: ip found is 1
27913:09/12/17 20:18:24 [69458] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
27914:09/12/17 20:18:24 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27915:09/12/17 20:18:24 [69458] IPVERIFY: ip found is 1
27916:09/12/17 20:18:24 [69458] IPVERIFY: checking mc0151-ib against 128.55.162.46
27917:09/12/17 20:18:24 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
27918:09/12/17 20:18:24 [69458] IPVERIFY: ip found is 1
27919:09/12/17 20:18:24 [69458] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
27920:09/12/17 20:18:24 [69458] DaemonCore: Leaving SendAliveToParent() - success
27921:09/12/17 20:18:24 [69458] Checking proxies
27922:09/12/17 20:18:27 [69458] Received ADD_JOBS signal
27923:09/12/17 20:18:27 [69458] in doContactSchedd()
27924:09/12/17 20:18:27 [69458] querying for new jobs
27925:09/12/17 20:18:27 [69458] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
27926:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 542.0
27927:09/12/17 20:18:27 [69458] (542.0) SetJobLeaseTimers()
27928:09/12/17 20:18:27 [69458] Found job 542.0 --- inserting
27929:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 541.0
27930:09/12/17 20:18:27 [69458] (541.0) SetJobLeaseTimers()
27931:09/12/17 20:18:27 [69458] Found job 541.0 --- inserting
27932:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 540.0
27933:09/12/17 20:18:27 [69458] (540.0) SetJobLeaseTimers()
27934:09/12/17 20:18:27 [69458] Found job 540.0 --- inserting
27935:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 539.0
27936:09/12/17 20:18:27 [69458] (539.0) SetJobLeaseTimers()
27937:09/12/17 20:18:27 [69458] Found job 539.0 --- inserting
27938:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 538.0
27939:09/12/17 20:18:27 [69458] (538.0) SetJobLeaseTimers()
27940:09/12/17 20:18:27 [69458] Found job 538.0 --- inserting
27941:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 537.0
27942:09/12/17 20:18:27 [69458] (537.0) SetJobLeaseTimers()
27943:09/12/17 20:18:27 [69458] Found job 537.0 --- inserting
27944:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 536.0
27945:09/12/17 20:18:27 [69458] (536.0) SetJobLeaseTimers()
27946:09/12/17 20:18:27 [69458] Found job 536.0 --- inserting
27947:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 535.0
27948:09/12/17 20:18:27 [69458] (535.0) SetJobLeaseTimers()
27949:09/12/17 20:18:27 [69458] Found job 535.0 --- inserting
27950:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 534.0
27951:09/12/17 20:18:27 [69458] (534.0) SetJobLeaseTimers()
27952:09/12/17 20:18:27 [69458] Found job 534.0 --- inserting
27953:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 533.0
27954:09/12/17 20:18:27 [69458] (533.0) SetJobLeaseTimers()
27955:09/12/17 20:18:27 [69458] Found job 533.0 --- inserting
27956:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 532.0
27957:09/12/17 20:18:27 [69458] (532.0) SetJobLeaseTimers()
27958:09/12/17 20:18:27 [69458] Found job 532.0 --- inserting
27959:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 531.0
27960:09/12/17 20:18:27 [69458] (531.0) SetJobLeaseTimers()
27961:09/12/17 20:18:27 [69458] Found job 531.0 --- inserting
27962:09/12/17 20:18:27 [69458] Using job type INFNBatch for job 530.0
27963:09/12/17 20:18:27 [69458] (530.0) SetJobLeaseTimers()
27964:09/12/17 20:18:27 [69458] Found job 530.0 --- inserting
27965:09/12/17 20:18:27 [69458] Fetched 13 new job ads from schedd
27966:09/12/17 20:18:27 [69458] querying for removed/held jobs
27967:09/12/17 20:18:27 [69458] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
27968:09/12/17 20:18:27 [69458] Fetched 0 job ads from schedd
27969:09/12/17 20:18:27 [69458] leaving doContactSchedd()
27970:09/12/17 20:18:27 [69458] gahp server not up yet, delaying ping
27971:09/12/17 20:18:27 [69458] *** UpdateLeases called
27972:09/12/17 20:18:27 [69458]     Leases not supported, cancelling timer
27973:09/12/17 20:18:27 [69458] BaseResource::UpdateResource: 
27993:09/12/17 20:18:27 [69458] Trying to update collector <128.55.162.46:9619>
27994:09/12/17 20:18:27 [69458] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
27995:09/12/17 20:18:27 [69458] File descriptor limits: max 4096, safe 3277
27996:09/12/17 20:18:27 [69458] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
27997:09/12/17 20:18:27 [69458] GAHP server pid = 69462
27998:09/12/17 20:18:27 [69458] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
27999:09/12/17 20:18:27 [69458] GAHP[69462] <- 'COMMANDS'
28000:09/12/17 20:18:27 [69458] GAHP[69462] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
28001:09/12/17 20:18:27 [69458] GAHP[69462] <- 'ASYNC_MODE_ON'
28002:09/12/17 20:18:27 [69458] GAHP[69462] -> 'S' 'Async mode on'
28003:09/12/17 20:18:27 [69458] (542.0) gm state change: GM_INIT -> GM_START
28004:09/12/17 20:18:27 [69458] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28005:09/12/17 20:18:27 [69458] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28006:09/12/17 20:18:27 [69458] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28007:09/12/17 20:18:27 [69458] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28008:09/12/17 20:18:27 [69458] (541.0) gm state change: GM_INIT -> GM_START
28009:09/12/17 20:18:27 [69458] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28010:09/12/17 20:18:27 [69458] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28011:09/12/17 20:18:27 [69458] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28012:09/12/17 20:18:27 [69458] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28013:09/12/17 20:18:27 [69458] (540.0) gm state change: GM_INIT -> GM_START
28014:09/12/17 20:18:27 [69458] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28015:09/12/17 20:18:27 [69458] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28016:09/12/17 20:18:27 [69458] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28017:09/12/17 20:18:27 [69458] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28018:09/12/17 20:18:27 [69458] (539.0) gm state change: GM_INIT -> GM_START
28019:09/12/17 20:18:27 [69458] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28020:09/12/17 20:18:27 [69458] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28021:09/12/17 20:18:27 [69458] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28022:09/12/17 20:18:27 [69458] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28023:09/12/17 20:18:27 [69458] (538.0) gm state change: GM_INIT -> GM_START
28024:09/12/17 20:18:27 [69458] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28025:09/12/17 20:18:27 [69458] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28026:09/12/17 20:18:27 [69458] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28027:09/12/17 20:18:27 [69458] This process has a valid certificate & key
28028:09/12/17 20:18:27 [69458] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28029:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28030:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28031:09/12/17 20:18:27 [69458] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28032:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28033:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28034:09/12/17 20:18:27 [69458] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28035:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28036:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28037:09/12/17 20:18:27 [69458] IPVERIFY: checking mc0151-ib against 128.55.162.46
28038:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28039:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28040:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28041:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28042:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28043:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28044:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28045:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28046:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
28047:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
28048:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
28049:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
28050:09/12/17 20:18:27 [69458] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
28051:09/12/17 20:18:27 [69458] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
28052:09/12/17 20:18:27 [69458] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28053:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28054:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28055:09/12/17 20:18:27 [69458] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28056:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28057:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28058:09/12/17 20:18:27 [69458] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28059:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28060:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28061:09/12/17 20:18:27 [69458] IPVERIFY: checking mc0151-ib against 128.55.162.46
28062:09/12/17 20:18:27 [69458] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28063:09/12/17 20:18:27 [69458] IPVERIFY: ip found is 1
28064:09/12/17 20:18:27 [69458] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28065:09/12/17 20:18:27 [69458] (537.0) gm state change: GM_INIT -> GM_START
28066:09/12/17 20:18:27 [69458] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28067:09/12/17 20:18:27 [69458] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28068:09/12/17 20:18:27 [69458] GAHP[69462] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
28069:09/12/17 20:18:27 [69458] GAHP[69462] -> 'S'
28070:09/12/17 20:18:27 [69458] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28071:09/12/17 20:18:27 [69458] (536.0) gm state change: GM_INIT -> GM_START
28072:09/12/17 20:18:27 [69458] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28073:09/12/17 20:18:27 [69458] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28074:09/12/17 20:18:27 [69458] GAHP[69462] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
28075:09/12/17 20:18:27 [69458] GAHP[69462] -> 'S'
28076:09/12/17 20:18:27 [69458] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28077:09/12/17 20:18:27 [69458] (535.0) gm state change: GM_INIT -> GM_START
28078:09/12/17 20:18:27 [69458] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28079:09/12/17 20:18:27 [69458] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28080:09/12/17 20:18:27 [69458] GAHP[69462] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
28081:09/12/17 20:18:27 [69458] GAHP[69462] -> 'S'
28082:09/12/17 20:18:27 [69458] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28083:09/12/17 20:18:27 [69458] (534.0) gm state change: GM_INIT -> GM_START
28084:09/12/17 20:18:27 [69458] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28085:09/12/17 20:18:27 [69458] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28086:09/12/17 20:18:27 [69458] GAHP[69462] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
28087:09/12/17 20:18:27 [69458] GAHP[69462] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
28088:09/12/17 20:18:27 [69458] GAHP[69462] -> EOF
28089:09/12/17 20:18:27 [69458] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
28090:09/12/17 20:23:25 Result of reading /etc/issue:  \S
28092:09/12/17 20:23:25 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
28094:09/12/17 20:23:25 Using IDs: 32 processors, 16 CPUs, 16 HTs
28095:09/12/17 20:23:25 Enumerating interfaces: lo 127.0.0.1 up
28096:09/12/17 20:23:25 Enumerating interfaces: eth0 10.36.162.46 up
28097:09/12/17 20:23:25 Enumerating interfaces: ib0 128.55.162.46 up
28098:09/12/17 20:23:25 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
28099:09/12/17 20:23:25 Initializing Directory: curr_dir = /etc/condor-ce/config.d
28100:09/12/17 20:23:25 ******************************************************
28101:09/12/17 20:23:25 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
28102:09/12/17 20:23:25 ** /usr/sbin/condor_gridmanager
28103:09/12/17 20:23:25 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
28104:09/12/17 20:23:25 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
28105:09/12/17 20:23:25 ** $CondorVersion: 8.4.12 Aug 07 2017 $
28106:09/12/17 20:23:25 ** $CondorPlatform: X86_64-CentOS_7.3 $
28107:09/12/17 20:23:25 ** PID = 69509
28108:09/12/17 20:23:25 ** Log last touched 9/12 20:18:27
28109:09/12/17 20:23:25 ******************************************************
28110:09/12/17 20:23:25 Using config source: /etc/condor-ce/condor_config
28111:09/12/17 20:23:25 Using local config sources: 
28112:09/12/17 20:23:25    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
28113:09/12/17 20:23:25    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
28114:09/12/17 20:23:25    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
28115:09/12/17 20:23:25    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
28116:09/12/17 20:23:25    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
28117:09/12/17 20:23:25    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
28118:09/12/17 20:23:25    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
28119:09/12/17 20:23:25    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
28120:09/12/17 20:23:25    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
28121:09/12/17 20:23:25    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
28122:09/12/17 20:23:25    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
28123:09/12/17 20:23:25    /etc/condor-ce/config.d/01-ce-auth.conf
28124:09/12/17 20:23:25    /etc/condor-ce/config.d/01-ce-router.conf
28125:09/12/17 20:23:25    /etc/condor-ce/config.d/01-common-auth.conf
28126:09/12/17 20:23:25    /etc/condor-ce/config.d/02-ce-slurm.conf
28127:09/12/17 20:23:25    /etc/condor-ce/config.d/03-ce-shared-port.conf
28128:09/12/17 20:23:25    /etc/condor-ce/config.d/03-managed-fork.conf
28129:09/12/17 20:23:25    /etc/condor-ce/config.d/05-ce-health.conf
28130:09/12/17 20:23:25    /etc/condor-ce/config.d/05-ce-view.conf
28131:09/12/17 20:23:25    /etc/condor-ce/config.d/10-ce-collector-generated.conf
28132:09/12/17 20:23:25    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
28133:09/12/17 20:23:25    /etc/condor-ce/config.d/50-osg-configure-present.conf
28134:09/12/17 20:23:25    /etc/condor-ce/config.d/50-osg-configure.conf
28135:09/12/17 20:23:25    /etc/condor-ce/config.d/99-local.conf
28136:09/12/17 20:23:25    /usr/share/condor-ce/condor_ce_router_defaults|
28137:09/12/17 20:23:25 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
28138:09/12/17 20:23:25 CLASSAD_CACHING is ENABLED
28139:09/12/17 20:23:25 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
28140:09/12/17 20:23:25 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_133
28141:09/12/17 20:23:25 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_133>
28142:09/12/17 20:23:25 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_133>
28143:09/12/17 20:23:25 Setting maximum accepts per cycle 8.
28144:09/12/17 20:23:25 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28145:09/12/17 20:23:25 [69509] Welcome to the all-singing, all dancing, "amazing" GridManager!
28146:09/12/17 20:23:25 [69509] DaemonCore: No more children processes to reap.
28147:09/12/17 20:23:25 [69509] DaemonCore: in SendAliveToParent()
28148:09/12/17 20:23:25 [69509] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28149:09/12/17 20:23:25 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28150:09/12/17 20:23:25 [69509] IPVERIFY: ip found is 1
28151:09/12/17 20:23:25 [69509] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28152:09/12/17 20:23:25 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28153:09/12/17 20:23:25 [69509] IPVERIFY: ip found is 1
28154:09/12/17 20:23:25 [69509] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28155:09/12/17 20:23:25 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28156:09/12/17 20:23:25 [69509] IPVERIFY: ip found is 1
28157:09/12/17 20:23:25 [69509] IPVERIFY: checking mc0151-ib against 128.55.162.46
28158:09/12/17 20:23:25 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28159:09/12/17 20:23:25 [69509] IPVERIFY: ip found is 1
28160:09/12/17 20:23:25 [69509] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
28161:09/12/17 20:23:25 [69509] DaemonCore: Leaving SendAliveToParent() - success
28162:09/12/17 20:23:25 [69509] Checking proxies
28163:09/12/17 20:23:28 [69509] Received ADD_JOBS signal
28164:09/12/17 20:23:28 [69509] in doContactSchedd()
28165:09/12/17 20:23:28 [69509] querying for new jobs
28166:09/12/17 20:23:28 [69509] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
28167:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 542.0
28168:09/12/17 20:23:28 [69509] (542.0) SetJobLeaseTimers()
28169:09/12/17 20:23:28 [69509] Found job 542.0 --- inserting
28170:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 541.0
28171:09/12/17 20:23:28 [69509] (541.0) SetJobLeaseTimers()
28172:09/12/17 20:23:28 [69509] Found job 541.0 --- inserting
28173:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 540.0
28174:09/12/17 20:23:28 [69509] (540.0) SetJobLeaseTimers()
28175:09/12/17 20:23:28 [69509] Found job 540.0 --- inserting
28176:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 539.0
28177:09/12/17 20:23:28 [69509] (539.0) SetJobLeaseTimers()
28178:09/12/17 20:23:28 [69509] Found job 539.0 --- inserting
28179:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 538.0
28180:09/12/17 20:23:28 [69509] (538.0) SetJobLeaseTimers()
28181:09/12/17 20:23:28 [69509] Found job 538.0 --- inserting
28182:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 537.0
28183:09/12/17 20:23:28 [69509] (537.0) SetJobLeaseTimers()
28184:09/12/17 20:23:28 [69509] Found job 537.0 --- inserting
28185:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 536.0
28186:09/12/17 20:23:28 [69509] (536.0) SetJobLeaseTimers()
28187:09/12/17 20:23:28 [69509] Found job 536.0 --- inserting
28188:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 535.0
28189:09/12/17 20:23:28 [69509] (535.0) SetJobLeaseTimers()
28190:09/12/17 20:23:28 [69509] Found job 535.0 --- inserting
28191:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 534.0
28192:09/12/17 20:23:28 [69509] (534.0) SetJobLeaseTimers()
28193:09/12/17 20:23:28 [69509] Found job 534.0 --- inserting
28194:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 533.0
28195:09/12/17 20:23:28 [69509] (533.0) SetJobLeaseTimers()
28196:09/12/17 20:23:28 [69509] Found job 533.0 --- inserting
28197:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 532.0
28198:09/12/17 20:23:28 [69509] (532.0) SetJobLeaseTimers()
28199:09/12/17 20:23:28 [69509] Found job 532.0 --- inserting
28200:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 531.0
28201:09/12/17 20:23:28 [69509] (531.0) SetJobLeaseTimers()
28202:09/12/17 20:23:28 [69509] Found job 531.0 --- inserting
28203:09/12/17 20:23:28 [69509] Using job type INFNBatch for job 530.0
28204:09/12/17 20:23:28 [69509] (530.0) SetJobLeaseTimers()
28205:09/12/17 20:23:28 [69509] Found job 530.0 --- inserting
28206:09/12/17 20:23:28 [69509] Fetched 13 new job ads from schedd
28207:09/12/17 20:23:28 [69509] querying for removed/held jobs
28208:09/12/17 20:23:28 [69509] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
28209:09/12/17 20:23:28 [69509] Fetched 0 job ads from schedd
28210:09/12/17 20:23:28 [69509] leaving doContactSchedd()
28211:09/12/17 20:23:28 [69509] gahp server not up yet, delaying ping
28212:09/12/17 20:23:28 [69509] *** UpdateLeases called
28213:09/12/17 20:23:28 [69509]     Leases not supported, cancelling timer
28214:09/12/17 20:23:28 [69509] BaseResource::UpdateResource: 
28234:09/12/17 20:23:28 [69509] Trying to update collector <128.55.162.46:9619>
28235:09/12/17 20:23:28 [69509] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28236:09/12/17 20:23:28 [69509] File descriptor limits: max 4096, safe 3277
28237:09/12/17 20:23:28 [69509] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28238:09/12/17 20:23:28 [69509] GAHP server pid = 69513
28239:09/12/17 20:23:28 [69509] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
28240:09/12/17 20:23:28 [69509] GAHP[69513] <- 'COMMANDS'
28241:09/12/17 20:23:28 [69509] GAHP[69513] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
28242:09/12/17 20:23:28 [69509] GAHP[69513] <- 'ASYNC_MODE_ON'
28243:09/12/17 20:23:28 [69509] GAHP[69513] -> 'S' 'Async mode on'
28244:09/12/17 20:23:28 [69509] (542.0) gm state change: GM_INIT -> GM_START
28245:09/12/17 20:23:28 [69509] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28246:09/12/17 20:23:28 [69509] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28247:09/12/17 20:23:28 [69509] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28248:09/12/17 20:23:28 [69509] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28249:09/12/17 20:23:28 [69509] (541.0) gm state change: GM_INIT -> GM_START
28250:09/12/17 20:23:28 [69509] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28251:09/12/17 20:23:28 [69509] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28252:09/12/17 20:23:28 [69509] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28253:09/12/17 20:23:28 [69509] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28254:09/12/17 20:23:28 [69509] (540.0) gm state change: GM_INIT -> GM_START
28255:09/12/17 20:23:28 [69509] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28256:09/12/17 20:23:28 [69509] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28257:09/12/17 20:23:28 [69509] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28258:09/12/17 20:23:28 [69509] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28259:09/12/17 20:23:28 [69509] (539.0) gm state change: GM_INIT -> GM_START
28260:09/12/17 20:23:28 [69509] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28261:09/12/17 20:23:28 [69509] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28262:09/12/17 20:23:28 [69509] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28263:09/12/17 20:23:28 [69509] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28264:09/12/17 20:23:28 [69509] (538.0) gm state change: GM_INIT -> GM_START
28265:09/12/17 20:23:28 [69509] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28266:09/12/17 20:23:28 [69509] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28267:09/12/17 20:23:28 [69509] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28268:09/12/17 20:23:28 [69509] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28269:09/12/17 20:23:28 [69509] (537.0) gm state change: GM_INIT -> GM_START
28270:09/12/17 20:23:28 [69509] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28271:09/12/17 20:23:28 [69509] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28272:09/12/17 20:23:28 [69509] GAHP[69513] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
28273:09/12/17 20:23:28 [69509] GAHP[69513] -> 'S'
28274:09/12/17 20:23:28 [69509] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28275:09/12/17 20:23:28 [69509] (536.0) gm state change: GM_INIT -> GM_START
28276:09/12/17 20:23:28 [69509] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28277:09/12/17 20:23:28 [69509] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28278:09/12/17 20:23:28 [69509] GAHP[69513] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
28279:09/12/17 20:23:28 [69509] GAHP[69513] -> 'S'
28280:09/12/17 20:23:28 [69509] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28281:09/12/17 20:23:28 [69509] (535.0) gm state change: GM_INIT -> GM_START
28282:09/12/17 20:23:28 [69509] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28283:09/12/17 20:23:28 [69509] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28284:09/12/17 20:23:28 [69509] GAHP[69513] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
28285:09/12/17 20:23:28 [69509] GAHP[69513] -> 'S'
28286:09/12/17 20:23:28 [69509] This process has a valid certificate & key
28287:09/12/17 20:23:28 [69509] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28288:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28289:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28290:09/12/17 20:23:28 [69509] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28291:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28292:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28293:09/12/17 20:23:28 [69509] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28294:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28295:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28296:09/12/17 20:23:28 [69509] IPVERIFY: checking mc0151-ib against 128.55.162.46
28297:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28298:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28299:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28300:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28301:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28302:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28303:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28304:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28305:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
28306:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
28307:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
28308:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
28309:09/12/17 20:23:28 [69509] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
28310:09/12/17 20:23:28 [69509] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
28311:09/12/17 20:23:28 [69509] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28312:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28313:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28314:09/12/17 20:23:28 [69509] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28315:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28316:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28317:09/12/17 20:23:28 [69509] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28318:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28319:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28320:09/12/17 20:23:28 [69509] IPVERIFY: checking mc0151-ib against 128.55.162.46
28321:09/12/17 20:23:28 [69509] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28322:09/12/17 20:23:28 [69509] IPVERIFY: ip found is 1
28323:09/12/17 20:23:28 [69509] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28324:09/12/17 20:23:28 [69509] (534.0) gm state change: GM_INIT -> GM_START
28325:09/12/17 20:23:28 [69509] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28326:09/12/17 20:23:28 [69509] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28327:09/12/17 20:23:28 [69509] GAHP[69513] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
28328:09/12/17 20:23:28 [69509] GAHP[69513] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
28329:09/12/17 20:23:28 [69509] GAHP[69513] -> EOF
28330:09/12/17 20:23:28 [69509] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
28331:09/12/17 20:28:26 Result of reading /etc/issue:  \S
28333:09/12/17 20:28:26 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
28335:09/12/17 20:28:26 Using IDs: 32 processors, 16 CPUs, 16 HTs
28336:09/12/17 20:28:26 Enumerating interfaces: lo 127.0.0.1 up
28337:09/12/17 20:28:26 Enumerating interfaces: eth0 10.36.162.46 up
28338:09/12/17 20:28:26 Enumerating interfaces: ib0 128.55.162.46 up
28339:09/12/17 20:28:26 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
28340:09/12/17 20:28:26 Initializing Directory: curr_dir = /etc/condor-ce/config.d
28341:09/12/17 20:28:26 ******************************************************
28342:09/12/17 20:28:26 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
28343:09/12/17 20:28:26 ** /usr/sbin/condor_gridmanager
28344:09/12/17 20:28:26 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
28345:09/12/17 20:28:26 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
28346:09/12/17 20:28:26 ** $CondorVersion: 8.4.12 Aug 07 2017 $
28347:09/12/17 20:28:26 ** $CondorPlatform: X86_64-CentOS_7.3 $
28348:09/12/17 20:28:26 ** PID = 69552
28349:09/12/17 20:28:26 ** Log last touched 9/12 20:23:28
28350:09/12/17 20:28:26 ******************************************************
28351:09/12/17 20:28:26 Using config source: /etc/condor-ce/condor_config
28352:09/12/17 20:28:26 Using local config sources: 
28353:09/12/17 20:28:26    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
28354:09/12/17 20:28:26    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
28355:09/12/17 20:28:26    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
28356:09/12/17 20:28:26    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
28357:09/12/17 20:28:26    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
28358:09/12/17 20:28:26    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
28359:09/12/17 20:28:26    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
28360:09/12/17 20:28:26    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
28361:09/12/17 20:28:26    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
28362:09/12/17 20:28:26    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
28363:09/12/17 20:28:26    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
28364:09/12/17 20:28:26    /etc/condor-ce/config.d/01-ce-auth.conf
28365:09/12/17 20:28:26    /etc/condor-ce/config.d/01-ce-router.conf
28366:09/12/17 20:28:26    /etc/condor-ce/config.d/01-common-auth.conf
28367:09/12/17 20:28:26    /etc/condor-ce/config.d/02-ce-slurm.conf
28368:09/12/17 20:28:26    /etc/condor-ce/config.d/03-ce-shared-port.conf
28369:09/12/17 20:28:26    /etc/condor-ce/config.d/03-managed-fork.conf
28370:09/12/17 20:28:26    /etc/condor-ce/config.d/05-ce-health.conf
28371:09/12/17 20:28:26    /etc/condor-ce/config.d/05-ce-view.conf
28372:09/12/17 20:28:26    /etc/condor-ce/config.d/10-ce-collector-generated.conf
28373:09/12/17 20:28:26    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
28374:09/12/17 20:28:26    /etc/condor-ce/config.d/50-osg-configure-present.conf
28375:09/12/17 20:28:26    /etc/condor-ce/config.d/50-osg-configure.conf
28376:09/12/17 20:28:26    /etc/condor-ce/config.d/99-local.conf
28377:09/12/17 20:28:26    /usr/share/condor-ce/condor_ce_router_defaults|
28378:09/12/17 20:28:26 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
28379:09/12/17 20:28:26 CLASSAD_CACHING is ENABLED
28380:09/12/17 20:28:26 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
28381:09/12/17 20:28:26 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_136
28382:09/12/17 20:28:26 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_136>
28383:09/12/17 20:28:26 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_136>
28384:09/12/17 20:28:26 Setting maximum accepts per cycle 8.
28385:09/12/17 20:28:26 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28386:09/12/17 20:28:26 [69552] Welcome to the all-singing, all dancing, "amazing" GridManager!
28387:09/12/17 20:28:26 [69552] DaemonCore: No more children processes to reap.
28388:09/12/17 20:28:26 [69552] DaemonCore: in SendAliveToParent()
28389:09/12/17 20:28:26 [69552] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28390:09/12/17 20:28:26 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28391:09/12/17 20:28:26 [69552] IPVERIFY: ip found is 1
28392:09/12/17 20:28:26 [69552] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28393:09/12/17 20:28:26 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28394:09/12/17 20:28:26 [69552] IPVERIFY: ip found is 1
28395:09/12/17 20:28:26 [69552] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28396:09/12/17 20:28:26 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28397:09/12/17 20:28:26 [69552] IPVERIFY: ip found is 1
28398:09/12/17 20:28:26 [69552] IPVERIFY: checking mc0151-ib against 128.55.162.46
28399:09/12/17 20:28:26 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28400:09/12/17 20:28:26 [69552] IPVERIFY: ip found is 1
28401:09/12/17 20:28:26 [69552] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
28402:09/12/17 20:28:26 [69552] DaemonCore: Leaving SendAliveToParent() - success
28403:09/12/17 20:28:26 [69552] Checking proxies
28404:09/12/17 20:28:29 [69552] Received ADD_JOBS signal
28405:09/12/17 20:28:29 [69552] in doContactSchedd()
28406:09/12/17 20:28:29 [69552] querying for new jobs
28407:09/12/17 20:28:29 [69552] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
28408:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 542.0
28409:09/12/17 20:28:29 [69552] (542.0) SetJobLeaseTimers()
28410:09/12/17 20:28:29 [69552] Found job 542.0 --- inserting
28411:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 541.0
28412:09/12/17 20:28:29 [69552] (541.0) SetJobLeaseTimers()
28413:09/12/17 20:28:29 [69552] Found job 541.0 --- inserting
28414:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 540.0
28415:09/12/17 20:28:29 [69552] (540.0) SetJobLeaseTimers()
28416:09/12/17 20:28:29 [69552] Found job 540.0 --- inserting
28417:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 539.0
28418:09/12/17 20:28:29 [69552] (539.0) SetJobLeaseTimers()
28419:09/12/17 20:28:29 [69552] Found job 539.0 --- inserting
28420:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 538.0
28421:09/12/17 20:28:29 [69552] (538.0) SetJobLeaseTimers()
28422:09/12/17 20:28:29 [69552] Found job 538.0 --- inserting
28423:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 537.0
28424:09/12/17 20:28:29 [69552] (537.0) SetJobLeaseTimers()
28425:09/12/17 20:28:29 [69552] Found job 537.0 --- inserting
28426:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 536.0
28427:09/12/17 20:28:29 [69552] (536.0) SetJobLeaseTimers()
28428:09/12/17 20:28:29 [69552] Found job 536.0 --- inserting
28429:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 535.0
28430:09/12/17 20:28:29 [69552] (535.0) SetJobLeaseTimers()
28431:09/12/17 20:28:29 [69552] Found job 535.0 --- inserting
28432:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 534.0
28433:09/12/17 20:28:29 [69552] (534.0) SetJobLeaseTimers()
28434:09/12/17 20:28:29 [69552] Found job 534.0 --- inserting
28435:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 533.0
28436:09/12/17 20:28:29 [69552] (533.0) SetJobLeaseTimers()
28437:09/12/17 20:28:29 [69552] Found job 533.0 --- inserting
28438:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 532.0
28439:09/12/17 20:28:29 [69552] (532.0) SetJobLeaseTimers()
28440:09/12/17 20:28:29 [69552] Found job 532.0 --- inserting
28441:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 531.0
28442:09/12/17 20:28:29 [69552] (531.0) SetJobLeaseTimers()
28443:09/12/17 20:28:29 [69552] Found job 531.0 --- inserting
28444:09/12/17 20:28:29 [69552] Using job type INFNBatch for job 530.0
28445:09/12/17 20:28:29 [69552] (530.0) SetJobLeaseTimers()
28446:09/12/17 20:28:29 [69552] Found job 530.0 --- inserting
28447:09/12/17 20:28:29 [69552] Fetched 13 new job ads from schedd
28448:09/12/17 20:28:29 [69552] querying for removed/held jobs
28449:09/12/17 20:28:29 [69552] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
28450:09/12/17 20:28:29 [69552] Fetched 0 job ads from schedd
28451:09/12/17 20:28:29 [69552] leaving doContactSchedd()
28452:09/12/17 20:28:29 [69552] gahp server not up yet, delaying ping
28453:09/12/17 20:28:29 [69552] *** UpdateLeases called
28454:09/12/17 20:28:29 [69552]     Leases not supported, cancelling timer
28455:09/12/17 20:28:29 [69552] BaseResource::UpdateResource: 
28475:09/12/17 20:28:29 [69552] Trying to update collector <128.55.162.46:9619>
28476:09/12/17 20:28:29 [69552] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28477:09/12/17 20:28:29 [69552] File descriptor limits: max 4096, safe 3277
28478:09/12/17 20:28:29 [69552] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28479:09/12/17 20:28:29 [69552] GAHP server pid = 69556
28480:09/12/17 20:28:29 [69552] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
28481:09/12/17 20:28:29 [69552] GAHP[69556] <- 'COMMANDS'
28482:09/12/17 20:28:29 [69552] GAHP[69556] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
28483:09/12/17 20:28:29 [69552] GAHP[69556] <- 'ASYNC_MODE_ON'
28484:09/12/17 20:28:29 [69552] GAHP[69556] -> 'S' 'Async mode on'
28485:09/12/17 20:28:29 [69552] (542.0) gm state change: GM_INIT -> GM_START
28486:09/12/17 20:28:29 [69552] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28487:09/12/17 20:28:29 [69552] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28488:09/12/17 20:28:29 [69552] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28489:09/12/17 20:28:29 [69552] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28490:09/12/17 20:28:29 [69552] (541.0) gm state change: GM_INIT -> GM_START
28491:09/12/17 20:28:29 [69552] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28492:09/12/17 20:28:29 [69552] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28493:09/12/17 20:28:29 [69552] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28494:09/12/17 20:28:29 [69552] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28495:09/12/17 20:28:29 [69552] (540.0) gm state change: GM_INIT -> GM_START
28496:09/12/17 20:28:29 [69552] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28497:09/12/17 20:28:29 [69552] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28498:09/12/17 20:28:29 [69552] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28499:09/12/17 20:28:29 [69552] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28500:09/12/17 20:28:29 [69552] (539.0) gm state change: GM_INIT -> GM_START
28501:09/12/17 20:28:29 [69552] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28502:09/12/17 20:28:29 [69552] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28503:09/12/17 20:28:29 [69552] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28504:09/12/17 20:28:29 [69552] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28505:09/12/17 20:28:29 [69552] (538.0) gm state change: GM_INIT -> GM_START
28506:09/12/17 20:28:29 [69552] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28507:09/12/17 20:28:29 [69552] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28508:09/12/17 20:28:29 [69552] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28509:09/12/17 20:28:29 [69552] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28510:09/12/17 20:28:29 [69552] (537.0) gm state change: GM_INIT -> GM_START
28511:09/12/17 20:28:29 [69552] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28512:09/12/17 20:28:29 [69552] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28513:09/12/17 20:28:29 [69552] GAHP[69556] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
28514:09/12/17 20:28:29 [69552] GAHP[69556] -> 'S'
28515:09/12/17 20:28:29 [69552] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28516:09/12/17 20:28:29 [69552] (536.0) gm state change: GM_INIT -> GM_START
28517:09/12/17 20:28:29 [69552] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28518:09/12/17 20:28:29 [69552] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28519:09/12/17 20:28:29 [69552] GAHP[69556] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
28520:09/12/17 20:28:29 [69552] GAHP[69556] -> 'S'
28521:09/12/17 20:28:29 [69552] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28522:09/12/17 20:28:29 [69552] (535.0) gm state change: GM_INIT -> GM_START
28523:09/12/17 20:28:29 [69552] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28524:09/12/17 20:28:29 [69552] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28525:09/12/17 20:28:29 [69552] GAHP[69556] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
28526:09/12/17 20:28:29 [69552] GAHP[69556] -> 'S'
28527:09/12/17 20:28:29 [69552] This process has a valid certificate & key
28528:09/12/17 20:28:30 [69552] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28529:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28530:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28531:09/12/17 20:28:30 [69552] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28532:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28533:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28534:09/12/17 20:28:30 [69552] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28535:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28536:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28537:09/12/17 20:28:30 [69552] IPVERIFY: checking mc0151-ib against 128.55.162.46
28538:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28539:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28540:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28541:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28542:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28543:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28544:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28545:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28546:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
28547:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
28548:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
28549:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
28550:09/12/17 20:28:30 [69552] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
28551:09/12/17 20:28:30 [69552] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
28552:09/12/17 20:28:30 [69552] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28553:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28554:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28555:09/12/17 20:28:30 [69552] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28556:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28557:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28558:09/12/17 20:28:30 [69552] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28559:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28560:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28561:09/12/17 20:28:30 [69552] IPVERIFY: checking mc0151-ib against 128.55.162.46
28562:09/12/17 20:28:30 [69552] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28563:09/12/17 20:28:30 [69552] IPVERIFY: ip found is 1
28564:09/12/17 20:28:30 [69552] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28565:09/12/17 20:28:30 [69552] (534.0) gm state change: GM_INIT -> GM_START
28566:09/12/17 20:28:30 [69552] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28567:09/12/17 20:28:30 [69552] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28568:09/12/17 20:28:30 [69552] GAHP[69556] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
28569:09/12/17 20:28:30 [69552] GAHP[69556] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
28570:09/12/17 20:28:30 [69552] GAHP[69556] -> EOF
28571:09/12/17 20:28:30 [69552] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
28572:09/12/17 20:33:27 Result of reading /etc/issue:  \S
28574:09/12/17 20:33:27 Result of reading /etc/redhat-release:  Scientific Linux release 7.3 (Nitrogen)
28576:09/12/17 20:33:27 Using IDs: 32 processors, 16 CPUs, 16 HTs
28577:09/12/17 20:33:27 Enumerating interfaces: lo 127.0.0.1 up
28578:09/12/17 20:33:27 Enumerating interfaces: eth0 10.36.162.46 up
28579:09/12/17 20:33:27 Enumerating interfaces: ib0 128.55.162.46 up
28580:09/12/17 20:33:27 Initializing Directory: curr_dir = /usr/share/condor-ce/config.d
28581:09/12/17 20:33:27 Initializing Directory: curr_dir = /etc/condor-ce/config.d
28582:09/12/17 20:33:27 ******************************************************
28583:09/12/17 20:33:27 ** condor_gridmanager (CONDOR_GRIDMANAGER) STARTING UP
28584:09/12/17 20:33:27 ** /usr/sbin/condor_gridmanager
28585:09/12/17 20:33:27 ** SubsystemInfo: name=GRIDMANAGER type=DAEMON(12) class=DAEMON(1)
28586:09/12/17 20:33:27 ** Configuration: subsystem:GRIDMANAGER local:<NONE> class:DAEMON
28587:09/12/17 20:33:27 ** $CondorVersion: 8.4.12 Aug 07 2017 $
28588:09/12/17 20:33:27 ** $CondorPlatform: X86_64-CentOS_7.3 $
28589:09/12/17 20:33:27 ** PID = 69602
28590:09/12/17 20:33:27 ** Log last touched 9/12 20:28:30
28591:09/12/17 20:33:27 ******************************************************
28592:09/12/17 20:33:27 Using config source: /etc/condor-ce/condor_config
28593:09/12/17 20:33:27 Using local config sources: 
28594:09/12/17 20:33:27    /usr/share/condor-ce/config.d/01-ce-auth-defaults.conf
28595:09/12/17 20:33:27    /usr/share/condor-ce/config.d/01-ce-info-services-defaults.conf
28596:09/12/17 20:33:27    /usr/share/condor-ce/config.d/01-ce-router-defaults.conf
28597:09/12/17 20:33:27    /usr/share/condor-ce/config.d/01-common-auth-defaults.conf
28598:09/12/17 20:33:27    /usr/share/condor-ce/config.d/01-common-collector-defaults.conf
28599:09/12/17 20:33:27    /usr/share/condor-ce/config.d/02-ce-slurm-defaults.conf
28600:09/12/17 20:33:27    /usr/share/condor-ce/config.d/03-ce-shared-port-defaults.conf
28601:09/12/17 20:33:27    /usr/share/condor-ce/config.d/03-gratia-cleanup.conf
28602:09/12/17 20:33:27    /usr/share/condor-ce/config.d/03-managed-fork-defaults.conf
28603:09/12/17 20:33:27    /usr/share/condor-ce/config.d/05-ce-health-defaults.conf
28604:09/12/17 20:33:27    /usr/share/condor-ce/config.d/05-ce-view-defaults.conf
28605:09/12/17 20:33:27    /etc/condor-ce/config.d/01-ce-auth.conf
28606:09/12/17 20:33:27    /etc/condor-ce/config.d/01-ce-router.conf
28607:09/12/17 20:33:27    /etc/condor-ce/config.d/01-common-auth.conf
28608:09/12/17 20:33:27    /etc/condor-ce/config.d/02-ce-slurm.conf
28609:09/12/17 20:33:27    /etc/condor-ce/config.d/03-ce-shared-port.conf
28610:09/12/17 20:33:27    /etc/condor-ce/config.d/03-managed-fork.conf
28611:09/12/17 20:33:27    /etc/condor-ce/config.d/05-ce-health.conf
28612:09/12/17 20:33:27    /etc/condor-ce/config.d/05-ce-view.conf
28613:09/12/17 20:33:27    /etc/condor-ce/config.d/10-ce-collector-generated.conf
28614:09/12/17 20:33:27    /etc/condor-ce/config.d/10-osg-attributes-generated.conf
28615:09/12/17 20:33:27    /etc/condor-ce/config.d/50-osg-configure-present.conf
28616:09/12/17 20:33:27    /etc/condor-ce/config.d/50-osg-configure.conf
28617:09/12/17 20:33:27    /etc/condor-ce/config.d/99-local.conf
28618:09/12/17 20:33:27    /usr/share/condor-ce/condor_ce_router_defaults|
28619:09/12/17 20:33:27 config Macros = 178, Sorted = 178, StringBytes = 15029, TablesBytes = 6648
28620:09/12/17 20:33:27 CLASSAD_CACHING is ENABLED
28621:09/12/17 20:33:27 Daemon Log is logging: D_FULLDEBUG D_ALWAYS D_ERROR
28622:09/12/17 20:33:27 SharedPortEndpoint: waiting for connections to named socket 62974_a13a_139
28623:09/12/17 20:33:27 DaemonCore: command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_139>
28624:09/12/17 20:33:27 DaemonCore: private command socket at <128.55.162.46:9619?addrs=128.55.162.46-9619&noUDP&sock=62974_a13a_139>
28625:09/12/17 20:33:27 Setting maximum accepts per cycle 8.
28626:09/12/17 20:33:27 Will use TCP to update collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28627:09/12/17 20:33:27 [69602] Welcome to the all-singing, all dancing, "amazing" GridManager!
28628:09/12/17 20:33:27 [69602] DaemonCore: No more children processes to reap.
28629:09/12/17 20:33:27 [69602] DaemonCore: in SendAliveToParent()
28630:09/12/17 20:33:27 [69602] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28631:09/12/17 20:33:27 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28632:09/12/17 20:33:27 [69602] IPVERIFY: ip found is 1
28633:09/12/17 20:33:27 [69602] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28634:09/12/17 20:33:27 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28635:09/12/17 20:33:27 [69602] IPVERIFY: ip found is 1
28636:09/12/17 20:33:27 [69602] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28637:09/12/17 20:33:27 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28638:09/12/17 20:33:27 [69602] IPVERIFY: ip found is 1
28639:09/12/17 20:33:27 [69602] IPVERIFY: checking mc0151-ib against 128.55.162.46
28640:09/12/17 20:33:27 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28641:09/12/17 20:33:27 [69602] IPVERIFY: ip found is 1
28642:09/12/17 20:33:27 [69602] Completed DC_CHILDALIVE to daemon at <128.55.162.46:2408>
28643:09/12/17 20:33:27 [69602] DaemonCore: Leaving SendAliveToParent() - success
28644:09/12/17 20:33:27 [69602] Checking proxies
28645:09/12/17 20:33:30 [69602] Received ADD_JOBS signal
28646:09/12/17 20:33:30 [69602] in doContactSchedd()
28647:09/12/17 20:33:30 [69602] querying for new jobs
28648:09/12/17 20:33:30 [69602] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && (Managed =!= "ScheddDone") && (((Matched =!= FALSE) && (JobStatus != 5)) || (Managed =?= "External"))
28649:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 542.0
28650:09/12/17 20:33:30 [69602] (542.0) SetJobLeaseTimers()
28651:09/12/17 20:33:30 [69602] Found job 542.0 --- inserting
28652:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 541.0
28653:09/12/17 20:33:30 [69602] (541.0) SetJobLeaseTimers()
28654:09/12/17 20:33:30 [69602] Found job 541.0 --- inserting
28655:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 540.0
28656:09/12/17 20:33:30 [69602] (540.0) SetJobLeaseTimers()
28657:09/12/17 20:33:30 [69602] Found job 540.0 --- inserting
28658:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 539.0
28659:09/12/17 20:33:30 [69602] (539.0) SetJobLeaseTimers()
28660:09/12/17 20:33:30 [69602] Found job 539.0 --- inserting
28661:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 538.0
28662:09/12/17 20:33:30 [69602] (538.0) SetJobLeaseTimers()
28663:09/12/17 20:33:30 [69602] Found job 538.0 --- inserting
28664:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 537.0
28665:09/12/17 20:33:30 [69602] (537.0) SetJobLeaseTimers()
28666:09/12/17 20:33:30 [69602] Found job 537.0 --- inserting
28667:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 536.0
28668:09/12/17 20:33:30 [69602] (536.0) SetJobLeaseTimers()
28669:09/12/17 20:33:30 [69602] Found job 536.0 --- inserting
28670:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 535.0
28671:09/12/17 20:33:30 [69602] (535.0) SetJobLeaseTimers()
28672:09/12/17 20:33:30 [69602] Found job 535.0 --- inserting
28673:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 534.0
28674:09/12/17 20:33:30 [69602] (534.0) SetJobLeaseTimers()
28675:09/12/17 20:33:30 [69602] Found job 534.0 --- inserting
28676:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 533.0
28677:09/12/17 20:33:30 [69602] (533.0) SetJobLeaseTimers()
28678:09/12/17 20:33:30 [69602] Found job 533.0 --- inserting
28679:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 532.0
28680:09/12/17 20:33:30 [69602] (532.0) SetJobLeaseTimers()
28681:09/12/17 20:33:30 [69602] Found job 532.0 --- inserting
28682:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 531.0
28683:09/12/17 20:33:30 [69602] (531.0) SetJobLeaseTimers()
28684:09/12/17 20:33:30 [69602] Found job 531.0 --- inserting
28685:09/12/17 20:33:30 [69602] Using job type INFNBatch for job 530.0
28686:09/12/17 20:33:30 [69602] (530.0) SetJobLeaseTimers()
28687:09/12/17 20:33:30 [69602] Found job 530.0 --- inserting
28688:09/12/17 20:33:30 [69602] Fetched 13 new job ads from schedd
28689:09/12/17 20:33:30 [69602] querying for removed/held jobs
28690:09/12/17 20:33:30 [69602] Using constraint ((Owner=?="alicesgm"&&JobUniverse==9)) && ((Managed =!= "ScheddDone")) && (JobStatus == 3 || JobStatus == 4 || (JobStatus == 5 && Managed =?= "External"))
28691:09/12/17 20:33:30 [69602] Fetched 0 job ads from schedd
28692:09/12/17 20:33:30 [69602] leaving doContactSchedd()
28693:09/12/17 20:33:30 [69602] gahp server not up yet, delaying ping
28694:09/12/17 20:33:30 [69602] *** UpdateLeases called
28695:09/12/17 20:33:30 [69602]     Leases not supported, cancelling timer
28696:09/12/17 20:33:30 [69602] BaseResource::UpdateResource: 
28716:09/12/17 20:33:30 [69602] Trying to update collector <128.55.162.46:9619>
28717:09/12/17 20:33:30 [69602] Attempting to send update via TCP to collector mpdsfgrid02.nersc.gov <128.55.162.46:9619>
28718:09/12/17 20:33:30 [69602] File descriptor limits: max 4096, safe 3277
28719:09/12/17 20:33:30 [69602] (542.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28720:09/12/17 20:33:30 [69602] GAHP server pid = 69606
28721:09/12/17 20:33:30 [69602] GAHP server version: $GahpVersion: 1.8.0 Mar 31 2008 INFN blahpd (poly,new_esc_format) $
28722:09/12/17 20:33:30 [69602] GAHP[69606] <- 'COMMANDS'
28723:09/12/17 20:33:30 [69602] GAHP[69606] -> 'S' 'ASYNC_MODE_OFF' 'ASYNC_MODE_ON' 'BLAH_GET_HOSTPORT' 'BLAH_JOB_CANCEL' 'BLAH_JOB_HOLD' 'BLAH_JOB_REFRESH_PROXY' 'BLAH_JOB_RESUME' 'BLAH_JOB_SEND_PROXY_TO_WORKER_NODE' 'BLAH_JOB_STATUS' 'BLAH_JOB_SUBMIT' 'BLAH_SET_GLEXEC_DN' 'BLAH_SET_GLEXEC_OFF' 'BLAH_SET_SUDO_ID' 'BLAH_SET_SUDO_OFF' 'COMMANDS' 'QUIT' 'RESULTS' 'VERSION'
28724:09/12/17 20:33:30 [69602] GAHP[69606] <- 'ASYNC_MODE_ON'
28725:09/12/17 20:33:30 [69602] GAHP[69606] -> 'S' 'Async mode on'
28726:09/12/17 20:33:30 [69602] (542.0) gm state change: GM_INIT -> GM_START
28727:09/12/17 20:33:30 [69602] (542.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28728:09/12/17 20:33:30 [69602] (542.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28729:09/12/17 20:33:30 [69602] (542.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28730:09/12/17 20:33:30 [69602] (541.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28731:09/12/17 20:33:30 [69602] (541.0) gm state change: GM_INIT -> GM_START
28732:09/12/17 20:33:30 [69602] (541.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28733:09/12/17 20:33:30 [69602] (541.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28734:09/12/17 20:33:30 [69602] (541.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28735:09/12/17 20:33:30 [69602] (540.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28736:09/12/17 20:33:30 [69602] (540.0) gm state change: GM_INIT -> GM_START
28737:09/12/17 20:33:30 [69602] (540.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28738:09/12/17 20:33:30 [69602] (540.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28739:09/12/17 20:33:30 [69602] (540.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28740:09/12/17 20:33:30 [69602] (539.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28741:09/12/17 20:33:30 [69602] (539.0) gm state change: GM_INIT -> GM_START
28742:09/12/17 20:33:30 [69602] (539.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28743:09/12/17 20:33:30 [69602] (539.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28744:09/12/17 20:33:30 [69602] (539.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28745:09/12/17 20:33:30 [69602] (538.0) doEvaluateState called: gmState GM_INIT, remoteState 0
28746:09/12/17 20:33:30 [69602] (538.0) gm state change: GM_INIT -> GM_START
28747:09/12/17 20:33:30 [69602] (538.0) gm state change: GM_START -> GM_CLEAR_REQUEST
28748:09/12/17 20:33:30 [69602] (538.0) gm state change: GM_CLEAR_REQUEST -> GM_UNSUBMITTED
28749:09/12/17 20:33:30 [69602] (538.0) gm state change: GM_UNSUBMITTED -> GM_SAVE_SANDBOX_ID
28750:09/12/17 20:33:30 [69602] (537.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28751:09/12/17 20:33:30 [69602] (537.0) gm state change: GM_INIT -> GM_START
28752:09/12/17 20:33:30 [69602] (537.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28753:09/12/17 20:33:30 [69602] (537.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28754:09/12/17 20:33:30 [69602] GAHP[69606] <- 'BLAH_JOB_SUBMIT 2 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#537.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/517/0/cluster517.proc0.subproc0/test.sh"\ ]'
28755:09/12/17 20:33:30 [69602] GAHP[69606] -> 'S'
28756:09/12/17 20:33:30 [69602] (536.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28757:09/12/17 20:33:30 [69602] (536.0) gm state change: GM_INIT -> GM_START
28758:09/12/17 20:33:30 [69602] (536.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28759:09/12/17 20:33:30 [69602] (536.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28760:09/12/17 20:33:30 [69602] GAHP[69606] <- 'BLAH_JOB_SUBMIT 3 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#536.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/525/0/cluster525.proc0.subproc0/test.sh"\ ]'
28761:09/12/17 20:33:30 [69602] GAHP[69606] -> 'S'
28762:09/12/17 20:33:30 [69602] (535.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28763:09/12/17 20:33:30 [69602] (535.0) gm state change: GM_INIT -> GM_START
28764:09/12/17 20:33:30 [69602] (535.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28765:09/12/17 20:33:30 [69602] (535.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28766:09/12/17 20:33:30 [69602] GAHP[69606] <- 'BLAH_JOB_SUBMIT 4 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#535.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/524/0/cluster524.proc0.subproc0/test.sh"\ ]'
28767:09/12/17 20:33:30 [69602] GAHP[69606] -> 'S'
28768:09/12/17 20:33:30 [69602] This process has a valid certificate & key
28769:09/12/17 20:33:30 [69602] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28770:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28771:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28772:09/12/17 20:33:30 [69602] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28773:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28774:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28775:09/12/17 20:33:30 [69602] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28776:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28777:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28778:09/12/17 20:33:30 [69602] IPVERIFY: checking mc0151-ib against 128.55.162.46
28779:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28780:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28781:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=com\/DC\=DigiCert-Grid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28782:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=DigiCert-Grid\/DC\=com\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28783:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=opensciencegrid\/O=Open Science Grid\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28784:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/C\=RU\/O\=RDIG\/OU\=hosts\/OU=*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28785:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/C\=BR\/O\=ANSP\/OU\=ANSPGrid\ CA\/OU\=Services\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28786:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=org\/DC\=terena\/DC\=tcs.*\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@daemon.opensciencegrid.org'
28787:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='^\/DC\=ch\/DC\=cern\/OU\=computers\/CN\=(host\/)?([A-Za-z0-9.\-]*)$' canonicalization='\2@cern.ch'
28788:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='(.*)' canonicalization='GSS_ASSIST_GRIDMAP'
28789:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='gsi' principal='(/CN=[-.A-Za-z0-9/= ]+)' canonicalization='\1@unmapped.opensciencegrid.org'
28790:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='claimtobe' principal='.*' canonicalization='anonymous@claimtobe'
28791:09/12/17 20:33:30 [69602] MapFile: Canonicalization File: method='fs' principal='(.*)' canonicalization='\1'
28792:09/12/17 20:33:30 [69602] ZKM: successful mapping to mpdsfgrid02.nersc.gov@daemon.opensciencegrid.org
28793:09/12/17 20:33:30 [69602] IPVERIFY: checking mpdsfgrid02.nersc.gov against 128.55.162.46
28794:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28795:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28796:09/12/17 20:33:30 [69602] IPVERIFY: checking mpdsfgrid02 against 128.55.162.46
28797:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28798:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28799:09/12/17 20:33:30 [69602] IPVERIFY: checking mc0151-ib.nersc.gov against 128.55.162.46
28800:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28801:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28802:09/12/17 20:33:30 [69602] IPVERIFY: checking mc0151-ib against 128.55.162.46
28803:09/12/17 20:33:30 [69602] IPVERIFY: matched 128.55.162.46 to 128.55.162.46
28804:09/12/17 20:33:30 [69602] IPVERIFY: ip found is 1
28805:09/12/17 20:33:30 [69602] (534.0) doEvaluateState called: gmState GM_INIT, remoteState -1
28806:09/12/17 20:33:30 [69602] (534.0) gm state change: GM_INIT -> GM_START
28807:09/12/17 20:33:30 [69602] (534.0) gm state change: GM_START -> GM_TRANSFER_INPUT
28808:09/12/17 20:33:30 [69602] (534.0) gm state change: GM_TRANSFER_INPUT -> GM_SUBMIT
28809:09/12/17 20:33:30 [69602] GAHP[69606] <- 'BLAH_JOB_SUBMIT 5 [\ OriginalMemory\ =\ 8000;\ cerequirements\ =\ "CondorCE\ ==\ 1";\ gridtype\ =\ "slurm";\ SMPGranularity\ =\ 1;\ NodeNumber\ =\ 1;\ JobDirectory\ =\ "home_bl_mpdsfgrid02.nersc.gov_9619_mpdsfgrid02.nersc.gov#534.0#1505266383";\ Arguments\ =\ "";\ Environment\ =\ "HOME=/global/homes/a/alicesgm\ CONDORCE_COLLECTOR_HOST=mpdsfgrid02.nersc.gov:9619\ OSG_GRID='/usr/common/usg/software/osg/3.1.35-tarball-1/osg-client/'\ OSG_SQUID_LOCATION='msquid01-ib.nersc.gov:3128'\ OSG_SITE_READ='/project/projectdirs/pdsf/osg_temp/pdsf/stage'\ OSG_APP='/project/projectdirs/pdsf/osg_temp/pdsf/app'\ OSG_HOSTNAME='mpdsfgrid02.nersc.gov'\ OSG_DATA='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_WN_TMP='/project/projectdirs/pdsf/osg_temp/pdsf/data'\ OSG_STORAGE_ELEMENT='False'\ OSG_SITE_NAME='NERSC-PDSF'\ GLOBUS_LOCATION='/usr'\ OSG_SITE_WRITE='/project/projectdirs/pdsf/osg_temp/pdsf/write'\ ";\ TransferOutputRemaps\ =\ undefined;\ In\ =\ "/dev/null";\ JobUniverse\ =\ 5;\ Err\ =\ "_condor_stderr";\ queue\ =\ "";\ Out\ =\ "_condor_stdout";\ x509userproxy\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/x509up_u49514";\ Iwd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0";\ GridResource\ =\ "batch\ slurm";\ RequestMemory\ =\ ifThenElse(WantWholeNode\ is\ true,\ !isUndefined(TotalMemory)\ ?\ TotalMemory\ *\ 95\ /\ 100\ :\ JobMemory,OriginalMemory);\ Cmd\ =\ "/common/osg/condor2/523/0/cluster523.proc0.subproc0/test.sh"\ ]'
28810:09/12/17 20:33:30 [69602] GAHP[69606] (stderr) -> Assertion 0 && "globus_hashtable_lookup bad parms" failed in file globus_hashtable.c at line 433
28811:09/12/17 20:33:30 [69602] GAHP[69606] -> EOF
28812:09/12/17 20:33:30 [69602] ERROR "Bad BLAH_JOB_SUBMIT Request: Empty response" at line 2620 in file /builddir/build/BUILD/condor-8.4.12/src/condor_gridmanager/gahp-client.cpp
